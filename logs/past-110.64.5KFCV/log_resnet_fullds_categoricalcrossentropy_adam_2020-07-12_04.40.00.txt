Dataset used: ../../datasets/full_dataset.csv 

   Temperature  Humidity  Sound  ...     Z2  Classification  Feedback
0           32        95      1  ... -15596             100     Happy
1           32        86      1  ... -15628             100     Happy
2           -1        -1      1  ... -15612             100     Happy
3           -1        -1     -1  ...     -1             100     Happy
4           32        75      1  ... -15720             100     Happy

[5 rows x 12 columns]

Objservations: 8560
Reshaping:  ((6848, 11), (6848, 4), (1712, 11), (1712, 4))  -> ((6848, 11, 1), (6848, 4), (1712, 11, 1), (1712, 4))

Layers:

{'batch_input_shape': (None, 11, 1), 'dtype': 'float32', 'sparse': False, 'name': 'input_1'} 

{'name': 'conv1d_43', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_85', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_44', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_86', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_45', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_1', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_87', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_46', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_88', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_47', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_2', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_89', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_48', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_90', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_49', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_3', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_91', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_50', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_92', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_51', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_52', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_4', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_93', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_53', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_10', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_94', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_54', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_11', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_5', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_95', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_55', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_12', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_96', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_56', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_13', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_6', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_97', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_57', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_14', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_98', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_58', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_59', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_15', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_7', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_99', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_60', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_16', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_100', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_61', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_17', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_8', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_101', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_62', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_18', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_102', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_63', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_19', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_9', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_103', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'average_pooling1d_1', 'trainable': True, 'dtype': 'float32', 'strides': (1,), 'pool_size': (1,), 'padding': 'valid', 'data_format': 'channels_last'} 

{'name': 'flatten_43', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'} 

{'name': 'dense_1171', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 7s - loss: 1.2007 - accuracy: 0.6564 - val_loss: 1.3900 - val_accuracy: 0.4745
Epoch 2/110
 - 3s - loss: 0.7599 - accuracy: 0.7744 - val_loss: 0.9216 - val_accuracy: 0.6978
Epoch 3/110
 - 3s - loss: 0.6980 - accuracy: 0.7996 - val_loss: 0.7951 - val_accuracy: 0.7533
Epoch 4/110
 - 3s - loss: 0.6611 - accuracy: 0.8081 - val_loss: 0.7727 - val_accuracy: 0.7701
Epoch 5/110
 - 3s - loss: 0.6363 - accuracy: 0.8165 - val_loss: 0.7381 - val_accuracy: 0.8109
Epoch 6/110
 - 3s - loss: 0.6128 - accuracy: 0.8257 - val_loss: 0.7360 - val_accuracy: 0.7942
Epoch 7/110
 - 3s - loss: 0.6040 - accuracy: 0.8246 - val_loss: 0.7352 - val_accuracy: 0.8080
Epoch 8/110
 - 3s - loss: 0.5930 - accuracy: 0.8286 - val_loss: 0.7299 - val_accuracy: 0.8007
Epoch 9/110
 - 3s - loss: 0.5715 - accuracy: 0.8377 - val_loss: 0.7196 - val_accuracy: 0.8197
Epoch 10/110
 - 3s - loss: 0.5665 - accuracy: 0.8335 - val_loss: 0.7138 - val_accuracy: 0.8095
Epoch 11/110
 - 3s - loss: 0.5498 - accuracy: 0.8456 - val_loss: 0.6776 - val_accuracy: 0.8212
Epoch 12/110
 - 3s - loss: 0.5434 - accuracy: 0.8465 - val_loss: 0.6865 - val_accuracy: 0.8190
Epoch 13/110
 - 3s - loss: 0.5310 - accuracy: 0.8488 - val_loss: 0.6796 - val_accuracy: 0.8241
Epoch 14/110
 - 3s - loss: 0.5358 - accuracy: 0.8479 - val_loss: 0.6944 - val_accuracy: 0.8241
Epoch 15/110
 - 3s - loss: 0.5311 - accuracy: 0.8518 - val_loss: 0.7119 - val_accuracy: 0.8131
Epoch 16/110
 - 3s - loss: 0.5241 - accuracy: 0.8545 - val_loss: 0.7075 - val_accuracy: 0.8175
Epoch 17/110
 - 3s - loss: 0.5057 - accuracy: 0.8585 - val_loss: 0.7657 - val_accuracy: 0.8029
Epoch 18/110
 - 3s - loss: 0.5062 - accuracy: 0.8609 - val_loss: 0.7011 - val_accuracy: 0.8175
Epoch 19/110
 - 3s - loss: 0.5046 - accuracy: 0.8593 - val_loss: 0.6673 - val_accuracy: 0.8248
Epoch 20/110
 - 3s - loss: 0.5161 - accuracy: 0.8532 - val_loss: 0.6636 - val_accuracy: 0.8219
Epoch 21/110
 - 3s - loss: 0.5028 - accuracy: 0.8616 - val_loss: 0.6407 - val_accuracy: 0.8307
Epoch 22/110
 - 3s - loss: 0.4892 - accuracy: 0.8614 - val_loss: 0.6932 - val_accuracy: 0.8102
Epoch 23/110
 - 3s - loss: 0.4860 - accuracy: 0.8687 - val_loss: 0.6372 - val_accuracy: 0.8350
Epoch 24/110
 - 3s - loss: 0.4847 - accuracy: 0.8651 - val_loss: 0.6481 - val_accuracy: 0.8153
Epoch 25/110
 - 3s - loss: 0.4866 - accuracy: 0.8649 - val_loss: 0.6442 - val_accuracy: 0.8380
Epoch 26/110
 - 3s - loss: 0.4954 - accuracy: 0.8633 - val_loss: 0.6715 - val_accuracy: 0.8226
Epoch 27/110
 - 2s - loss: 0.4912 - accuracy: 0.8644 - val_loss: 0.6711 - val_accuracy: 0.8292
Epoch 28/110
 - 3s - loss: 0.4705 - accuracy: 0.8740 - val_loss: 0.6923 - val_accuracy: 0.8146
Epoch 29/110
 - 3s - loss: 0.4654 - accuracy: 0.8711 - val_loss: 0.6833 - val_accuracy: 0.8350
Epoch 30/110
 - 3s - loss: 0.4564 - accuracy: 0.8797 - val_loss: 0.6777 - val_accuracy: 0.8277
Epoch 31/110
 - 3s - loss: 0.4618 - accuracy: 0.8768 - val_loss: 0.6854 - val_accuracy: 0.8255
Epoch 32/110
 - 3s - loss: 0.4572 - accuracy: 0.8750 - val_loss: 0.7343 - val_accuracy: 0.8131
Epoch 33/110
 - 3s - loss: 0.4474 - accuracy: 0.8806 - val_loss: 0.6929 - val_accuracy: 0.8102
Epoch 34/110
 - 3s - loss: 0.4569 - accuracy: 0.8764 - val_loss: 0.6860 - val_accuracy: 0.8197
Epoch 35/110
 - 3s - loss: 0.4464 - accuracy: 0.8799 - val_loss: 0.6513 - val_accuracy: 0.8226
Epoch 36/110
 - 3s - loss: 0.4565 - accuracy: 0.8744 - val_loss: 0.6728 - val_accuracy: 0.8175
Epoch 37/110
 - 3s - loss: 0.4542 - accuracy: 0.8751 - val_loss: 0.6641 - val_accuracy: 0.8212
Epoch 38/110
 - 3s - loss: 0.4292 - accuracy: 0.8890 - val_loss: 0.6691 - val_accuracy: 0.8204
Epoch 39/110
 - 3s - loss: 0.4079 - accuracy: 0.8921 - val_loss: 0.6802 - val_accuracy: 0.8226
Epoch 40/110
 - 3s - loss: 0.3989 - accuracy: 0.8959 - val_loss: 0.6434 - val_accuracy: 0.8328
Epoch 41/110
 - 3s - loss: 0.4034 - accuracy: 0.8939 - val_loss: 0.7113 - val_accuracy: 0.8109
Epoch 42/110
 - 3s - loss: 0.4083 - accuracy: 0.8983 - val_loss: 0.7202 - val_accuracy: 0.8263
Epoch 43/110
 - 3s - loss: 0.4038 - accuracy: 0.8970 - val_loss: 0.6827 - val_accuracy: 0.8124
Epoch 44/110
 - 3s - loss: 0.4033 - accuracy: 0.8958 - val_loss: 0.7141 - val_accuracy: 0.8212
Epoch 45/110
 - 3s - loss: 0.4231 - accuracy: 0.8907 - val_loss: 0.6554 - val_accuracy: 0.8226
Epoch 46/110
 - 3s - loss: 0.3870 - accuracy: 0.9096 - val_loss: 0.8045 - val_accuracy: 0.7949
Epoch 47/110
 - 3s - loss: 0.4003 - accuracy: 0.8965 - val_loss: 0.6981 - val_accuracy: 0.8241
Epoch 48/110
 - 3s - loss: 0.4083 - accuracy: 0.8985 - val_loss: 0.7049 - val_accuracy: 0.8182
Epoch 49/110
 - 3s - loss: 0.3912 - accuracy: 0.9020 - val_loss: 0.6900 - val_accuracy: 0.8248
Epoch 50/110
 - 3s - loss: 0.3949 - accuracy: 0.9005 - val_loss: 0.6373 - val_accuracy: 0.8394
Epoch 51/110
 - 3s - loss: 0.3824 - accuracy: 0.9043 - val_loss: 0.6520 - val_accuracy: 0.8350
Epoch 52/110
 - 3s - loss: 0.3819 - accuracy: 0.9023 - val_loss: 0.6703 - val_accuracy: 0.8270
Epoch 53/110
 - 3s - loss: 0.3970 - accuracy: 0.8987 - val_loss: 0.6458 - val_accuracy: 0.8394
Epoch 54/110
 - 3s - loss: 0.3876 - accuracy: 0.9022 - val_loss: 0.6477 - val_accuracy: 0.8314
Epoch 55/110
 - 3s - loss: 0.3917 - accuracy: 0.9047 - val_loss: 0.6676 - val_accuracy: 0.8321
Epoch 56/110
 - 3s - loss: 0.3781 - accuracy: 0.9043 - val_loss: 0.6327 - val_accuracy: 0.8482
Epoch 57/110
 - 3s - loss: 0.3742 - accuracy: 0.9084 - val_loss: 0.6850 - val_accuracy: 0.8234
Epoch 58/110
 - 3s - loss: 0.3704 - accuracy: 0.9127 - val_loss: 0.6940 - val_accuracy: 0.8299
Epoch 59/110
 - 3s - loss: 0.3879 - accuracy: 0.9016 - val_loss: 0.7083 - val_accuracy: 0.8343
Epoch 60/110
 - 3s - loss: 0.3729 - accuracy: 0.9084 - val_loss: 0.6679 - val_accuracy: 0.8328
Epoch 61/110
 - 3s - loss: 0.3763 - accuracy: 0.9098 - val_loss: 0.6250 - val_accuracy: 0.8460
Epoch 62/110
 - 3s - loss: 0.3627 - accuracy: 0.9089 - val_loss: 0.7211 - val_accuracy: 0.8146
Epoch 63/110
 - 3s - loss: 0.3773 - accuracy: 0.9093 - val_loss: 0.6548 - val_accuracy: 0.8307
Epoch 64/110
 - 3s - loss: 0.3664 - accuracy: 0.9144 - val_loss: 0.6744 - val_accuracy: 0.8336
Epoch 65/110
 - 3s - loss: 0.3324 - accuracy: 0.9226 - val_loss: 0.7399 - val_accuracy: 0.8182
Epoch 66/110
 - 3s - loss: 0.3297 - accuracy: 0.9272 - val_loss: 0.6655 - val_accuracy: 0.8314
Epoch 67/110
 - 3s - loss: 0.3335 - accuracy: 0.9263 - val_loss: 0.6941 - val_accuracy: 0.8226
Epoch 68/110
 - 3s - loss: 0.3367 - accuracy: 0.9195 - val_loss: 0.6951 - val_accuracy: 0.8365
Epoch 69/110
 - 3s - loss: 0.3592 - accuracy: 0.9144 - val_loss: 0.7199 - val_accuracy: 0.8270
Epoch 70/110
 - 3s - loss: 0.3492 - accuracy: 0.9179 - val_loss: 0.7331 - val_accuracy: 0.8299
Epoch 71/110
 - 3s - loss: 0.3433 - accuracy: 0.9255 - val_loss: 0.7856 - val_accuracy: 0.8117
Epoch 72/110
 - 3s - loss: 0.3221 - accuracy: 0.9317 - val_loss: 0.6779 - val_accuracy: 0.8416
Epoch 73/110
 - 3s - loss: 0.3348 - accuracy: 0.9281 - val_loss: 0.7633 - val_accuracy: 0.8299
Epoch 74/110
 - 3s - loss: 0.3275 - accuracy: 0.9275 - val_loss: 0.6700 - val_accuracy: 0.8380
Epoch 75/110
 - 3s - loss: 0.3278 - accuracy: 0.9310 - val_loss: 0.7314 - val_accuracy: 0.8117
Epoch 76/110
 - 3s - loss: 0.3176 - accuracy: 0.9310 - val_loss: 0.6850 - val_accuracy: 0.8314
Epoch 77/110
 - 3s - loss: 0.3211 - accuracy: 0.9321 - val_loss: 0.7539 - val_accuracy: 0.8015
Epoch 78/110
 - 3s - loss: 0.3133 - accuracy: 0.9299 - val_loss: 0.7756 - val_accuracy: 0.8175
Epoch 79/110
 - 3s - loss: 0.3190 - accuracy: 0.9328 - val_loss: 0.7274 - val_accuracy: 0.8139
Epoch 80/110
 - 3s - loss: 0.3158 - accuracy: 0.9357 - val_loss: 0.6859 - val_accuracy: 0.8197
Epoch 81/110
 - 3s - loss: 0.3032 - accuracy: 0.9407 - val_loss: 0.8324 - val_accuracy: 0.8080
Epoch 82/110
 - 3s - loss: 0.3054 - accuracy: 0.9387 - val_loss: 0.7777 - val_accuracy: 0.8088
Epoch 83/110
 - 3s - loss: 0.3113 - accuracy: 0.9361 - val_loss: 0.7378 - val_accuracy: 0.8307
Epoch 84/110
 - 3s - loss: 0.3419 - accuracy: 0.9246 - val_loss: 0.7357 - val_accuracy: 0.8117
Epoch 85/110
 - 3s - loss: 0.3620 - accuracy: 0.9213 - val_loss: 0.8846 - val_accuracy: 0.7993
Epoch 86/110
 - 3s - loss: 0.3407 - accuracy: 0.9241 - val_loss: 0.7792 - val_accuracy: 0.8190
Epoch 87/110
 - 3s - loss: 0.3004 - accuracy: 0.9398 - val_loss: 0.7426 - val_accuracy: 0.8292
Epoch 88/110
 - 3s - loss: 0.2945 - accuracy: 0.9403 - val_loss: 0.9132 - val_accuracy: 0.8051
Epoch 89/110
 - 3s - loss: 0.3038 - accuracy: 0.9385 - val_loss: 0.8265 - val_accuracy: 0.8146
Epoch 90/110
 - 3s - loss: 0.3140 - accuracy: 0.9330 - val_loss: 0.7364 - val_accuracy: 0.8365
Epoch 91/110
 - 3s - loss: 0.2977 - accuracy: 0.9430 - val_loss: 0.7192 - val_accuracy: 0.8365
Epoch 92/110
 - 3s - loss: 0.2975 - accuracy: 0.9438 - val_loss: 0.7357 - val_accuracy: 0.8292
Epoch 93/110
 - 3s - loss: 0.2915 - accuracy: 0.9443 - val_loss: 0.8053 - val_accuracy: 0.8248
Epoch 94/110
 - 3s - loss: 0.2863 - accuracy: 0.9409 - val_loss: 0.7712 - val_accuracy: 0.8314
Epoch 95/110
 - 3s - loss: 0.3019 - accuracy: 0.9385 - val_loss: 0.6919 - val_accuracy: 0.8358
Epoch 96/110
 - 3s - loss: 0.2910 - accuracy: 0.9425 - val_loss: 0.7981 - val_accuracy: 0.8146
Epoch 97/110
 - 3s - loss: 0.2978 - accuracy: 0.9407 - val_loss: 0.8192 - val_accuracy: 0.8109
Epoch 98/110
 - 3s - loss: 0.2913 - accuracy: 0.9414 - val_loss: 0.7081 - val_accuracy: 0.8328
Epoch 99/110
 - 3s - loss: 0.3213 - accuracy: 0.9297 - val_loss: 0.7318 - val_accuracy: 0.8423
Epoch 100/110
 - 3s - loss: 0.2964 - accuracy: 0.9412 - val_loss: 0.7270 - val_accuracy: 0.8401
Epoch 101/110
 - 2s - loss: 0.2928 - accuracy: 0.9440 - val_loss: 0.7899 - val_accuracy: 0.8445
Epoch 102/110
 - 3s - loss: 0.2759 - accuracy: 0.9494 - val_loss: 0.7242 - val_accuracy: 0.8328
Epoch 103/110
 - 3s - loss: 0.2635 - accuracy: 0.9529 - val_loss: 0.7761 - val_accuracy: 0.8445
Epoch 104/110
 - 3s - loss: 0.2771 - accuracy: 0.9494 - val_loss: 0.8686 - val_accuracy: 0.8124
Epoch 105/110
 - 3s - loss: 0.4246 - accuracy: 0.9098 - val_loss: 0.8165 - val_accuracy: 0.8168
Epoch 106/110
 - 3s - loss: 0.3664 - accuracy: 0.9188 - val_loss: 0.7204 - val_accuracy: 0.8285
Epoch 107/110
 - 3s - loss: 0.2769 - accuracy: 0.9482 - val_loss: 0.7061 - val_accuracy: 0.8518
Epoch 108/110
 - 2s - loss: 0.2658 - accuracy: 0.9560 - val_loss: 0.6770 - val_accuracy: 0.8431
Epoch 109/110
 - 3s - loss: 0.2709 - accuracy: 0.9520 - val_loss: 0.8245 - val_accuracy: 0.8175
Epoch 110/110
 - 3s - loss: 0.2858 - accuracy: 0.9425 - val_loss: 0.8141 - val_accuracy: 0.8182

Number of filters: 16 , Kernel Size: 3 , Strides: 1 Batch Normalization: True , Conv_First: True , Depth Value: 20

Fit: epochs= 110 , batch_size= 64 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 11, 1)        0                                            
__________________________________________________________________________________________________
conv1d_43 (Conv1D)              (None, 11, 16)       64          input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 11, 16)       64          conv1d_43[0][0]                  
__________________________________________________________________________________________________
activation_85 (Activation)      (None, 11, 16)       0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv1d_44 (Conv1D)              (None, 11, 16)       784         activation_85[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 11, 16)       64          conv1d_44[0][0]                  
__________________________________________________________________________________________________
activation_86 (Activation)      (None, 11, 16)       0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv1d_45 (Conv1D)              (None, 11, 16)       784         activation_86[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 11, 16)       64          conv1d_45[0][0]                  
__________________________________________________________________________________________________
add_1 (Add)                     (None, 11, 16)       0           activation_85[0][0]              
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_87 (Activation)      (None, 11, 16)       0           add_1[0][0]                      
__________________________________________________________________________________________________
conv1d_46 (Conv1D)              (None, 11, 16)       784         activation_87[0][0]              
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 11, 16)       64          conv1d_46[0][0]                  
__________________________________________________________________________________________________
activation_88 (Activation)      (None, 11, 16)       0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv1d_47 (Conv1D)              (None, 11, 16)       784         activation_88[0][0]              
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 11, 16)       64          conv1d_47[0][0]                  
__________________________________________________________________________________________________
add_2 (Add)                     (None, 11, 16)       0           activation_87[0][0]              
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_89 (Activation)      (None, 11, 16)       0           add_2[0][0]                      
__________________________________________________________________________________________________
conv1d_48 (Conv1D)              (None, 11, 16)       784         activation_89[0][0]              
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 11, 16)       64          conv1d_48[0][0]                  
__________________________________________________________________________________________________
activation_90 (Activation)      (None, 11, 16)       0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv1d_49 (Conv1D)              (None, 11, 16)       784         activation_90[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 11, 16)       64          conv1d_49[0][0]                  
__________________________________________________________________________________________________
add_3 (Add)                     (None, 11, 16)       0           activation_89[0][0]              
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_91 (Activation)      (None, 11, 16)       0           add_3[0][0]                      
__________________________________________________________________________________________________
conv1d_50 (Conv1D)              (None, 6, 32)        1568        activation_91[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 6, 32)        128         conv1d_50[0][0]                  
__________________________________________________________________________________________________
activation_92 (Activation)      (None, 6, 32)        0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv1d_51 (Conv1D)              (None, 6, 32)        3104        activation_92[0][0]              
__________________________________________________________________________________________________
conv1d_52 (Conv1D)              (None, 6, 32)        544         activation_91[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 6, 32)        128         conv1d_51[0][0]                  
__________________________________________________________________________________________________
add_4 (Add)                     (None, 6, 32)        0           conv1d_52[0][0]                  
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_93 (Activation)      (None, 6, 32)        0           add_4[0][0]                      
__________________________________________________________________________________________________
conv1d_53 (Conv1D)              (None, 6, 32)        3104        activation_93[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 6, 32)        128         conv1d_53[0][0]                  
__________________________________________________________________________________________________
activation_94 (Activation)      (None, 6, 32)        0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv1d_54 (Conv1D)              (None, 6, 32)        3104        activation_94[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 6, 32)        128         conv1d_54[0][0]                  
__________________________________________________________________________________________________
add_5 (Add)                     (None, 6, 32)        0           activation_93[0][0]              
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_95 (Activation)      (None, 6, 32)        0           add_5[0][0]                      
__________________________________________________________________________________________________
conv1d_55 (Conv1D)              (None, 6, 32)        3104        activation_95[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 6, 32)        128         conv1d_55[0][0]                  
__________________________________________________________________________________________________
activation_96 (Activation)      (None, 6, 32)        0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv1d_56 (Conv1D)              (None, 6, 32)        3104        activation_96[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 6, 32)        128         conv1d_56[0][0]                  
__________________________________________________________________________________________________
add_6 (Add)                     (None, 6, 32)        0           activation_95[0][0]              
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_97 (Activation)      (None, 6, 32)        0           add_6[0][0]                      
__________________________________________________________________________________________________
conv1d_57 (Conv1D)              (None, 3, 64)        6208        activation_97[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 3, 64)        256         conv1d_57[0][0]                  
__________________________________________________________________________________________________
activation_98 (Activation)      (None, 3, 64)        0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv1d_58 (Conv1D)              (None, 3, 64)        12352       activation_98[0][0]              
__________________________________________________________________________________________________
conv1d_59 (Conv1D)              (None, 3, 64)        2112        activation_97[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 3, 64)        256         conv1d_58[0][0]                  
__________________________________________________________________________________________________
add_7 (Add)                     (None, 3, 64)        0           conv1d_59[0][0]                  
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_99 (Activation)      (None, 3, 64)        0           add_7[0][0]                      
__________________________________________________________________________________________________
conv1d_60 (Conv1D)              (None, 3, 64)        12352       activation_99[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 3, 64)        256         conv1d_60[0][0]                  
__________________________________________________________________________________________________
activation_100 (Activation)     (None, 3, 64)        0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv1d_61 (Conv1D)              (None, 3, 64)        12352       activation_100[0][0]             
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 3, 64)        256         conv1d_61[0][0]                  
__________________________________________________________________________________________________
add_8 (Add)                     (None, 3, 64)        0           activation_99[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_101 (Activation)     (None, 3, 64)        0           add_8[0][0]                      
__________________________________________________________________________________________________
conv1d_62 (Conv1D)              (None, 3, 64)        12352       activation_101[0][0]             
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 3, 64)        256         conv1d_62[0][0]                  
__________________________________________________________________________________________________
activation_102 (Activation)     (None, 3, 64)        0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv1d_63 (Conv1D)              (None, 3, 64)        12352       activation_102[0][0]             
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 3, 64)        256         conv1d_63[0][0]                  
__________________________________________________________________________________________________
add_9 (Add)                     (None, 3, 64)        0           activation_101[0][0]             
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_103 (Activation)     (None, 3, 64)        0           add_9[0][0]                      
__________________________________________________________________________________________________
average_pooling1d_1 (AveragePoo (None, 3, 64)        0           activation_103[0][0]             
__________________________________________________________________________________________________
flatten_43 (Flatten)            (None, 192)          0           average_pooling1d_1[0][0]        
__________________________________________________________________________________________________
dense_1171 (Dense)              (None, 4)            772         flatten_43[0][0]                 
==================================================================================================
Total params: 96,004
Trainable params: 94,628
Non-trainable params: 1,376
__________________________________________________________________________________________________
None

Accuracy Train: 83.12%
Accuracy Test: 81.78%
Loss Train: 0.71
Loss Test: 0.86
Numero dati esaminati: 1712
True Positive 1400
False Positive 312


------------------------------------------------------------------------
K-fold Cross Validation
------------------------------------------------------------------------
Training for fold 1 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 3s - loss: 0.3018 - accuracy: 0.9409 - val_loss: 0.7081 - val_accuracy: 0.8431
Epoch 2/110
 - 3s - loss: 0.2763 - accuracy: 0.9522 - val_loss: 0.7032 - val_accuracy: 0.8387
Epoch 3/110
 - 3s - loss: 0.2686 - accuracy: 0.9522 - val_loss: 0.7842 - val_accuracy: 0.8051
Epoch 4/110
 - 3s - loss: 0.2757 - accuracy: 0.9529 - val_loss: 0.7678 - val_accuracy: 0.8372
Epoch 5/110
 - 3s - loss: 0.2674 - accuracy: 0.9524 - val_loss: 0.7866 - val_accuracy: 0.8175
Epoch 6/110
 - 3s - loss: 0.2816 - accuracy: 0.9494 - val_loss: 0.8134 - val_accuracy: 0.8336
Epoch 7/110
 - 3s - loss: 0.2735 - accuracy: 0.9483 - val_loss: 0.7653 - val_accuracy: 0.8226
Epoch 8/110
 - 3s - loss: 0.2678 - accuracy: 0.9558 - val_loss: 0.8110 - val_accuracy: 0.8226
Epoch 9/110
 - 3s - loss: 0.2639 - accuracy: 0.9522 - val_loss: 0.7503 - val_accuracy: 0.8343
Epoch 10/110
 - 3s - loss: 0.2644 - accuracy: 0.9562 - val_loss: 0.7962 - val_accuracy: 0.8307
Epoch 11/110
 - 3s - loss: 0.2858 - accuracy: 0.9472 - val_loss: 0.8172 - val_accuracy: 0.8328
Epoch 12/110
 - 3s - loss: 0.2579 - accuracy: 0.9584 - val_loss: 0.7722 - val_accuracy: 0.8219
Epoch 13/110
 - 3s - loss: 0.2614 - accuracy: 0.9558 - val_loss: 0.7836 - val_accuracy: 0.8372
Epoch 14/110
 - 2s - loss: 0.2762 - accuracy: 0.9491 - val_loss: 0.7810 - val_accuracy: 0.8328
Epoch 15/110
 - 3s - loss: 0.2850 - accuracy: 0.9503 - val_loss: 0.7770 - val_accuracy: 0.8365
Epoch 16/110
 - 3s - loss: 0.3285 - accuracy: 0.9325 - val_loss: 0.7906 - val_accuracy: 0.8343
Epoch 17/110
 - 3s - loss: 0.3149 - accuracy: 0.9350 - val_loss: 0.7683 - val_accuracy: 0.8328
Epoch 18/110
 - 3s - loss: 0.2611 - accuracy: 0.9573 - val_loss: 0.7596 - val_accuracy: 0.8394
Epoch 19/110
 - 2s - loss: 0.2667 - accuracy: 0.9562 - val_loss: 0.7861 - val_accuracy: 0.8401
Epoch 20/110
 - 3s - loss: 0.2403 - accuracy: 0.9644 - val_loss: 0.7756 - val_accuracy: 0.8526
Epoch 21/110
 - 3s - loss: 0.2348 - accuracy: 0.9681 - val_loss: 0.8555 - val_accuracy: 0.8423
Epoch 22/110
 - 3s - loss: 0.2325 - accuracy: 0.9686 - val_loss: 0.8681 - val_accuracy: 0.8248
Epoch 23/110
 - 2s - loss: 0.2378 - accuracy: 0.9642 - val_loss: 0.8493 - val_accuracy: 0.8328
Epoch 24/110
 - 2s - loss: 0.2465 - accuracy: 0.9615 - val_loss: 0.8396 - val_accuracy: 0.8299
Epoch 25/110
 - 3s - loss: 0.2419 - accuracy: 0.9618 - val_loss: 0.8172 - val_accuracy: 0.8474
Epoch 26/110
 - 3s - loss: 0.2489 - accuracy: 0.9591 - val_loss: 0.7785 - val_accuracy: 0.8489
Epoch 27/110
 - 2s - loss: 0.2591 - accuracy: 0.9589 - val_loss: 0.9551 - val_accuracy: 0.8102
Epoch 28/110
 - 3s - loss: 0.2948 - accuracy: 0.9461 - val_loss: 0.7741 - val_accuracy: 0.8423
Epoch 29/110
 - 3s - loss: 0.2935 - accuracy: 0.9467 - val_loss: 0.9231 - val_accuracy: 0.8190
Epoch 30/110
 - 3s - loss: 0.2736 - accuracy: 0.9545 - val_loss: 0.8407 - val_accuracy: 0.8277
Epoch 31/110
 - 3s - loss: 0.2536 - accuracy: 0.9571 - val_loss: 0.8502 - val_accuracy: 0.8307
Epoch 32/110
 - 3s - loss: 0.2511 - accuracy: 0.9606 - val_loss: 0.7765 - val_accuracy: 0.8409
Epoch 33/110
 - 3s - loss: 0.2615 - accuracy: 0.9602 - val_loss: 0.8669 - val_accuracy: 0.8219
Epoch 34/110
 - 3s - loss: 0.2470 - accuracy: 0.9608 - val_loss: 0.7669 - val_accuracy: 0.8248
Epoch 35/110
 - 3s - loss: 0.2349 - accuracy: 0.9666 - val_loss: 0.7824 - val_accuracy: 0.8307
Epoch 36/110
 - 3s - loss: 0.2313 - accuracy: 0.9666 - val_loss: 0.8231 - val_accuracy: 0.8453
Epoch 37/110
 - 3s - loss: 0.2374 - accuracy: 0.9631 - val_loss: 0.7978 - val_accuracy: 0.8416
Epoch 38/110
 - 3s - loss: 0.2471 - accuracy: 0.9633 - val_loss: 0.7965 - val_accuracy: 0.8350
Epoch 39/110
 - 3s - loss: 0.2473 - accuracy: 0.9606 - val_loss: 0.8295 - val_accuracy: 0.8394
Epoch 40/110
 - 3s - loss: 0.2598 - accuracy: 0.9606 - val_loss: 0.8262 - val_accuracy: 0.8445
Epoch 41/110
 - 3s - loss: 0.2397 - accuracy: 0.9673 - val_loss: 0.8066 - val_accuracy: 0.8409
Epoch 42/110
 - 3s - loss: 0.2326 - accuracy: 0.9688 - val_loss: 0.8123 - val_accuracy: 0.8380
Epoch 43/110
 - 3s - loss: 0.2433 - accuracy: 0.9618 - val_loss: 0.8547 - val_accuracy: 0.8270
Epoch 44/110
 - 3s - loss: 0.2862 - accuracy: 0.9511 - val_loss: 0.8470 - val_accuracy: 0.8226
Epoch 45/110
 - 3s - loss: 0.2589 - accuracy: 0.9602 - val_loss: 0.7616 - val_accuracy: 0.8314
Epoch 46/110
 - 3s - loss: 0.2512 - accuracy: 0.9602 - val_loss: 0.8593 - val_accuracy: 0.8431
Epoch 47/110
 - 3s - loss: 0.2412 - accuracy: 0.9642 - val_loss: 0.8207 - val_accuracy: 0.8350
Epoch 48/110
 - 3s - loss: 0.2472 - accuracy: 0.9640 - val_loss: 0.8394 - val_accuracy: 0.8277
Epoch 49/110
 - 3s - loss: 0.2334 - accuracy: 0.9635 - val_loss: 0.8383 - val_accuracy: 0.8474
Epoch 50/110
 - 3s - loss: 0.2209 - accuracy: 0.9697 - val_loss: 0.8591 - val_accuracy: 0.8409
Epoch 51/110
 - 3s - loss: 0.2211 - accuracy: 0.9717 - val_loss: 0.8353 - val_accuracy: 0.8365
Epoch 52/110
 - 3s - loss: 0.2360 - accuracy: 0.9659 - val_loss: 0.8182 - val_accuracy: 0.8511
Epoch 53/110
 - 3s - loss: 0.2312 - accuracy: 0.9660 - val_loss: 0.8771 - val_accuracy: 0.8336
Epoch 54/110
 - 3s - loss: 0.2586 - accuracy: 0.9544 - val_loss: 0.8696 - val_accuracy: 0.8299
Epoch 55/110
 - 3s - loss: 0.2439 - accuracy: 0.9640 - val_loss: 0.8897 - val_accuracy: 0.8255
Epoch 56/110
 - 3s - loss: 0.2305 - accuracy: 0.9675 - val_loss: 0.8428 - val_accuracy: 0.8321
Epoch 57/110
 - 3s - loss: 0.2311 - accuracy: 0.9673 - val_loss: 0.8065 - val_accuracy: 0.8518
Epoch 58/110
 - 3s - loss: 0.2290 - accuracy: 0.9699 - val_loss: 0.8736 - val_accuracy: 0.8321
Epoch 59/110
 - 3s - loss: 0.2416 - accuracy: 0.9629 - val_loss: 0.8314 - val_accuracy: 0.8380
Epoch 60/110
 - 3s - loss: 0.2430 - accuracy: 0.9620 - val_loss: 0.7755 - val_accuracy: 0.8409
Epoch 61/110
 - 3s - loss: 0.3313 - accuracy: 0.9403 - val_loss: 0.7842 - val_accuracy: 0.8241
Epoch 62/110
 - 3s - loss: 0.3498 - accuracy: 0.9294 - val_loss: 0.8334 - val_accuracy: 0.8190
Epoch 63/110
 - 3s - loss: 0.2811 - accuracy: 0.9503 - val_loss: 0.7839 - val_accuracy: 0.8372
Epoch 64/110
 - 3s - loss: 0.2167 - accuracy: 0.9752 - val_loss: 0.8415 - val_accuracy: 0.8423
Epoch 65/110
 - 3s - loss: 0.2173 - accuracy: 0.9728 - val_loss: 0.8396 - val_accuracy: 0.8526
Epoch 66/110
 - 3s - loss: 0.2094 - accuracy: 0.9712 - val_loss: 0.8143 - val_accuracy: 0.8409
Epoch 67/110
 - 3s - loss: 0.2098 - accuracy: 0.9723 - val_loss: 0.8556 - val_accuracy: 0.8453
Epoch 68/110
 - 3s - loss: 0.2017 - accuracy: 0.9779 - val_loss: 0.8053 - val_accuracy: 0.8416
Epoch 69/110
 - 2s - loss: 0.1971 - accuracy: 0.9794 - val_loss: 0.8226 - val_accuracy: 0.8460
Epoch 70/110
 - 2s - loss: 0.2258 - accuracy: 0.9710 - val_loss: 0.7764 - val_accuracy: 0.8540
Epoch 71/110
 - 2s - loss: 0.2396 - accuracy: 0.9637 - val_loss: 0.8300 - val_accuracy: 0.8372
Epoch 72/110
 - 2s - loss: 0.2300 - accuracy: 0.9686 - val_loss: 0.7830 - val_accuracy: 0.8438
Epoch 73/110
 - 3s - loss: 0.2043 - accuracy: 0.9772 - val_loss: 0.8110 - val_accuracy: 0.8460
Epoch 74/110
 - 3s - loss: 0.2035 - accuracy: 0.9775 - val_loss: 0.8360 - val_accuracy: 0.8431
Epoch 75/110
 - 3s - loss: 0.2167 - accuracy: 0.9724 - val_loss: 0.8031 - val_accuracy: 0.8387
Epoch 76/110
 - 3s - loss: 0.2025 - accuracy: 0.9792 - val_loss: 0.7570 - val_accuracy: 0.8584
Epoch 77/110
 - 3s - loss: 0.2124 - accuracy: 0.9750 - val_loss: 0.8661 - val_accuracy: 0.8496
Epoch 78/110
 - 3s - loss: 0.2023 - accuracy: 0.9766 - val_loss: 0.8072 - val_accuracy: 0.8496
Epoch 79/110
 - 3s - loss: 0.2299 - accuracy: 0.9691 - val_loss: 0.8783 - val_accuracy: 0.8314
Epoch 80/110
 - 2s - loss: 0.2429 - accuracy: 0.9620 - val_loss: 0.8538 - val_accuracy: 0.8372
Epoch 81/110
 - 3s - loss: 0.2264 - accuracy: 0.9684 - val_loss: 0.8343 - val_accuracy: 0.8328
Epoch 82/110
 - 3s - loss: 0.2256 - accuracy: 0.9690 - val_loss: 0.8436 - val_accuracy: 0.8401
Epoch 83/110
 - 3s - loss: 0.2584 - accuracy: 0.9622 - val_loss: 0.8788 - val_accuracy: 0.8321
Epoch 84/110
 - 3s - loss: 0.3218 - accuracy: 0.9363 - val_loss: 0.7799 - val_accuracy: 0.8241
Epoch 85/110
 - 3s - loss: 0.2703 - accuracy: 0.9529 - val_loss: 0.8154 - val_accuracy: 0.8423
Epoch 86/110
 - 2s - loss: 0.2369 - accuracy: 0.9659 - val_loss: 0.8242 - val_accuracy: 0.8518
Epoch 87/110
 - 2s - loss: 0.2155 - accuracy: 0.9713 - val_loss: 0.8298 - val_accuracy: 0.8489
Epoch 88/110
 - 2s - loss: 0.2175 - accuracy: 0.9708 - val_loss: 0.8413 - val_accuracy: 0.8540
Epoch 89/110
 - 3s - loss: 0.2219 - accuracy: 0.9719 - val_loss: 0.8068 - val_accuracy: 0.8365
Epoch 90/110
 - 3s - loss: 0.2062 - accuracy: 0.9755 - val_loss: 0.8033 - val_accuracy: 0.8453
Epoch 91/110
 - 3s - loss: 0.2072 - accuracy: 0.9755 - val_loss: 0.7733 - val_accuracy: 0.8496
Epoch 92/110
 - 3s - loss: 0.2012 - accuracy: 0.9775 - val_loss: 0.8271 - val_accuracy: 0.8460
Epoch 93/110
 - 3s - loss: 0.2038 - accuracy: 0.9770 - val_loss: 0.8007 - val_accuracy: 0.8453
Epoch 94/110
 - 3s - loss: 0.2154 - accuracy: 0.9741 - val_loss: 0.8621 - val_accuracy: 0.8372
Epoch 95/110
 - 3s - loss: 0.2224 - accuracy: 0.9684 - val_loss: 0.7931 - val_accuracy: 0.8474
Epoch 96/110
 - 3s - loss: 0.2212 - accuracy: 0.9690 - val_loss: 0.8682 - val_accuracy: 0.8365
Epoch 97/110
 - 3s - loss: 0.2384 - accuracy: 0.9628 - val_loss: 0.9696 - val_accuracy: 0.8255
Epoch 98/110
 - 3s - loss: 0.2752 - accuracy: 0.9520 - val_loss: 0.8018 - val_accuracy: 0.8380
Epoch 99/110
 - 3s - loss: 0.2298 - accuracy: 0.9671 - val_loss: 0.8283 - val_accuracy: 0.8350
Epoch 100/110
 - 3s - loss: 0.1979 - accuracy: 0.9779 - val_loss: 0.7974 - val_accuracy: 0.8431
Epoch 101/110
 - 3s - loss: 0.1987 - accuracy: 0.9763 - val_loss: 0.8405 - val_accuracy: 0.8445
Epoch 102/110
 - 3s - loss: 0.2136 - accuracy: 0.9719 - val_loss: 0.8100 - val_accuracy: 0.8358
Epoch 103/110
 - 3s - loss: 0.2120 - accuracy: 0.9719 - val_loss: 0.8736 - val_accuracy: 0.8431
Epoch 104/110
 - 3s - loss: 0.2018 - accuracy: 0.9766 - val_loss: 0.8067 - val_accuracy: 0.8380
Epoch 105/110
 - 3s - loss: 0.1957 - accuracy: 0.9765 - val_loss: 0.8481 - val_accuracy: 0.8423
Epoch 106/110
 - 3s - loss: 0.1953 - accuracy: 0.9766 - val_loss: 0.8852 - val_accuracy: 0.8285
Epoch 107/110
 - 3s - loss: 0.2019 - accuracy: 0.9743 - val_loss: 0.8517 - val_accuracy: 0.8380
Epoch 108/110
 - 3s - loss: 0.1961 - accuracy: 0.9777 - val_loss: 0.8309 - val_accuracy: 0.8431
Epoch 109/110
 - 3s - loss: 0.2115 - accuracy: 0.9724 - val_loss: 0.8253 - val_accuracy: 0.8489
Epoch 110/110
 - 3s - loss: 0.2240 - accuracy: 0.9701 - val_loss: 0.8308 - val_accuracy: 0.8343
------------------------------------------------------------------------
Training for fold 2 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 3s - loss: 0.2701 - accuracy: 0.9507 - val_loss: 0.8390 - val_accuracy: 0.8299
Epoch 2/110
 - 3s - loss: 0.3108 - accuracy: 0.9396 - val_loss: 0.8431 - val_accuracy: 0.8190
Epoch 3/110
 - 3s - loss: 0.2466 - accuracy: 0.9618 - val_loss: 0.7667 - val_accuracy: 0.8504
Epoch 4/110
 - 3s - loss: 0.2096 - accuracy: 0.9737 - val_loss: 0.7981 - val_accuracy: 0.8482
Epoch 5/110
 - 3s - loss: 0.1957 - accuracy: 0.9777 - val_loss: 0.8427 - val_accuracy: 0.8380
Epoch 6/110
 - 3s - loss: 0.2029 - accuracy: 0.9755 - val_loss: 0.8095 - val_accuracy: 0.8453
Epoch 7/110
 - 3s - loss: 0.1965 - accuracy: 0.9761 - val_loss: 0.8142 - val_accuracy: 0.8504
Epoch 8/110
 - 3s - loss: 0.2076 - accuracy: 0.9744 - val_loss: 0.8109 - val_accuracy: 0.8511
Epoch 9/110
 - 3s - loss: 0.2113 - accuracy: 0.9721 - val_loss: 0.8604 - val_accuracy: 0.8380
Epoch 10/110
 - 3s - loss: 0.1992 - accuracy: 0.9763 - val_loss: 0.8814 - val_accuracy: 0.8467
Epoch 11/110
 - 3s - loss: 0.2135 - accuracy: 0.9726 - val_loss: 0.8405 - val_accuracy: 0.8445
Epoch 12/110
 - 3s - loss: 0.2290 - accuracy: 0.9684 - val_loss: 0.7842 - val_accuracy: 0.8387
Epoch 13/110
 - 3s - loss: 0.2088 - accuracy: 0.9717 - val_loss: 0.8012 - val_accuracy: 0.8489
Epoch 14/110
 - 3s - loss: 0.1987 - accuracy: 0.9772 - val_loss: 0.7987 - val_accuracy: 0.8401
Epoch 15/110
 - 3s - loss: 0.2131 - accuracy: 0.9726 - val_loss: 0.8577 - val_accuracy: 0.8474
Epoch 16/110
 - 3s - loss: 0.2145 - accuracy: 0.9728 - val_loss: 0.7968 - val_accuracy: 0.8474
Epoch 17/110
 - 3s - loss: 0.2052 - accuracy: 0.9744 - val_loss: 0.8076 - val_accuracy: 0.8482
Epoch 18/110
 - 3s - loss: 0.2118 - accuracy: 0.9713 - val_loss: 0.7940 - val_accuracy: 0.8460
Epoch 19/110
 - 3s - loss: 0.2009 - accuracy: 0.9739 - val_loss: 0.7886 - val_accuracy: 0.8526
Epoch 20/110
 - 3s - loss: 0.1926 - accuracy: 0.9766 - val_loss: 0.8040 - val_accuracy: 0.8445
Epoch 21/110
 - 3s - loss: 0.2159 - accuracy: 0.9717 - val_loss: 0.8957 - val_accuracy: 0.8372
Epoch 22/110
 - 3s - loss: 0.2360 - accuracy: 0.9646 - val_loss: 0.9114 - val_accuracy: 0.8255
Epoch 23/110
 - 3s - loss: 0.3374 - accuracy: 0.9361 - val_loss: 0.8372 - val_accuracy: 0.8248
Epoch 24/110
 - 3s - loss: 0.3050 - accuracy: 0.9427 - val_loss: 0.7963 - val_accuracy: 0.8453
Epoch 25/110
 - 3s - loss: 0.3294 - accuracy: 0.9496 - val_loss: 0.8244 - val_accuracy: 0.8270
Epoch 26/110
 - 3s - loss: 0.2580 - accuracy: 0.9560 - val_loss: 0.7707 - val_accuracy: 0.8489
Epoch 27/110
 - 3s - loss: 0.2002 - accuracy: 0.9761 - val_loss: 0.7918 - val_accuracy: 0.8474
Epoch 28/110
 - 3s - loss: 0.1910 - accuracy: 0.9785 - val_loss: 0.7694 - val_accuracy: 0.8577
Epoch 29/110
 - 3s - loss: 0.1830 - accuracy: 0.9812 - val_loss: 0.8733 - val_accuracy: 0.8453
Epoch 30/110
 - 3s - loss: 0.1952 - accuracy: 0.9763 - val_loss: 0.8074 - val_accuracy: 0.8533
Epoch 31/110
 - 3s - loss: 0.1881 - accuracy: 0.9786 - val_loss: 0.8226 - val_accuracy: 0.8533
Epoch 32/110
 - 3s - loss: 0.1842 - accuracy: 0.9799 - val_loss: 0.8025 - val_accuracy: 0.8489
Epoch 33/110
 - 3s - loss: 0.1812 - accuracy: 0.9810 - val_loss: 0.8069 - val_accuracy: 0.8540
Epoch 34/110
 - 3s - loss: 0.1789 - accuracy: 0.9812 - val_loss: 0.8496 - val_accuracy: 0.8467
Epoch 35/110
 - 3s - loss: 0.1835 - accuracy: 0.9808 - val_loss: 0.8230 - val_accuracy: 0.8526
Epoch 36/110
 - 3s - loss: 0.1913 - accuracy: 0.9779 - val_loss: 0.7945 - val_accuracy: 0.8453
Epoch 37/110
 - 3s - loss: 0.1846 - accuracy: 0.9799 - val_loss: 0.8022 - val_accuracy: 0.8577
Epoch 38/110
 - 3s - loss: 0.1952 - accuracy: 0.9755 - val_loss: 0.8796 - val_accuracy: 0.8336
Epoch 39/110
 - 3s - loss: 0.1995 - accuracy: 0.9743 - val_loss: 0.8645 - val_accuracy: 0.8423
Epoch 40/110
 - 3s - loss: 0.2254 - accuracy: 0.9675 - val_loss: 0.8800 - val_accuracy: 0.8314
Epoch 41/110
 - 3s - loss: 0.2518 - accuracy: 0.9538 - val_loss: 0.8582 - val_accuracy: 0.8365
Epoch 42/110
 - 3s - loss: 0.2381 - accuracy: 0.9609 - val_loss: 0.8079 - val_accuracy: 0.8401
Epoch 43/110
 - 3s - loss: 0.2068 - accuracy: 0.9728 - val_loss: 0.8205 - val_accuracy: 0.8504
Epoch 44/110
 - 3s - loss: 0.1952 - accuracy: 0.9774 - val_loss: 0.7697 - val_accuracy: 0.8438
Epoch 45/110
 - 3s - loss: 0.1922 - accuracy: 0.9779 - val_loss: 0.8517 - val_accuracy: 0.8416
Epoch 46/110
 - 3s - loss: 0.1921 - accuracy: 0.9774 - val_loss: 0.8670 - val_accuracy: 0.8387
Epoch 47/110
 - 3s - loss: 0.1911 - accuracy: 0.9775 - val_loss: 0.8228 - val_accuracy: 0.8350
Epoch 48/110
 - 3s - loss: 0.1867 - accuracy: 0.9786 - val_loss: 0.7767 - val_accuracy: 0.8591
Epoch 49/110
 - 3s - loss: 0.1997 - accuracy: 0.9746 - val_loss: 0.8232 - val_accuracy: 0.8372
Epoch 50/110
 - 3s - loss: 0.1991 - accuracy: 0.9775 - val_loss: 0.7629 - val_accuracy: 0.8416
Epoch 51/110
 - 3s - loss: 0.2098 - accuracy: 0.9721 - val_loss: 0.8237 - val_accuracy: 0.8401
Epoch 52/110
 - 3s - loss: 0.2327 - accuracy: 0.9660 - val_loss: 0.8472 - val_accuracy: 0.8401
Epoch 53/110
 - 3s - loss: 0.2371 - accuracy: 0.9620 - val_loss: 0.7615 - val_accuracy: 0.8569
Epoch 54/110
 - 3s - loss: 0.2393 - accuracy: 0.9606 - val_loss: 0.7598 - val_accuracy: 0.8577
Epoch 55/110
 - 3s - loss: 0.2055 - accuracy: 0.9732 - val_loss: 0.7687 - val_accuracy: 0.8540
Epoch 56/110
 - 3s - loss: 0.2051 - accuracy: 0.9735 - val_loss: 0.9009 - val_accuracy: 0.8292
Epoch 57/110
 - 3s - loss: 0.1880 - accuracy: 0.9794 - val_loss: 0.8571 - val_accuracy: 0.8445
Epoch 58/110
 - 3s - loss: 0.1813 - accuracy: 0.9814 - val_loss: 0.8019 - val_accuracy: 0.8540
Epoch 59/110
 - 3s - loss: 0.1850 - accuracy: 0.9788 - val_loss: 0.8336 - val_accuracy: 0.8336
Epoch 60/110
 - 3s - loss: 0.1831 - accuracy: 0.9788 - val_loss: 0.7821 - val_accuracy: 0.8540
Epoch 61/110
 - 3s - loss: 0.1772 - accuracy: 0.9828 - val_loss: 0.8336 - val_accuracy: 0.8460
Epoch 62/110
 - 3s - loss: 0.1806 - accuracy: 0.9794 - val_loss: 0.8928 - val_accuracy: 0.8299
Epoch 63/110
 - 3s - loss: 0.1916 - accuracy: 0.9785 - val_loss: 0.8336 - val_accuracy: 0.8467
Epoch 64/110
 - 3s - loss: 0.2134 - accuracy: 0.9699 - val_loss: 0.7488 - val_accuracy: 0.8482
Epoch 65/110
 - 3s - loss: 0.2089 - accuracy: 0.9697 - val_loss: 0.8434 - val_accuracy: 0.8453
Epoch 66/110
 - 3s - loss: 0.2273 - accuracy: 0.9650 - val_loss: 0.7939 - val_accuracy: 0.8263
Epoch 67/110
 - 3s - loss: 0.2789 - accuracy: 0.9494 - val_loss: 0.9611 - val_accuracy: 0.8336
Epoch 68/110
 - 3s - loss: 0.2418 - accuracy: 0.9629 - val_loss: 0.8795 - val_accuracy: 0.8409
Epoch 69/110
 - 3s - loss: 0.2231 - accuracy: 0.9671 - val_loss: 0.7987 - val_accuracy: 0.8533
Epoch 70/110
 - 3s - loss: 0.1870 - accuracy: 0.9788 - val_loss: 0.7881 - val_accuracy: 0.8511
Epoch 71/110
 - 3s - loss: 0.1782 - accuracy: 0.9821 - val_loss: 0.8385 - val_accuracy: 0.8489
Epoch 72/110
 - 3s - loss: 0.1721 - accuracy: 0.9817 - val_loss: 0.8286 - val_accuracy: 0.8533
Epoch 73/110
 - 3s - loss: 0.1789 - accuracy: 0.9806 - val_loss: 0.8487 - val_accuracy: 0.8460
Epoch 74/110
 - 3s - loss: 0.1722 - accuracy: 0.9834 - val_loss: 0.8360 - val_accuracy: 0.8599
Epoch 75/110
 - 3s - loss: 0.1741 - accuracy: 0.9827 - val_loss: 0.8480 - val_accuracy: 0.8423
Epoch 76/110
 - 2s - loss: 0.1795 - accuracy: 0.9794 - val_loss: 0.8206 - val_accuracy: 0.8511
Epoch 77/110
 - 3s - loss: 0.1811 - accuracy: 0.9799 - val_loss: 0.9096 - val_accuracy: 0.8358
Epoch 78/110
 - 3s - loss: 0.1941 - accuracy: 0.9766 - val_loss: 0.8144 - val_accuracy: 0.8431
Epoch 79/110
 - 3s - loss: 0.2006 - accuracy: 0.9741 - val_loss: 0.8556 - val_accuracy: 0.8336
Epoch 80/110
 - 3s - loss: 0.1846 - accuracy: 0.9777 - val_loss: 0.9790 - val_accuracy: 0.8358
Epoch 81/110
 - 3s - loss: 0.2447 - accuracy: 0.9598 - val_loss: 0.8512 - val_accuracy: 0.8445
Epoch 82/110
 - 3s - loss: 0.2499 - accuracy: 0.9542 - val_loss: 0.8580 - val_accuracy: 0.8358
Epoch 83/110
 - 3s - loss: 0.2165 - accuracy: 0.9655 - val_loss: 0.8328 - val_accuracy: 0.8526
Epoch 84/110
 - 3s - loss: 0.1838 - accuracy: 0.9783 - val_loss: 0.8068 - val_accuracy: 0.8569
Epoch 85/110
 - 3s - loss: 0.1752 - accuracy: 0.9812 - val_loss: 0.8066 - val_accuracy: 0.8562
Epoch 86/110
 - 3s - loss: 0.1699 - accuracy: 0.9838 - val_loss: 0.9017 - val_accuracy: 0.8358
Epoch 87/110
 - 3s - loss: 0.1811 - accuracy: 0.9783 - val_loss: 0.8280 - val_accuracy: 0.8460
Epoch 88/110
 - 3s - loss: 0.1897 - accuracy: 0.9757 - val_loss: 0.8458 - val_accuracy: 0.8423
Epoch 89/110
 - 3s - loss: 0.1901 - accuracy: 0.9757 - val_loss: 0.8742 - val_accuracy: 0.8365
Epoch 90/110
 - 3s - loss: 0.1901 - accuracy: 0.9765 - val_loss: 0.8556 - val_accuracy: 0.8401
Epoch 91/110
 - 3s - loss: 0.1974 - accuracy: 0.9728 - val_loss: 0.8500 - val_accuracy: 0.8489
Epoch 92/110
 - 3s - loss: 0.1982 - accuracy: 0.9728 - val_loss: 0.8697 - val_accuracy: 0.8467
Epoch 93/110
 - 3s - loss: 0.2049 - accuracy: 0.9733 - val_loss: 0.7977 - val_accuracy: 0.8380
Epoch 94/110
 - 3s - loss: 0.1888 - accuracy: 0.9766 - val_loss: 0.9203 - val_accuracy: 0.8153
Epoch 95/110
 - 3s - loss: 0.1915 - accuracy: 0.9754 - val_loss: 0.8067 - val_accuracy: 0.8577
Epoch 96/110
 - 3s - loss: 0.1739 - accuracy: 0.9799 - val_loss: 0.8152 - val_accuracy: 0.8467
Epoch 97/110
 - 3s - loss: 0.2053 - accuracy: 0.9741 - val_loss: 0.8146 - val_accuracy: 0.8285
Epoch 98/110
 - 3s - loss: 0.2904 - accuracy: 0.9454 - val_loss: 0.7817 - val_accuracy: 0.8431
Epoch 99/110
 - 3s - loss: 0.2466 - accuracy: 0.9569 - val_loss: 0.7898 - val_accuracy: 0.8336
Epoch 100/110
 - 3s - loss: 0.1995 - accuracy: 0.9732 - val_loss: 0.8151 - val_accuracy: 0.8416
Epoch 101/110
 - 3s - loss: 0.1847 - accuracy: 0.9777 - val_loss: 0.8983 - val_accuracy: 0.8350
Epoch 102/110
 - 3s - loss: 0.1791 - accuracy: 0.9805 - val_loss: 0.8557 - val_accuracy: 0.8504
Epoch 103/110
 - 3s - loss: 0.1666 - accuracy: 0.9827 - val_loss: 0.8082 - val_accuracy: 0.8526
Epoch 104/110
 - 3s - loss: 0.1663 - accuracy: 0.9834 - val_loss: 0.9702 - val_accuracy: 0.8277
Epoch 105/110
 - 3s - loss: 0.1726 - accuracy: 0.9817 - val_loss: 0.8380 - val_accuracy: 0.8445
Epoch 106/110
 - 3s - loss: 0.1855 - accuracy: 0.9759 - val_loss: 0.8932 - val_accuracy: 0.8343
Epoch 107/110
 - 3s - loss: 0.1786 - accuracy: 0.9777 - val_loss: 0.8522 - val_accuracy: 0.8445
Epoch 108/110
 - 2s - loss: 0.1821 - accuracy: 0.9775 - val_loss: 0.8776 - val_accuracy: 0.8467
Epoch 109/110
 - 3s - loss: 0.1800 - accuracy: 0.9794 - val_loss: 0.8434 - val_accuracy: 0.8314
Epoch 110/110
 - 3s - loss: 0.1803 - accuracy: 0.9788 - val_loss: 0.8618 - val_accuracy: 0.8365
------------------------------------------------------------------------
Training for fold 3 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 3s - loss: 0.2108 - accuracy: 0.9688 - val_loss: 0.7890 - val_accuracy: 0.8358
Epoch 2/110
 - 3s - loss: 0.2074 - accuracy: 0.9671 - val_loss: 0.8519 - val_accuracy: 0.8343
Epoch 3/110
 - 3s - loss: 0.3976 - accuracy: 0.9146 - val_loss: 0.9011 - val_accuracy: 0.8285
Epoch 4/110
 - 3s - loss: 0.2728 - accuracy: 0.9496 - val_loss: 0.8203 - val_accuracy: 0.8438
Epoch 5/110
 - 3s - loss: 0.1926 - accuracy: 0.9770 - val_loss: 0.8267 - val_accuracy: 0.8504
Epoch 6/110
 - 3s - loss: 0.1763 - accuracy: 0.9806 - val_loss: 0.8125 - val_accuracy: 0.8511
Epoch 7/110
 - 3s - loss: 0.1710 - accuracy: 0.9832 - val_loss: 0.8118 - val_accuracy: 0.8504
Epoch 8/110
 - 3s - loss: 0.1732 - accuracy: 0.9806 - val_loss: 0.8713 - val_accuracy: 0.8482
Epoch 9/110
 - 3s - loss: 0.1676 - accuracy: 0.9832 - val_loss: 0.8445 - val_accuracy: 0.8343
Epoch 10/110
 - 3s - loss: 0.1655 - accuracy: 0.9839 - val_loss: 0.8361 - val_accuracy: 0.8526
Epoch 11/110
 - 3s - loss: 0.1682 - accuracy: 0.9832 - val_loss: 0.8720 - val_accuracy: 0.8401
Epoch 12/110
 - 3s - loss: 0.1606 - accuracy: 0.9843 - val_loss: 0.8618 - val_accuracy: 0.8467
Epoch 13/110
 - 3s - loss: 0.2025 - accuracy: 0.9732 - val_loss: 1.0041 - val_accuracy: 0.8255
Epoch 14/110
 - 3s - loss: 0.2159 - accuracy: 0.9673 - val_loss: 0.8921 - val_accuracy: 0.8416
Epoch 15/110
 - 3s - loss: 0.2248 - accuracy: 0.9622 - val_loss: 0.7924 - val_accuracy: 0.8394
Epoch 16/110
 - 3s - loss: 0.1870 - accuracy: 0.9755 - val_loss: 0.8935 - val_accuracy: 0.8423
Epoch 17/110
 - 3s - loss: 0.1708 - accuracy: 0.9803 - val_loss: 0.8588 - val_accuracy: 0.8445
Epoch 18/110
 - 3s - loss: 0.1702 - accuracy: 0.9812 - val_loss: 0.9850 - val_accuracy: 0.8350
Epoch 19/110
 - 3s - loss: 0.1693 - accuracy: 0.9810 - val_loss: 0.8542 - val_accuracy: 0.8336
Epoch 20/110
 - 2s - loss: 0.1810 - accuracy: 0.9772 - val_loss: 0.9110 - val_accuracy: 0.8401
Epoch 21/110
 - 3s - loss: 0.1793 - accuracy: 0.9775 - val_loss: 0.8501 - val_accuracy: 0.8460
Epoch 22/110
 - 3s - loss: 0.1777 - accuracy: 0.9772 - val_loss: 0.9396 - val_accuracy: 0.8328
Epoch 23/110
 - 3s - loss: 0.1879 - accuracy: 0.9761 - val_loss: 1.0088 - val_accuracy: 0.8248
Epoch 24/110
 - 3s - loss: 0.2079 - accuracy: 0.9713 - val_loss: 0.8311 - val_accuracy: 0.8438
Epoch 25/110
 - 3s - loss: 0.2212 - accuracy: 0.9648 - val_loss: 0.8182 - val_accuracy: 0.8372
Epoch 26/110
 - 3s - loss: 0.2276 - accuracy: 0.9639 - val_loss: 0.9055 - val_accuracy: 0.8321
Epoch 27/110
 - 3s - loss: 0.1829 - accuracy: 0.9772 - val_loss: 0.9082 - val_accuracy: 0.8431
Epoch 28/110
 - 3s - loss: 0.1766 - accuracy: 0.9763 - val_loss: 0.8873 - val_accuracy: 0.8336
Epoch 29/110
 - 3s - loss: 0.1825 - accuracy: 0.9766 - val_loss: 0.9266 - val_accuracy: 0.8358
Epoch 30/110
 - 3s - loss: 0.1859 - accuracy: 0.9750 - val_loss: 0.8926 - val_accuracy: 0.8409
Epoch 31/110
 - 3s - loss: 0.1702 - accuracy: 0.9810 - val_loss: 0.8203 - val_accuracy: 0.8445
Epoch 32/110
 - 3s - loss: 0.1677 - accuracy: 0.9799 - val_loss: 0.8478 - val_accuracy: 0.8409
Epoch 33/110
 - 3s - loss: 0.1853 - accuracy: 0.9761 - val_loss: 0.8642 - val_accuracy: 0.8409
Epoch 34/110
 - 3s - loss: 0.1774 - accuracy: 0.9794 - val_loss: 0.8775 - val_accuracy: 0.8431
Epoch 35/110
 - 3s - loss: 0.1686 - accuracy: 0.9810 - val_loss: 0.8839 - val_accuracy: 0.8423
Epoch 36/110
 - 3s - loss: 0.1847 - accuracy: 0.9761 - val_loss: 0.8997 - val_accuracy: 0.8190
Epoch 37/110
 - 3s - loss: 0.2013 - accuracy: 0.9695 - val_loss: 0.8109 - val_accuracy: 0.8372
Epoch 38/110
 - 3s - loss: 0.1936 - accuracy: 0.9739 - val_loss: 0.7924 - val_accuracy: 0.8496
Epoch 39/110
 - 3s - loss: 0.2502 - accuracy: 0.9600 - val_loss: 0.8098 - val_accuracy: 0.8255
Epoch 40/110
 - 3s - loss: 0.2615 - accuracy: 0.9509 - val_loss: 0.7979 - val_accuracy: 0.8365
Epoch 41/110
 - 3s - loss: 0.2237 - accuracy: 0.9653 - val_loss: 0.8311 - val_accuracy: 0.8343
Epoch 42/110
 - 3s - loss: 0.2078 - accuracy: 0.9697 - val_loss: 0.7828 - val_accuracy: 0.8394
Epoch 43/110
 - 3s - loss: 0.1701 - accuracy: 0.9803 - val_loss: 0.9089 - val_accuracy: 0.8292
Epoch 44/110
 - 3s - loss: 0.1610 - accuracy: 0.9834 - val_loss: 0.8242 - val_accuracy: 0.8314
Epoch 45/110
 - 3s - loss: 0.1603 - accuracy: 0.9854 - val_loss: 0.8822 - val_accuracy: 0.8270
Epoch 46/110
 - 3s - loss: 0.1628 - accuracy: 0.9827 - val_loss: 0.8477 - val_accuracy: 0.8445
Epoch 47/110
 - 3s - loss: 0.1634 - accuracy: 0.9827 - val_loss: 0.8822 - val_accuracy: 0.8372
Epoch 48/110
 - 3s - loss: 0.1713 - accuracy: 0.9796 - val_loss: 0.8667 - val_accuracy: 0.8526
Epoch 49/110
 - 3s - loss: 0.1829 - accuracy: 0.9757 - val_loss: 0.7892 - val_accuracy: 0.8438
Epoch 50/110
 - 3s - loss: 0.1788 - accuracy: 0.9766 - val_loss: 0.8690 - val_accuracy: 0.8518
Epoch 51/110
 - 3s - loss: 0.1690 - accuracy: 0.9808 - val_loss: 0.9148 - val_accuracy: 0.8467
Epoch 52/110
 - 3s - loss: 0.1652 - accuracy: 0.9814 - val_loss: 0.9233 - val_accuracy: 0.8307
Epoch 53/110
 - 3s - loss: 0.1607 - accuracy: 0.9838 - val_loss: 0.8494 - val_accuracy: 0.8526
Epoch 54/110
 - 3s - loss: 0.1580 - accuracy: 0.9836 - val_loss: 0.9162 - val_accuracy: 0.8431
Epoch 55/110
 - 3s - loss: 0.1693 - accuracy: 0.9788 - val_loss: 0.8892 - val_accuracy: 0.8533
Epoch 56/110
 - 3s - loss: 0.1742 - accuracy: 0.9768 - val_loss: 0.8520 - val_accuracy: 0.8467
Epoch 57/110
 - 3s - loss: 0.1752 - accuracy: 0.9786 - val_loss: 0.9417 - val_accuracy: 0.8292
Epoch 58/110
 - 3s - loss: 0.1883 - accuracy: 0.9732 - val_loss: 0.8891 - val_accuracy: 0.8380
Epoch 59/110
 - 3s - loss: 0.3906 - accuracy: 0.9261 - val_loss: 0.8175 - val_accuracy: 0.8255
Epoch 60/110
 - 3s - loss: 0.2361 - accuracy: 0.9582 - val_loss: 0.7976 - val_accuracy: 0.8431
Epoch 61/110
 - 3s - loss: 0.1852 - accuracy: 0.9766 - val_loss: 0.8309 - val_accuracy: 0.8409
Epoch 62/110
 - 3s - loss: 0.1740 - accuracy: 0.9827 - val_loss: 0.8131 - val_accuracy: 0.8307
Epoch 63/110
 - 3s - loss: 0.1586 - accuracy: 0.9841 - val_loss: 0.7785 - val_accuracy: 0.8438
Epoch 64/110
 - 3s - loss: 0.1607 - accuracy: 0.9814 - val_loss: 0.8975 - val_accuracy: 0.8307
Epoch 65/110
 - 3s - loss: 0.1703 - accuracy: 0.9794 - val_loss: 0.8915 - val_accuracy: 0.8314
Epoch 66/110
 - 3s - loss: 0.1763 - accuracy: 0.9775 - val_loss: 0.9908 - val_accuracy: 0.8270
Epoch 67/110
 - 3s - loss: 0.1659 - accuracy: 0.9796 - val_loss: 0.7747 - val_accuracy: 0.8511
Epoch 68/110
 - 3s - loss: 0.1680 - accuracy: 0.9799 - val_loss: 0.8909 - val_accuracy: 0.8445
Epoch 69/110
 - 3s - loss: 0.1715 - accuracy: 0.9796 - val_loss: 0.8383 - val_accuracy: 0.8358
Epoch 70/110
 - 3s - loss: 0.1686 - accuracy: 0.9808 - val_loss: 0.8212 - val_accuracy: 0.8277
Epoch 71/110
 - 3s - loss: 0.1624 - accuracy: 0.9821 - val_loss: 0.8023 - val_accuracy: 0.8460
Epoch 72/110
 - 3s - loss: 0.1661 - accuracy: 0.9805 - val_loss: 0.8585 - val_accuracy: 0.8526
Epoch 73/110
 - 3s - loss: 0.1638 - accuracy: 0.9808 - val_loss: 0.8766 - val_accuracy: 0.8299
Epoch 74/110
 - 3s - loss: 0.1976 - accuracy: 0.9724 - val_loss: 0.8160 - val_accuracy: 0.8255
Epoch 75/110
 - 3s - loss: 0.2139 - accuracy: 0.9655 - val_loss: 0.7796 - val_accuracy: 0.8401
Epoch 76/110
 - 3s - loss: 0.2081 - accuracy: 0.9673 - val_loss: 0.8065 - val_accuracy: 0.8445
Epoch 77/110
 - 3s - loss: 0.1888 - accuracy: 0.9741 - val_loss: 0.8346 - val_accuracy: 0.8372
Epoch 78/110
 - 3s - loss: 0.1911 - accuracy: 0.9701 - val_loss: 0.8926 - val_accuracy: 0.8263
Epoch 79/110
 - 3s - loss: 0.2218 - accuracy: 0.9635 - val_loss: 0.8535 - val_accuracy: 0.8423
Epoch 80/110
 - 3s - loss: 0.1973 - accuracy: 0.9710 - val_loss: 0.7405 - val_accuracy: 0.8526
Epoch 81/110
 - 3s - loss: 0.1850 - accuracy: 0.9743 - val_loss: 0.8887 - val_accuracy: 0.8299
Epoch 82/110
 - 3s - loss: 0.1694 - accuracy: 0.9794 - val_loss: 0.8084 - val_accuracy: 0.8504
Epoch 83/110
 - 3s - loss: 0.1576 - accuracy: 0.9830 - val_loss: 0.8150 - val_accuracy: 0.8518
Epoch 84/110
 - 3s - loss: 0.1572 - accuracy: 0.9816 - val_loss: 0.8413 - val_accuracy: 0.8431
Epoch 85/110
 - 3s - loss: 0.1546 - accuracy: 0.9828 - val_loss: 0.8806 - val_accuracy: 0.8474
Epoch 86/110
 - 3s - loss: 0.1555 - accuracy: 0.9828 - val_loss: 0.8460 - val_accuracy: 0.8547
Epoch 87/110
 - 3s - loss: 0.1600 - accuracy: 0.9812 - val_loss: 0.8257 - val_accuracy: 0.8482
Epoch 88/110
 - 3s - loss: 0.2380 - accuracy: 0.9640 - val_loss: 0.9054 - val_accuracy: 0.8241
Epoch 89/110
 - 3s - loss: 0.2513 - accuracy: 0.9498 - val_loss: 0.7826 - val_accuracy: 0.8423
Epoch 90/110
 - 3s - loss: 0.1818 - accuracy: 0.9741 - val_loss: 0.9072 - val_accuracy: 0.8270
Epoch 91/110
 - 3s - loss: 0.1715 - accuracy: 0.9794 - val_loss: 0.8312 - val_accuracy: 0.8350
Epoch 92/110
 - 3s - loss: 0.1594 - accuracy: 0.9816 - val_loss: 0.8867 - val_accuracy: 0.8372
Epoch 93/110
 - 3s - loss: 0.1584 - accuracy: 0.9839 - val_loss: 0.8228 - val_accuracy: 0.8496
Epoch 94/110
 - 3s - loss: 0.1702 - accuracy: 0.9779 - val_loss: 0.8747 - val_accuracy: 0.8445
Epoch 95/110
 - 3s - loss: 0.1593 - accuracy: 0.9823 - val_loss: 0.8801 - val_accuracy: 0.8394
Epoch 96/110
 - 3s - loss: 0.1538 - accuracy: 0.9828 - val_loss: 0.8801 - val_accuracy: 0.8533
Epoch 97/110
 - 3s - loss: 0.1537 - accuracy: 0.9830 - val_loss: 0.8472 - val_accuracy: 0.8394
Epoch 98/110
 - 3s - loss: 0.1646 - accuracy: 0.9790 - val_loss: 0.8331 - val_accuracy: 0.8423
Epoch 99/110
 - 3s - loss: 0.1814 - accuracy: 0.9755 - val_loss: 0.8991 - val_accuracy: 0.8380
Epoch 100/110
 - 3s - loss: 0.2038 - accuracy: 0.9701 - val_loss: 0.8780 - val_accuracy: 0.8401
Epoch 101/110
 - 3s - loss: 0.1779 - accuracy: 0.9765 - val_loss: 0.8046 - val_accuracy: 0.8387
Epoch 102/110
 - 3s - loss: 0.1668 - accuracy: 0.9777 - val_loss: 0.9000 - val_accuracy: 0.8423
Epoch 103/110
 - 2s - loss: 0.1662 - accuracy: 0.9785 - val_loss: 0.9354 - val_accuracy: 0.8270
Epoch 104/110
 - 3s - loss: 0.1574 - accuracy: 0.9830 - val_loss: 0.8349 - val_accuracy: 0.8453
Epoch 105/110
 - 3s - loss: 0.1832 - accuracy: 0.9713 - val_loss: 0.9478 - val_accuracy: 0.8394
Epoch 106/110
 - 3s - loss: 0.2016 - accuracy: 0.9697 - val_loss: 0.7725 - val_accuracy: 0.8584
Epoch 107/110
 - 3s - loss: 0.1756 - accuracy: 0.9768 - val_loss: 0.7592 - val_accuracy: 0.8474
Epoch 108/110
 - 3s - loss: 0.1685 - accuracy: 0.9777 - val_loss: 0.7715 - val_accuracy: 0.8555
Epoch 109/110
 - 3s - loss: 0.1753 - accuracy: 0.9788 - val_loss: 0.8666 - val_accuracy: 0.8299
Epoch 110/110
 - 3s - loss: 0.2038 - accuracy: 0.9686 - val_loss: 0.8369 - val_accuracy: 0.8409
------------------------------------------------------------------------
Training for fold 4 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 3s - loss: 0.1973 - accuracy: 0.9686 - val_loss: 1.0448 - val_accuracy: 0.8219
Epoch 2/110
 - 3s - loss: 0.1812 - accuracy: 0.9735 - val_loss: 0.8491 - val_accuracy: 0.8423
Epoch 3/110
 - 3s - loss: 0.1670 - accuracy: 0.9799 - val_loss: 0.8117 - val_accuracy: 0.8489
Epoch 4/110
 - 3s - loss: 0.1658 - accuracy: 0.9794 - val_loss: 0.9599 - val_accuracy: 0.8314
Epoch 5/110
 - 3s - loss: 0.1625 - accuracy: 0.9816 - val_loss: 0.8904 - val_accuracy: 0.8350
Epoch 6/110
 - 3s - loss: 0.1757 - accuracy: 0.9779 - val_loss: 0.9034 - val_accuracy: 0.8460
Epoch 7/110
 - 3s - loss: 0.1632 - accuracy: 0.9810 - val_loss: 0.9334 - val_accuracy: 0.8394
Epoch 8/110
 - 3s - loss: 0.1702 - accuracy: 0.9766 - val_loss: 0.8680 - val_accuracy: 0.8358
Epoch 9/110
 - 3s - loss: 0.1839 - accuracy: 0.9754 - val_loss: 0.9710 - val_accuracy: 0.8358
Epoch 10/110
 - 3s - loss: 0.2279 - accuracy: 0.9633 - val_loss: 0.8361 - val_accuracy: 0.8409
Epoch 11/110
 - 3s - loss: 0.1815 - accuracy: 0.9732 - val_loss: 0.8598 - val_accuracy: 0.8365
Epoch 12/110
 - 3s - loss: 0.1838 - accuracy: 0.9735 - val_loss: 0.8167 - val_accuracy: 0.8321
Epoch 13/110
 - 3s - loss: 0.1704 - accuracy: 0.9785 - val_loss: 0.8547 - val_accuracy: 0.8350
Epoch 14/110
 - 3s - loss: 0.1641 - accuracy: 0.9801 - val_loss: 0.8636 - val_accuracy: 0.8409
Epoch 15/110
 - 3s - loss: 0.1542 - accuracy: 0.9825 - val_loss: 0.8403 - val_accuracy: 0.8336
Epoch 16/110
 - 3s - loss: 0.1724 - accuracy: 0.9768 - val_loss: 0.8318 - val_accuracy: 0.8416
Epoch 17/110
 - 3s - loss: 0.1568 - accuracy: 0.9827 - val_loss: 0.8916 - val_accuracy: 0.8460
Epoch 18/110
 - 3s - loss: 0.1720 - accuracy: 0.9770 - val_loss: 0.9195 - val_accuracy: 0.8350
Epoch 19/110
 - 3s - loss: 0.1632 - accuracy: 0.9805 - val_loss: 0.8300 - val_accuracy: 0.8416
Epoch 20/110
 - 3s - loss: 0.1754 - accuracy: 0.9781 - val_loss: 0.9052 - val_accuracy: 0.8372
Epoch 21/110
 - 3s - loss: 0.1707 - accuracy: 0.9799 - val_loss: 0.9338 - val_accuracy: 0.8555
Epoch 22/110
 - 3s - loss: 0.1574 - accuracy: 0.9812 - val_loss: 0.9670 - val_accuracy: 0.8416
Epoch 23/110
 - 3s - loss: 0.1579 - accuracy: 0.9808 - val_loss: 0.9106 - val_accuracy: 0.8460
Epoch 24/110
 - 3s - loss: 0.1590 - accuracy: 0.9814 - val_loss: 0.9189 - val_accuracy: 0.8474
Epoch 25/110
 - 3s - loss: 0.1562 - accuracy: 0.9823 - val_loss: 0.9423 - val_accuracy: 0.8453
Epoch 26/110
 - 3s - loss: 0.1665 - accuracy: 0.9768 - val_loss: 0.9202 - val_accuracy: 0.8453
Epoch 27/110
 - 3s - loss: 0.1952 - accuracy: 0.9706 - val_loss: 0.9129 - val_accuracy: 0.8285
Epoch 28/110
 - 3s - loss: 0.2186 - accuracy: 0.9650 - val_loss: 1.0638 - val_accuracy: 0.8022
Epoch 29/110
 - 3s - loss: 0.2192 - accuracy: 0.9639 - val_loss: 0.7995 - val_accuracy: 0.8453
Epoch 30/110
 - 3s - loss: 0.1765 - accuracy: 0.9761 - val_loss: 0.8764 - val_accuracy: 0.8423
Epoch 31/110
 - 3s - loss: 0.1791 - accuracy: 0.9766 - val_loss: 0.8357 - val_accuracy: 0.8394
Epoch 32/110
 - 3s - loss: 0.1791 - accuracy: 0.9750 - val_loss: 0.8441 - val_accuracy: 0.8518
Epoch 33/110
 - 3s - loss: 0.1610 - accuracy: 0.9806 - val_loss: 0.8744 - val_accuracy: 0.8365
Epoch 34/110
 - 3s - loss: 0.1536 - accuracy: 0.9828 - val_loss: 0.8747 - val_accuracy: 0.8474
Epoch 35/110
 - 3s - loss: 0.1694 - accuracy: 0.9797 - val_loss: 0.8731 - val_accuracy: 0.8350
Epoch 36/110
 - 3s - loss: 0.1581 - accuracy: 0.9801 - val_loss: 0.9591 - val_accuracy: 0.8453
Epoch 37/110
 - 3s - loss: 0.1687 - accuracy: 0.9788 - val_loss: 0.8696 - val_accuracy: 0.8350
Epoch 38/110
 - 3s - loss: 0.1597 - accuracy: 0.9810 - val_loss: 0.8648 - val_accuracy: 0.8460
Epoch 39/110
 - 2s - loss: 0.1590 - accuracy: 0.9805 - val_loss: 0.9174 - val_accuracy: 0.8496
Epoch 40/110
 - 3s - loss: 0.1638 - accuracy: 0.9799 - val_loss: 1.1049 - val_accuracy: 0.8190
Epoch 41/110
 - 3s - loss: 0.1741 - accuracy: 0.9770 - val_loss: 1.0190 - val_accuracy: 0.8387
Epoch 42/110
 - 3s - loss: 0.1832 - accuracy: 0.9730 - val_loss: 0.8879 - val_accuracy: 0.8321
Epoch 43/110
 - 3s - loss: 0.1761 - accuracy: 0.9755 - val_loss: 0.9189 - val_accuracy: 0.8423
Epoch 44/110
 - 3s - loss: 0.1847 - accuracy: 0.9735 - val_loss: 1.1020 - val_accuracy: 0.8102
Epoch 45/110
 - 3s - loss: 0.1690 - accuracy: 0.9761 - val_loss: 0.8550 - val_accuracy: 0.8496
Epoch 46/110
 - 3s - loss: 0.1490 - accuracy: 0.9834 - val_loss: 0.9168 - val_accuracy: 0.8540
Epoch 47/110
 - 3s - loss: 0.1661 - accuracy: 0.9781 - val_loss: 0.9075 - val_accuracy: 0.8336
Epoch 48/110
 - 3s - loss: 0.1774 - accuracy: 0.9726 - val_loss: 0.9249 - val_accuracy: 0.8343
Epoch 49/110
 - 3s - loss: 0.1656 - accuracy: 0.9785 - val_loss: 0.9051 - val_accuracy: 0.8343
Epoch 50/110
 - 3s - loss: 0.1639 - accuracy: 0.9774 - val_loss: 0.8559 - val_accuracy: 0.8307
Epoch 51/110
 - 2s - loss: 0.1698 - accuracy: 0.9770 - val_loss: 0.8993 - val_accuracy: 0.8526
Epoch 52/110
 - 3s - loss: 0.1647 - accuracy: 0.9783 - val_loss: 0.9314 - val_accuracy: 0.8380
Epoch 53/110
 - 3s - loss: 0.1560 - accuracy: 0.9827 - val_loss: 0.8410 - val_accuracy: 0.8453
Epoch 54/110
 - 3s - loss: 0.1575 - accuracy: 0.9810 - val_loss: 0.8819 - val_accuracy: 0.8365
Epoch 55/110
 - 3s - loss: 0.1566 - accuracy: 0.9812 - val_loss: 0.9303 - val_accuracy: 0.8416
Epoch 56/110
 - 3s - loss: 0.1468 - accuracy: 0.9852 - val_loss: 0.9102 - val_accuracy: 0.8496
Epoch 57/110
 - 3s - loss: 0.1525 - accuracy: 0.9812 - val_loss: 0.9673 - val_accuracy: 0.8307
Epoch 58/110
 - 3s - loss: 0.1863 - accuracy: 0.9717 - val_loss: 0.8923 - val_accuracy: 0.8431
Epoch 59/110
 - 3s - loss: 0.1691 - accuracy: 0.9759 - val_loss: 0.7984 - val_accuracy: 0.8482
Epoch 60/110
 - 3s - loss: 0.1781 - accuracy: 0.9746 - val_loss: 0.7797 - val_accuracy: 0.8416
Epoch 61/110
 - 3s - loss: 0.1754 - accuracy: 0.9737 - val_loss: 0.8645 - val_accuracy: 0.8482
Epoch 62/110
 - 3s - loss: 0.2266 - accuracy: 0.9597 - val_loss: 0.8376 - val_accuracy: 0.8482
Epoch 63/110
 - 3s - loss: 0.2616 - accuracy: 0.9524 - val_loss: 0.9140 - val_accuracy: 0.8496
Epoch 64/110
 - 3s - loss: 0.1928 - accuracy: 0.9726 - val_loss: 0.9042 - val_accuracy: 0.8526
Epoch 65/110
 - 3s - loss: 0.1746 - accuracy: 0.9786 - val_loss: 0.8606 - val_accuracy: 0.8584
Epoch 66/110
 - 3s - loss: 0.1534 - accuracy: 0.9825 - val_loss: 0.9300 - val_accuracy: 0.8474
Epoch 67/110
 - 3s - loss: 0.1509 - accuracy: 0.9836 - val_loss: 0.9563 - val_accuracy: 0.8504
Epoch 68/110
 - 3s - loss: 0.1479 - accuracy: 0.9834 - val_loss: 0.9384 - val_accuracy: 0.8526
Epoch 69/110
 - 3s - loss: 0.1463 - accuracy: 0.9841 - val_loss: 0.9661 - val_accuracy: 0.8460
Epoch 70/110
 - 3s - loss: 0.1502 - accuracy: 0.9832 - val_loss: 0.9612 - val_accuracy: 0.8467
Epoch 71/110
 - 3s - loss: 0.1494 - accuracy: 0.9832 - val_loss: 1.0117 - val_accuracy: 0.8511
Epoch 72/110
 - 3s - loss: 0.1498 - accuracy: 0.9825 - val_loss: 0.9727 - val_accuracy: 0.8416
Epoch 73/110
 - 3s - loss: 0.1537 - accuracy: 0.9812 - val_loss: 1.0128 - val_accuracy: 0.8416
Epoch 74/110
 - 3s - loss: 0.1505 - accuracy: 0.9825 - val_loss: 1.0308 - val_accuracy: 0.8474
Epoch 75/110
 - 3s - loss: 0.1611 - accuracy: 0.9797 - val_loss: 0.9984 - val_accuracy: 0.8504
Epoch 76/110
 - 3s - loss: 0.1972 - accuracy: 0.9686 - val_loss: 0.9994 - val_accuracy: 0.8299
Epoch 77/110
 - 3s - loss: 0.2177 - accuracy: 0.9642 - val_loss: 1.0800 - val_accuracy: 0.8285
Epoch 78/110
 - 3s - loss: 0.2641 - accuracy: 0.9498 - val_loss: 0.8445 - val_accuracy: 0.8248
Epoch 79/110
 - 3s - loss: 0.2014 - accuracy: 0.9660 - val_loss: 0.8535 - val_accuracy: 0.8423
Epoch 80/110
 - 3s - loss: 0.1642 - accuracy: 0.9781 - val_loss: 0.9225 - val_accuracy: 0.8401
Epoch 81/110
 - 3s - loss: 0.1492 - accuracy: 0.9843 - val_loss: 0.8728 - val_accuracy: 0.8489
Epoch 82/110
 - 3s - loss: 0.1469 - accuracy: 0.9841 - val_loss: 0.9841 - val_accuracy: 0.8358
Epoch 83/110
 - 3s - loss: 0.1452 - accuracy: 0.9845 - val_loss: 1.0886 - val_accuracy: 0.8409
Epoch 84/110
 - 3s - loss: 0.1570 - accuracy: 0.9796 - val_loss: 0.9308 - val_accuracy: 0.8416
Epoch 85/110
 - 3s - loss: 0.1752 - accuracy: 0.9754 - val_loss: 0.9933 - val_accuracy: 0.8314
Epoch 86/110
 - 3s - loss: 0.2044 - accuracy: 0.9657 - val_loss: 0.9503 - val_accuracy: 0.8438
Epoch 87/110
 - 3s - loss: 0.1776 - accuracy: 0.9754 - val_loss: 0.9129 - val_accuracy: 0.8343
Epoch 88/110
 - 3s - loss: 0.1626 - accuracy: 0.9801 - val_loss: 0.9334 - val_accuracy: 0.8547
Epoch 89/110
 - 3s - loss: 0.1571 - accuracy: 0.9792 - val_loss: 0.9202 - val_accuracy: 0.8496
Epoch 90/110
 - 3s - loss: 0.1520 - accuracy: 0.9841 - val_loss: 0.9698 - val_accuracy: 0.8394
Epoch 91/110
 - 3s - loss: 0.1478 - accuracy: 0.9821 - val_loss: 0.9388 - val_accuracy: 0.8423
Epoch 92/110
 - 3s - loss: 0.1488 - accuracy: 0.9828 - val_loss: 0.9410 - val_accuracy: 0.8489
Epoch 93/110
 - 3s - loss: 0.1480 - accuracy: 0.9823 - val_loss: 0.9336 - val_accuracy: 0.8445
Epoch 94/110
 - 3s - loss: 0.1519 - accuracy: 0.9810 - val_loss: 0.9694 - val_accuracy: 0.8394
Epoch 95/110
 - 3s - loss: 0.1512 - accuracy: 0.9805 - val_loss: 0.9212 - val_accuracy: 0.8460
Epoch 96/110
 - 3s - loss: 0.1472 - accuracy: 0.9832 - val_loss: 0.9661 - val_accuracy: 0.8445
Epoch 97/110
 - 3s - loss: 0.1483 - accuracy: 0.9816 - val_loss: 0.9036 - val_accuracy: 0.8533
Epoch 98/110
 - 3s - loss: 0.1440 - accuracy: 0.9834 - val_loss: 0.9586 - val_accuracy: 0.8467
Epoch 99/110
 - 3s - loss: 0.1479 - accuracy: 0.9823 - val_loss: 1.0428 - val_accuracy: 0.8409
Epoch 100/110
 - 2s - loss: 0.1415 - accuracy: 0.9845 - val_loss: 0.9124 - val_accuracy: 0.8504
Epoch 101/110
 - 3s - loss: 0.1405 - accuracy: 0.9848 - val_loss: 1.1172 - val_accuracy: 0.8255
Epoch 102/110
 - 3s - loss: 0.1482 - accuracy: 0.9816 - val_loss: 0.9943 - val_accuracy: 0.8307
Epoch 103/110
 - 3s - loss: 0.1493 - accuracy: 0.9814 - val_loss: 0.9322 - val_accuracy: 0.8358
Epoch 104/110
 - 3s - loss: 0.1600 - accuracy: 0.9783 - val_loss: 0.8783 - val_accuracy: 0.8445
Epoch 105/110
 - 3s - loss: 0.1921 - accuracy: 0.9697 - val_loss: 0.8962 - val_accuracy: 0.8445
Epoch 106/110
 - 3s - loss: 0.2095 - accuracy: 0.9640 - val_loss: 0.8497 - val_accuracy: 0.8372
Epoch 107/110
 - 3s - loss: 0.1834 - accuracy: 0.9697 - val_loss: 0.9068 - val_accuracy: 0.8307
Epoch 108/110
 - 3s - loss: 0.2051 - accuracy: 0.9628 - val_loss: 0.8690 - val_accuracy: 0.8343
Epoch 109/110
 - 3s - loss: 0.1977 - accuracy: 0.9671 - val_loss: 0.7814 - val_accuracy: 0.8504
Epoch 110/110
 - 3s - loss: 0.1724 - accuracy: 0.9770 - val_loss: 0.8510 - val_accuracy: 0.8358
------------------------------------------------------------------------
Training for fold 5 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 3s - loss: 0.1798 - accuracy: 0.9737 - val_loss: 0.9383 - val_accuracy: 0.8358
Epoch 2/110
 - 3s - loss: 0.1627 - accuracy: 0.9772 - val_loss: 0.8599 - val_accuracy: 0.8380
Epoch 3/110
 - 3s - loss: 0.1543 - accuracy: 0.9812 - val_loss: 0.9387 - val_accuracy: 0.8226
Epoch 4/110
 - 3s - loss: 0.1565 - accuracy: 0.9786 - val_loss: 0.8385 - val_accuracy: 0.8511
Epoch 5/110
 - 3s - loss: 0.1528 - accuracy: 0.9817 - val_loss: 0.8926 - val_accuracy: 0.8467
Epoch 6/110
 - 2s - loss: 0.1546 - accuracy: 0.9803 - val_loss: 0.8864 - val_accuracy: 0.8372
Epoch 7/110
 - 3s - loss: 0.1460 - accuracy: 0.9825 - val_loss: 0.8440 - val_accuracy: 0.8511
Epoch 8/110
 - 3s - loss: 0.1529 - accuracy: 0.9825 - val_loss: 0.9181 - val_accuracy: 0.8394
Epoch 9/110
 - 3s - loss: 0.1665 - accuracy: 0.9763 - val_loss: 0.8469 - val_accuracy: 0.8380
Epoch 10/110
 - 3s - loss: 0.2650 - accuracy: 0.9509 - val_loss: 0.9357 - val_accuracy: 0.8263
Epoch 11/110
 - 3s - loss: 0.2962 - accuracy: 0.9416 - val_loss: 0.7218 - val_accuracy: 0.8423
Epoch 12/110
 - 3s - loss: 0.1739 - accuracy: 0.9757 - val_loss: 0.7264 - val_accuracy: 0.8482
Epoch 13/110
 - 3s - loss: 0.1454 - accuracy: 0.9836 - val_loss: 0.8021 - val_accuracy: 0.8460
Epoch 14/110
 - 3s - loss: 0.1396 - accuracy: 0.9854 - val_loss: 0.8382 - val_accuracy: 0.8511
Epoch 15/110
 - 3s - loss: 0.1376 - accuracy: 0.9845 - val_loss: 0.8025 - val_accuracy: 0.8533
Epoch 16/110
 - 3s - loss: 0.1419 - accuracy: 0.9839 - val_loss: 0.8656 - val_accuracy: 0.8526
Epoch 17/110
 - 3s - loss: 0.1376 - accuracy: 0.9859 - val_loss: 0.8417 - val_accuracy: 0.8423
Epoch 18/110
 - 3s - loss: 0.1499 - accuracy: 0.9830 - val_loss: 0.9192 - val_accuracy: 0.8482
Epoch 19/110
 - 3s - loss: 0.1446 - accuracy: 0.9825 - val_loss: 0.8057 - val_accuracy: 0.8438
Epoch 20/110
 - 3s - loss: 0.1413 - accuracy: 0.9838 - val_loss: 0.8708 - val_accuracy: 0.8511
Epoch 21/110
 - 3s - loss: 0.1405 - accuracy: 0.9841 - val_loss: 0.8575 - val_accuracy: 0.8460
Epoch 22/110
 - 3s - loss: 0.1481 - accuracy: 0.9817 - val_loss: 0.8884 - val_accuracy: 0.8445
Epoch 23/110
 - 3s - loss: 0.1566 - accuracy: 0.9788 - val_loss: 0.8979 - val_accuracy: 0.8365
Epoch 24/110
 - 3s - loss: 0.1743 - accuracy: 0.9746 - val_loss: 0.8139 - val_accuracy: 0.8394
Epoch 25/110
 - 3s - loss: 0.1898 - accuracy: 0.9690 - val_loss: 0.8117 - val_accuracy: 0.8343
Epoch 26/110
 - 3s - loss: 0.1582 - accuracy: 0.9801 - val_loss: 0.8094 - val_accuracy: 0.8336
Epoch 27/110
 - 3s - loss: 0.1570 - accuracy: 0.9803 - val_loss: 0.8630 - val_accuracy: 0.8336
Epoch 28/110
 - 3s - loss: 0.1603 - accuracy: 0.9786 - val_loss: 0.8646 - val_accuracy: 0.8431
Epoch 29/110
 - 3s - loss: 0.1459 - accuracy: 0.9825 - val_loss: 0.7943 - val_accuracy: 0.8482
Epoch 30/110
 - 3s - loss: 0.1395 - accuracy: 0.9843 - val_loss: 0.8186 - val_accuracy: 0.8504
Epoch 31/110
 - 3s - loss: 0.1539 - accuracy: 0.9786 - val_loss: 0.8607 - val_accuracy: 0.8401
Epoch 32/110
 - 3s - loss: 0.1591 - accuracy: 0.9772 - val_loss: 0.8649 - val_accuracy: 0.8350
Epoch 33/110
 - 2s - loss: 0.1610 - accuracy: 0.9759 - val_loss: 0.8236 - val_accuracy: 0.8453
Epoch 34/110
 - 3s - loss: 0.1592 - accuracy: 0.9772 - val_loss: 0.8496 - val_accuracy: 0.8394
Epoch 35/110
 - 3s - loss: 0.1619 - accuracy: 0.9768 - val_loss: 0.8999 - val_accuracy: 0.8350
Epoch 36/110
 - 3s - loss: 0.1670 - accuracy: 0.9779 - val_loss: 0.9298 - val_accuracy: 0.8489
Epoch 37/110
 - 3s - loss: 0.1461 - accuracy: 0.9832 - val_loss: 0.9218 - val_accuracy: 0.8380
Epoch 38/110
 - 3s - loss: 0.1475 - accuracy: 0.9823 - val_loss: 0.8652 - val_accuracy: 0.8482
Epoch 39/110
 - 2s - loss: 0.1502 - accuracy: 0.9814 - val_loss: 0.8749 - val_accuracy: 0.8387
Epoch 40/110
 - 3s - loss: 0.1647 - accuracy: 0.9779 - val_loss: 0.8429 - val_accuracy: 0.8387
Epoch 41/110
 - 3s - loss: 0.1663 - accuracy: 0.9746 - val_loss: 0.8166 - val_accuracy: 0.8423
Epoch 42/110
 - 3s - loss: 0.1762 - accuracy: 0.9744 - val_loss: 0.9180 - val_accuracy: 0.8380
Epoch 43/110
 - 3s - loss: 0.1776 - accuracy: 0.9708 - val_loss: 0.8358 - val_accuracy: 0.8504
Epoch 44/110
 - 2s - loss: 0.1586 - accuracy: 0.9772 - val_loss: 0.8046 - val_accuracy: 0.8460
Epoch 45/110
 - 3s - loss: 0.1439 - accuracy: 0.9838 - val_loss: 0.9239 - val_accuracy: 0.8336
Epoch 46/110
 - 3s - loss: 0.1449 - accuracy: 0.9814 - val_loss: 0.8211 - val_accuracy: 0.8467
Epoch 47/110
 - 3s - loss: 0.1632 - accuracy: 0.9783 - val_loss: 0.8167 - val_accuracy: 0.8416
Epoch 48/110
 - 3s - loss: 0.1623 - accuracy: 0.9759 - val_loss: 0.8835 - val_accuracy: 0.8372
Epoch 49/110
 - 3s - loss: 0.1621 - accuracy: 0.9768 - val_loss: 0.8047 - val_accuracy: 0.8482
Epoch 50/110
 - 3s - loss: 0.1707 - accuracy: 0.9763 - val_loss: 0.8064 - val_accuracy: 0.8445
Epoch 51/110
 - 3s - loss: 0.1678 - accuracy: 0.9770 - val_loss: 0.7907 - val_accuracy: 0.8401
Epoch 52/110
 - 3s - loss: 0.1575 - accuracy: 0.9786 - val_loss: 0.9179 - val_accuracy: 0.8307
Epoch 53/110
 - 3s - loss: 0.1438 - accuracy: 0.9827 - val_loss: 0.8812 - val_accuracy: 0.8474
Epoch 54/110
 - 3s - loss: 0.1481 - accuracy: 0.9812 - val_loss: 0.8967 - val_accuracy: 0.8511
Epoch 55/110
 - 3s - loss: 0.1691 - accuracy: 0.9746 - val_loss: 0.8610 - val_accuracy: 0.8533
Epoch 56/110
 - 3s - loss: 0.1611 - accuracy: 0.9768 - val_loss: 1.0062 - val_accuracy: 0.8438
Epoch 57/110
 - 3s - loss: 0.1500 - accuracy: 0.9817 - val_loss: 0.9922 - val_accuracy: 0.8504
Epoch 58/110
 - 2s - loss: 0.1435 - accuracy: 0.9834 - val_loss: 1.0338 - val_accuracy: 0.8511
Epoch 59/110
 - 3s - loss: 0.1429 - accuracy: 0.9823 - val_loss: 0.9895 - val_accuracy: 0.8453
Epoch 60/110
 - 3s - loss: 0.1354 - accuracy: 0.9854 - val_loss: 0.9984 - val_accuracy: 0.8496
Epoch 61/110
 - 3s - loss: 0.1324 - accuracy: 0.9859 - val_loss: 0.9843 - val_accuracy: 0.8489
Epoch 62/110
 - 3s - loss: 0.1377 - accuracy: 0.9843 - val_loss: 1.0414 - val_accuracy: 0.8482
Epoch 63/110
 - 3s - loss: 0.1484 - accuracy: 0.9783 - val_loss: 1.0085 - val_accuracy: 0.8409
Epoch 64/110
 - 3s - loss: 0.1769 - accuracy: 0.9723 - val_loss: 1.0775 - val_accuracy: 0.8474
Epoch 65/110
 - 3s - loss: 0.2605 - accuracy: 0.9502 - val_loss: 0.9908 - val_accuracy: 0.8051
Epoch 66/110
 - 3s - loss: 0.2420 - accuracy: 0.9533 - val_loss: 0.8026 - val_accuracy: 0.8438
Epoch 67/110
 - 3s - loss: 0.2112 - accuracy: 0.9635 - val_loss: 0.8427 - val_accuracy: 0.8518
Epoch 68/110
 - 3s - loss: 0.2261 - accuracy: 0.9673 - val_loss: 0.8003 - val_accuracy: 0.8511
Epoch 69/110
 - 3s - loss: 0.1477 - accuracy: 0.9816 - val_loss: 0.8679 - val_accuracy: 0.8474
Epoch 70/110
 - 3s - loss: 0.1398 - accuracy: 0.9854 - val_loss: 0.8557 - val_accuracy: 0.8511
Epoch 71/110
 - 2s - loss: 0.1366 - accuracy: 0.9845 - val_loss: 0.8852 - val_accuracy: 0.8474
Epoch 72/110
 - 3s - loss: 0.1383 - accuracy: 0.9848 - val_loss: 0.8956 - val_accuracy: 0.8482
Epoch 73/110
 - 2s - loss: 0.1372 - accuracy: 0.9845 - val_loss: 0.8599 - val_accuracy: 0.8511
Epoch 74/110
 - 2s - loss: 0.1316 - accuracy: 0.9859 - val_loss: 0.8270 - val_accuracy: 0.8489
Epoch 75/110
 - 3s - loss: 0.1337 - accuracy: 0.9848 - val_loss: 0.8981 - val_accuracy: 0.8533
Epoch 76/110
 - 3s - loss: 0.1339 - accuracy: 0.9847 - val_loss: 0.8986 - val_accuracy: 0.8511
Epoch 77/110
 - 3s - loss: 0.1307 - accuracy: 0.9847 - val_loss: 0.8739 - val_accuracy: 0.8423
Epoch 78/110
 - 3s - loss: 0.1286 - accuracy: 0.9867 - val_loss: 0.8988 - val_accuracy: 0.8423
Epoch 79/110
 - 2s - loss: 0.1303 - accuracy: 0.9847 - val_loss: 0.9035 - val_accuracy: 0.8409
Epoch 80/110
 - 2s - loss: 0.1457 - accuracy: 0.9812 - val_loss: 0.9171 - val_accuracy: 0.8423
Epoch 81/110
 - 3s - loss: 0.1481 - accuracy: 0.9796 - val_loss: 0.8648 - val_accuracy: 0.8394
Epoch 82/110
 - 3s - loss: 0.2317 - accuracy: 0.9509 - val_loss: 0.9125 - val_accuracy: 0.8234
Epoch 83/110
 - 3s - loss: 0.2487 - accuracy: 0.9467 - val_loss: 0.9292 - val_accuracy: 0.8234
Epoch 84/110
 - 3s - loss: 0.2079 - accuracy: 0.9633 - val_loss: 0.8272 - val_accuracy: 0.8474
Epoch 85/110
 - 3s - loss: 0.1621 - accuracy: 0.9775 - val_loss: 0.8256 - val_accuracy: 0.8401
Epoch 86/110
 - 3s - loss: 0.1534 - accuracy: 0.9812 - val_loss: 0.8588 - val_accuracy: 0.8431
Epoch 87/110
 - 3s - loss: 0.1366 - accuracy: 0.9852 - val_loss: 0.8804 - val_accuracy: 0.8533
Epoch 88/110
 - 3s - loss: 0.1317 - accuracy: 0.9859 - val_loss: 0.9124 - val_accuracy: 0.8482
Epoch 89/110
 - 3s - loss: 0.1363 - accuracy: 0.9847 - val_loss: 0.9351 - val_accuracy: 0.8533
Epoch 90/110
 - 3s - loss: 0.1391 - accuracy: 0.9838 - val_loss: 0.8587 - val_accuracy: 0.8606
Epoch 91/110
 - 3s - loss: 0.1329 - accuracy: 0.9856 - val_loss: 0.9116 - val_accuracy: 0.8496
Epoch 92/110
 - 3s - loss: 0.1322 - accuracy: 0.9854 - val_loss: 0.8884 - val_accuracy: 0.8489
Epoch 93/110
 - 3s - loss: 0.1382 - accuracy: 0.9832 - val_loss: 0.9091 - val_accuracy: 0.8540
Epoch 94/110
 - 2s - loss: 0.1610 - accuracy: 0.9783 - val_loss: 0.9239 - val_accuracy: 0.8343
Epoch 95/110
 - 2s - loss: 0.1524 - accuracy: 0.9806 - val_loss: 0.7451 - val_accuracy: 0.8496
Epoch 96/110
 - 2s - loss: 0.1566 - accuracy: 0.9774 - val_loss: 0.8951 - val_accuracy: 0.8489
Epoch 97/110
 - 3s - loss: 0.1991 - accuracy: 0.9660 - val_loss: 0.8353 - val_accuracy: 0.8358
Epoch 98/110
 - 3s - loss: 0.1921 - accuracy: 0.9653 - val_loss: 0.8232 - val_accuracy: 0.8409
Epoch 99/110
 - 3s - loss: 0.1770 - accuracy: 0.9706 - val_loss: 0.8129 - val_accuracy: 0.8401
Epoch 100/110
 - 3s - loss: 0.1601 - accuracy: 0.9781 - val_loss: 0.8440 - val_accuracy: 0.8409
Epoch 101/110
 - 3s - loss: 0.1464 - accuracy: 0.9819 - val_loss: 0.8377 - val_accuracy: 0.8474
Epoch 102/110
 - 2s - loss: 0.1495 - accuracy: 0.9796 - val_loss: 0.8834 - val_accuracy: 0.8540
Epoch 103/110
 - 3s - loss: 0.1594 - accuracy: 0.9785 - val_loss: 0.8258 - val_accuracy: 0.8504
Epoch 104/110
 - 3s - loss: 0.1469 - accuracy: 0.9836 - val_loss: 0.8653 - val_accuracy: 0.8496
Epoch 105/110
 - 3s - loss: 0.1378 - accuracy: 0.9845 - val_loss: 0.8618 - val_accuracy: 0.8423
Epoch 106/110
 - 2s - loss: 0.1337 - accuracy: 0.9859 - val_loss: 0.8875 - val_accuracy: 0.8358
Epoch 107/110
 - 2s - loss: 0.1386 - accuracy: 0.9836 - val_loss: 0.8851 - val_accuracy: 0.8423
Epoch 108/110
 - 2s - loss: 0.1414 - accuracy: 0.9823 - val_loss: 0.8606 - val_accuracy: 0.8401
Epoch 109/110
 - 2s - loss: 0.1595 - accuracy: 0.9761 - val_loss: 0.9360 - val_accuracy: 0.8219
Epoch 110/110
 - 3s - loss: 0.1618 - accuracy: 0.9739 - val_loss: 0.8482 - val_accuracy: 0.8460
------------------------------------------------------------------------
Score per fold
------------------------------------------------------------------------
Score for fold 1
Accuracy_Train: 21.36%
Accuracy_Test: 20.74%
Loss_Train: 42.57
Loss_Test: 42.50
------------------------------------------------------------------------
Score for fold 2
Accuracy_Train: 23.34%
Accuracy_Test: 24.30%
Loss_Train: 44.76
Loss_Test: 44.20
------------------------------------------------------------------------
Score for fold 3
Accuracy_Train: 21.31%
Accuracy_Test: 20.97%
Loss_Train: 12.45
Loss_Test: 12.55
------------------------------------------------------------------------
Score for fold 4
Accuracy_Train: 25.41%
Accuracy_Test: 25.76%
Loss_Train: 10.04
Loss_Test: 9.70
------------------------------------------------------------------------
Score for fold 5
Accuracy_Train: 29.04%
Accuracy_Test: 29.15%
Loss_Train: 33.82
Loss_Test: 33.54
------------------------------------------------------------------------
Average scores for all folds:
Average_Accuracy_Train: 24.09%
	-> (+- 2.8998594174548953 )
Average_Accuracy_Test: 24.18%
	-> (+- 3.141632900731146 )
Average_Loss_Train: 28.73
	-> (+- 14.75659348673861 )
Average_Loss_Test: 28.50
	-> (+- 14.66954211323195 )
------------------------------------------------------------------------
