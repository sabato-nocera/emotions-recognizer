Dataset used: ../../datasets/full_dataset_without_humidity.csv 

   Temperature  Sound  Heartbeat   X1  ...    Y2     Z2  Classification  Feedback
0           32      1         60 -680  ... -7424 -15596             100     Happy
1           32      1         60 -780  ... -7408 -15628             100     Happy
2           -1      1         60   -1  ... -7276 -15612             100     Happy
3           -1     -1         60   -1  ...    -1     -1             100     Happy
4           32      1         60 -860  ... -7340 -15720             100     Happy

[5 rows x 11 columns]

Objservations: 8560
Reshaping:  ((6848, 10), (6848, 4), (1712, 10), (1712, 4))  -> ((6848, 10, 1), (6848, 4), (1712, 10, 1), (1712, 4))

Layers:

{'batch_input_shape': (None, 10, 1), 'dtype': 'float32', 'sparse': False, 'name': 'input_25'} 

{'name': 'conv1d_505', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_457', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_457', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_506', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_458', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_458', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_507', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_459', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_217', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_459', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_508', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_460', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_460', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_509', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_461', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_218', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_461', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_510', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_462', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_462', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_511', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_463', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_219', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_463', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_512', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_464', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_464', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_513', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_514', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_465', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_220', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_465', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_515', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_466', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_466', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_516', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_467', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_221', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_467', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_517', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_468', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_468', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_518', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_469', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_222', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_469', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_519', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_470', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_470', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_520', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_521', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_471', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_223', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_471', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_522', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_472', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_472', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_523', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_473', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_224', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_473', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_524', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_474', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_474', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_525', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_475', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_225', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_475', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'average_pooling1d_25', 'trainable': True, 'dtype': 'float32', 'strides': (1,), 'pool_size': (1,), 'padding': 'valid', 'data_format': 'channels_last'} 

{'name': 'flatten_25', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'} 

{'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 7s - loss: 1.5948 - accuracy: 0.4668 - val_loss: 1.9575 - val_accuracy: 0.3562
Epoch 2/110
 - 3s - loss: 1.1631 - accuracy: 0.5836 - val_loss: 1.3696 - val_accuracy: 0.5124
Epoch 3/110
 - 3s - loss: 1.0579 - accuracy: 0.6271 - val_loss: 1.2198 - val_accuracy: 0.5635
Epoch 4/110
 - 3s - loss: 0.9918 - accuracy: 0.6621 - val_loss: 1.2077 - val_accuracy: 0.5701
Epoch 5/110
 - 3s - loss: 0.9331 - accuracy: 0.6906 - val_loss: 1.1969 - val_accuracy: 0.5810
Epoch 6/110
 - 3s - loss: 0.9016 - accuracy: 0.7026 - val_loss: 1.2392 - val_accuracy: 0.5708
Epoch 7/110
 - 3s - loss: 0.8831 - accuracy: 0.7068 - val_loss: 1.2784 - val_accuracy: 0.5715
Epoch 8/110
 - 3s - loss: 0.8814 - accuracy: 0.7160 - val_loss: 1.2684 - val_accuracy: 0.5686
Epoch 9/110
 - 3s - loss: 0.8683 - accuracy: 0.7171 - val_loss: 1.1801 - val_accuracy: 0.6109
Epoch 10/110
 - 3s - loss: 0.8363 - accuracy: 0.7331 - val_loss: 1.1870 - val_accuracy: 0.6051
Epoch 11/110
 - 3s - loss: 0.8628 - accuracy: 0.7152 - val_loss: 1.2296 - val_accuracy: 0.5876
Epoch 12/110
 - 3s - loss: 0.8718 - accuracy: 0.7099 - val_loss: 1.2160 - val_accuracy: 0.5978
Epoch 13/110
 - 3s - loss: 0.8395 - accuracy: 0.7205 - val_loss: 1.1982 - val_accuracy: 0.6146
Epoch 14/110
 - 3s - loss: 0.7917 - accuracy: 0.7432 - val_loss: 1.2671 - val_accuracy: 0.5679
Epoch 15/110
 - 3s - loss: 0.7866 - accuracy: 0.7426 - val_loss: 1.1966 - val_accuracy: 0.5993
Epoch 16/110
 - 3s - loss: 0.7867 - accuracy: 0.7479 - val_loss: 1.3319 - val_accuracy: 0.5745
Epoch 17/110
 - 3s - loss: 0.7786 - accuracy: 0.7559 - val_loss: 1.3353 - val_accuracy: 0.5657
Epoch 18/110
 - 3s - loss: 0.7767 - accuracy: 0.7506 - val_loss: 1.3282 - val_accuracy: 0.5839
Epoch 19/110
 - 3s - loss: 0.7925 - accuracy: 0.7393 - val_loss: 1.3508 - val_accuracy: 0.5796
Epoch 20/110
 - 3s - loss: 0.8028 - accuracy: 0.7388 - val_loss: 1.2631 - val_accuracy: 0.5869
Epoch 21/110
 - 3s - loss: 0.7982 - accuracy: 0.7380 - val_loss: 1.1929 - val_accuracy: 0.5964
Epoch 22/110
 - 3s - loss: 0.7903 - accuracy: 0.7472 - val_loss: 1.1880 - val_accuracy: 0.6117
Epoch 23/110
 - 3s - loss: 0.7504 - accuracy: 0.7568 - val_loss: 1.1764 - val_accuracy: 0.6088
Epoch 24/110
 - 3s - loss: 0.7377 - accuracy: 0.7694 - val_loss: 1.2147 - val_accuracy: 0.6139
Epoch 25/110
 - 3s - loss: 0.7136 - accuracy: 0.7716 - val_loss: 1.2196 - val_accuracy: 0.6153
Epoch 26/110
 - 3s - loss: 0.7070 - accuracy: 0.7753 - val_loss: 1.2196 - val_accuracy: 0.6124
Epoch 27/110
 - 3s - loss: 0.7065 - accuracy: 0.7735 - val_loss: 1.2418 - val_accuracy: 0.6029
Epoch 28/110
 - 3s - loss: 0.7094 - accuracy: 0.7736 - val_loss: 1.2823 - val_accuracy: 0.5964
Epoch 29/110
 - 3s - loss: 0.7025 - accuracy: 0.7788 - val_loss: 1.2042 - val_accuracy: 0.6401
Epoch 30/110
 - 3s - loss: 0.6928 - accuracy: 0.7806 - val_loss: 1.2216 - val_accuracy: 0.6131
Epoch 31/110
 - 3s - loss: 0.6880 - accuracy: 0.7879 - val_loss: 1.1890 - val_accuracy: 0.6226
Epoch 32/110
 - 3s - loss: 0.6744 - accuracy: 0.7897 - val_loss: 1.2159 - val_accuracy: 0.6277
Epoch 33/110
 - 3s - loss: 0.6310 - accuracy: 0.8091 - val_loss: 1.2747 - val_accuracy: 0.6109
Epoch 34/110
 - 3s - loss: 0.6180 - accuracy: 0.8120 - val_loss: 1.2004 - val_accuracy: 0.6387
Epoch 35/110
 - 3s - loss: 0.6262 - accuracy: 0.8089 - val_loss: 1.1803 - val_accuracy: 0.6467
Epoch 36/110
 - 3s - loss: 0.6466 - accuracy: 0.7970 - val_loss: 1.1821 - val_accuracy: 0.6423
Epoch 37/110
 - 3s - loss: 0.6323 - accuracy: 0.8118 - val_loss: 1.2735 - val_accuracy: 0.6197
Epoch 38/110
 - 3s - loss: 0.6301 - accuracy: 0.8101 - val_loss: 1.2358 - val_accuracy: 0.6219
Epoch 39/110
 - 3s - loss: 0.6149 - accuracy: 0.8138 - val_loss: 1.2161 - val_accuracy: 0.6453
Epoch 40/110
 - 3s - loss: 0.5934 - accuracy: 0.8176 - val_loss: 1.2031 - val_accuracy: 0.6197
Epoch 41/110
 - 3s - loss: 0.5811 - accuracy: 0.8308 - val_loss: 1.2856 - val_accuracy: 0.6219
Epoch 42/110
 - 3s - loss: 0.5911 - accuracy: 0.8251 - val_loss: 1.2733 - val_accuracy: 0.6241
Epoch 43/110
 - 3s - loss: 0.5751 - accuracy: 0.8352 - val_loss: 1.2567 - val_accuracy: 0.6394
Epoch 44/110
 - 3s - loss: 0.5516 - accuracy: 0.8421 - val_loss: 1.3208 - val_accuracy: 0.6153
Epoch 45/110
 - 3s - loss: 0.5770 - accuracy: 0.8373 - val_loss: 1.2940 - val_accuracy: 0.6350
Epoch 46/110
 - 3s - loss: 0.5623 - accuracy: 0.8394 - val_loss: 1.2943 - val_accuracy: 0.6255
Epoch 47/110
 - 3s - loss: 0.5511 - accuracy: 0.8406 - val_loss: 1.3605 - val_accuracy: 0.6066
Epoch 48/110
 - 3s - loss: 0.5500 - accuracy: 0.8470 - val_loss: 1.3272 - val_accuracy: 0.6299
Epoch 49/110
 - 3s - loss: 0.5437 - accuracy: 0.8478 - val_loss: 1.2936 - val_accuracy: 0.6299
Epoch 50/110
 - 3s - loss: 0.5443 - accuracy: 0.8545 - val_loss: 1.2451 - val_accuracy: 0.6453
Epoch 51/110
 - 3s - loss: 0.5281 - accuracy: 0.8541 - val_loss: 1.2125 - val_accuracy: 0.6438
Epoch 52/110
 - 3s - loss: 0.5298 - accuracy: 0.8551 - val_loss: 1.2659 - val_accuracy: 0.6526
Epoch 53/110
 - 3s - loss: 0.5003 - accuracy: 0.8686 - val_loss: 1.2743 - val_accuracy: 0.6642
Epoch 54/110
 - 3s - loss: 0.5110 - accuracy: 0.8618 - val_loss: 1.3422 - val_accuracy: 0.6657
Epoch 55/110
 - 3s - loss: 0.5038 - accuracy: 0.8596 - val_loss: 1.3799 - val_accuracy: 0.6555
Epoch 56/110
 - 3s - loss: 0.4839 - accuracy: 0.8717 - val_loss: 1.3558 - val_accuracy: 0.6708
Epoch 57/110
 - 3s - loss: 0.5049 - accuracy: 0.8636 - val_loss: 1.4162 - val_accuracy: 0.6518
Epoch 58/110
 - 3s - loss: 0.4995 - accuracy: 0.8644 - val_loss: 1.4280 - val_accuracy: 0.6431
Epoch 59/110
 - 3s - loss: 0.5097 - accuracy: 0.8669 - val_loss: 1.3676 - val_accuracy: 0.6635
Epoch 60/110
 - 3s - loss: 0.4815 - accuracy: 0.8746 - val_loss: 1.3953 - val_accuracy: 0.6642
Epoch 61/110
 - 3s - loss: 0.4900 - accuracy: 0.8777 - val_loss: 1.3786 - val_accuracy: 0.6693
Epoch 62/110
 - 3s - loss: 0.4574 - accuracy: 0.8872 - val_loss: 1.3867 - val_accuracy: 0.6752
Epoch 63/110
 - 3s - loss: 0.4824 - accuracy: 0.8751 - val_loss: 1.4261 - val_accuracy: 0.6766
Epoch 64/110
 - 3s - loss: 0.4454 - accuracy: 0.8934 - val_loss: 1.3242 - val_accuracy: 0.6657
Epoch 65/110
 - 3s - loss: 0.4449 - accuracy: 0.8885 - val_loss: 1.4535 - val_accuracy: 0.6635
Epoch 66/110
 - 3s - loss: 0.4291 - accuracy: 0.8954 - val_loss: 1.5158 - val_accuracy: 0.6518
Epoch 67/110
 - 3s - loss: 0.4561 - accuracy: 0.8917 - val_loss: 1.4174 - val_accuracy: 0.6781
Epoch 68/110
 - 3s - loss: 0.4467 - accuracy: 0.8932 - val_loss: 1.4936 - val_accuracy: 0.6372
Epoch 69/110
 - 3s - loss: 0.4227 - accuracy: 0.8992 - val_loss: 1.4741 - val_accuracy: 0.6562
Epoch 70/110
 - 3s - loss: 0.4194 - accuracy: 0.9069 - val_loss: 1.5632 - val_accuracy: 0.6496
Epoch 71/110
 - 3s - loss: 0.4307 - accuracy: 0.9012 - val_loss: 1.5427 - val_accuracy: 0.6380
Epoch 72/110
 - 3s - loss: 0.4047 - accuracy: 0.9091 - val_loss: 1.5029 - val_accuracy: 0.6474
Epoch 73/110
 - 3s - loss: 0.4424 - accuracy: 0.8939 - val_loss: 1.4948 - val_accuracy: 0.6474
Epoch 74/110
 - 3s - loss: 0.3958 - accuracy: 0.9155 - val_loss: 1.5196 - val_accuracy: 0.6387
Epoch 75/110
 - 3s - loss: 0.4070 - accuracy: 0.9085 - val_loss: 1.5304 - val_accuracy: 0.6635
Epoch 76/110
 - 3s - loss: 0.4160 - accuracy: 0.9034 - val_loss: 1.6963 - val_accuracy: 0.6445
Epoch 77/110
 - 3s - loss: 0.4216 - accuracy: 0.9034 - val_loss: 1.5931 - val_accuracy: 0.6504
Epoch 78/110
 - 3s - loss: 0.4055 - accuracy: 0.9122 - val_loss: 1.5759 - val_accuracy: 0.6723
Epoch 79/110
 - 3s - loss: 0.4015 - accuracy: 0.9116 - val_loss: 1.5794 - val_accuracy: 0.6526
Epoch 80/110
 - 3s - loss: 0.4056 - accuracy: 0.9109 - val_loss: 1.5983 - val_accuracy: 0.6701
Epoch 81/110
 - 3s - loss: 0.3945 - accuracy: 0.9157 - val_loss: 1.6203 - val_accuracy: 0.6701
Epoch 82/110
 - 3s - loss: 0.3851 - accuracy: 0.9211 - val_loss: 1.5419 - val_accuracy: 0.6839
Epoch 83/110
 - 3s - loss: 0.3909 - accuracy: 0.9140 - val_loss: 1.5633 - val_accuracy: 0.6861
Epoch 84/110
 - 3s - loss: 0.4149 - accuracy: 0.9074 - val_loss: 1.6604 - val_accuracy: 0.6467
Epoch 85/110
 - 3s - loss: 0.3948 - accuracy: 0.9177 - val_loss: 1.3981 - val_accuracy: 0.6788
Epoch 86/110
 - 3s - loss: 0.4042 - accuracy: 0.9142 - val_loss: 1.5935 - val_accuracy: 0.6796
Epoch 87/110
 - 3s - loss: 0.3732 - accuracy: 0.9239 - val_loss: 1.5274 - val_accuracy: 0.6891
Epoch 88/110
 - 3s - loss: 0.4075 - accuracy: 0.9142 - val_loss: 1.5137 - val_accuracy: 0.6796
Epoch 89/110
 - 3s - loss: 0.3792 - accuracy: 0.9202 - val_loss: 1.5683 - val_accuracy: 0.6679
Epoch 90/110
 - 3s - loss: 0.3526 - accuracy: 0.9314 - val_loss: 1.6210 - val_accuracy: 0.6693
Epoch 91/110
 - 3s - loss: 0.3540 - accuracy: 0.9323 - val_loss: 1.6502 - val_accuracy: 0.6620
Epoch 92/110
 - 3s - loss: 0.3521 - accuracy: 0.9306 - val_loss: 1.5332 - val_accuracy: 0.6737
Epoch 93/110
 - 3s - loss: 0.3343 - accuracy: 0.9394 - val_loss: 1.6155 - val_accuracy: 0.6679
Epoch 94/110
 - 3s - loss: 0.3433 - accuracy: 0.9341 - val_loss: 1.6180 - val_accuracy: 0.6788
Epoch 95/110
 - 3s - loss: 0.3459 - accuracy: 0.9361 - val_loss: 1.6280 - val_accuracy: 0.6672
Epoch 96/110
 - 3s - loss: 0.3659 - accuracy: 0.9266 - val_loss: 1.5751 - val_accuracy: 0.6839
Epoch 97/110
 - 3s - loss: 0.3755 - accuracy: 0.9261 - val_loss: 1.5366 - val_accuracy: 0.6730
Epoch 98/110
 - 3s - loss: 0.3340 - accuracy: 0.9365 - val_loss: 1.5858 - val_accuracy: 0.6715
Epoch 99/110
 - 3s - loss: 0.3485 - accuracy: 0.9339 - val_loss: 1.5493 - val_accuracy: 0.6737
Epoch 100/110
 - 3s - loss: 0.3633 - accuracy: 0.9252 - val_loss: 1.6327 - val_accuracy: 0.6606
Epoch 101/110
 - 3s - loss: 0.3725 - accuracy: 0.9295 - val_loss: 1.6777 - val_accuracy: 0.6453
Epoch 102/110
 - 3s - loss: 0.3807 - accuracy: 0.9264 - val_loss: 1.6330 - val_accuracy: 0.6489
Epoch 103/110
 - 3s - loss: 0.3429 - accuracy: 0.9368 - val_loss: 1.4910 - val_accuracy: 0.6839
Epoch 104/110
 - 3s - loss: 0.3179 - accuracy: 0.9454 - val_loss: 1.5300 - val_accuracy: 0.6964
Epoch 105/110
 - 3s - loss: 0.3207 - accuracy: 0.9476 - val_loss: 1.5533 - val_accuracy: 0.6912
Epoch 106/110
 - 3s - loss: 0.3503 - accuracy: 0.9401 - val_loss: 1.5592 - val_accuracy: 0.6788
Epoch 107/110
 - 3s - loss: 0.3402 - accuracy: 0.9361 - val_loss: 1.5831 - val_accuracy: 0.6759
Epoch 108/110
 - 3s - loss: 0.3308 - accuracy: 0.9412 - val_loss: 1.5614 - val_accuracy: 0.6672
Epoch 109/110
 - 3s - loss: 0.3488 - accuracy: 0.9412 - val_loss: 1.6520 - val_accuracy: 0.6679
Epoch 110/110
 - 3s - loss: 0.3500 - accuracy: 0.9370 - val_loss: 1.5704 - val_accuracy: 0.6781

Number of filters: 16 , Kernel Size: 3 , Strides: 1 Batch Normalization: True , Conv_First: True , Depth Value: 20

Fit: epochs= 110 , batch_size= 64 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "model_25"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_25 (InputLayer)           (None, 10, 1)        0                                            
__________________________________________________________________________________________________
conv1d_505 (Conv1D)             (None, 10, 16)       64          input_25[0][0]                   
__________________________________________________________________________________________________
batch_normalization_457 (BatchN (None, 10, 16)       64          conv1d_505[0][0]                 
__________________________________________________________________________________________________
activation_457 (Activation)     (None, 10, 16)       0           batch_normalization_457[0][0]    
__________________________________________________________________________________________________
conv1d_506 (Conv1D)             (None, 10, 16)       784         activation_457[0][0]             
__________________________________________________________________________________________________
batch_normalization_458 (BatchN (None, 10, 16)       64          conv1d_506[0][0]                 
__________________________________________________________________________________________________
activation_458 (Activation)     (None, 10, 16)       0           batch_normalization_458[0][0]    
__________________________________________________________________________________________________
conv1d_507 (Conv1D)             (None, 10, 16)       784         activation_458[0][0]             
__________________________________________________________________________________________________
batch_normalization_459 (BatchN (None, 10, 16)       64          conv1d_507[0][0]                 
__________________________________________________________________________________________________
add_217 (Add)                   (None, 10, 16)       0           activation_457[0][0]             
                                                                 batch_normalization_459[0][0]    
__________________________________________________________________________________________________
activation_459 (Activation)     (None, 10, 16)       0           add_217[0][0]                    
__________________________________________________________________________________________________
conv1d_508 (Conv1D)             (None, 10, 16)       784         activation_459[0][0]             
__________________________________________________________________________________________________
batch_normalization_460 (BatchN (None, 10, 16)       64          conv1d_508[0][0]                 
__________________________________________________________________________________________________
activation_460 (Activation)     (None, 10, 16)       0           batch_normalization_460[0][0]    
__________________________________________________________________________________________________
conv1d_509 (Conv1D)             (None, 10, 16)       784         activation_460[0][0]             
__________________________________________________________________________________________________
batch_normalization_461 (BatchN (None, 10, 16)       64          conv1d_509[0][0]                 
__________________________________________________________________________________________________
add_218 (Add)                   (None, 10, 16)       0           activation_459[0][0]             
                                                                 batch_normalization_461[0][0]    
__________________________________________________________________________________________________
activation_461 (Activation)     (None, 10, 16)       0           add_218[0][0]                    
__________________________________________________________________________________________________
conv1d_510 (Conv1D)             (None, 10, 16)       784         activation_461[0][0]             
__________________________________________________________________________________________________
batch_normalization_462 (BatchN (None, 10, 16)       64          conv1d_510[0][0]                 
__________________________________________________________________________________________________
activation_462 (Activation)     (None, 10, 16)       0           batch_normalization_462[0][0]    
__________________________________________________________________________________________________
conv1d_511 (Conv1D)             (None, 10, 16)       784         activation_462[0][0]             
__________________________________________________________________________________________________
batch_normalization_463 (BatchN (None, 10, 16)       64          conv1d_511[0][0]                 
__________________________________________________________________________________________________
add_219 (Add)                   (None, 10, 16)       0           activation_461[0][0]             
                                                                 batch_normalization_463[0][0]    
__________________________________________________________________________________________________
activation_463 (Activation)     (None, 10, 16)       0           add_219[0][0]                    
__________________________________________________________________________________________________
conv1d_512 (Conv1D)             (None, 5, 32)        1568        activation_463[0][0]             
__________________________________________________________________________________________________
batch_normalization_464 (BatchN (None, 5, 32)        128         conv1d_512[0][0]                 
__________________________________________________________________________________________________
activation_464 (Activation)     (None, 5, 32)        0           batch_normalization_464[0][0]    
__________________________________________________________________________________________________
conv1d_513 (Conv1D)             (None, 5, 32)        3104        activation_464[0][0]             
__________________________________________________________________________________________________
conv1d_514 (Conv1D)             (None, 5, 32)        544         activation_463[0][0]             
__________________________________________________________________________________________________
batch_normalization_465 (BatchN (None, 5, 32)        128         conv1d_513[0][0]                 
__________________________________________________________________________________________________
add_220 (Add)                   (None, 5, 32)        0           conv1d_514[0][0]                 
                                                                 batch_normalization_465[0][0]    
__________________________________________________________________________________________________
activation_465 (Activation)     (None, 5, 32)        0           add_220[0][0]                    
__________________________________________________________________________________________________
conv1d_515 (Conv1D)             (None, 5, 32)        3104        activation_465[0][0]             
__________________________________________________________________________________________________
batch_normalization_466 (BatchN (None, 5, 32)        128         conv1d_515[0][0]                 
__________________________________________________________________________________________________
activation_466 (Activation)     (None, 5, 32)        0           batch_normalization_466[0][0]    
__________________________________________________________________________________________________
conv1d_516 (Conv1D)             (None, 5, 32)        3104        activation_466[0][0]             
__________________________________________________________________________________________________
batch_normalization_467 (BatchN (None, 5, 32)        128         conv1d_516[0][0]                 
__________________________________________________________________________________________________
add_221 (Add)                   (None, 5, 32)        0           activation_465[0][0]             
                                                                 batch_normalization_467[0][0]    
__________________________________________________________________________________________________
activation_467 (Activation)     (None, 5, 32)        0           add_221[0][0]                    
__________________________________________________________________________________________________
conv1d_517 (Conv1D)             (None, 5, 32)        3104        activation_467[0][0]             
__________________________________________________________________________________________________
batch_normalization_468 (BatchN (None, 5, 32)        128         conv1d_517[0][0]                 
__________________________________________________________________________________________________
activation_468 (Activation)     (None, 5, 32)        0           batch_normalization_468[0][0]    
__________________________________________________________________________________________________
conv1d_518 (Conv1D)             (None, 5, 32)        3104        activation_468[0][0]             
__________________________________________________________________________________________________
batch_normalization_469 (BatchN (None, 5, 32)        128         conv1d_518[0][0]                 
__________________________________________________________________________________________________
add_222 (Add)                   (None, 5, 32)        0           activation_467[0][0]             
                                                                 batch_normalization_469[0][0]    
__________________________________________________________________________________________________
activation_469 (Activation)     (None, 5, 32)        0           add_222[0][0]                    
__________________________________________________________________________________________________
conv1d_519 (Conv1D)             (None, 3, 64)        6208        activation_469[0][0]             
__________________________________________________________________________________________________
batch_normalization_470 (BatchN (None, 3, 64)        256         conv1d_519[0][0]                 
__________________________________________________________________________________________________
activation_470 (Activation)     (None, 3, 64)        0           batch_normalization_470[0][0]    
__________________________________________________________________________________________________
conv1d_520 (Conv1D)             (None, 3, 64)        12352       activation_470[0][0]             
__________________________________________________________________________________________________
conv1d_521 (Conv1D)             (None, 3, 64)        2112        activation_469[0][0]             
__________________________________________________________________________________________________
batch_normalization_471 (BatchN (None, 3, 64)        256         conv1d_520[0][0]                 
__________________________________________________________________________________________________
add_223 (Add)                   (None, 3, 64)        0           conv1d_521[0][0]                 
                                                                 batch_normalization_471[0][0]    
__________________________________________________________________________________________________
activation_471 (Activation)     (None, 3, 64)        0           add_223[0][0]                    
__________________________________________________________________________________________________
conv1d_522 (Conv1D)             (None, 3, 64)        12352       activation_471[0][0]             
__________________________________________________________________________________________________
batch_normalization_472 (BatchN (None, 3, 64)        256         conv1d_522[0][0]                 
__________________________________________________________________________________________________
activation_472 (Activation)     (None, 3, 64)        0           batch_normalization_472[0][0]    
__________________________________________________________________________________________________
conv1d_523 (Conv1D)             (None, 3, 64)        12352       activation_472[0][0]             
__________________________________________________________________________________________________
batch_normalization_473 (BatchN (None, 3, 64)        256         conv1d_523[0][0]                 
__________________________________________________________________________________________________
add_224 (Add)                   (None, 3, 64)        0           activation_471[0][0]             
                                                                 batch_normalization_473[0][0]    
__________________________________________________________________________________________________
activation_473 (Activation)     (None, 3, 64)        0           add_224[0][0]                    
__________________________________________________________________________________________________
conv1d_524 (Conv1D)             (None, 3, 64)        12352       activation_473[0][0]             
__________________________________________________________________________________________________
batch_normalization_474 (BatchN (None, 3, 64)        256         conv1d_524[0][0]                 
__________________________________________________________________________________________________
activation_474 (Activation)     (None, 3, 64)        0           batch_normalization_474[0][0]    
__________________________________________________________________________________________________
conv1d_525 (Conv1D)             (None, 3, 64)        12352       activation_474[0][0]             
__________________________________________________________________________________________________
batch_normalization_475 (BatchN (None, 3, 64)        256         conv1d_525[0][0]                 
__________________________________________________________________________________________________
add_225 (Add)                   (None, 3, 64)        0           activation_473[0][0]             
                                                                 batch_normalization_475[0][0]    
__________________________________________________________________________________________________
activation_475 (Activation)     (None, 3, 64)        0           add_225[0][0]                    
__________________________________________________________________________________________________
average_pooling1d_25 (AveragePo (None, 3, 64)        0           activation_475[0][0]             
__________________________________________________________________________________________________
flatten_25 (Flatten)            (None, 192)          0           average_pooling1d_25[0][0]       
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 4)            772         flatten_25[0][0]                 
==================================================================================================
Total params: 96,004
Trainable params: 94,628
Non-trainable params: 1,376
__________________________________________________________________________________________________
None

Accuracy Train: 76.72%
Accuracy Test: 67.52%
Loss Train: 1.01
Loss Test: 1.63
Numero dati esaminati: 1712
True Positive 1156
False Positive 556


------------------------------------------------------------------------
K-fold Cross Validation
------------------------------------------------------------------------
Training for fold 1 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 7s - loss: 1.6435 - accuracy: 0.4551 - val_loss: 2.4318 - val_accuracy: 0.2927
Epoch 2/110
 - 3s - loss: 1.1752 - accuracy: 0.5770 - val_loss: 1.5130 - val_accuracy: 0.4255
Epoch 3/110
 - 3s - loss: 1.0765 - accuracy: 0.6163 - val_loss: 1.3440 - val_accuracy: 0.4883
Epoch 4/110
 - 3s - loss: 1.0126 - accuracy: 0.6418 - val_loss: 1.2601 - val_accuracy: 0.5409
Epoch 5/110
 - 3s - loss: 0.9720 - accuracy: 0.6694 - val_loss: 1.2401 - val_accuracy: 0.5387
Epoch 6/110
 - 3s - loss: 0.9392 - accuracy: 0.6813 - val_loss: 1.2765 - val_accuracy: 0.5423
Epoch 7/110
 - 3s - loss: 0.9083 - accuracy: 0.6940 - val_loss: 1.2120 - val_accuracy: 0.5737
Epoch 8/110
 - 3s - loss: 0.8861 - accuracy: 0.7070 - val_loss: 1.2233 - val_accuracy: 0.5832
Epoch 9/110
 - 3s - loss: 0.8686 - accuracy: 0.7087 - val_loss: 1.2744 - val_accuracy: 0.5737
Epoch 10/110
 - 3s - loss: 0.8405 - accuracy: 0.7222 - val_loss: 1.2593 - val_accuracy: 0.5708
Epoch 11/110
 - 3s - loss: 0.8201 - accuracy: 0.7346 - val_loss: 1.2400 - val_accuracy: 0.5759
Epoch 12/110
 - 3s - loss: 0.8259 - accuracy: 0.7338 - val_loss: 1.2126 - val_accuracy: 0.5920
Epoch 13/110
 - 3s - loss: 0.8038 - accuracy: 0.7411 - val_loss: 1.2472 - val_accuracy: 0.5891
Epoch 14/110
 - 3s - loss: 0.7946 - accuracy: 0.7391 - val_loss: 1.2829 - val_accuracy: 0.5737
Epoch 15/110
 - 3s - loss: 0.8110 - accuracy: 0.7324 - val_loss: 1.2513 - val_accuracy: 0.5628
Epoch 16/110
 - 3s - loss: 0.7883 - accuracy: 0.7466 - val_loss: 1.1763 - val_accuracy: 0.6000
Epoch 17/110
 - 3s - loss: 0.7615 - accuracy: 0.7558 - val_loss: 1.2370 - val_accuracy: 0.5745
Epoch 18/110
 - 3s - loss: 0.7177 - accuracy: 0.7696 - val_loss: 1.2976 - val_accuracy: 0.5577
Epoch 19/110
 - 3s - loss: 0.7214 - accuracy: 0.7700 - val_loss: 1.2853 - val_accuracy: 0.5956
Epoch 20/110
 - 3s - loss: 0.7167 - accuracy: 0.7760 - val_loss: 1.2697 - val_accuracy: 0.5956
Epoch 21/110
 - 3s - loss: 0.7417 - accuracy: 0.7620 - val_loss: 1.3545 - val_accuracy: 0.5730
Epoch 22/110
 - 3s - loss: 0.7298 - accuracy: 0.7691 - val_loss: 1.2297 - val_accuracy: 0.6088
Epoch 23/110
 - 3s - loss: 0.7211 - accuracy: 0.7725 - val_loss: 1.1950 - val_accuracy: 0.6131
Epoch 24/110
 - 3s - loss: 0.6814 - accuracy: 0.7871 - val_loss: 1.2640 - val_accuracy: 0.6109
Epoch 25/110
 - 3s - loss: 0.6843 - accuracy: 0.7882 - val_loss: 1.2224 - val_accuracy: 0.6161
Epoch 26/110
 - 3s - loss: 0.6799 - accuracy: 0.7884 - val_loss: 1.3480 - val_accuracy: 0.5861
Epoch 27/110
 - 3s - loss: 0.6773 - accuracy: 0.7882 - val_loss: 1.2416 - val_accuracy: 0.6109
Epoch 28/110
 - 3s - loss: 0.6668 - accuracy: 0.7901 - val_loss: 1.3183 - val_accuracy: 0.5956
Epoch 29/110
 - 3s - loss: 0.6661 - accuracy: 0.7966 - val_loss: 1.3658 - val_accuracy: 0.5942
Epoch 30/110
 - 3s - loss: 0.6467 - accuracy: 0.8036 - val_loss: 1.2563 - val_accuracy: 0.6139
Epoch 31/110
 - 3s - loss: 0.6414 - accuracy: 0.8074 - val_loss: 1.3623 - val_accuracy: 0.5774
Epoch 32/110
 - 3s - loss: 0.6508 - accuracy: 0.7979 - val_loss: 1.2614 - val_accuracy: 0.6190
Epoch 33/110
 - 3s - loss: 0.6366 - accuracy: 0.8081 - val_loss: 1.2478 - val_accuracy: 0.6226
Epoch 34/110
 - 3s - loss: 0.6302 - accuracy: 0.8100 - val_loss: 1.2497 - val_accuracy: 0.6226
Epoch 35/110
 - 3s - loss: 0.6087 - accuracy: 0.8162 - val_loss: 1.2142 - val_accuracy: 0.6409
Epoch 36/110
 - 3s - loss: 0.5812 - accuracy: 0.8353 - val_loss: 1.2517 - val_accuracy: 0.6372
Epoch 37/110
 - 3s - loss: 0.5782 - accuracy: 0.8372 - val_loss: 1.3856 - val_accuracy: 0.6226
Epoch 38/110
 - 3s - loss: 0.6008 - accuracy: 0.8269 - val_loss: 1.4389 - val_accuracy: 0.6117
Epoch 39/110
 - 3s - loss: 0.6052 - accuracy: 0.8220 - val_loss: 1.3948 - val_accuracy: 0.6248
Epoch 40/110
 - 3s - loss: 0.5812 - accuracy: 0.8306 - val_loss: 1.3767 - val_accuracy: 0.6153
Epoch 41/110
 - 3s - loss: 0.5644 - accuracy: 0.8412 - val_loss: 1.3610 - val_accuracy: 0.6241
Epoch 42/110
 - 3s - loss: 0.5812 - accuracy: 0.8372 - val_loss: 1.2534 - val_accuracy: 0.6555
Epoch 43/110
 - 3s - loss: 0.5689 - accuracy: 0.8381 - val_loss: 1.3451 - val_accuracy: 0.6161
Epoch 44/110
 - 3s - loss: 0.5665 - accuracy: 0.8357 - val_loss: 1.3299 - val_accuracy: 0.6321
Epoch 45/110
 - 3s - loss: 0.5474 - accuracy: 0.8501 - val_loss: 1.4129 - val_accuracy: 0.6241
Epoch 46/110
 - 3s - loss: 0.5424 - accuracy: 0.8488 - val_loss: 1.4284 - val_accuracy: 0.6226
Epoch 47/110
 - 3s - loss: 0.5251 - accuracy: 0.8543 - val_loss: 1.4950 - val_accuracy: 0.6197
Epoch 48/110
 - 3s - loss: 0.5257 - accuracy: 0.8642 - val_loss: 1.3712 - val_accuracy: 0.6394
Epoch 49/110
 - 3s - loss: 0.5342 - accuracy: 0.8565 - val_loss: 1.3974 - val_accuracy: 0.6518
Epoch 50/110
 - 3s - loss: 0.5269 - accuracy: 0.8585 - val_loss: 1.4905 - val_accuracy: 0.6226
Epoch 51/110
 - 3s - loss: 0.5467 - accuracy: 0.8463 - val_loss: 1.5580 - val_accuracy: 0.6241
Epoch 52/110
 - 3s - loss: 0.5479 - accuracy: 0.8459 - val_loss: 1.4186 - val_accuracy: 0.6350
Epoch 53/110
 - 3s - loss: 0.5394 - accuracy: 0.8529 - val_loss: 1.4048 - val_accuracy: 0.6423
Epoch 54/110
 - 3s - loss: 0.5240 - accuracy: 0.8591 - val_loss: 1.4824 - val_accuracy: 0.6175
Epoch 55/110
 - 3s - loss: 0.5148 - accuracy: 0.8660 - val_loss: 1.3687 - val_accuracy: 0.6460
Epoch 56/110
 - 3s - loss: 0.4852 - accuracy: 0.8768 - val_loss: 1.3547 - val_accuracy: 0.6620
Epoch 57/110
 - 3s - loss: 0.4701 - accuracy: 0.8799 - val_loss: 1.3229 - val_accuracy: 0.6540
Epoch 58/110
 - 3s - loss: 0.4703 - accuracy: 0.8771 - val_loss: 1.4038 - val_accuracy: 0.6358
Epoch 59/110
 - 3s - loss: 0.4620 - accuracy: 0.8775 - val_loss: 1.4504 - val_accuracy: 0.6474
Epoch 60/110
 - 3s - loss: 0.4693 - accuracy: 0.8793 - val_loss: 1.3680 - val_accuracy: 0.6533
Epoch 61/110
 - 3s - loss: 0.4670 - accuracy: 0.8835 - val_loss: 1.4893 - val_accuracy: 0.6380
Epoch 62/110
 - 3s - loss: 0.4424 - accuracy: 0.8939 - val_loss: 1.4082 - val_accuracy: 0.6693
Epoch 63/110
 - 3s - loss: 0.4495 - accuracy: 0.8870 - val_loss: 1.5081 - val_accuracy: 0.6438
Epoch 64/110
 - 3s - loss: 0.4791 - accuracy: 0.8779 - val_loss: 1.4522 - val_accuracy: 0.6708
Epoch 65/110
 - 3s - loss: 0.4338 - accuracy: 0.8970 - val_loss: 1.4662 - val_accuracy: 0.6672
Epoch 66/110
 - 3s - loss: 0.4480 - accuracy: 0.8868 - val_loss: 1.5574 - val_accuracy: 0.6628
Epoch 67/110
 - 3s - loss: 0.4256 - accuracy: 0.8949 - val_loss: 1.5116 - val_accuracy: 0.6686
Epoch 68/110
 - 3s - loss: 0.4082 - accuracy: 0.9087 - val_loss: 1.5904 - val_accuracy: 0.6606
Epoch 69/110
 - 3s - loss: 0.4110 - accuracy: 0.9085 - val_loss: 1.4977 - val_accuracy: 0.6788
Epoch 70/110
 - 3s - loss: 0.4162 - accuracy: 0.9038 - val_loss: 1.5109 - val_accuracy: 0.6562
Epoch 71/110
 - 3s - loss: 0.4031 - accuracy: 0.9098 - val_loss: 1.4850 - val_accuracy: 0.6562
Epoch 72/110
 - 3s - loss: 0.4050 - accuracy: 0.9078 - val_loss: 1.5432 - val_accuracy: 0.6650
Epoch 73/110
 - 3s - loss: 0.4347 - accuracy: 0.9020 - val_loss: 1.5476 - val_accuracy: 0.6453
Epoch 74/110
 - 3s - loss: 0.3995 - accuracy: 0.9133 - val_loss: 1.4829 - val_accuracy: 0.6869
Epoch 75/110
 - 3s - loss: 0.3854 - accuracy: 0.9186 - val_loss: 1.6622 - val_accuracy: 0.6467
Epoch 76/110
 - 3s - loss: 0.4171 - accuracy: 0.9067 - val_loss: 1.5005 - val_accuracy: 0.6650
Epoch 77/110
 - 3s - loss: 0.3806 - accuracy: 0.9179 - val_loss: 1.6089 - val_accuracy: 0.6504
Epoch 78/110
 - 3s - loss: 0.4104 - accuracy: 0.9129 - val_loss: 1.6631 - val_accuracy: 0.6496
Epoch 79/110
 - 3s - loss: 0.4021 - accuracy: 0.9113 - val_loss: 1.5492 - val_accuracy: 0.6723
Epoch 80/110
 - 3s - loss: 0.3906 - accuracy: 0.9171 - val_loss: 1.6583 - val_accuracy: 0.6292
Epoch 81/110
 - 3s - loss: 0.3859 - accuracy: 0.9171 - val_loss: 1.5846 - val_accuracy: 0.6577
Epoch 82/110
 - 3s - loss: 0.3735 - accuracy: 0.9222 - val_loss: 1.6620 - val_accuracy: 0.6606
Epoch 83/110
 - 3s - loss: 0.3813 - accuracy: 0.9168 - val_loss: 1.6001 - val_accuracy: 0.6635
Epoch 84/110
 - 3s - loss: 0.3937 - accuracy: 0.9166 - val_loss: 1.6377 - val_accuracy: 0.6562
Epoch 85/110
 - 3s - loss: 0.3945 - accuracy: 0.9160 - val_loss: 1.6491 - val_accuracy: 0.6555
Epoch 86/110
 - 3s - loss: 0.4019 - accuracy: 0.9144 - val_loss: 1.6173 - val_accuracy: 0.6394
Epoch 87/110
 - 3s - loss: 0.3861 - accuracy: 0.9202 - val_loss: 1.5913 - val_accuracy: 0.6518
Epoch 88/110
 - 3s - loss: 0.3806 - accuracy: 0.9193 - val_loss: 1.7045 - val_accuracy: 0.6489
Epoch 89/110
 - 3s - loss: 0.3559 - accuracy: 0.9281 - val_loss: 1.5094 - val_accuracy: 0.6898
Epoch 90/110
 - 3s - loss: 0.3681 - accuracy: 0.9264 - val_loss: 1.6336 - val_accuracy: 0.6745
Epoch 91/110
 - 3s - loss: 0.3719 - accuracy: 0.9261 - val_loss: 1.6779 - val_accuracy: 0.6664
Epoch 92/110
 - 3s - loss: 0.3845 - accuracy: 0.9215 - val_loss: 1.5805 - val_accuracy: 0.6774
Epoch 93/110
 - 3s - loss: 0.4102 - accuracy: 0.9107 - val_loss: 1.6306 - val_accuracy: 0.6657
Epoch 94/110
 - 3s - loss: 0.3692 - accuracy: 0.9295 - val_loss: 1.7275 - val_accuracy: 0.6693
Epoch 95/110
 - 3s - loss: 0.3724 - accuracy: 0.9292 - val_loss: 1.7182 - val_accuracy: 0.6547
Epoch 96/110
 - 3s - loss: 0.3688 - accuracy: 0.9270 - val_loss: 1.7540 - val_accuracy: 0.6562
Epoch 97/110
 - 3s - loss: 0.3579 - accuracy: 0.9326 - val_loss: 1.6721 - val_accuracy: 0.6686
Epoch 98/110
 - 3s - loss: 0.3379 - accuracy: 0.9383 - val_loss: 1.7402 - val_accuracy: 0.6562
Epoch 99/110
 - 3s - loss: 0.3475 - accuracy: 0.9334 - val_loss: 1.7014 - val_accuracy: 0.6518
Epoch 100/110
 - 3s - loss: 0.3350 - accuracy: 0.9407 - val_loss: 1.7792 - val_accuracy: 0.6620
Epoch 101/110
 - 3s - loss: 0.3582 - accuracy: 0.9341 - val_loss: 1.7099 - val_accuracy: 0.6504
Epoch 102/110
 - 2s - loss: 0.3786 - accuracy: 0.9284 - val_loss: 1.7033 - val_accuracy: 0.6372
Epoch 103/110
 - 3s - loss: 0.3478 - accuracy: 0.9354 - val_loss: 1.6088 - val_accuracy: 0.6774
Epoch 104/110
 - 3s - loss: 0.3598 - accuracy: 0.9306 - val_loss: 1.6940 - val_accuracy: 0.6562
Epoch 105/110
 - 3s - loss: 0.3871 - accuracy: 0.9237 - val_loss: 1.6757 - val_accuracy: 0.6723
Epoch 106/110
 - 3s - loss: 0.3364 - accuracy: 0.9416 - val_loss: 1.6470 - val_accuracy: 0.6730
Epoch 107/110
 - 3s - loss: 0.3282 - accuracy: 0.9410 - val_loss: 1.7419 - val_accuracy: 0.6672
Epoch 108/110
 - 3s - loss: 0.3397 - accuracy: 0.9398 - val_loss: 1.7513 - val_accuracy: 0.6883
Epoch 109/110
 - 3s - loss: 0.3532 - accuracy: 0.9345 - val_loss: 1.7284 - val_accuracy: 0.6606
Epoch 110/110
 - 3s - loss: 0.3422 - accuracy: 0.9361 - val_loss: 1.7479 - val_accuracy: 0.6701
------------------------------------------------------------------------
Training for fold 2 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 7s - loss: 1.4854 - accuracy: 0.4719 - val_loss: 2.6418 - val_accuracy: 0.3000
Epoch 2/110
 - 3s - loss: 1.1794 - accuracy: 0.5748 - val_loss: 1.4046 - val_accuracy: 0.4781
Epoch 3/110
 - 3s - loss: 1.0813 - accuracy: 0.6256 - val_loss: 1.2425 - val_accuracy: 0.5562
Epoch 4/110
 - 3s - loss: 1.0219 - accuracy: 0.6504 - val_loss: 1.2088 - val_accuracy: 0.5788
Epoch 5/110
 - 2s - loss: 0.9690 - accuracy: 0.6681 - val_loss: 1.1950 - val_accuracy: 0.5701
Epoch 6/110
 - 3s - loss: 0.9352 - accuracy: 0.6855 - val_loss: 1.2421 - val_accuracy: 0.5606
Epoch 7/110
 - 3s - loss: 0.9179 - accuracy: 0.6946 - val_loss: 1.2043 - val_accuracy: 0.5796
Epoch 8/110
 - 3s - loss: 0.9184 - accuracy: 0.6888 - val_loss: 1.1901 - val_accuracy: 0.5796
Epoch 9/110
 - 3s - loss: 0.8989 - accuracy: 0.6992 - val_loss: 1.2062 - val_accuracy: 0.5708
Epoch 10/110
 - 3s - loss: 0.8962 - accuracy: 0.7059 - val_loss: 1.2363 - val_accuracy: 0.5723
Epoch 11/110
 - 3s - loss: 0.8570 - accuracy: 0.7143 - val_loss: 1.2593 - val_accuracy: 0.5664
Epoch 12/110
 - 3s - loss: 0.8375 - accuracy: 0.7174 - val_loss: 1.3527 - val_accuracy: 0.5431
Epoch 13/110
 - 3s - loss: 0.8527 - accuracy: 0.7150 - val_loss: 1.3138 - val_accuracy: 0.5642
Epoch 14/110
 - 2s - loss: 0.8381 - accuracy: 0.7258 - val_loss: 1.2766 - val_accuracy: 0.5715
Epoch 15/110
 - 3s - loss: 0.8037 - accuracy: 0.7349 - val_loss: 1.2264 - val_accuracy: 0.5832
Epoch 16/110
 - 3s - loss: 0.7958 - accuracy: 0.7384 - val_loss: 1.2478 - val_accuracy: 0.5730
Epoch 17/110
 - 2s - loss: 0.7703 - accuracy: 0.7541 - val_loss: 1.2310 - val_accuracy: 0.5934
Epoch 18/110
 - 2s - loss: 0.7656 - accuracy: 0.7506 - val_loss: 1.2645 - val_accuracy: 0.5949
Epoch 19/110
 - 3s - loss: 0.7346 - accuracy: 0.7647 - val_loss: 1.2336 - val_accuracy: 0.5891
Epoch 20/110
 - 2s - loss: 0.7247 - accuracy: 0.7722 - val_loss: 1.2572 - val_accuracy: 0.6095
Epoch 21/110
 - 2s - loss: 0.7148 - accuracy: 0.7744 - val_loss: 1.2497 - val_accuracy: 0.5985
Epoch 22/110
 - 3s - loss: 0.7394 - accuracy: 0.7693 - val_loss: 1.2858 - val_accuracy: 0.5832
Epoch 23/110
 - 2s - loss: 0.7107 - accuracy: 0.7769 - val_loss: 1.4263 - val_accuracy: 0.5642
Epoch 24/110
 - 2s - loss: 0.7167 - accuracy: 0.7722 - val_loss: 1.3567 - val_accuracy: 0.5752
Epoch 25/110
 - 2s - loss: 0.6907 - accuracy: 0.7793 - val_loss: 1.3415 - val_accuracy: 0.5810
Epoch 26/110
 - 2s - loss: 0.6881 - accuracy: 0.7833 - val_loss: 1.2967 - val_accuracy: 0.6117
Epoch 27/110
 - 3s - loss: 0.6715 - accuracy: 0.7923 - val_loss: 1.2831 - val_accuracy: 0.6117
Epoch 28/110
 - 3s - loss: 0.6883 - accuracy: 0.7870 - val_loss: 1.3784 - val_accuracy: 0.5766
Epoch 29/110
 - 2s - loss: 0.6643 - accuracy: 0.7948 - val_loss: 1.4691 - val_accuracy: 0.5591
Epoch 30/110
 - 2s - loss: 0.6421 - accuracy: 0.8070 - val_loss: 1.4827 - val_accuracy: 0.5577
Epoch 31/110
 - 3s - loss: 0.6221 - accuracy: 0.8158 - val_loss: 1.4140 - val_accuracy: 0.5766
Epoch 32/110
 - 3s - loss: 0.6303 - accuracy: 0.8153 - val_loss: 1.4161 - val_accuracy: 0.5891
Epoch 33/110
 - 3s - loss: 0.6268 - accuracy: 0.8133 - val_loss: 1.3471 - val_accuracy: 0.5949
Epoch 34/110
 - 3s - loss: 0.6362 - accuracy: 0.8120 - val_loss: 1.3542 - val_accuracy: 0.6007
Epoch 35/110
 - 3s - loss: 0.6105 - accuracy: 0.8169 - val_loss: 1.3816 - val_accuracy: 0.6168
Epoch 36/110
 - 2s - loss: 0.5915 - accuracy: 0.8246 - val_loss: 1.3837 - val_accuracy: 0.6204
Epoch 37/110
 - 2s - loss: 0.6136 - accuracy: 0.8204 - val_loss: 1.5444 - val_accuracy: 0.5766
Epoch 38/110
 - 2s - loss: 0.5912 - accuracy: 0.8271 - val_loss: 1.5014 - val_accuracy: 0.5788
Epoch 39/110
 - 2s - loss: 0.5724 - accuracy: 0.8405 - val_loss: 1.3998 - val_accuracy: 0.5818
Epoch 40/110
 - 3s - loss: 0.6063 - accuracy: 0.8189 - val_loss: 1.4012 - val_accuracy: 0.5949
Epoch 41/110
 - 3s - loss: 0.5898 - accuracy: 0.8275 - val_loss: 1.4037 - val_accuracy: 0.5956
Epoch 42/110
 - 3s - loss: 0.5599 - accuracy: 0.8423 - val_loss: 1.4570 - val_accuracy: 0.5839
Epoch 43/110
 - 3s - loss: 0.5650 - accuracy: 0.8423 - val_loss: 1.4001 - val_accuracy: 0.6080
Epoch 44/110
 - 2s - loss: 0.5602 - accuracy: 0.8399 - val_loss: 1.3352 - val_accuracy: 0.6314
Epoch 45/110
 - 2s - loss: 0.5633 - accuracy: 0.8405 - val_loss: 1.3988 - val_accuracy: 0.6292
Epoch 46/110
 - 2s - loss: 0.5694 - accuracy: 0.8348 - val_loss: 1.5074 - val_accuracy: 0.5927
Epoch 47/110
 - 2s - loss: 0.5904 - accuracy: 0.8240 - val_loss: 1.3869 - val_accuracy: 0.6197
Epoch 48/110
 - 3s - loss: 0.5773 - accuracy: 0.8353 - val_loss: 1.3351 - val_accuracy: 0.6438
Epoch 49/110
 - 2s - loss: 0.5402 - accuracy: 0.8556 - val_loss: 1.3424 - val_accuracy: 0.6482
Epoch 50/110
 - 2s - loss: 0.5141 - accuracy: 0.8587 - val_loss: 1.2995 - val_accuracy: 0.6540
Epoch 51/110
 - 2s - loss: 0.5396 - accuracy: 0.8525 - val_loss: 1.3442 - val_accuracy: 0.6409
Epoch 52/110
 - 3s - loss: 0.5144 - accuracy: 0.8631 - val_loss: 1.4322 - val_accuracy: 0.6358
Epoch 53/110
 - 3s - loss: 0.5326 - accuracy: 0.8556 - val_loss: 1.3705 - val_accuracy: 0.6219
Epoch 54/110
 - 3s - loss: 0.4886 - accuracy: 0.8766 - val_loss: 1.3770 - val_accuracy: 0.6416
Epoch 55/110
 - 2s - loss: 0.4760 - accuracy: 0.8815 - val_loss: 1.3933 - val_accuracy: 0.6474
Epoch 56/110
 - 2s - loss: 0.4953 - accuracy: 0.8667 - val_loss: 1.4311 - val_accuracy: 0.6328
Epoch 57/110
 - 2s - loss: 0.4847 - accuracy: 0.8782 - val_loss: 1.5649 - val_accuracy: 0.6219
Epoch 58/110
 - 2s - loss: 0.4987 - accuracy: 0.8724 - val_loss: 1.5939 - val_accuracy: 0.6431
Epoch 59/110
 - 2s - loss: 0.4926 - accuracy: 0.8724 - val_loss: 1.4248 - val_accuracy: 0.6358
Epoch 60/110
 - 2s - loss: 0.4969 - accuracy: 0.8695 - val_loss: 1.4678 - val_accuracy: 0.6372
Epoch 61/110
 - 3s - loss: 0.4758 - accuracy: 0.8841 - val_loss: 1.5682 - val_accuracy: 0.6350
Epoch 62/110
 - 3s - loss: 0.4919 - accuracy: 0.8733 - val_loss: 1.4773 - val_accuracy: 0.6387
Epoch 63/110
 - 2s - loss: 0.4722 - accuracy: 0.8802 - val_loss: 1.4507 - val_accuracy: 0.6343
Epoch 64/110
 - 2s - loss: 0.4658 - accuracy: 0.8846 - val_loss: 1.4244 - val_accuracy: 0.6365
Epoch 65/110
 - 2s - loss: 0.4507 - accuracy: 0.8923 - val_loss: 1.4669 - val_accuracy: 0.6474
Epoch 66/110
 - 3s - loss: 0.4251 - accuracy: 0.9000 - val_loss: 1.5254 - val_accuracy: 0.6321
Epoch 67/110
 - 3s - loss: 0.4557 - accuracy: 0.8894 - val_loss: 1.6765 - val_accuracy: 0.6182
Epoch 68/110
 - 3s - loss: 0.4605 - accuracy: 0.8865 - val_loss: 1.4646 - val_accuracy: 0.6547
Epoch 69/110
 - 2s - loss: 0.4461 - accuracy: 0.8972 - val_loss: 1.4976 - val_accuracy: 0.6372
Epoch 70/110
 - 2s - loss: 0.4599 - accuracy: 0.8850 - val_loss: 1.4504 - val_accuracy: 0.6628
Epoch 71/110
 - 2s - loss: 0.4421 - accuracy: 0.8961 - val_loss: 1.4714 - val_accuracy: 0.6467
Epoch 72/110
 - 2s - loss: 0.4245 - accuracy: 0.8985 - val_loss: 1.5311 - val_accuracy: 0.6613
Epoch 73/110
 - 2s - loss: 0.4416 - accuracy: 0.8983 - val_loss: 1.4860 - val_accuracy: 0.6635
Epoch 74/110
 - 2s - loss: 0.4275 - accuracy: 0.9027 - val_loss: 1.6001 - val_accuracy: 0.6234
Epoch 75/110
 - 3s - loss: 0.4235 - accuracy: 0.8989 - val_loss: 1.4156 - val_accuracy: 0.6686
Epoch 76/110
 - 2s - loss: 0.4263 - accuracy: 0.8991 - val_loss: 1.5618 - val_accuracy: 0.6270
Epoch 77/110
 - 2s - loss: 0.4125 - accuracy: 0.9069 - val_loss: 1.5740 - val_accuracy: 0.6693
Epoch 78/110
 - 2s - loss: 0.3864 - accuracy: 0.9210 - val_loss: 1.4848 - val_accuracy: 0.6613
Epoch 79/110
 - 2s - loss: 0.3908 - accuracy: 0.9177 - val_loss: 1.5414 - val_accuracy: 0.6467
Epoch 80/110
 - 2s - loss: 0.3650 - accuracy: 0.9283 - val_loss: 1.5410 - val_accuracy: 0.6715
Epoch 81/110
 - 2s - loss: 0.3822 - accuracy: 0.9221 - val_loss: 1.6497 - val_accuracy: 0.6518
Epoch 82/110
 - 2s - loss: 0.4051 - accuracy: 0.9149 - val_loss: 1.5497 - val_accuracy: 0.6650
Epoch 83/110
 - 2s - loss: 0.3903 - accuracy: 0.9228 - val_loss: 1.5447 - val_accuracy: 0.6540
Epoch 84/110
 - 3s - loss: 0.3706 - accuracy: 0.9231 - val_loss: 1.6930 - val_accuracy: 0.6270
Epoch 85/110
 - 2s - loss: 0.3679 - accuracy: 0.9252 - val_loss: 1.5791 - val_accuracy: 0.6591
Epoch 86/110
 - 2s - loss: 0.3548 - accuracy: 0.9336 - val_loss: 1.6573 - val_accuracy: 0.6657
Epoch 87/110
 - 2s - loss: 0.4061 - accuracy: 0.9160 - val_loss: 1.5945 - val_accuracy: 0.6715
Epoch 88/110
 - 3s - loss: 0.3922 - accuracy: 0.9166 - val_loss: 1.6663 - val_accuracy: 0.6752
Epoch 89/110
 - 2s - loss: 0.4000 - accuracy: 0.9142 - val_loss: 1.6585 - val_accuracy: 0.6650
Epoch 90/110
 - 2s - loss: 0.3682 - accuracy: 0.9279 - val_loss: 1.6527 - val_accuracy: 0.6686
Epoch 91/110
 - 3s - loss: 0.3764 - accuracy: 0.9275 - val_loss: 1.5482 - val_accuracy: 0.6854
Epoch 92/110
 - 3s - loss: 0.3771 - accuracy: 0.9222 - val_loss: 1.7219 - val_accuracy: 0.6511
Epoch 93/110
 - 3s - loss: 0.3432 - accuracy: 0.9357 - val_loss: 1.6654 - val_accuracy: 0.6766
Epoch 94/110
 - 3s - loss: 0.3317 - accuracy: 0.9427 - val_loss: 1.6144 - val_accuracy: 0.6912
Epoch 95/110
 - 2s - loss: 0.3622 - accuracy: 0.9317 - val_loss: 1.8471 - val_accuracy: 0.6292
Epoch 96/110
 - 3s - loss: 0.3771 - accuracy: 0.9250 - val_loss: 1.6977 - val_accuracy: 0.6489
Epoch 97/110
 - 3s - loss: 0.4076 - accuracy: 0.9157 - val_loss: 1.6194 - val_accuracy: 0.6394
Epoch 98/110
 - 2s - loss: 0.3739 - accuracy: 0.9253 - val_loss: 1.5253 - val_accuracy: 0.6825
Epoch 99/110
 - 3s - loss: 0.3779 - accuracy: 0.9250 - val_loss: 1.7066 - val_accuracy: 0.6460
Epoch 100/110
 - 3s - loss: 0.3429 - accuracy: 0.9388 - val_loss: 1.5884 - val_accuracy: 0.6620
Epoch 101/110
 - 3s - loss: 0.3213 - accuracy: 0.9480 - val_loss: 1.6477 - val_accuracy: 0.6664
Epoch 102/110
 - 3s - loss: 0.3226 - accuracy: 0.9474 - val_loss: 1.6752 - val_accuracy: 0.6715
Epoch 103/110
 - 2s - loss: 0.3308 - accuracy: 0.9460 - val_loss: 1.6484 - val_accuracy: 0.6737
Epoch 104/110
 - 2s - loss: 0.3234 - accuracy: 0.9451 - val_loss: 1.6932 - val_accuracy: 0.6701
Epoch 105/110
 - 3s - loss: 0.3390 - accuracy: 0.9414 - val_loss: 1.8063 - val_accuracy: 0.6365
Epoch 106/110
 - 3s - loss: 0.3463 - accuracy: 0.9345 - val_loss: 1.7413 - val_accuracy: 0.6737
Epoch 107/110
 - 2s - loss: 0.3527 - accuracy: 0.9370 - val_loss: 1.6347 - val_accuracy: 0.6854
Epoch 108/110
 - 2s - loss: 0.3319 - accuracy: 0.9429 - val_loss: 1.5547 - val_accuracy: 0.6964
Epoch 109/110
 - 2s - loss: 0.3353 - accuracy: 0.9458 - val_loss: 1.6833 - val_accuracy: 0.6584
Epoch 110/110
 - 3s - loss: 0.3268 - accuracy: 0.9465 - val_loss: 1.8686 - val_accuracy: 0.6555
------------------------------------------------------------------------
Training for fold 3 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 6s - loss: 1.4581 - accuracy: 0.4746 - val_loss: 2.0046 - val_accuracy: 0.3453
Epoch 2/110
 - 3s - loss: 1.1712 - accuracy: 0.5736 - val_loss: 1.3758 - val_accuracy: 0.4854
Epoch 3/110
 - 2s - loss: 1.0854 - accuracy: 0.6163 - val_loss: 1.2052 - val_accuracy: 0.5496
Epoch 4/110
 - 2s - loss: 1.0217 - accuracy: 0.6473 - val_loss: 1.1921 - val_accuracy: 0.5591
Epoch 5/110
 - 2s - loss: 0.9826 - accuracy: 0.6605 - val_loss: 1.1689 - val_accuracy: 0.5686
Epoch 6/110
 - 3s - loss: 0.9521 - accuracy: 0.6798 - val_loss: 1.2152 - val_accuracy: 0.5635
Epoch 7/110
 - 2s - loss: 0.9238 - accuracy: 0.6880 - val_loss: 1.2488 - val_accuracy: 0.5679
Epoch 8/110
 - 3s - loss: 0.9105 - accuracy: 0.6858 - val_loss: 1.2243 - val_accuracy: 0.5650
Epoch 9/110
 - 3s - loss: 0.8879 - accuracy: 0.7026 - val_loss: 1.2348 - val_accuracy: 0.5599
Epoch 10/110
 - 3s - loss: 0.8701 - accuracy: 0.7167 - val_loss: 1.2073 - val_accuracy: 0.5730
Epoch 11/110
 - 2s - loss: 0.8325 - accuracy: 0.7276 - val_loss: 1.2378 - val_accuracy: 0.5869
Epoch 12/110
 - 2s - loss: 0.8269 - accuracy: 0.7317 - val_loss: 1.2713 - val_accuracy: 0.5628
Epoch 13/110
 - 3s - loss: 0.8175 - accuracy: 0.7353 - val_loss: 1.2350 - val_accuracy: 0.5818
Epoch 14/110
 - 3s - loss: 0.7930 - accuracy: 0.7428 - val_loss: 1.2578 - val_accuracy: 0.5613
Epoch 15/110
 - 3s - loss: 0.7534 - accuracy: 0.7612 - val_loss: 1.1637 - val_accuracy: 0.6036
Epoch 16/110
 - 3s - loss: 0.7258 - accuracy: 0.7707 - val_loss: 1.2652 - val_accuracy: 0.5905
Epoch 17/110
 - 2s - loss: 0.7368 - accuracy: 0.7643 - val_loss: 1.2361 - val_accuracy: 0.5891
Epoch 18/110
 - 2s - loss: 0.7381 - accuracy: 0.7680 - val_loss: 1.2423 - val_accuracy: 0.6109
Epoch 19/110
 - 2s - loss: 0.7331 - accuracy: 0.7658 - val_loss: 1.2030 - val_accuracy: 0.6124
Epoch 20/110
 - 2s - loss: 0.7139 - accuracy: 0.7753 - val_loss: 1.3213 - val_accuracy: 0.5723
Epoch 21/110
 - 3s - loss: 0.7231 - accuracy: 0.7691 - val_loss: 1.1902 - val_accuracy: 0.6153
Epoch 22/110
 - 2s - loss: 0.6662 - accuracy: 0.7961 - val_loss: 1.2771 - val_accuracy: 0.6022
Epoch 23/110
 - 2s - loss: 0.6758 - accuracy: 0.7926 - val_loss: 1.3662 - val_accuracy: 0.6051
Epoch 24/110
 - 2s - loss: 0.6895 - accuracy: 0.7798 - val_loss: 1.3634 - val_accuracy: 0.5861
Epoch 25/110
 - 2s - loss: 0.6746 - accuracy: 0.7855 - val_loss: 1.3111 - val_accuracy: 0.6080
Epoch 26/110
 - 2s - loss: 0.6778 - accuracy: 0.7895 - val_loss: 1.3402 - val_accuracy: 0.6146
Epoch 27/110
 - 3s - loss: 0.6832 - accuracy: 0.7895 - val_loss: 1.3666 - val_accuracy: 0.6000
Epoch 28/110
 - 2s - loss: 0.6860 - accuracy: 0.7844 - val_loss: 1.3419 - val_accuracy: 0.5971
Epoch 29/110
 - 3s - loss: 0.6670 - accuracy: 0.7919 - val_loss: 1.3759 - val_accuracy: 0.5920
Epoch 30/110
 - 2s - loss: 0.6818 - accuracy: 0.7912 - val_loss: 1.3085 - val_accuracy: 0.6270
Epoch 31/110
 - 2s - loss: 0.6658 - accuracy: 0.7945 - val_loss: 1.3635 - val_accuracy: 0.5934
Epoch 32/110
 - 2s - loss: 0.6616 - accuracy: 0.8014 - val_loss: 1.3293 - val_accuracy: 0.6226
Epoch 33/110
 - 2s - loss: 0.6420 - accuracy: 0.8078 - val_loss: 1.3553 - val_accuracy: 0.6248
Epoch 34/110
 - 2s - loss: 0.6239 - accuracy: 0.8094 - val_loss: 1.3804 - val_accuracy: 0.6292
Epoch 35/110
 - 2s - loss: 0.6035 - accuracy: 0.8198 - val_loss: 1.3636 - val_accuracy: 0.6139
Epoch 36/110
 - 3s - loss: 0.6069 - accuracy: 0.8175 - val_loss: 1.3798 - val_accuracy: 0.6175
Epoch 37/110
 - 3s - loss: 0.6227 - accuracy: 0.8153 - val_loss: 1.3686 - val_accuracy: 0.6131
Epoch 38/110
 - 2s - loss: 0.6069 - accuracy: 0.8237 - val_loss: 1.3614 - val_accuracy: 0.6139
Epoch 39/110
 - 3s - loss: 0.5974 - accuracy: 0.8224 - val_loss: 1.4083 - val_accuracy: 0.5927
Epoch 40/110
 - 3s - loss: 0.5875 - accuracy: 0.8302 - val_loss: 1.4189 - val_accuracy: 0.6095
Epoch 41/110
 - 3s - loss: 0.5741 - accuracy: 0.8335 - val_loss: 1.2978 - val_accuracy: 0.6372
Epoch 42/110
 - 3s - loss: 0.5693 - accuracy: 0.8395 - val_loss: 1.2625 - val_accuracy: 0.6606
Epoch 43/110
 - 3s - loss: 0.5480 - accuracy: 0.8503 - val_loss: 1.3804 - val_accuracy: 0.6387
Epoch 44/110
 - 2s - loss: 0.5145 - accuracy: 0.8645 - val_loss: 1.3635 - val_accuracy: 0.6394
Epoch 45/110
 - 2s - loss: 0.4951 - accuracy: 0.8655 - val_loss: 1.3767 - val_accuracy: 0.6409
Epoch 46/110
 - 2s - loss: 0.5339 - accuracy: 0.8492 - val_loss: 1.4068 - val_accuracy: 0.6380
Epoch 47/110
 - 2s - loss: 0.5336 - accuracy: 0.8490 - val_loss: 1.4300 - val_accuracy: 0.6328
Epoch 48/110
 - 3s - loss: 0.5121 - accuracy: 0.8593 - val_loss: 1.4555 - val_accuracy: 0.6153
Epoch 49/110
 - 3s - loss: 0.5330 - accuracy: 0.8589 - val_loss: 1.3954 - val_accuracy: 0.6365
Epoch 50/110
 - 3s - loss: 0.5082 - accuracy: 0.8589 - val_loss: 1.3233 - val_accuracy: 0.6701
Epoch 51/110
 - 3s - loss: 0.4734 - accuracy: 0.8788 - val_loss: 1.2987 - val_accuracy: 0.6650
Epoch 52/110
 - 3s - loss: 0.4705 - accuracy: 0.8812 - val_loss: 1.3577 - val_accuracy: 0.6460
Epoch 53/110
 - 3s - loss: 0.4897 - accuracy: 0.8744 - val_loss: 1.4370 - val_accuracy: 0.6321
Epoch 54/110
 - 2s - loss: 0.5071 - accuracy: 0.8633 - val_loss: 1.5534 - val_accuracy: 0.6036
Epoch 55/110
 - 2s - loss: 0.5306 - accuracy: 0.8583 - val_loss: 1.4490 - val_accuracy: 0.6372
Epoch 56/110
 - 2s - loss: 0.4777 - accuracy: 0.8810 - val_loss: 1.3885 - val_accuracy: 0.6496
Epoch 57/110
 - 2s - loss: 0.5067 - accuracy: 0.8691 - val_loss: 1.4080 - val_accuracy: 0.6226
Epoch 58/110
 - 3s - loss: 0.4897 - accuracy: 0.8746 - val_loss: 1.4445 - val_accuracy: 0.6285
Epoch 59/110
 - 2s - loss: 0.4641 - accuracy: 0.8850 - val_loss: 1.4828 - val_accuracy: 0.6139
Epoch 60/110
 - 2s - loss: 0.4530 - accuracy: 0.8883 - val_loss: 1.4185 - val_accuracy: 0.6380
Epoch 61/110
 - 2s - loss: 0.4342 - accuracy: 0.8992 - val_loss: 1.4302 - val_accuracy: 0.6526
Epoch 62/110
 - 2s - loss: 0.4694 - accuracy: 0.8786 - val_loss: 1.6088 - val_accuracy: 0.6328
Epoch 63/110
 - 2s - loss: 0.4549 - accuracy: 0.8901 - val_loss: 1.5899 - val_accuracy: 0.6131
Epoch 64/110
 - 2s - loss: 0.4388 - accuracy: 0.8965 - val_loss: 1.5922 - val_accuracy: 0.5920
Epoch 65/110
 - 2s - loss: 0.4726 - accuracy: 0.8839 - val_loss: 1.5789 - val_accuracy: 0.6204
Epoch 66/110
 - 3s - loss: 0.4676 - accuracy: 0.8859 - val_loss: 1.5195 - val_accuracy: 0.6380
Epoch 67/110
 - 3s - loss: 0.4371 - accuracy: 0.9000 - val_loss: 1.5571 - val_accuracy: 0.6285
Epoch 68/110
 - 3s - loss: 0.4727 - accuracy: 0.8857 - val_loss: 1.4211 - val_accuracy: 0.6591
Epoch 69/110
 - 2s - loss: 0.4551 - accuracy: 0.8908 - val_loss: 1.4416 - val_accuracy: 0.6438
Epoch 70/110
 - 3s - loss: 0.4629 - accuracy: 0.8905 - val_loss: 1.4517 - val_accuracy: 0.6445
Epoch 71/110
 - 3s - loss: 0.4579 - accuracy: 0.8917 - val_loss: 1.3838 - val_accuracy: 0.6460
Epoch 72/110
 - 2s - loss: 0.4175 - accuracy: 0.9027 - val_loss: 1.3968 - val_accuracy: 0.6672
Epoch 73/110
 - 2s - loss: 0.4115 - accuracy: 0.9038 - val_loss: 1.4704 - val_accuracy: 0.6511
Epoch 74/110
 - 2s - loss: 0.4007 - accuracy: 0.9120 - val_loss: 1.4875 - val_accuracy: 0.6562
Epoch 75/110
 - 2s - loss: 0.4022 - accuracy: 0.9124 - val_loss: 1.6099 - val_accuracy: 0.6336
Epoch 76/110
 - 2s - loss: 0.4251 - accuracy: 0.9029 - val_loss: 1.4044 - val_accuracy: 0.6708
Epoch 77/110
 - 2s - loss: 0.4022 - accuracy: 0.9160 - val_loss: 1.4499 - val_accuracy: 0.6555
Epoch 78/110
 - 2s - loss: 0.4194 - accuracy: 0.9074 - val_loss: 1.5637 - val_accuracy: 0.6453
Epoch 79/110
 - 3s - loss: 0.4300 - accuracy: 0.8983 - val_loss: 1.5171 - val_accuracy: 0.6650
Epoch 80/110
 - 3s - loss: 0.4049 - accuracy: 0.9135 - val_loss: 1.5416 - val_accuracy: 0.6467
Epoch 81/110
 - 3s - loss: 0.3964 - accuracy: 0.9168 - val_loss: 1.6207 - val_accuracy: 0.6168
Epoch 82/110
 - 2s - loss: 0.3769 - accuracy: 0.9184 - val_loss: 1.5672 - val_accuracy: 0.6380
Epoch 83/110
 - 3s - loss: 0.4452 - accuracy: 0.9023 - val_loss: 1.5736 - val_accuracy: 0.6460
Epoch 84/110
 - 2s - loss: 0.4414 - accuracy: 0.8956 - val_loss: 1.5406 - val_accuracy: 0.6664
Epoch 85/110
 - 2s - loss: 0.3916 - accuracy: 0.9197 - val_loss: 1.4696 - val_accuracy: 0.6708
Epoch 86/110
 - 3s - loss: 0.3587 - accuracy: 0.9321 - val_loss: 1.5057 - val_accuracy: 0.6650
Epoch 87/110
 - 3s - loss: 0.3856 - accuracy: 0.9199 - val_loss: 1.6339 - val_accuracy: 0.6175
Epoch 88/110
 - 3s - loss: 0.3990 - accuracy: 0.9118 - val_loss: 1.5481 - val_accuracy: 0.6628
Epoch 89/110
 - 3s - loss: 0.3993 - accuracy: 0.9180 - val_loss: 1.4520 - val_accuracy: 0.6825
Epoch 90/110
 - 3s - loss: 0.3776 - accuracy: 0.9230 - val_loss: 1.5956 - val_accuracy: 0.6504
Epoch 91/110
 - 3s - loss: 0.3740 - accuracy: 0.9259 - val_loss: 1.5598 - val_accuracy: 0.6591
Epoch 92/110
 - 3s - loss: 0.3830 - accuracy: 0.9206 - val_loss: 1.5745 - val_accuracy: 0.6628
Epoch 93/110
 - 3s - loss: 0.3803 - accuracy: 0.9261 - val_loss: 1.5142 - val_accuracy: 0.6810
Epoch 94/110
 - 2s - loss: 0.3573 - accuracy: 0.9315 - val_loss: 1.5828 - val_accuracy: 0.6657
Epoch 95/110
 - 2s - loss: 0.3710 - accuracy: 0.9299 - val_loss: 1.4616 - val_accuracy: 0.6635
Epoch 96/110
 - 3s - loss: 0.3448 - accuracy: 0.9367 - val_loss: 1.7483 - val_accuracy: 0.6482
Epoch 97/110
 - 2s - loss: 0.3633 - accuracy: 0.9321 - val_loss: 1.6607 - val_accuracy: 0.6635
Epoch 98/110
 - 3s - loss: 0.3589 - accuracy: 0.9321 - val_loss: 1.5902 - val_accuracy: 0.6701
Epoch 99/110
 - 2s - loss: 0.3405 - accuracy: 0.9390 - val_loss: 1.6420 - val_accuracy: 0.6613
Epoch 100/110
 - 3s - loss: 0.3919 - accuracy: 0.9210 - val_loss: 1.5977 - val_accuracy: 0.6650
Epoch 101/110
 - 3s - loss: 0.3734 - accuracy: 0.9281 - val_loss: 1.6247 - val_accuracy: 0.6526
Epoch 102/110
 - 2s - loss: 0.3578 - accuracy: 0.9336 - val_loss: 1.5810 - val_accuracy: 0.6679
Epoch 103/110
 - 3s - loss: 0.3539 - accuracy: 0.9336 - val_loss: 1.5271 - val_accuracy: 0.6766
Epoch 104/110
 - 3s - loss: 0.3472 - accuracy: 0.9356 - val_loss: 1.6081 - val_accuracy: 0.6876
Epoch 105/110
 - 2s - loss: 0.3517 - accuracy: 0.9359 - val_loss: 1.6630 - val_accuracy: 0.6606
Epoch 106/110
 - 2s - loss: 0.3712 - accuracy: 0.9295 - val_loss: 1.5722 - val_accuracy: 0.6642
Epoch 107/110
 - 3s - loss: 0.3762 - accuracy: 0.9261 - val_loss: 1.5859 - val_accuracy: 0.6818
Epoch 108/110
 - 3s - loss: 0.3588 - accuracy: 0.9308 - val_loss: 1.6186 - val_accuracy: 0.6416
Epoch 109/110
 - 2s - loss: 0.3544 - accuracy: 0.9354 - val_loss: 1.6666 - val_accuracy: 0.6803
Epoch 110/110
 - 3s - loss: 0.3463 - accuracy: 0.9378 - val_loss: 1.6333 - val_accuracy: 0.6825
------------------------------------------------------------------------
Training for fold 4 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 7s - loss: 1.5849 - accuracy: 0.4545 - val_loss: 2.1969 - val_accuracy: 0.2978
Epoch 2/110
 - 3s - loss: 1.1791 - accuracy: 0.5661 - val_loss: 1.5918 - val_accuracy: 0.4015
Epoch 3/110
 - 3s - loss: 1.0797 - accuracy: 0.6170 - val_loss: 1.3103 - val_accuracy: 0.5044
Epoch 4/110
 - 3s - loss: 1.0124 - accuracy: 0.6497 - val_loss: 1.1892 - val_accuracy: 0.5672
Epoch 5/110
 - 3s - loss: 0.9627 - accuracy: 0.6687 - val_loss: 1.2042 - val_accuracy: 0.5723
Epoch 6/110
 - 2s - loss: 0.9277 - accuracy: 0.6889 - val_loss: 1.2331 - val_accuracy: 0.5715
Epoch 7/110
 - 3s - loss: 0.9094 - accuracy: 0.6950 - val_loss: 1.2025 - val_accuracy: 0.5839
Epoch 8/110
 - 3s - loss: 0.8963 - accuracy: 0.6951 - val_loss: 1.1923 - val_accuracy: 0.5796
Epoch 9/110
 - 3s - loss: 0.9033 - accuracy: 0.6961 - val_loss: 1.2704 - val_accuracy: 0.5555
Epoch 10/110
 - 3s - loss: 0.8747 - accuracy: 0.7032 - val_loss: 1.2205 - val_accuracy: 0.5818
Epoch 11/110
 - 3s - loss: 0.8395 - accuracy: 0.7231 - val_loss: 1.2515 - val_accuracy: 0.5891
Epoch 12/110
 - 3s - loss: 0.8526 - accuracy: 0.7147 - val_loss: 1.2706 - val_accuracy: 0.5796
Epoch 13/110
 - 3s - loss: 0.8404 - accuracy: 0.7194 - val_loss: 1.3495 - val_accuracy: 0.5730
Epoch 14/110
 - 3s - loss: 0.8573 - accuracy: 0.7156 - val_loss: 1.2043 - val_accuracy: 0.5796
Epoch 15/110
 - 3s - loss: 0.8129 - accuracy: 0.7322 - val_loss: 1.2255 - val_accuracy: 0.5752
Epoch 16/110
 - 3s - loss: 0.7802 - accuracy: 0.7448 - val_loss: 1.2579 - val_accuracy: 0.5715
Epoch 17/110
 - 3s - loss: 0.7655 - accuracy: 0.7532 - val_loss: 1.2654 - val_accuracy: 0.5737
Epoch 18/110
 - 3s - loss: 0.7491 - accuracy: 0.7574 - val_loss: 1.2169 - val_accuracy: 0.5912
Epoch 19/110
 - 3s - loss: 0.7282 - accuracy: 0.7621 - val_loss: 1.1783 - val_accuracy: 0.6182
Epoch 20/110
 - 3s - loss: 0.7220 - accuracy: 0.7738 - val_loss: 1.2705 - val_accuracy: 0.5876
Epoch 21/110
 - 2s - loss: 0.7193 - accuracy: 0.7736 - val_loss: 1.2619 - val_accuracy: 0.5956
Epoch 22/110
 - 2s - loss: 0.6937 - accuracy: 0.7848 - val_loss: 1.2438 - val_accuracy: 0.5964
Epoch 23/110
 - 3s - loss: 0.6996 - accuracy: 0.7864 - val_loss: 1.2587 - val_accuracy: 0.6015
Epoch 24/110
 - 3s - loss: 0.6948 - accuracy: 0.7808 - val_loss: 1.3763 - val_accuracy: 0.5708
Epoch 25/110
 - 3s - loss: 0.7025 - accuracy: 0.7788 - val_loss: 1.3696 - val_accuracy: 0.5584
Epoch 26/110
 - 3s - loss: 0.6979 - accuracy: 0.7870 - val_loss: 1.3980 - val_accuracy: 0.5620
Epoch 27/110
 - 3s - loss: 0.7256 - accuracy: 0.7724 - val_loss: 1.3239 - val_accuracy: 0.5854
Epoch 28/110
 - 2s - loss: 0.7236 - accuracy: 0.7607 - val_loss: 1.3503 - val_accuracy: 0.5818
Epoch 29/110
 - 3s - loss: 0.7112 - accuracy: 0.7727 - val_loss: 1.3411 - val_accuracy: 0.5876
Epoch 30/110
 - 3s - loss: 0.6837 - accuracy: 0.7886 - val_loss: 1.2721 - val_accuracy: 0.5876
Epoch 31/110
 - 3s - loss: 0.6757 - accuracy: 0.7886 - val_loss: 1.3485 - val_accuracy: 0.5847
Epoch 32/110
 - 2s - loss: 0.6679 - accuracy: 0.7997 - val_loss: 1.3278 - val_accuracy: 0.6073
Epoch 33/110
 - 2s - loss: 0.6650 - accuracy: 0.7939 - val_loss: 1.2910 - val_accuracy: 0.6153
Epoch 34/110
 - 3s - loss: 0.6511 - accuracy: 0.7985 - val_loss: 1.3947 - val_accuracy: 0.5927
Epoch 35/110
 - 2s - loss: 0.6384 - accuracy: 0.8065 - val_loss: 1.3227 - val_accuracy: 0.6153
Epoch 36/110
 - 3s - loss: 0.6157 - accuracy: 0.8154 - val_loss: 1.4049 - val_accuracy: 0.5927
Epoch 37/110
 - 2s - loss: 0.6242 - accuracy: 0.8067 - val_loss: 1.3252 - val_accuracy: 0.6234
Epoch 38/110
 - 3s - loss: 0.6220 - accuracy: 0.8142 - val_loss: 1.3989 - val_accuracy: 0.6073
Epoch 39/110
 - 3s - loss: 0.6005 - accuracy: 0.8184 - val_loss: 1.3731 - val_accuracy: 0.6095
Epoch 40/110
 - 2s - loss: 0.6026 - accuracy: 0.8195 - val_loss: 1.3722 - val_accuracy: 0.6088
Epoch 41/110
 - 3s - loss: 0.5989 - accuracy: 0.8200 - val_loss: 1.3099 - val_accuracy: 0.6380
Epoch 42/110
 - 3s - loss: 0.5856 - accuracy: 0.8268 - val_loss: 1.4604 - val_accuracy: 0.5839
Epoch 43/110
 - 3s - loss: 0.6016 - accuracy: 0.8251 - val_loss: 1.5148 - val_accuracy: 0.5723
Epoch 44/110
 - 3s - loss: 0.5962 - accuracy: 0.8262 - val_loss: 1.3653 - val_accuracy: 0.6102
Epoch 45/110
 - 3s - loss: 0.6031 - accuracy: 0.8195 - val_loss: 1.3032 - val_accuracy: 0.6358
Epoch 46/110
 - 3s - loss: 0.5712 - accuracy: 0.8415 - val_loss: 1.3807 - val_accuracy: 0.6117
Epoch 47/110
 - 3s - loss: 0.5789 - accuracy: 0.8379 - val_loss: 1.3397 - val_accuracy: 0.6212
Epoch 48/110
 - 3s - loss: 0.5696 - accuracy: 0.8403 - val_loss: 1.4128 - val_accuracy: 0.6066
Epoch 49/110
 - 3s - loss: 0.5423 - accuracy: 0.8501 - val_loss: 1.3727 - val_accuracy: 0.6131
Epoch 50/110
 - 3s - loss: 0.5266 - accuracy: 0.8529 - val_loss: 1.4929 - val_accuracy: 0.6219
Epoch 51/110
 - 3s - loss: 0.5429 - accuracy: 0.8410 - val_loss: 1.5257 - val_accuracy: 0.6182
Epoch 52/110
 - 3s - loss: 0.5686 - accuracy: 0.8346 - val_loss: 1.4551 - val_accuracy: 0.6204
Epoch 53/110
 - 3s - loss: 0.5635 - accuracy: 0.8439 - val_loss: 1.4548 - val_accuracy: 0.6197
Epoch 54/110
 - 3s - loss: 0.5753 - accuracy: 0.8304 - val_loss: 1.3265 - val_accuracy: 0.6241
Epoch 55/110
 - 2s - loss: 0.5379 - accuracy: 0.8474 - val_loss: 1.4822 - val_accuracy: 0.6044
Epoch 56/110
 - 3s - loss: 0.5513 - accuracy: 0.8408 - val_loss: 1.3918 - val_accuracy: 0.6248
Epoch 57/110
 - 3s - loss: 0.5250 - accuracy: 0.8563 - val_loss: 1.3506 - val_accuracy: 0.6380
Epoch 58/110
 - 2s - loss: 0.5251 - accuracy: 0.8574 - val_loss: 1.3473 - val_accuracy: 0.6467
Epoch 59/110
 - 2s - loss: 0.5070 - accuracy: 0.8618 - val_loss: 1.3759 - val_accuracy: 0.6431
Epoch 60/110
 - 3s - loss: 0.5126 - accuracy: 0.8645 - val_loss: 1.3853 - val_accuracy: 0.6401
Epoch 61/110
 - 3s - loss: 0.5222 - accuracy: 0.8578 - val_loss: 1.4669 - val_accuracy: 0.6299
Epoch 62/110
 - 3s - loss: 0.5231 - accuracy: 0.8574 - val_loss: 1.3491 - val_accuracy: 0.6423
Epoch 63/110
 - 2s - loss: 0.5103 - accuracy: 0.8645 - val_loss: 1.4351 - val_accuracy: 0.6547
Epoch 64/110
 - 3s - loss: 0.4753 - accuracy: 0.8793 - val_loss: 1.3847 - val_accuracy: 0.6562
Epoch 65/110
 - 3s - loss: 0.4932 - accuracy: 0.8704 - val_loss: 1.4827 - val_accuracy: 0.6599
Epoch 66/110
 - 3s - loss: 0.4678 - accuracy: 0.8839 - val_loss: 1.5077 - val_accuracy: 0.6591
Epoch 67/110
 - 3s - loss: 0.4860 - accuracy: 0.8722 - val_loss: 1.5688 - val_accuracy: 0.6511
Epoch 68/110
 - 3s - loss: 0.4861 - accuracy: 0.8779 - val_loss: 1.5338 - val_accuracy: 0.6518
Epoch 69/110
 - 3s - loss: 0.4802 - accuracy: 0.8757 - val_loss: 1.5492 - val_accuracy: 0.6416
Epoch 70/110
 - 3s - loss: 0.4581 - accuracy: 0.8861 - val_loss: 1.5157 - val_accuracy: 0.6343
Epoch 71/110
 - 3s - loss: 0.4354 - accuracy: 0.8961 - val_loss: 1.4868 - val_accuracy: 0.6606
Epoch 72/110
 - 3s - loss: 0.4045 - accuracy: 0.9100 - val_loss: 1.5557 - val_accuracy: 0.6365
Epoch 73/110
 - 3s - loss: 0.4233 - accuracy: 0.9032 - val_loss: 1.5604 - val_accuracy: 0.6372
Epoch 74/110
 - 3s - loss: 0.4450 - accuracy: 0.8980 - val_loss: 1.5318 - val_accuracy: 0.6511
Epoch 75/110
 - 3s - loss: 0.4299 - accuracy: 0.9009 - val_loss: 1.6015 - val_accuracy: 0.6372
Epoch 76/110
 - 3s - loss: 0.4395 - accuracy: 0.8996 - val_loss: 1.4879 - val_accuracy: 0.6679
Epoch 77/110
 - 3s - loss: 0.4320 - accuracy: 0.8972 - val_loss: 1.5976 - val_accuracy: 0.6620
Epoch 78/110
 - 3s - loss: 0.4305 - accuracy: 0.9001 - val_loss: 1.6192 - val_accuracy: 0.6474
Epoch 79/110
 - 3s - loss: 0.4076 - accuracy: 0.9084 - val_loss: 1.5950 - val_accuracy: 0.6526
Epoch 80/110
 - 3s - loss: 0.4327 - accuracy: 0.8987 - val_loss: 1.6862 - val_accuracy: 0.6438
Epoch 81/110
 - 3s - loss: 0.4099 - accuracy: 0.9071 - val_loss: 1.6073 - val_accuracy: 0.6445
Epoch 82/110
 - 3s - loss: 0.3989 - accuracy: 0.9173 - val_loss: 1.6574 - val_accuracy: 0.6365
Epoch 83/110
 - 3s - loss: 0.4164 - accuracy: 0.9047 - val_loss: 1.6041 - val_accuracy: 0.6642
Epoch 84/110
 - 3s - loss: 0.4337 - accuracy: 0.9022 - val_loss: 1.9126 - val_accuracy: 0.6336
Epoch 85/110
 - 3s - loss: 0.4484 - accuracy: 0.8914 - val_loss: 1.5126 - val_accuracy: 0.6482
Epoch 86/110
 - 3s - loss: 0.3888 - accuracy: 0.9188 - val_loss: 1.5559 - val_accuracy: 0.6467
Epoch 87/110
 - 3s - loss: 0.3944 - accuracy: 0.9191 - val_loss: 1.5398 - val_accuracy: 0.6350
Epoch 88/110
 - 3s - loss: 0.3990 - accuracy: 0.9102 - val_loss: 1.7173 - val_accuracy: 0.6474
Epoch 89/110
 - 3s - loss: 0.3942 - accuracy: 0.9166 - val_loss: 1.5295 - val_accuracy: 0.6606
Epoch 90/110
 - 2s - loss: 0.3964 - accuracy: 0.9137 - val_loss: 1.6616 - val_accuracy: 0.6533
Epoch 91/110
 - 3s - loss: 0.4128 - accuracy: 0.9098 - val_loss: 1.7211 - val_accuracy: 0.6365
Epoch 92/110
 - 3s - loss: 0.3911 - accuracy: 0.9193 - val_loss: 1.6606 - val_accuracy: 0.6540
Epoch 93/110
 - 3s - loss: 0.3772 - accuracy: 0.9235 - val_loss: 1.6588 - val_accuracy: 0.6599
Epoch 94/110
 - 3s - loss: 0.3558 - accuracy: 0.9306 - val_loss: 1.6751 - val_accuracy: 0.6460
Epoch 95/110
 - 3s - loss: 0.3535 - accuracy: 0.9359 - val_loss: 1.7809 - val_accuracy: 0.6657
Epoch 96/110
 - 3s - loss: 0.3807 - accuracy: 0.9242 - val_loss: 1.8167 - val_accuracy: 0.6569
Epoch 97/110
 - 3s - loss: 0.3921 - accuracy: 0.9200 - val_loss: 1.7141 - val_accuracy: 0.6577
Epoch 98/110
 - 3s - loss: 0.3762 - accuracy: 0.9264 - val_loss: 1.7462 - val_accuracy: 0.6577
Epoch 99/110
 - 3s - loss: 0.4014 - accuracy: 0.9135 - val_loss: 1.8057 - val_accuracy: 0.6372
Epoch 100/110
 - 2s - loss: 0.3823 - accuracy: 0.9230 - val_loss: 1.6099 - val_accuracy: 0.6657
Epoch 101/110
 - 3s - loss: 0.3555 - accuracy: 0.9367 - val_loss: 1.6001 - val_accuracy: 0.6847
Epoch 102/110
 - 3s - loss: 0.3437 - accuracy: 0.9374 - val_loss: 1.7354 - val_accuracy: 0.6518
Epoch 103/110
 - 2s - loss: 0.3414 - accuracy: 0.9390 - val_loss: 1.7073 - val_accuracy: 0.6518
Epoch 104/110
 - 2s - loss: 0.3464 - accuracy: 0.9376 - val_loss: 1.7908 - val_accuracy: 0.6679
Epoch 105/110
 - 2s - loss: 0.3842 - accuracy: 0.9242 - val_loss: 1.9062 - val_accuracy: 0.6416
Epoch 106/110
 - 3s - loss: 0.3924 - accuracy: 0.9219 - val_loss: 1.6067 - val_accuracy: 0.6854
Epoch 107/110
 - 2s - loss: 0.3522 - accuracy: 0.9372 - val_loss: 1.6306 - val_accuracy: 0.6810
Epoch 108/110
 - 2s - loss: 0.3386 - accuracy: 0.9385 - val_loss: 1.8896 - val_accuracy: 0.6533
Epoch 109/110
 - 2s - loss: 0.3629 - accuracy: 0.9370 - val_loss: 1.7863 - val_accuracy: 0.6723
Epoch 110/110
 - 3s - loss: 0.3537 - accuracy: 0.9378 - val_loss: 1.6546 - val_accuracy: 0.6715
------------------------------------------------------------------------
Training for fold 5 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 7s - loss: 1.5328 - accuracy: 0.4726 - val_loss: 1.7452 - val_accuracy: 0.3241
Epoch 2/110
 - 3s - loss: 1.1555 - accuracy: 0.5818 - val_loss: 1.4405 - val_accuracy: 0.4336
Epoch 3/110
 - 3s - loss: 1.0521 - accuracy: 0.6313 - val_loss: 1.2823 - val_accuracy: 0.5175
Epoch 4/110
 - 3s - loss: 0.9884 - accuracy: 0.6692 - val_loss: 1.1911 - val_accuracy: 0.5679
Epoch 5/110
 - 3s - loss: 0.9384 - accuracy: 0.6829 - val_loss: 1.1535 - val_accuracy: 0.6073
Epoch 6/110
 - 3s - loss: 0.9105 - accuracy: 0.6920 - val_loss: 1.1701 - val_accuracy: 0.6007
Epoch 7/110
 - 3s - loss: 0.9018 - accuracy: 0.6981 - val_loss: 1.1526 - val_accuracy: 0.5825
Epoch 8/110
 - 3s - loss: 0.8719 - accuracy: 0.7085 - val_loss: 1.1455 - val_accuracy: 0.6015
Epoch 9/110
 - 3s - loss: 0.8833 - accuracy: 0.7112 - val_loss: 1.2062 - val_accuracy: 0.5752
Epoch 10/110
 - 3s - loss: 0.8516 - accuracy: 0.7200 - val_loss: 1.2454 - val_accuracy: 0.5686
Epoch 11/110
 - 3s - loss: 0.8536 - accuracy: 0.7222 - val_loss: 1.2300 - val_accuracy: 0.5628
Epoch 12/110
 - 3s - loss: 0.8420 - accuracy: 0.7218 - val_loss: 1.1984 - val_accuracy: 0.6022
Epoch 13/110
 - 3s - loss: 0.8391 - accuracy: 0.7200 - val_loss: 1.2904 - val_accuracy: 0.5591
Epoch 14/110
 - 3s - loss: 0.7907 - accuracy: 0.7426 - val_loss: 1.3469 - val_accuracy: 0.5416
Epoch 15/110
 - 3s - loss: 0.7754 - accuracy: 0.7455 - val_loss: 1.3105 - val_accuracy: 0.5861
Epoch 16/110
 - 3s - loss: 0.7672 - accuracy: 0.7499 - val_loss: 1.2093 - val_accuracy: 0.6066
Epoch 17/110
 - 3s - loss: 0.7601 - accuracy: 0.7558 - val_loss: 1.2134 - val_accuracy: 0.5861
Epoch 18/110
 - 3s - loss: 0.7478 - accuracy: 0.7651 - val_loss: 1.2567 - val_accuracy: 0.5788
Epoch 19/110
 - 3s - loss: 0.7510 - accuracy: 0.7561 - val_loss: 1.2346 - val_accuracy: 0.6051
Epoch 20/110
 - 3s - loss: 0.7531 - accuracy: 0.7592 - val_loss: 1.2108 - val_accuracy: 0.6190
Epoch 21/110
 - 3s - loss: 0.7339 - accuracy: 0.7680 - val_loss: 1.3405 - val_accuracy: 0.5810
Epoch 22/110
 - 3s - loss: 0.7284 - accuracy: 0.7662 - val_loss: 1.4261 - val_accuracy: 0.5672
Epoch 23/110
 - 3s - loss: 0.7016 - accuracy: 0.7791 - val_loss: 1.4634 - val_accuracy: 0.5686
Epoch 24/110
 - 3s - loss: 0.7119 - accuracy: 0.7725 - val_loss: 1.4110 - val_accuracy: 0.5701
Epoch 25/110
 - 3s - loss: 0.7268 - accuracy: 0.7656 - val_loss: 1.3418 - val_accuracy: 0.6029
Epoch 26/110
 - 3s - loss: 0.7365 - accuracy: 0.7641 - val_loss: 1.2964 - val_accuracy: 0.5861
Epoch 27/110
 - 3s - loss: 0.7453 - accuracy: 0.7537 - val_loss: 1.3610 - val_accuracy: 0.5693
Epoch 28/110
 - 3s - loss: 0.7192 - accuracy: 0.7696 - val_loss: 1.2795 - val_accuracy: 0.5964
Epoch 29/110
 - 3s - loss: 0.7069 - accuracy: 0.7771 - val_loss: 1.2384 - val_accuracy: 0.6212
Epoch 30/110
 - 3s - loss: 0.6700 - accuracy: 0.7943 - val_loss: 1.2458 - val_accuracy: 0.6182
Epoch 31/110
 - 3s - loss: 0.6479 - accuracy: 0.7992 - val_loss: 1.2236 - val_accuracy: 0.6321
Epoch 32/110
 - 3s - loss: 0.6538 - accuracy: 0.7999 - val_loss: 1.2307 - val_accuracy: 0.6314
Epoch 33/110
 - 3s - loss: 0.6554 - accuracy: 0.7961 - val_loss: 1.2980 - val_accuracy: 0.6073
Epoch 34/110
 - 3s - loss: 0.6624 - accuracy: 0.7974 - val_loss: 1.2794 - val_accuracy: 0.6036
Epoch 35/110
 - 3s - loss: 0.6203 - accuracy: 0.8127 - val_loss: 1.2898 - val_accuracy: 0.6029
Epoch 36/110
 - 3s - loss: 0.6027 - accuracy: 0.8238 - val_loss: 1.2638 - val_accuracy: 0.5985
Epoch 37/110
 - 3s - loss: 0.6196 - accuracy: 0.8162 - val_loss: 1.3263 - val_accuracy: 0.6095
Epoch 38/110
 - 3s - loss: 0.5949 - accuracy: 0.8269 - val_loss: 1.2963 - val_accuracy: 0.6226
Epoch 39/110
 - 3s - loss: 0.6109 - accuracy: 0.8187 - val_loss: 1.3934 - val_accuracy: 0.5949
Epoch 40/110
 - 3s - loss: 0.6206 - accuracy: 0.8129 - val_loss: 1.3702 - val_accuracy: 0.6102
Epoch 41/110
 - 3s - loss: 0.6044 - accuracy: 0.8187 - val_loss: 1.3178 - val_accuracy: 0.6073
Epoch 42/110
 - 3s - loss: 0.5824 - accuracy: 0.8288 - val_loss: 1.3173 - val_accuracy: 0.6277
Epoch 43/110
 - 3s - loss: 0.5768 - accuracy: 0.8322 - val_loss: 1.2974 - val_accuracy: 0.6380
Epoch 44/110
 - 3s - loss: 0.5955 - accuracy: 0.8277 - val_loss: 1.4169 - val_accuracy: 0.6029
Epoch 45/110
 - 3s - loss: 0.5805 - accuracy: 0.8302 - val_loss: 1.4118 - val_accuracy: 0.6182
Epoch 46/110
 - 3s - loss: 0.5649 - accuracy: 0.8419 - val_loss: 1.3789 - val_accuracy: 0.6117
Epoch 47/110
 - 3s - loss: 0.5781 - accuracy: 0.8322 - val_loss: 1.3941 - val_accuracy: 0.6036
Epoch 48/110
 - 3s - loss: 0.5693 - accuracy: 0.8350 - val_loss: 1.2769 - val_accuracy: 0.6358
Epoch 49/110
 - 3s - loss: 0.5397 - accuracy: 0.8430 - val_loss: 1.3177 - val_accuracy: 0.6423
Epoch 50/110
 - 3s - loss: 0.5339 - accuracy: 0.8530 - val_loss: 1.3959 - val_accuracy: 0.6562
Epoch 51/110
 - 3s - loss: 0.5309 - accuracy: 0.8510 - val_loss: 1.4241 - val_accuracy: 0.6350
Epoch 52/110
 - 3s - loss: 0.5425 - accuracy: 0.8516 - val_loss: 1.3951 - val_accuracy: 0.6241
Epoch 53/110
 - 3s - loss: 0.5323 - accuracy: 0.8556 - val_loss: 1.3511 - val_accuracy: 0.6336
Epoch 54/110
 - 3s - loss: 0.5354 - accuracy: 0.8518 - val_loss: 1.3430 - val_accuracy: 0.6394
Epoch 55/110
 - 3s - loss: 0.4923 - accuracy: 0.8717 - val_loss: 1.4030 - val_accuracy: 0.6635
Epoch 56/110
 - 3s - loss: 0.4796 - accuracy: 0.8792 - val_loss: 1.3714 - val_accuracy: 0.6679
Epoch 57/110
 - 3s - loss: 0.5065 - accuracy: 0.8647 - val_loss: 1.4390 - val_accuracy: 0.6226
Epoch 58/110
 - 3s - loss: 0.5005 - accuracy: 0.8728 - val_loss: 1.3809 - val_accuracy: 0.6453
Epoch 59/110
 - 3s - loss: 0.4764 - accuracy: 0.8792 - val_loss: 1.4163 - val_accuracy: 0.6460
Epoch 60/110
 - 3s - loss: 0.4611 - accuracy: 0.8819 - val_loss: 1.3781 - val_accuracy: 0.6642
Epoch 61/110
 - 3s - loss: 0.4644 - accuracy: 0.8799 - val_loss: 1.5785 - val_accuracy: 0.6328
Epoch 62/110
 - 3s - loss: 0.4600 - accuracy: 0.8828 - val_loss: 1.5173 - val_accuracy: 0.6263
Epoch 63/110
 - 3s - loss: 0.4662 - accuracy: 0.8841 - val_loss: 1.5334 - val_accuracy: 0.6307
Epoch 64/110
 - 3s - loss: 0.4606 - accuracy: 0.8848 - val_loss: 1.5532 - val_accuracy: 0.6299
Epoch 65/110
 - 3s - loss: 0.4793 - accuracy: 0.8799 - val_loss: 1.5585 - val_accuracy: 0.6387
Epoch 66/110
 - 3s - loss: 0.4562 - accuracy: 0.8843 - val_loss: 1.4971 - val_accuracy: 0.6416
Epoch 67/110
 - 3s - loss: 0.4668 - accuracy: 0.8832 - val_loss: 1.6162 - val_accuracy: 0.6460
Epoch 68/110
 - 3s - loss: 0.4607 - accuracy: 0.8832 - val_loss: 1.5895 - val_accuracy: 0.6453
Epoch 69/110
 - 3s - loss: 0.4534 - accuracy: 0.8908 - val_loss: 1.5977 - val_accuracy: 0.6526
Epoch 70/110
 - 3s - loss: 0.4429 - accuracy: 0.8978 - val_loss: 1.5471 - val_accuracy: 0.6511
Epoch 71/110
 - 3s - loss: 0.4546 - accuracy: 0.8950 - val_loss: 1.5209 - val_accuracy: 0.6693
Epoch 72/110
 - 3s - loss: 0.4529 - accuracy: 0.8910 - val_loss: 1.5457 - val_accuracy: 0.6482
Epoch 73/110
 - 3s - loss: 0.4345 - accuracy: 0.8989 - val_loss: 1.5620 - val_accuracy: 0.6628
Epoch 74/110
 - 3s - loss: 0.4726 - accuracy: 0.8839 - val_loss: 1.5331 - val_accuracy: 0.6686
Epoch 75/110
 - 3s - loss: 0.4308 - accuracy: 0.8998 - val_loss: 1.5895 - val_accuracy: 0.6482
Epoch 76/110
 - 3s - loss: 0.4179 - accuracy: 0.9023 - val_loss: 1.7055 - val_accuracy: 0.6131
Epoch 77/110
 - 3s - loss: 0.4195 - accuracy: 0.9093 - val_loss: 1.5837 - val_accuracy: 0.6372
Epoch 78/110
 - 3s - loss: 0.4130 - accuracy: 0.9040 - val_loss: 1.6038 - val_accuracy: 0.6445
Epoch 79/110
 - 3s - loss: 0.4294 - accuracy: 0.8978 - val_loss: 1.6146 - val_accuracy: 0.6438
Epoch 80/110
 - 3s - loss: 0.4707 - accuracy: 0.8870 - val_loss: 1.4909 - val_accuracy: 0.6562
Epoch 81/110
 - 3s - loss: 0.4277 - accuracy: 0.9011 - val_loss: 1.4892 - val_accuracy: 0.6642
Epoch 82/110
 - 3s - loss: 0.3829 - accuracy: 0.9179 - val_loss: 1.4947 - val_accuracy: 0.6628
Epoch 83/110
 - 3s - loss: 0.3774 - accuracy: 0.9211 - val_loss: 1.6161 - val_accuracy: 0.6577
Epoch 84/110
 - 3s - loss: 0.4093 - accuracy: 0.9118 - val_loss: 1.6693 - val_accuracy: 0.6540
Epoch 85/110
 - 3s - loss: 0.4155 - accuracy: 0.9065 - val_loss: 1.5305 - val_accuracy: 0.6511
Epoch 86/110
 - 3s - loss: 0.3864 - accuracy: 0.9189 - val_loss: 1.6343 - val_accuracy: 0.6657
Epoch 87/110
 - 3s - loss: 0.3954 - accuracy: 0.9162 - val_loss: 1.5554 - val_accuracy: 0.6693
Epoch 88/110
 - 3s - loss: 0.4040 - accuracy: 0.9169 - val_loss: 1.6219 - val_accuracy: 0.6467
Epoch 89/110
 - 3s - loss: 0.3762 - accuracy: 0.9210 - val_loss: 1.7050 - val_accuracy: 0.6423
Epoch 90/110
 - 3s - loss: 0.4123 - accuracy: 0.9106 - val_loss: 1.6073 - val_accuracy: 0.6577
Epoch 91/110
 - 3s - loss: 0.3821 - accuracy: 0.9275 - val_loss: 1.5935 - val_accuracy: 0.6693
Epoch 92/110
 - 3s - loss: 0.3661 - accuracy: 0.9246 - val_loss: 1.6293 - val_accuracy: 0.6672
Epoch 93/110
 - 3s - loss: 0.3596 - accuracy: 0.9315 - val_loss: 1.7085 - val_accuracy: 0.6496
Epoch 94/110
 - 3s - loss: 0.3939 - accuracy: 0.9168 - val_loss: 1.6723 - val_accuracy: 0.6438
Epoch 95/110
 - 3s - loss: 0.4029 - accuracy: 0.9127 - val_loss: 1.7962 - val_accuracy: 0.6394
Epoch 96/110
 - 3s - loss: 0.4056 - accuracy: 0.9137 - val_loss: 1.7226 - val_accuracy: 0.6416
Epoch 97/110
 - 3s - loss: 0.4087 - accuracy: 0.9146 - val_loss: 1.6342 - val_accuracy: 0.6504
Epoch 98/110
 - 3s - loss: 0.3638 - accuracy: 0.9319 - val_loss: 1.5056 - val_accuracy: 0.6672
Epoch 99/110
 - 3s - loss: 0.3668 - accuracy: 0.9310 - val_loss: 1.5694 - val_accuracy: 0.6540
Epoch 100/110
 - 3s - loss: 0.3564 - accuracy: 0.9294 - val_loss: 1.5671 - val_accuracy: 0.6664
Epoch 101/110
 - 3s - loss: 0.3781 - accuracy: 0.9263 - val_loss: 1.6553 - val_accuracy: 0.6562
Epoch 102/110
 - 3s - loss: 0.3905 - accuracy: 0.9224 - val_loss: 1.7148 - val_accuracy: 0.6547
Epoch 103/110
 - 3s - loss: 0.3690 - accuracy: 0.9266 - val_loss: 1.5702 - val_accuracy: 0.6679
Epoch 104/110
 - 3s - loss: 0.3737 - accuracy: 0.9292 - val_loss: 1.5601 - val_accuracy: 0.6657
Epoch 105/110
 - 3s - loss: 0.3436 - accuracy: 0.9383 - val_loss: 1.4168 - val_accuracy: 0.6818
Epoch 106/110
 - 3s - loss: 0.3562 - accuracy: 0.9319 - val_loss: 1.5957 - val_accuracy: 0.6781
Epoch 107/110
 - 3s - loss: 0.3623 - accuracy: 0.9301 - val_loss: 1.5499 - val_accuracy: 0.6752
Epoch 108/110
 - 3s - loss: 0.3468 - accuracy: 0.9359 - val_loss: 1.6034 - val_accuracy: 0.6679
Epoch 109/110
 - 3s - loss: 0.3594 - accuracy: 0.9308 - val_loss: 1.6774 - val_accuracy: 0.6540
Epoch 110/110
 - 3s - loss: 0.3623 - accuracy: 0.9317 - val_loss: 1.5293 - val_accuracy: 0.6781
------------------------------------------------------------------------
Score per fold
------------------------------------------------------------------------
Score for fold 1
Accuracy_Train: 74.59%
Accuracy_Test: 72.96%
Loss_Train: 1.21
Loss_Test: 1.25
------------------------------------------------------------------------
Score for fold 2
Accuracy_Train: 71.47%
Accuracy_Test: 71.90%
Loss_Train: 1.35
Loss_Test: 1.42
------------------------------------------------------------------------
Score for fold 3
Accuracy_Train: 73.15%
Accuracy_Test: 75.41%
Loss_Train: 1.23
Loss_Test: 1.12
------------------------------------------------------------------------
Score for fold 4
Accuracy_Train: 74.53%
Accuracy_Test: 74.24%
Loss_Train: 1.19
Loss_Test: 1.16
------------------------------------------------------------------------
Score for fold 5
Accuracy_Train: 71.83%
Accuracy_Test: 70.91%
Loss_Train: 1.20
Loss_Test: 1.27
------------------------------------------------------------------------
Average scores for all folds:
Average_Accuracy_Train: 73.11%
	-> (+- 1.3081834188143389 )
Average_Accuracy_Test: 73.08%
	-> (+- 1.6045113243751685 )
Average_Loss_Train: 1.24
	-> (+- 0.05674235002974509 )
Average_Loss_Test: 1.24
	-> (+- 0.10349922815316889 )
------------------------------------------------------------------------
