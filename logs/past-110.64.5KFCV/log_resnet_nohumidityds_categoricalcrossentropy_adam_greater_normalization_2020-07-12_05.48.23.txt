Dataset used: ../../datasets/full_dataset_without_humidity.csv 

   Temperature  Sound  Heartbeat   X1  ...    Y2     Z2  Classification  Feedback
0           32      1         60 -680  ... -7424 -15596             100     Happy
1           32      1         60 -780  ... -7408 -15628             100     Happy
2           -1      1         60   -1  ... -7276 -15612             100     Happy
3           -1     -1         60   -1  ...    -1     -1             100     Happy
4           32      1         60 -860  ... -7340 -15720             100     Happy

[5 rows x 11 columns]

Objservations: 8560
Reshaping:  ((6848, 10), (6848, 4), (1712, 10), (1712, 4))  -> ((6848, 10, 1), (6848, 4), (1712, 10, 1), (1712, 4))

Layers:

{'batch_input_shape': (None, 10, 1), 'dtype': 'float32', 'sparse': False, 'name': 'input_19'} 

{'name': 'conv1d_421', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_343', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_427', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_422', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_344', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_428', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_423', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_345', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_163', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_429', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_424', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_346', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_430', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_425', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_347', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_164', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_431', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_426', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_348', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_432', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_427', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_349', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_165', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_433', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_428', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_350', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_434', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_429', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_430', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_351', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_166', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_435', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_431', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_352', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_436', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_432', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_353', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_167', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_437', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_433', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_354', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_438', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_434', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_355', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_168', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_439', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_435', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_356', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_440', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_436', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_437', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_357', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_169', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_441', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_438', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_358', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_442', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_439', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_359', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_170', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_443', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_440', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_360', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_444', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_441', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_361', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_171', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_445', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'average_pooling1d_19', 'trainable': True, 'dtype': 'float32', 'strides': (1,), 'pool_size': (1,), 'padding': 'valid', 'data_format': 'channels_last'} 

{'name': 'flatten_61', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'} 

{'name': 'dense_1189', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 6s - loss: 1.1721 - accuracy: 0.6378 - val_loss: 1.9446 - val_accuracy: 0.3978
Epoch 2/110
 - 3s - loss: 0.7408 - accuracy: 0.7775 - val_loss: 0.9706 - val_accuracy: 0.6752
Epoch 3/110
 - 3s - loss: 0.6162 - accuracy: 0.8264 - val_loss: 0.7963 - val_accuracy: 0.7679
Epoch 4/110
 - 3s - loss: 0.5518 - accuracy: 0.8510 - val_loss: 0.7151 - val_accuracy: 0.8000
Epoch 5/110
 - 3s - loss: 0.5174 - accuracy: 0.8635 - val_loss: 0.7110 - val_accuracy: 0.7985
Epoch 6/110
 - 3s - loss: 0.4841 - accuracy: 0.8766 - val_loss: 0.6926 - val_accuracy: 0.8131
Epoch 7/110
 - 3s - loss: 0.4716 - accuracy: 0.8792 - val_loss: 0.7213 - val_accuracy: 0.8022
Epoch 8/110
 - 3s - loss: 0.4678 - accuracy: 0.8786 - val_loss: 0.7989 - val_accuracy: 0.7759
Epoch 9/110
 - 3s - loss: 0.4453 - accuracy: 0.8897 - val_loss: 0.8835 - val_accuracy: 0.7723
Epoch 10/110
 - 3s - loss: 0.4409 - accuracy: 0.8896 - val_loss: 0.8201 - val_accuracy: 0.7657
Epoch 11/110
 - 3s - loss: 0.4413 - accuracy: 0.8890 - val_loss: 0.8081 - val_accuracy: 0.7715
Epoch 12/110
 - 3s - loss: 0.4403 - accuracy: 0.8917 - val_loss: 0.7609 - val_accuracy: 0.7993
Epoch 13/110
 - 3s - loss: 0.4248 - accuracy: 0.8943 - val_loss: 0.7603 - val_accuracy: 0.7978
Epoch 14/110
 - 2s - loss: 0.4285 - accuracy: 0.8912 - val_loss: 0.7810 - val_accuracy: 0.7993
Epoch 15/110
 - 3s - loss: 0.4296 - accuracy: 0.8883 - val_loss: 0.7665 - val_accuracy: 0.8022
Epoch 16/110
 - 3s - loss: 0.4198 - accuracy: 0.8963 - val_loss: 0.7537 - val_accuracy: 0.8117
Epoch 17/110
 - 3s - loss: 0.4258 - accuracy: 0.8959 - val_loss: 0.7923 - val_accuracy: 0.8131
Epoch 18/110
 - 3s - loss: 0.4405 - accuracy: 0.8928 - val_loss: 0.8151 - val_accuracy: 0.8117
Epoch 19/110
 - 3s - loss: 0.4255 - accuracy: 0.8914 - val_loss: 0.8636 - val_accuracy: 0.7891
Epoch 20/110
 - 3s - loss: 0.3944 - accuracy: 0.9069 - val_loss: 0.8160 - val_accuracy: 0.8102
Epoch 21/110
 - 3s - loss: 0.3864 - accuracy: 0.9067 - val_loss: 0.8616 - val_accuracy: 0.8029
Epoch 22/110
 - 3s - loss: 0.3686 - accuracy: 0.9151 - val_loss: 0.8322 - val_accuracy: 0.8109
Epoch 23/110
 - 3s - loss: 0.3589 - accuracy: 0.9177 - val_loss: 0.7699 - val_accuracy: 0.8175
Epoch 24/110
 - 3s - loss: 0.3569 - accuracy: 0.9231 - val_loss: 0.7487 - val_accuracy: 0.8314
Epoch 25/110
 - 3s - loss: 0.3602 - accuracy: 0.9175 - val_loss: 0.8265 - val_accuracy: 0.8255
Epoch 26/110
 - 3s - loss: 0.3616 - accuracy: 0.9200 - val_loss: 0.9229 - val_accuracy: 0.7942
Epoch 27/110
 - 3s - loss: 0.3595 - accuracy: 0.9208 - val_loss: 0.7676 - val_accuracy: 0.8153
Epoch 28/110
 - 3s - loss: 0.3528 - accuracy: 0.9199 - val_loss: 0.7299 - val_accuracy: 0.8255
Epoch 29/110
 - 3s - loss: 0.3496 - accuracy: 0.9255 - val_loss: 0.8276 - val_accuracy: 0.8146
Epoch 30/110
 - 2s - loss: 0.3357 - accuracy: 0.9292 - val_loss: 0.8263 - val_accuracy: 0.8190
Epoch 31/110
 - 2s - loss: 0.3238 - accuracy: 0.9326 - val_loss: 0.8467 - val_accuracy: 0.8161
Epoch 32/110
 - 3s - loss: 0.3285 - accuracy: 0.9334 - val_loss: 0.8099 - val_accuracy: 0.8263
Epoch 33/110
 - 3s - loss: 0.3216 - accuracy: 0.9341 - val_loss: 0.8070 - val_accuracy: 0.8182
Epoch 34/110
 - 3s - loss: 0.3228 - accuracy: 0.9356 - val_loss: 0.7950 - val_accuracy: 0.8372
Epoch 35/110
 - 3s - loss: 0.3254 - accuracy: 0.9339 - val_loss: 0.7482 - val_accuracy: 0.8343
Epoch 36/110
 - 2s - loss: 0.3002 - accuracy: 0.9425 - val_loss: 0.7721 - val_accuracy: 0.8190
Epoch 37/110
 - 2s - loss: 0.3046 - accuracy: 0.9430 - val_loss: 0.7843 - val_accuracy: 0.8255
Epoch 38/110
 - 2s - loss: 0.3166 - accuracy: 0.9376 - val_loss: 0.7913 - val_accuracy: 0.8416
Epoch 39/110
 - 3s - loss: 0.3105 - accuracy: 0.9434 - val_loss: 0.8559 - val_accuracy: 0.8226
Epoch 40/110
 - 3s - loss: 0.3154 - accuracy: 0.9359 - val_loss: 0.8383 - val_accuracy: 0.8255
Epoch 41/110
 - 3s - loss: 0.3041 - accuracy: 0.9416 - val_loss: 0.9000 - val_accuracy: 0.8241
Epoch 42/110
 - 2s - loss: 0.2938 - accuracy: 0.9487 - val_loss: 0.8544 - val_accuracy: 0.8204
Epoch 43/110
 - 3s - loss: 0.2939 - accuracy: 0.9472 - val_loss: 0.9188 - val_accuracy: 0.8131
Epoch 44/110
 - 3s - loss: 0.2915 - accuracy: 0.9494 - val_loss: 0.8156 - val_accuracy: 0.8321
Epoch 45/110
 - 3s - loss: 0.2729 - accuracy: 0.9540 - val_loss: 0.8123 - val_accuracy: 0.8372
Epoch 46/110
 - 3s - loss: 0.2745 - accuracy: 0.9566 - val_loss: 0.8651 - val_accuracy: 0.8380
Epoch 47/110
 - 3s - loss: 0.2799 - accuracy: 0.9524 - val_loss: 0.8163 - val_accuracy: 0.8401
Epoch 48/110
 - 3s - loss: 0.2759 - accuracy: 0.9547 - val_loss: 0.9097 - val_accuracy: 0.8175
Epoch 49/110
 - 3s - loss: 0.2661 - accuracy: 0.9580 - val_loss: 0.9255 - val_accuracy: 0.8321
Epoch 50/110
 - 3s - loss: 0.2804 - accuracy: 0.9527 - val_loss: 0.8770 - val_accuracy: 0.8277
Epoch 51/110
 - 3s - loss: 0.2860 - accuracy: 0.9474 - val_loss: 0.8861 - val_accuracy: 0.8328
Epoch 52/110
 - 3s - loss: 0.2795 - accuracy: 0.9535 - val_loss: 0.9256 - val_accuracy: 0.8190
Epoch 53/110
 - 3s - loss: 0.2795 - accuracy: 0.9549 - val_loss: 0.8339 - val_accuracy: 0.8431
Epoch 54/110
 - 3s - loss: 0.2624 - accuracy: 0.9628 - val_loss: 0.9212 - val_accuracy: 0.8299
Epoch 55/110
 - 2s - loss: 0.2611 - accuracy: 0.9586 - val_loss: 0.9392 - val_accuracy: 0.8226
Epoch 56/110
 - 3s - loss: 0.2702 - accuracy: 0.9571 - val_loss: 0.9023 - val_accuracy: 0.8343
Epoch 57/110
 - 3s - loss: 0.2679 - accuracy: 0.9575 - val_loss: 0.9263 - val_accuracy: 0.8248
Epoch 58/110
 - 3s - loss: 0.2654 - accuracy: 0.9589 - val_loss: 0.9300 - val_accuracy: 0.8365
Epoch 59/110
 - 3s - loss: 0.2561 - accuracy: 0.9637 - val_loss: 0.8834 - val_accuracy: 0.8416
Epoch 60/110
 - 3s - loss: 0.2658 - accuracy: 0.9593 - val_loss: 0.8598 - val_accuracy: 0.8423
Epoch 61/110
 - 3s - loss: 0.2553 - accuracy: 0.9608 - val_loss: 0.9135 - val_accuracy: 0.8204
Epoch 62/110
 - 2s - loss: 0.2627 - accuracy: 0.9598 - val_loss: 0.8988 - val_accuracy: 0.8387
Epoch 63/110
 - 2s - loss: 0.2505 - accuracy: 0.9668 - val_loss: 0.9610 - val_accuracy: 0.8307
Epoch 64/110
 - 3s - loss: 0.2481 - accuracy: 0.9651 - val_loss: 0.9368 - val_accuracy: 0.8372
Epoch 65/110
 - 3s - loss: 0.2311 - accuracy: 0.9712 - val_loss: 0.9965 - val_accuracy: 0.8401
Epoch 66/110
 - 2s - loss: 0.2438 - accuracy: 0.9688 - val_loss: 0.9417 - val_accuracy: 0.8372
Epoch 67/110
 - 2s - loss: 0.2517 - accuracy: 0.9631 - val_loss: 0.8364 - val_accuracy: 0.8518
Epoch 68/110
 - 3s - loss: 0.2398 - accuracy: 0.9653 - val_loss: 0.9587 - val_accuracy: 0.8263
Epoch 69/110
 - 3s - loss: 0.2769 - accuracy: 0.9538 - val_loss: 0.8996 - val_accuracy: 0.8445
Epoch 70/110
 - 3s - loss: 0.2639 - accuracy: 0.9598 - val_loss: 0.8853 - val_accuracy: 0.8416
Epoch 71/110
 - 2s - loss: 0.2430 - accuracy: 0.9675 - val_loss: 0.9370 - val_accuracy: 0.8241
Epoch 72/110
 - 2s - loss: 0.2373 - accuracy: 0.9668 - val_loss: 1.0151 - val_accuracy: 0.8212
Epoch 73/110
 - 2s - loss: 0.2541 - accuracy: 0.9655 - val_loss: 0.8884 - val_accuracy: 0.8394
Epoch 74/110
 - 2s - loss: 0.2557 - accuracy: 0.9626 - val_loss: 0.9261 - val_accuracy: 0.8365
Epoch 75/110
 - 2s - loss: 0.2417 - accuracy: 0.9681 - val_loss: 0.8409 - val_accuracy: 0.8504
Epoch 76/110
 - 2s - loss: 0.2476 - accuracy: 0.9673 - val_loss: 0.8690 - val_accuracy: 0.8496
Epoch 77/110
 - 2s - loss: 0.2203 - accuracy: 0.9759 - val_loss: 0.8097 - val_accuracy: 0.8533
Epoch 78/110
 - 2s - loss: 0.2319 - accuracy: 0.9732 - val_loss: 0.8842 - val_accuracy: 0.8416
Epoch 79/110
 - 2s - loss: 0.2214 - accuracy: 0.9768 - val_loss: 0.8608 - val_accuracy: 0.8496
Epoch 80/110
 - 2s - loss: 0.2365 - accuracy: 0.9704 - val_loss: 0.9332 - val_accuracy: 0.8416
Epoch 81/110
 - 2s - loss: 0.2367 - accuracy: 0.9679 - val_loss: 0.8898 - val_accuracy: 0.8460
Epoch 82/110
 - 2s - loss: 0.2572 - accuracy: 0.9633 - val_loss: 0.8425 - val_accuracy: 0.8504
Epoch 83/110
 - 2s - loss: 0.2263 - accuracy: 0.9728 - val_loss: 0.9393 - val_accuracy: 0.8321
Epoch 84/110
 - 2s - loss: 0.2355 - accuracy: 0.9695 - val_loss: 0.8440 - val_accuracy: 0.8474
Epoch 85/110
 - 2s - loss: 0.2273 - accuracy: 0.9730 - val_loss: 0.8975 - val_accuracy: 0.8350
Epoch 86/110
 - 2s - loss: 0.2146 - accuracy: 0.9777 - val_loss: 0.8634 - val_accuracy: 0.8423
Epoch 87/110
 - 2s - loss: 0.2249 - accuracy: 0.9766 - val_loss: 0.8378 - val_accuracy: 0.8423
Epoch 88/110
 - 2s - loss: 0.2190 - accuracy: 0.9733 - val_loss: 0.9769 - val_accuracy: 0.8314
Epoch 89/110
 - 2s - loss: 0.2555 - accuracy: 0.9633 - val_loss: 0.9820 - val_accuracy: 0.8182
Epoch 90/110
 - 2s - loss: 0.2659 - accuracy: 0.9586 - val_loss: 0.9444 - val_accuracy: 0.8401
Epoch 91/110
 - 2s - loss: 0.2645 - accuracy: 0.9584 - val_loss: 0.9036 - val_accuracy: 0.8394
Epoch 92/110
 - 2s - loss: 0.2538 - accuracy: 0.9657 - val_loss: 0.8604 - val_accuracy: 0.8496
Epoch 93/110
 - 2s - loss: 0.2200 - accuracy: 0.9733 - val_loss: 0.8859 - val_accuracy: 0.8387
Epoch 94/110
 - 2s - loss: 0.2162 - accuracy: 0.9790 - val_loss: 0.8811 - val_accuracy: 0.8482
Epoch 95/110
 - 2s - loss: 0.2194 - accuracy: 0.9754 - val_loss: 0.8849 - val_accuracy: 0.8409
Epoch 96/110
 - 2s - loss: 0.2373 - accuracy: 0.9708 - val_loss: 0.9103 - val_accuracy: 0.8438
Epoch 97/110
 - 2s - loss: 0.2143 - accuracy: 0.9757 - val_loss: 0.9208 - val_accuracy: 0.8489
Epoch 98/110
 - 2s - loss: 0.2119 - accuracy: 0.9808 - val_loss: 0.9073 - val_accuracy: 0.8394
Epoch 99/110
 - 2s - loss: 0.2209 - accuracy: 0.9737 - val_loss: 0.9811 - val_accuracy: 0.8336
Epoch 100/110
 - 2s - loss: 0.2273 - accuracy: 0.9735 - val_loss: 0.9893 - val_accuracy: 0.8328
Epoch 101/110
 - 2s - loss: 0.2551 - accuracy: 0.9657 - val_loss: 1.0740 - val_accuracy: 0.8146
Epoch 102/110
 - 2s - loss: 0.2462 - accuracy: 0.9660 - val_loss: 0.8729 - val_accuracy: 0.8474
Epoch 103/110
 - 2s - loss: 0.2242 - accuracy: 0.9748 - val_loss: 0.9501 - val_accuracy: 0.8460
Epoch 104/110
 - 2s - loss: 0.2263 - accuracy: 0.9746 - val_loss: 0.8777 - val_accuracy: 0.8489
Epoch 105/110
 - 2s - loss: 0.2145 - accuracy: 0.9766 - val_loss: 0.9020 - val_accuracy: 0.8526
Epoch 106/110
 - 2s - loss: 0.2194 - accuracy: 0.9766 - val_loss: 0.9095 - val_accuracy: 0.8650
Epoch 107/110
 - 2s - loss: 0.2116 - accuracy: 0.9774 - val_loss: 0.8566 - val_accuracy: 0.8569
Epoch 108/110
 - 2s - loss: 0.2227 - accuracy: 0.9765 - val_loss: 0.9071 - val_accuracy: 0.8526
Epoch 109/110
 - 2s - loss: 0.2049 - accuracy: 0.9828 - val_loss: 0.8455 - val_accuracy: 0.8613
Epoch 110/110
 - 2s - loss: 0.2154 - accuracy: 0.9797 - val_loss: 0.9924 - val_accuracy: 0.8365

Number of filters: 16 , Kernel Size: 3 , Strides: 1 Batch Normalization: True , Conv_First: True , Depth Value: 20

Fit: epochs= 110 , batch_size= 64 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "model_19"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_19 (InputLayer)           (None, 10, 1)        0                                            
__________________________________________________________________________________________________
conv1d_421 (Conv1D)             (None, 10, 16)       64          input_19[0][0]                   
__________________________________________________________________________________________________
batch_normalization_343 (BatchN (None, 10, 16)       64          conv1d_421[0][0]                 
__________________________________________________________________________________________________
activation_427 (Activation)     (None, 10, 16)       0           batch_normalization_343[0][0]    
__________________________________________________________________________________________________
conv1d_422 (Conv1D)             (None, 10, 16)       784         activation_427[0][0]             
__________________________________________________________________________________________________
batch_normalization_344 (BatchN (None, 10, 16)       64          conv1d_422[0][0]                 
__________________________________________________________________________________________________
activation_428 (Activation)     (None, 10, 16)       0           batch_normalization_344[0][0]    
__________________________________________________________________________________________________
conv1d_423 (Conv1D)             (None, 10, 16)       784         activation_428[0][0]             
__________________________________________________________________________________________________
batch_normalization_345 (BatchN (None, 10, 16)       64          conv1d_423[0][0]                 
__________________________________________________________________________________________________
add_163 (Add)                   (None, 10, 16)       0           activation_427[0][0]             
                                                                 batch_normalization_345[0][0]    
__________________________________________________________________________________________________
activation_429 (Activation)     (None, 10, 16)       0           add_163[0][0]                    
__________________________________________________________________________________________________
conv1d_424 (Conv1D)             (None, 10, 16)       784         activation_429[0][0]             
__________________________________________________________________________________________________
batch_normalization_346 (BatchN (None, 10, 16)       64          conv1d_424[0][0]                 
__________________________________________________________________________________________________
activation_430 (Activation)     (None, 10, 16)       0           batch_normalization_346[0][0]    
__________________________________________________________________________________________________
conv1d_425 (Conv1D)             (None, 10, 16)       784         activation_430[0][0]             
__________________________________________________________________________________________________
batch_normalization_347 (BatchN (None, 10, 16)       64          conv1d_425[0][0]                 
__________________________________________________________________________________________________
add_164 (Add)                   (None, 10, 16)       0           activation_429[0][0]             
                                                                 batch_normalization_347[0][0]    
__________________________________________________________________________________________________
activation_431 (Activation)     (None, 10, 16)       0           add_164[0][0]                    
__________________________________________________________________________________________________
conv1d_426 (Conv1D)             (None, 10, 16)       784         activation_431[0][0]             
__________________________________________________________________________________________________
batch_normalization_348 (BatchN (None, 10, 16)       64          conv1d_426[0][0]                 
__________________________________________________________________________________________________
activation_432 (Activation)     (None, 10, 16)       0           batch_normalization_348[0][0]    
__________________________________________________________________________________________________
conv1d_427 (Conv1D)             (None, 10, 16)       784         activation_432[0][0]             
__________________________________________________________________________________________________
batch_normalization_349 (BatchN (None, 10, 16)       64          conv1d_427[0][0]                 
__________________________________________________________________________________________________
add_165 (Add)                   (None, 10, 16)       0           activation_431[0][0]             
                                                                 batch_normalization_349[0][0]    
__________________________________________________________________________________________________
activation_433 (Activation)     (None, 10, 16)       0           add_165[0][0]                    
__________________________________________________________________________________________________
conv1d_428 (Conv1D)             (None, 5, 32)        1568        activation_433[0][0]             
__________________________________________________________________________________________________
batch_normalization_350 (BatchN (None, 5, 32)        128         conv1d_428[0][0]                 
__________________________________________________________________________________________________
activation_434 (Activation)     (None, 5, 32)        0           batch_normalization_350[0][0]    
__________________________________________________________________________________________________
conv1d_429 (Conv1D)             (None, 5, 32)        3104        activation_434[0][0]             
__________________________________________________________________________________________________
conv1d_430 (Conv1D)             (None, 5, 32)        544         activation_433[0][0]             
__________________________________________________________________________________________________
batch_normalization_351 (BatchN (None, 5, 32)        128         conv1d_429[0][0]                 
__________________________________________________________________________________________________
add_166 (Add)                   (None, 5, 32)        0           conv1d_430[0][0]                 
                                                                 batch_normalization_351[0][0]    
__________________________________________________________________________________________________
activation_435 (Activation)     (None, 5, 32)        0           add_166[0][0]                    
__________________________________________________________________________________________________
conv1d_431 (Conv1D)             (None, 5, 32)        3104        activation_435[0][0]             
__________________________________________________________________________________________________
batch_normalization_352 (BatchN (None, 5, 32)        128         conv1d_431[0][0]                 
__________________________________________________________________________________________________
activation_436 (Activation)     (None, 5, 32)        0           batch_normalization_352[0][0]    
__________________________________________________________________________________________________
conv1d_432 (Conv1D)             (None, 5, 32)        3104        activation_436[0][0]             
__________________________________________________________________________________________________
batch_normalization_353 (BatchN (None, 5, 32)        128         conv1d_432[0][0]                 
__________________________________________________________________________________________________
add_167 (Add)                   (None, 5, 32)        0           activation_435[0][0]             
                                                                 batch_normalization_353[0][0]    
__________________________________________________________________________________________________
activation_437 (Activation)     (None, 5, 32)        0           add_167[0][0]                    
__________________________________________________________________________________________________
conv1d_433 (Conv1D)             (None, 5, 32)        3104        activation_437[0][0]             
__________________________________________________________________________________________________
batch_normalization_354 (BatchN (None, 5, 32)        128         conv1d_433[0][0]                 
__________________________________________________________________________________________________
activation_438 (Activation)     (None, 5, 32)        0           batch_normalization_354[0][0]    
__________________________________________________________________________________________________
conv1d_434 (Conv1D)             (None, 5, 32)        3104        activation_438[0][0]             
__________________________________________________________________________________________________
batch_normalization_355 (BatchN (None, 5, 32)        128         conv1d_434[0][0]                 
__________________________________________________________________________________________________
add_168 (Add)                   (None, 5, 32)        0           activation_437[0][0]             
                                                                 batch_normalization_355[0][0]    
__________________________________________________________________________________________________
activation_439 (Activation)     (None, 5, 32)        0           add_168[0][0]                    
__________________________________________________________________________________________________
conv1d_435 (Conv1D)             (None, 3, 64)        6208        activation_439[0][0]             
__________________________________________________________________________________________________
batch_normalization_356 (BatchN (None, 3, 64)        256         conv1d_435[0][0]                 
__________________________________________________________________________________________________
activation_440 (Activation)     (None, 3, 64)        0           batch_normalization_356[0][0]    
__________________________________________________________________________________________________
conv1d_436 (Conv1D)             (None, 3, 64)        12352       activation_440[0][0]             
__________________________________________________________________________________________________
conv1d_437 (Conv1D)             (None, 3, 64)        2112        activation_439[0][0]             
__________________________________________________________________________________________________
batch_normalization_357 (BatchN (None, 3, 64)        256         conv1d_436[0][0]                 
__________________________________________________________________________________________________
add_169 (Add)                   (None, 3, 64)        0           conv1d_437[0][0]                 
                                                                 batch_normalization_357[0][0]    
__________________________________________________________________________________________________
activation_441 (Activation)     (None, 3, 64)        0           add_169[0][0]                    
__________________________________________________________________________________________________
conv1d_438 (Conv1D)             (None, 3, 64)        12352       activation_441[0][0]             
__________________________________________________________________________________________________
batch_normalization_358 (BatchN (None, 3, 64)        256         conv1d_438[0][0]                 
__________________________________________________________________________________________________
activation_442 (Activation)     (None, 3, 64)        0           batch_normalization_358[0][0]    
__________________________________________________________________________________________________
conv1d_439 (Conv1D)             (None, 3, 64)        12352       activation_442[0][0]             
__________________________________________________________________________________________________
batch_normalization_359 (BatchN (None, 3, 64)        256         conv1d_439[0][0]                 
__________________________________________________________________________________________________
add_170 (Add)                   (None, 3, 64)        0           activation_441[0][0]             
                                                                 batch_normalization_359[0][0]    
__________________________________________________________________________________________________
activation_443 (Activation)     (None, 3, 64)        0           add_170[0][0]                    
__________________________________________________________________________________________________
conv1d_440 (Conv1D)             (None, 3, 64)        12352       activation_443[0][0]             
__________________________________________________________________________________________________
batch_normalization_360 (BatchN (None, 3, 64)        256         conv1d_440[0][0]                 
__________________________________________________________________________________________________
activation_444 (Activation)     (None, 3, 64)        0           batch_normalization_360[0][0]    
__________________________________________________________________________________________________
conv1d_441 (Conv1D)             (None, 3, 64)        12352       activation_444[0][0]             
__________________________________________________________________________________________________
batch_normalization_361 (BatchN (None, 3, 64)        256         conv1d_441[0][0]                 
__________________________________________________________________________________________________
add_171 (Add)                   (None, 3, 64)        0           activation_443[0][0]             
                                                                 batch_normalization_361[0][0]    
__________________________________________________________________________________________________
activation_445 (Activation)     (None, 3, 64)        0           add_171[0][0]                    
__________________________________________________________________________________________________
average_pooling1d_19 (AveragePo (None, 3, 64)        0           activation_445[0][0]             
__________________________________________________________________________________________________
flatten_61 (Flatten)            (None, 192)          0           average_pooling1d_19[0][0]       
__________________________________________________________________________________________________
dense_1189 (Dense)              (None, 4)            772         flatten_61[0][0]                 
==================================================================================================
Total params: 96,004
Trainable params: 94,628
Non-trainable params: 1,376
__________________________________________________________________________________________________
None

Accuracy Train: 89.76%
Accuracy Test: 84.35%
Loss Train: 0.55
Loss Test: 0.91
Numero dati esaminati: 1712
True Positive 1444
False Positive 268


------------------------------------------------------------------------
K-fold Cross Validation
------------------------------------------------------------------------
Training for fold 1 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 2s - loss: 0.2173 - accuracy: 0.9792 - val_loss: 0.8969 - val_accuracy: 0.8445
Epoch 2/110
 - 2s - loss: 0.2057 - accuracy: 0.9814 - val_loss: 0.8375 - val_accuracy: 0.8584
Epoch 3/110
 - 2s - loss: 0.2028 - accuracy: 0.9827 - val_loss: 0.8863 - val_accuracy: 0.8518
Epoch 4/110
 - 2s - loss: 0.1980 - accuracy: 0.9827 - val_loss: 0.8886 - val_accuracy: 0.8474
Epoch 5/110
 - 2s - loss: 0.2198 - accuracy: 0.9765 - val_loss: 0.8968 - val_accuracy: 0.8511
Epoch 6/110
 - 2s - loss: 0.2395 - accuracy: 0.9691 - val_loss: 0.9597 - val_accuracy: 0.8307
Epoch 7/110
 - 2s - loss: 0.2286 - accuracy: 0.9726 - val_loss: 0.9412 - val_accuracy: 0.8328
Epoch 8/110
 - 2s - loss: 0.2260 - accuracy: 0.9732 - val_loss: 0.9219 - val_accuracy: 0.8431
Epoch 9/110
 - 2s - loss: 0.2071 - accuracy: 0.9806 - val_loss: 0.8751 - val_accuracy: 0.8423
Epoch 10/110
 - 2s - loss: 0.2008 - accuracy: 0.9828 - val_loss: 0.8015 - val_accuracy: 0.8584
Epoch 11/110
 - 2s - loss: 0.1957 - accuracy: 0.9845 - val_loss: 0.8684 - val_accuracy: 0.8423
Epoch 12/110
 - 2s - loss: 0.2092 - accuracy: 0.9803 - val_loss: 0.8965 - val_accuracy: 0.8438
Epoch 13/110
 - 2s - loss: 0.2045 - accuracy: 0.9799 - val_loss: 0.9392 - val_accuracy: 0.8496
Epoch 14/110
 - 2s - loss: 0.1970 - accuracy: 0.9825 - val_loss: 0.8506 - val_accuracy: 0.8496
Epoch 15/110
 - 2s - loss: 0.2009 - accuracy: 0.9819 - val_loss: 0.9138 - val_accuracy: 0.8577
Epoch 16/110
 - 2s - loss: 0.2330 - accuracy: 0.9697 - val_loss: 0.8793 - val_accuracy: 0.8394
Epoch 17/110
 - 2s - loss: 0.2259 - accuracy: 0.9693 - val_loss: 0.8871 - val_accuracy: 0.8445
Epoch 18/110
 - 2s - loss: 0.2253 - accuracy: 0.9721 - val_loss: 0.8502 - val_accuracy: 0.8380
Epoch 19/110
 - 2s - loss: 0.2051 - accuracy: 0.9772 - val_loss: 0.8895 - val_accuracy: 0.8416
Epoch 20/110
 - 2s - loss: 0.2069 - accuracy: 0.9801 - val_loss: 0.8828 - val_accuracy: 0.8482
Epoch 21/110
 - 2s - loss: 0.1917 - accuracy: 0.9847 - val_loss: 0.9328 - val_accuracy: 0.8569
Epoch 22/110
 - 2s - loss: 0.1994 - accuracy: 0.9816 - val_loss: 0.8422 - val_accuracy: 0.8628
Epoch 23/110
 - 2s - loss: 0.2112 - accuracy: 0.9779 - val_loss: 0.8961 - val_accuracy: 0.8423
Epoch 24/110
 - 2s - loss: 0.2059 - accuracy: 0.9808 - val_loss: 0.9329 - val_accuracy: 0.8467
Epoch 25/110
 - 2s - loss: 0.2090 - accuracy: 0.9812 - val_loss: 0.9497 - val_accuracy: 0.8460
Epoch 26/110
 - 2s - loss: 0.2178 - accuracy: 0.9765 - val_loss: 0.8593 - val_accuracy: 0.8496
Epoch 27/110
 - 2s - loss: 0.1916 - accuracy: 0.9832 - val_loss: 0.8389 - val_accuracy: 0.8628
Epoch 28/110
 - 2s - loss: 0.2104 - accuracy: 0.9785 - val_loss: 0.8812 - val_accuracy: 0.8518
Epoch 29/110
 - 2s - loss: 0.2045 - accuracy: 0.9792 - val_loss: 0.8583 - val_accuracy: 0.8562
Epoch 30/110
 - 2s - loss: 0.2034 - accuracy: 0.9828 - val_loss: 0.8592 - val_accuracy: 0.8438
Epoch 31/110
 - 2s - loss: 0.1925 - accuracy: 0.9856 - val_loss: 0.8423 - val_accuracy: 0.8562
Epoch 32/110
 - 2s - loss: 0.1919 - accuracy: 0.9834 - val_loss: 0.8846 - val_accuracy: 0.8372
Epoch 33/110
 - 2s - loss: 0.2251 - accuracy: 0.9737 - val_loss: 0.9027 - val_accuracy: 0.8394
Epoch 34/110
 - 2s - loss: 0.2432 - accuracy: 0.9679 - val_loss: 0.8658 - val_accuracy: 0.8431
Epoch 35/110
 - 2s - loss: 0.2314 - accuracy: 0.9710 - val_loss: 0.8881 - val_accuracy: 0.8467
Epoch 36/110
 - 2s - loss: 0.2135 - accuracy: 0.9774 - val_loss: 0.9015 - val_accuracy: 0.8511
Epoch 37/110
 - 2s - loss: 0.2035 - accuracy: 0.9821 - val_loss: 0.8527 - val_accuracy: 0.8540
Epoch 38/110
 - 2s - loss: 0.1985 - accuracy: 0.9819 - val_loss: 0.9910 - val_accuracy: 0.8365
Epoch 39/110
 - 3s - loss: 0.1884 - accuracy: 0.9858 - val_loss: 0.8648 - val_accuracy: 0.8504
Epoch 40/110
 - 2s - loss: 0.1801 - accuracy: 0.9889 - val_loss: 0.8871 - val_accuracy: 0.8693
Epoch 41/110
 - 2s - loss: 0.1702 - accuracy: 0.9912 - val_loss: 0.8805 - val_accuracy: 0.8489
Epoch 42/110
 - 2s - loss: 0.1850 - accuracy: 0.9867 - val_loss: 0.9460 - val_accuracy: 0.8496
Epoch 43/110
 - 2s - loss: 0.1867 - accuracy: 0.9865 - val_loss: 0.9155 - val_accuracy: 0.8496
Epoch 44/110
 - 2s - loss: 0.1838 - accuracy: 0.9869 - val_loss: 0.9242 - val_accuracy: 0.8533
Epoch 45/110
 - 2s - loss: 0.2033 - accuracy: 0.9796 - val_loss: 0.9154 - val_accuracy: 0.8489
Epoch 46/110
 - 2s - loss: 0.2292 - accuracy: 0.9739 - val_loss: 0.9337 - val_accuracy: 0.8380
Epoch 47/110
 - 2s - loss: 0.2351 - accuracy: 0.9691 - val_loss: 0.8804 - val_accuracy: 0.8518
Epoch 48/110
 - 2s - loss: 0.1951 - accuracy: 0.9810 - val_loss: 0.9471 - val_accuracy: 0.8438
Epoch 49/110
 - 2s - loss: 0.1827 - accuracy: 0.9869 - val_loss: 0.8492 - val_accuracy: 0.8679
Epoch 50/110
 - 2s - loss: 0.1668 - accuracy: 0.9929 - val_loss: 0.8437 - val_accuracy: 0.8591
Epoch 51/110
 - 2s - loss: 0.1743 - accuracy: 0.9907 - val_loss: 0.8697 - val_accuracy: 0.8577
Epoch 52/110
 - 2s - loss: 0.1734 - accuracy: 0.9883 - val_loss: 0.8502 - val_accuracy: 0.8635
Epoch 53/110
 - 3s - loss: 0.1771 - accuracy: 0.9887 - val_loss: 0.9174 - val_accuracy: 0.8533
Epoch 54/110
 - 2s - loss: 0.1915 - accuracy: 0.9848 - val_loss: 0.9326 - val_accuracy: 0.8380
Epoch 55/110
 - 2s - loss: 0.2048 - accuracy: 0.9803 - val_loss: 0.9431 - val_accuracy: 0.8445
Epoch 56/110
 - 2s - loss: 0.2613 - accuracy: 0.9606 - val_loss: 0.8596 - val_accuracy: 0.8358
Epoch 57/110
 - 2s - loss: 0.2345 - accuracy: 0.9688 - val_loss: 0.8247 - val_accuracy: 0.8555
Epoch 58/110
 - 2s - loss: 0.1974 - accuracy: 0.9823 - val_loss: 0.8515 - val_accuracy: 0.8518
Epoch 59/110
 - 2s - loss: 0.1794 - accuracy: 0.9883 - val_loss: 0.7792 - val_accuracy: 0.8606
Epoch 60/110
 - 2s - loss: 0.1717 - accuracy: 0.9889 - val_loss: 0.8626 - val_accuracy: 0.8584
Epoch 61/110
 - 3s - loss: 0.1744 - accuracy: 0.9892 - val_loss: 0.8701 - val_accuracy: 0.8620
Epoch 62/110
 - 3s - loss: 0.1776 - accuracy: 0.9878 - val_loss: 0.7810 - val_accuracy: 0.8635
Epoch 63/110
 - 3s - loss: 0.1763 - accuracy: 0.9876 - val_loss: 0.8017 - val_accuracy: 0.8599
Epoch 64/110
 - 3s - loss: 0.1830 - accuracy: 0.9854 - val_loss: 0.9609 - val_accuracy: 0.8511
Epoch 65/110
 - 3s - loss: 0.2451 - accuracy: 0.9651 - val_loss: 0.9027 - val_accuracy: 0.8336
Epoch 66/110
 - 2s - loss: 0.2668 - accuracy: 0.9571 - val_loss: 0.8876 - val_accuracy: 0.8409
Epoch 67/110
 - 3s - loss: 0.2046 - accuracy: 0.9781 - val_loss: 0.8215 - val_accuracy: 0.8467
Epoch 68/110
 - 2s - loss: 0.1761 - accuracy: 0.9874 - val_loss: 0.8207 - val_accuracy: 0.8533
Epoch 69/110
 - 2s - loss: 0.1670 - accuracy: 0.9918 - val_loss: 0.8448 - val_accuracy: 0.8599
Epoch 70/110
 - 3s - loss: 0.1654 - accuracy: 0.9918 - val_loss: 0.8329 - val_accuracy: 0.8708
Epoch 71/110
 - 3s - loss: 0.1930 - accuracy: 0.9852 - val_loss: 0.9581 - val_accuracy: 0.8453
Epoch 72/110
 - 3s - loss: 0.1779 - accuracy: 0.9872 - val_loss: 0.8783 - val_accuracy: 0.8423
Epoch 73/110
 - 3s - loss: 0.1805 - accuracy: 0.9867 - val_loss: 0.8904 - val_accuracy: 0.8555
Epoch 74/110
 - 3s - loss: 0.1791 - accuracy: 0.9883 - val_loss: 0.8633 - val_accuracy: 0.8664
Epoch 75/110
 - 2s - loss: 0.1711 - accuracy: 0.9889 - val_loss: 0.8621 - val_accuracy: 0.8518
Epoch 76/110
 - 3s - loss: 0.1663 - accuracy: 0.9898 - val_loss: 0.8889 - val_accuracy: 0.8504
Epoch 77/110
 - 3s - loss: 0.1907 - accuracy: 0.9843 - val_loss: 0.9724 - val_accuracy: 0.8401
Epoch 78/110
 - 2s - loss: 0.1874 - accuracy: 0.9848 - val_loss: 0.9049 - val_accuracy: 0.8460
Epoch 79/110
 - 2s - loss: 0.2435 - accuracy: 0.9642 - val_loss: 0.8898 - val_accuracy: 0.8328
Epoch 80/110
 - 2s - loss: 0.2257 - accuracy: 0.9693 - val_loss: 0.8897 - val_accuracy: 0.8489
Epoch 81/110
 - 2s - loss: 0.1893 - accuracy: 0.9834 - val_loss: 0.8323 - val_accuracy: 0.8540
Epoch 82/110
 - 2s - loss: 0.1777 - accuracy: 0.9885 - val_loss: 0.8491 - val_accuracy: 0.8445
Epoch 83/110
 - 2s - loss: 0.1742 - accuracy: 0.9856 - val_loss: 0.8829 - val_accuracy: 0.8540
Epoch 84/110
 - 2s - loss: 0.1648 - accuracy: 0.9920 - val_loss: 0.8572 - val_accuracy: 0.8620
Epoch 85/110
 - 2s - loss: 0.1755 - accuracy: 0.9881 - val_loss: 0.8452 - val_accuracy: 0.8562
Epoch 86/110
 - 2s - loss: 0.1806 - accuracy: 0.9870 - val_loss: 0.8602 - val_accuracy: 0.8555
Epoch 87/110
 - 2s - loss: 0.1949 - accuracy: 0.9819 - val_loss: 0.8492 - val_accuracy: 0.8489
Epoch 88/110
 - 2s - loss: 0.1977 - accuracy: 0.9797 - val_loss: 0.8564 - val_accuracy: 0.8511
Epoch 89/110
 - 2s - loss: 0.2072 - accuracy: 0.9775 - val_loss: 0.8308 - val_accuracy: 0.8518
Epoch 90/110
 - 2s - loss: 0.1954 - accuracy: 0.9799 - val_loss: 0.8784 - val_accuracy: 0.8445
Epoch 91/110
 - 2s - loss: 0.1977 - accuracy: 0.9794 - val_loss: 0.9186 - val_accuracy: 0.8438
Epoch 92/110
 - 2s - loss: 0.1726 - accuracy: 0.9898 - val_loss: 0.8371 - val_accuracy: 0.8599
Epoch 93/110
 - 2s - loss: 0.1544 - accuracy: 0.9942 - val_loss: 0.8300 - val_accuracy: 0.8635
Epoch 94/110
 - 2s - loss: 0.1521 - accuracy: 0.9945 - val_loss: 0.8524 - val_accuracy: 0.8635
Epoch 95/110
 - 2s - loss: 0.1557 - accuracy: 0.9931 - val_loss: 0.8292 - val_accuracy: 0.8591
Epoch 96/110
 - 2s - loss: 0.1459 - accuracy: 0.9963 - val_loss: 0.8526 - val_accuracy: 0.8642
Epoch 97/110
 - 2s - loss: 0.1475 - accuracy: 0.9954 - val_loss: 0.8864 - val_accuracy: 0.8628
Epoch 98/110
 - 2s - loss: 0.1717 - accuracy: 0.9892 - val_loss: 0.9154 - val_accuracy: 0.8533
Epoch 99/110
 - 2s - loss: 0.2416 - accuracy: 0.9662 - val_loss: 1.0280 - val_accuracy: 0.8314
Epoch 100/110
 - 2s - loss: 0.2349 - accuracy: 0.9662 - val_loss: 0.8231 - val_accuracy: 0.8504
Epoch 101/110
 - 2s - loss: 0.2080 - accuracy: 0.9770 - val_loss: 0.8637 - val_accuracy: 0.8526
Epoch 102/110
 - 2s - loss: 0.1693 - accuracy: 0.9887 - val_loss: 0.8824 - val_accuracy: 0.8577
Epoch 103/110
 - 2s - loss: 0.1613 - accuracy: 0.9918 - val_loss: 0.8505 - val_accuracy: 0.8584
Epoch 104/110
 - 2s - loss: 0.1567 - accuracy: 0.9936 - val_loss: 0.8794 - val_accuracy: 0.8504
Epoch 105/110
 - 2s - loss: 0.1479 - accuracy: 0.9954 - val_loss: 0.9626 - val_accuracy: 0.8401
Epoch 106/110
 - 2s - loss: 0.1566 - accuracy: 0.9925 - val_loss: 0.8995 - val_accuracy: 0.8445
Epoch 107/110
 - 2s - loss: 0.1648 - accuracy: 0.9898 - val_loss: 0.9354 - val_accuracy: 0.8482
Epoch 108/110
 - 2s - loss: 0.1992 - accuracy: 0.9821 - val_loss: 0.9070 - val_accuracy: 0.8394
Epoch 109/110
 - 2s - loss: 0.1954 - accuracy: 0.9806 - val_loss: 0.9144 - val_accuracy: 0.8394
Epoch 110/110
 - 2s - loss: 0.2113 - accuracy: 0.9761 - val_loss: 0.9368 - val_accuracy: 0.8423
------------------------------------------------------------------------
Training for fold 2 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 2s - loss: 0.2079 - accuracy: 0.9743 - val_loss: 0.8418 - val_accuracy: 0.8431
Epoch 2/110
 - 2s - loss: 0.2129 - accuracy: 0.9730 - val_loss: 0.8607 - val_accuracy: 0.8489
Epoch 3/110
 - 2s - loss: 0.1764 - accuracy: 0.9858 - val_loss: 0.7852 - val_accuracy: 0.8547
Epoch 4/110
 - 2s - loss: 0.1549 - accuracy: 0.9934 - val_loss: 0.8158 - val_accuracy: 0.8606
Epoch 5/110
 - 2s - loss: 0.1466 - accuracy: 0.9954 - val_loss: 0.7958 - val_accuracy: 0.8613
Epoch 6/110
 - 2s - loss: 0.1549 - accuracy: 0.9931 - val_loss: 0.8762 - val_accuracy: 0.8635
Epoch 7/110
 - 2s - loss: 0.1543 - accuracy: 0.9922 - val_loss: 0.8218 - val_accuracy: 0.8708
Epoch 8/110
 - 2s - loss: 0.1657 - accuracy: 0.9894 - val_loss: 0.8625 - val_accuracy: 0.8591
Epoch 9/110
 - 3s - loss: 0.1854 - accuracy: 0.9832 - val_loss: 0.8346 - val_accuracy: 0.8577
Epoch 10/110
 - 3s - loss: 0.2058 - accuracy: 0.9770 - val_loss: 0.8092 - val_accuracy: 0.8533
Epoch 11/110
 - 2s - loss: 0.1869 - accuracy: 0.9810 - val_loss: 0.8251 - val_accuracy: 0.8496
Epoch 12/110
 - 2s - loss: 0.1779 - accuracy: 0.9832 - val_loss: 0.8052 - val_accuracy: 0.8511
Epoch 13/110
 - 2s - loss: 0.1854 - accuracy: 0.9810 - val_loss: 0.9034 - val_accuracy: 0.8394
Epoch 14/110
 - 2s - loss: 0.2040 - accuracy: 0.9770 - val_loss: 0.9044 - val_accuracy: 0.8336
Epoch 15/110
 - 2s - loss: 0.1904 - accuracy: 0.9810 - val_loss: 0.7816 - val_accuracy: 0.8504
Epoch 16/110
 - 2s - loss: 0.2017 - accuracy: 0.9759 - val_loss: 0.8731 - val_accuracy: 0.8562
Epoch 17/110
 - 2s - loss: 0.2082 - accuracy: 0.9788 - val_loss: 0.8613 - val_accuracy: 0.8431
Epoch 18/110
 - 2s - loss: 0.2182 - accuracy: 0.9735 - val_loss: 0.8917 - val_accuracy: 0.8518
Epoch 19/110
 - 3s - loss: 0.1822 - accuracy: 0.9863 - val_loss: 0.8113 - val_accuracy: 0.8628
Epoch 20/110
 - 3s - loss: 0.1617 - accuracy: 0.9907 - val_loss: 0.8188 - val_accuracy: 0.8642
Epoch 21/110
 - 3s - loss: 0.1593 - accuracy: 0.9898 - val_loss: 0.8563 - val_accuracy: 0.8540
Epoch 22/110
 - 3s - loss: 0.1555 - accuracy: 0.9929 - val_loss: 0.8899 - val_accuracy: 0.8533
Epoch 23/110
 - 3s - loss: 0.1485 - accuracy: 0.9953 - val_loss: 0.8177 - val_accuracy: 0.8591
Epoch 24/110
 - 3s - loss: 0.1389 - accuracy: 0.9978 - val_loss: 0.8472 - val_accuracy: 0.8657
Epoch 25/110
 - 3s - loss: 0.1408 - accuracy: 0.9971 - val_loss: 0.8666 - val_accuracy: 0.8657
Epoch 26/110
 - 3s - loss: 0.1377 - accuracy: 0.9962 - val_loss: 0.8401 - val_accuracy: 0.8613
Epoch 27/110
 - 3s - loss: 0.1448 - accuracy: 0.9945 - val_loss: 0.8435 - val_accuracy: 0.8657
Epoch 28/110
 - 3s - loss: 0.1638 - accuracy: 0.9896 - val_loss: 0.9173 - val_accuracy: 0.8453
Epoch 29/110
 - 3s - loss: 0.1923 - accuracy: 0.9799 - val_loss: 0.8273 - val_accuracy: 0.8584
Epoch 30/110
 - 3s - loss: 0.2262 - accuracy: 0.9681 - val_loss: 0.9436 - val_accuracy: 0.8401
Epoch 31/110
 - 2s - loss: 0.2239 - accuracy: 0.9671 - val_loss: 0.8729 - val_accuracy: 0.8358
Epoch 32/110
 - 2s - loss: 0.1904 - accuracy: 0.9779 - val_loss: 0.8065 - val_accuracy: 0.8489
Epoch 33/110
 - 2s - loss: 0.1989 - accuracy: 0.9805 - val_loss: 0.8238 - val_accuracy: 0.8489
Epoch 34/110
 - 3s - loss: 0.1696 - accuracy: 0.9896 - val_loss: 0.8441 - val_accuracy: 0.8504
Epoch 35/110
 - 3s - loss: 0.1555 - accuracy: 0.9922 - val_loss: 0.8158 - val_accuracy: 0.8562
Epoch 36/110
 - 3s - loss: 0.1455 - accuracy: 0.9960 - val_loss: 0.8091 - val_accuracy: 0.8569
Epoch 37/110
 - 3s - loss: 0.1383 - accuracy: 0.9963 - val_loss: 0.8450 - val_accuracy: 0.8591
Epoch 38/110
 - 2s - loss: 0.1375 - accuracy: 0.9965 - val_loss: 0.8260 - val_accuracy: 0.8613
Epoch 39/110
 - 3s - loss: 0.1397 - accuracy: 0.9974 - val_loss: 0.8421 - val_accuracy: 0.8562
Epoch 40/110
 - 3s - loss: 0.1478 - accuracy: 0.9940 - val_loss: 0.8948 - val_accuracy: 0.8504
Epoch 41/110
 - 3s - loss: 0.1564 - accuracy: 0.9900 - val_loss: 0.8942 - val_accuracy: 0.8511
Epoch 42/110
 - 3s - loss: 0.2141 - accuracy: 0.9754 - val_loss: 0.9849 - val_accuracy: 0.8255
Epoch 43/110
 - 3s - loss: 0.3338 - accuracy: 0.9336 - val_loss: 0.8777 - val_accuracy: 0.8343
Epoch 44/110
 - 2s - loss: 0.2238 - accuracy: 0.9668 - val_loss: 0.8270 - val_accuracy: 0.8474
Epoch 45/110
 - 2s - loss: 0.1675 - accuracy: 0.9887 - val_loss: 0.7650 - val_accuracy: 0.8591
Epoch 46/110
 - 2s - loss: 0.1452 - accuracy: 0.9956 - val_loss: 0.7846 - val_accuracy: 0.8672
Epoch 47/110
 - 2s - loss: 0.1342 - accuracy: 0.9985 - val_loss: 0.7922 - val_accuracy: 0.8606
Epoch 48/110
 - 3s - loss: 0.1342 - accuracy: 0.9985 - val_loss: 0.8439 - val_accuracy: 0.8606
Epoch 49/110
 - 3s - loss: 0.1350 - accuracy: 0.9976 - val_loss: 0.8370 - val_accuracy: 0.8635
Epoch 50/110
 - 3s - loss: 0.1382 - accuracy: 0.9958 - val_loss: 0.8604 - val_accuracy: 0.8540
Epoch 51/110
 - 3s - loss: 0.1398 - accuracy: 0.9954 - val_loss: 0.8124 - val_accuracy: 0.8708
Epoch 52/110
 - 3s - loss: 0.1393 - accuracy: 0.9954 - val_loss: 0.8635 - val_accuracy: 0.8620
Epoch 53/110
 - 3s - loss: 0.1677 - accuracy: 0.9863 - val_loss: 0.9291 - val_accuracy: 0.8533
Epoch 54/110
 - 3s - loss: 0.1930 - accuracy: 0.9772 - val_loss: 0.9153 - val_accuracy: 0.8372
Epoch 55/110
 - 3s - loss: 0.2010 - accuracy: 0.9744 - val_loss: 0.8496 - val_accuracy: 0.8431
Epoch 56/110
 - 3s - loss: 0.1851 - accuracy: 0.9806 - val_loss: 0.8692 - val_accuracy: 0.8540
Epoch 57/110
 - 2s - loss: 0.1752 - accuracy: 0.9838 - val_loss: 0.9090 - val_accuracy: 0.8526
Epoch 58/110
 - 2s - loss: 0.1646 - accuracy: 0.9876 - val_loss: 0.8515 - val_accuracy: 0.8613
Epoch 59/110
 - 3s - loss: 0.1619 - accuracy: 0.9901 - val_loss: 0.8745 - val_accuracy: 0.8613
Epoch 60/110
 - 3s - loss: 0.1633 - accuracy: 0.9885 - val_loss: 0.8750 - val_accuracy: 0.8555
Epoch 61/110
 - 2s - loss: 0.1951 - accuracy: 0.9796 - val_loss: 0.8737 - val_accuracy: 0.8438
Epoch 62/110
 - 2s - loss: 0.2286 - accuracy: 0.9670 - val_loss: 0.8999 - val_accuracy: 0.8263
Epoch 63/110
 - 2s - loss: 0.1975 - accuracy: 0.9737 - val_loss: 0.8096 - val_accuracy: 0.8409
Epoch 64/110
 - 3s - loss: 0.1540 - accuracy: 0.9925 - val_loss: 0.8204 - val_accuracy: 0.8511
Epoch 65/110
 - 3s - loss: 0.1480 - accuracy: 0.9929 - val_loss: 0.7914 - val_accuracy: 0.8511
Epoch 66/110
 - 3s - loss: 0.1423 - accuracy: 0.9951 - val_loss: 0.7905 - val_accuracy: 0.8540
Epoch 67/110
 - 2s - loss: 0.1498 - accuracy: 0.9914 - val_loss: 0.8080 - val_accuracy: 0.8526
Epoch 68/110
 - 3s - loss: 0.1546 - accuracy: 0.9912 - val_loss: 0.8322 - val_accuracy: 0.8540
Epoch 69/110
 - 2s - loss: 0.1486 - accuracy: 0.9923 - val_loss: 0.7852 - val_accuracy: 0.8562
Epoch 70/110
 - 2s - loss: 0.1429 - accuracy: 0.9947 - val_loss: 0.8067 - val_accuracy: 0.8577
Epoch 71/110
 - 2s - loss: 0.1439 - accuracy: 0.9932 - val_loss: 0.8904 - val_accuracy: 0.8438
Epoch 72/110
 - 3s - loss: 0.1546 - accuracy: 0.9916 - val_loss: 0.7871 - val_accuracy: 0.8657
Epoch 73/110
 - 2s - loss: 0.1402 - accuracy: 0.9938 - val_loss: 0.8316 - val_accuracy: 0.8496
Epoch 74/110
 - 3s - loss: 0.1462 - accuracy: 0.9922 - val_loss: 0.8406 - val_accuracy: 0.8555
Epoch 75/110
 - 3s - loss: 0.1576 - accuracy: 0.9894 - val_loss: 0.7945 - val_accuracy: 0.8599
Epoch 76/110
 - 3s - loss: 0.1883 - accuracy: 0.9777 - val_loss: 0.9952 - val_accuracy: 0.8387
Epoch 77/110
 - 2s - loss: 0.2376 - accuracy: 0.9666 - val_loss: 0.8275 - val_accuracy: 0.8431
Epoch 78/110
 - 3s - loss: 0.1928 - accuracy: 0.9754 - val_loss: 0.7836 - val_accuracy: 0.8555
Epoch 79/110
 - 3s - loss: 0.1605 - accuracy: 0.9859 - val_loss: 0.8688 - val_accuracy: 0.8569
Epoch 80/110
 - 3s - loss: 0.1578 - accuracy: 0.9907 - val_loss: 0.8408 - val_accuracy: 0.8591
Epoch 81/110
 - 3s - loss: 0.1525 - accuracy: 0.9907 - val_loss: 0.7959 - val_accuracy: 0.8591
Epoch 82/110
 - 2s - loss: 0.1416 - accuracy: 0.9940 - val_loss: 0.7742 - val_accuracy: 0.8701
Epoch 83/110
 - 2s - loss: 0.1277 - accuracy: 0.9989 - val_loss: 0.7796 - val_accuracy: 0.8693
Epoch 84/110
 - 2s - loss: 0.1321 - accuracy: 0.9965 - val_loss: 0.8643 - val_accuracy: 0.8526
Epoch 85/110
 - 3s - loss: 0.1641 - accuracy: 0.9876 - val_loss: 0.8348 - val_accuracy: 0.8540
Epoch 86/110
 - 3s - loss: 0.2100 - accuracy: 0.9746 - val_loss: 0.9610 - val_accuracy: 0.8139
Epoch 87/110
 - 3s - loss: 0.2400 - accuracy: 0.9602 - val_loss: 0.8242 - val_accuracy: 0.8453
Epoch 88/110
 - 3s - loss: 0.1760 - accuracy: 0.9819 - val_loss: 0.7875 - val_accuracy: 0.8562
Epoch 89/110
 - 3s - loss: 0.1556 - accuracy: 0.9892 - val_loss: 0.8211 - val_accuracy: 0.8584
Epoch 90/110
 - 2s - loss: 0.1449 - accuracy: 0.9934 - val_loss: 0.7800 - val_accuracy: 0.8650
Epoch 91/110
 - 2s - loss: 0.1359 - accuracy: 0.9967 - val_loss: 0.7806 - val_accuracy: 0.8584
Epoch 92/110
 - 3s - loss: 0.1283 - accuracy: 0.9980 - val_loss: 0.8080 - val_accuracy: 0.8591
Epoch 93/110
 - 3s - loss: 0.1288 - accuracy: 0.9971 - val_loss: 0.8488 - val_accuracy: 0.8642
Epoch 94/110
 - 2s - loss: 0.1309 - accuracy: 0.9974 - val_loss: 0.8411 - val_accuracy: 0.8613
Epoch 95/110
 - 3s - loss: 0.1219 - accuracy: 0.9991 - val_loss: 0.8549 - val_accuracy: 0.8657
Epoch 96/110
 - 3s - loss: 0.1281 - accuracy: 0.9974 - val_loss: 0.8967 - val_accuracy: 0.8657
Epoch 97/110
 - 2s - loss: 0.1433 - accuracy: 0.9936 - val_loss: 0.8696 - val_accuracy: 0.8599
Epoch 98/110
 - 3s - loss: 0.1993 - accuracy: 0.9755 - val_loss: 0.9842 - val_accuracy: 0.8321
Epoch 99/110
 - 3s - loss: 0.2741 - accuracy: 0.9496 - val_loss: 0.9129 - val_accuracy: 0.8073
Epoch 100/110
 - 3s - loss: 0.2690 - accuracy: 0.9509 - val_loss: 0.8117 - val_accuracy: 0.8328
Epoch 101/110
 - 3s - loss: 0.2007 - accuracy: 0.9728 - val_loss: 0.7683 - val_accuracy: 0.8540
Epoch 102/110
 - 2s - loss: 0.1553 - accuracy: 0.9903 - val_loss: 0.7504 - val_accuracy: 0.8679
Epoch 103/110
 - 3s - loss: 0.1344 - accuracy: 0.9973 - val_loss: 0.7612 - val_accuracy: 0.8657
Epoch 104/110
 - 3s - loss: 0.1293 - accuracy: 0.9974 - val_loss: 0.8007 - val_accuracy: 0.8650
Epoch 105/110
 - 3s - loss: 0.1287 - accuracy: 0.9980 - val_loss: 0.8221 - val_accuracy: 0.8686
Epoch 106/110
 - 2s - loss: 0.1288 - accuracy: 0.9969 - val_loss: 0.7999 - val_accuracy: 0.8606
Epoch 107/110
 - 2s - loss: 0.1261 - accuracy: 0.9978 - val_loss: 0.8347 - val_accuracy: 0.8620
Epoch 108/110
 - 3s - loss: 0.1290 - accuracy: 0.9967 - val_loss: 0.8076 - val_accuracy: 0.8628
Epoch 109/110
 - 3s - loss: 0.1258 - accuracy: 0.9971 - val_loss: 0.8096 - val_accuracy: 0.8774
Epoch 110/110
 - 3s - loss: 0.1301 - accuracy: 0.9971 - val_loss: 0.8247 - val_accuracy: 0.8657
------------------------------------------------------------------------
Training for fold 3 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 3s - loss: 0.1536 - accuracy: 0.9883 - val_loss: 0.8259 - val_accuracy: 0.8599
Epoch 2/110
 - 2s - loss: 0.1672 - accuracy: 0.9830 - val_loss: 0.8635 - val_accuracy: 0.8467
Epoch 3/110
 - 2s - loss: 0.1897 - accuracy: 0.9803 - val_loss: 0.9142 - val_accuracy: 0.8314
Epoch 4/110
 - 3s - loss: 0.2006 - accuracy: 0.9737 - val_loss: 0.7420 - val_accuracy: 0.8387
Epoch 5/110
 - 3s - loss: 0.1823 - accuracy: 0.9803 - val_loss: 0.8100 - val_accuracy: 0.8401
Epoch 6/110
 - 3s - loss: 0.1813 - accuracy: 0.9805 - val_loss: 0.7824 - val_accuracy: 0.8496
Epoch 7/110
 - 3s - loss: 0.1664 - accuracy: 0.9863 - val_loss: 0.7666 - val_accuracy: 0.8577
Epoch 8/110
 - 3s - loss: 0.1582 - accuracy: 0.9870 - val_loss: 0.8629 - val_accuracy: 0.8467
Epoch 9/110
 - 3s - loss: 0.1694 - accuracy: 0.9852 - val_loss: 0.8458 - val_accuracy: 0.8482
Epoch 10/110
 - 3s - loss: 0.1503 - accuracy: 0.9912 - val_loss: 0.7904 - val_accuracy: 0.8504
Epoch 11/110
 - 2s - loss: 0.1552 - accuracy: 0.9901 - val_loss: 0.8357 - val_accuracy: 0.8445
Epoch 12/110
 - 2s - loss: 0.1469 - accuracy: 0.9918 - val_loss: 0.8730 - val_accuracy: 0.8482
Epoch 13/110
 - 2s - loss: 0.1288 - accuracy: 0.9971 - val_loss: 0.8165 - val_accuracy: 0.8650
Epoch 14/110
 - 2s - loss: 0.1317 - accuracy: 0.9954 - val_loss: 0.8479 - val_accuracy: 0.8547
Epoch 15/110
 - 2s - loss: 0.1379 - accuracy: 0.9934 - val_loss: 0.8397 - val_accuracy: 0.8591
Epoch 16/110
 - 2s - loss: 0.1640 - accuracy: 0.9828 - val_loss: 0.8743 - val_accuracy: 0.8540
Epoch 17/110
 - 3s - loss: 0.1464 - accuracy: 0.9900 - val_loss: 0.8593 - val_accuracy: 0.8496
Epoch 18/110
 - 3s - loss: 0.1563 - accuracy: 0.9880 - val_loss: 0.8411 - val_accuracy: 0.8453
Epoch 19/110
 - 3s - loss: 0.1754 - accuracy: 0.9808 - val_loss: 0.8449 - val_accuracy: 0.8467
Epoch 20/110
 - 3s - loss: 0.1724 - accuracy: 0.9816 - val_loss: 0.7946 - val_accuracy: 0.8482
Epoch 21/110
 - 2s - loss: 0.1570 - accuracy: 0.9869 - val_loss: 0.7568 - val_accuracy: 0.8511
Epoch 22/110
 - 2s - loss: 0.1608 - accuracy: 0.9872 - val_loss: 0.7817 - val_accuracy: 0.8533
Epoch 23/110
 - 2s - loss: 0.1384 - accuracy: 0.9936 - val_loss: 0.8018 - val_accuracy: 0.8584
Epoch 24/110
 - 2s - loss: 0.1415 - accuracy: 0.9929 - val_loss: 0.8414 - val_accuracy: 0.8577
Epoch 25/110
 - 2s - loss: 0.1509 - accuracy: 0.9907 - val_loss: 0.7804 - val_accuracy: 0.8547
Epoch 26/110
 - 2s - loss: 0.1470 - accuracy: 0.9887 - val_loss: 0.8110 - val_accuracy: 0.8467
Epoch 27/110
 - 2s - loss: 0.1447 - accuracy: 0.9918 - val_loss: 0.7876 - val_accuracy: 0.8569
Epoch 28/110
 - 3s - loss: 0.1478 - accuracy: 0.9896 - val_loss: 0.8181 - val_accuracy: 0.8540
Epoch 29/110
 - 3s - loss: 0.1874 - accuracy: 0.9792 - val_loss: 0.9368 - val_accuracy: 0.8504
Epoch 30/110
 - 3s - loss: 0.1661 - accuracy: 0.9823 - val_loss: 0.8055 - val_accuracy: 0.8416
Epoch 31/110
 - 3s - loss: 0.1512 - accuracy: 0.9887 - val_loss: 0.8120 - val_accuracy: 0.8584
Epoch 32/110
 - 3s - loss: 0.1505 - accuracy: 0.9903 - val_loss: 0.7610 - val_accuracy: 0.8613
Epoch 33/110
 - 3s - loss: 0.1515 - accuracy: 0.9894 - val_loss: 0.8089 - val_accuracy: 0.8672
Epoch 34/110
 - 2s - loss: 0.1430 - accuracy: 0.9920 - val_loss: 0.7681 - val_accuracy: 0.8562
Epoch 35/110
 - 3s - loss: 0.1784 - accuracy: 0.9876 - val_loss: 0.7613 - val_accuracy: 0.8518
Epoch 36/110
 - 2s - loss: 0.2018 - accuracy: 0.9721 - val_loss: 0.8191 - val_accuracy: 0.8460
Epoch 37/110
 - 3s - loss: 0.1723 - accuracy: 0.9836 - val_loss: 0.8132 - val_accuracy: 0.8416
Epoch 38/110
 - 3s - loss: 0.1427 - accuracy: 0.9925 - val_loss: 0.8547 - val_accuracy: 0.8518
Epoch 39/110
 - 3s - loss: 0.1368 - accuracy: 0.9947 - val_loss: 0.8318 - val_accuracy: 0.8613
Epoch 40/110
 - 3s - loss: 0.1377 - accuracy: 0.9936 - val_loss: 0.8679 - val_accuracy: 0.8526
Epoch 41/110
 - 3s - loss: 0.1450 - accuracy: 0.9918 - val_loss: 0.8292 - val_accuracy: 0.8489
Epoch 42/110
 - 2s - loss: 0.1290 - accuracy: 0.9953 - val_loss: 0.8060 - val_accuracy: 0.8599
Epoch 43/110
 - 2s - loss: 0.1308 - accuracy: 0.9967 - val_loss: 0.8584 - val_accuracy: 0.8613
Epoch 44/110
 - 2s - loss: 0.1308 - accuracy: 0.9942 - val_loss: 0.8824 - val_accuracy: 0.8540
Epoch 45/110
 - 2s - loss: 0.1486 - accuracy: 0.9890 - val_loss: 0.8727 - val_accuracy: 0.8555
Epoch 46/110
 - 3s - loss: 0.1776 - accuracy: 0.9816 - val_loss: 0.8006 - val_accuracy: 0.8380
Epoch 47/110
 - 3s - loss: 0.1793 - accuracy: 0.9786 - val_loss: 0.8323 - val_accuracy: 0.8504
Epoch 48/110
 - 2s - loss: 0.1519 - accuracy: 0.9900 - val_loss: 0.8560 - val_accuracy: 0.8489
Epoch 49/110
 - 2s - loss: 0.1462 - accuracy: 0.9911 - val_loss: 0.7823 - val_accuracy: 0.8606
Epoch 50/110
 - 3s - loss: 0.1269 - accuracy: 0.9962 - val_loss: 0.8086 - val_accuracy: 0.8547
Epoch 51/110
 - 3s - loss: 0.1364 - accuracy: 0.9942 - val_loss: 0.8137 - val_accuracy: 0.8584
Epoch 52/110
 - 3s - loss: 0.1401 - accuracy: 0.9914 - val_loss: 0.8490 - val_accuracy: 0.8650
Epoch 53/110
 - 2s - loss: 0.1506 - accuracy: 0.9880 - val_loss: 0.8616 - val_accuracy: 0.8467
Epoch 54/110
 - 3s - loss: 0.1832 - accuracy: 0.9786 - val_loss: 0.7827 - val_accuracy: 0.8555
Epoch 55/110
 - 3s - loss: 0.1847 - accuracy: 0.9763 - val_loss: 0.8216 - val_accuracy: 0.8526
Epoch 56/110
 - 3s - loss: 0.1740 - accuracy: 0.9803 - val_loss: 0.7831 - val_accuracy: 0.8584
Epoch 57/110
 - 2s - loss: 0.1530 - accuracy: 0.9892 - val_loss: 0.7742 - val_accuracy: 0.8540
Epoch 58/110
 - 3s - loss: 0.1406 - accuracy: 0.9927 - val_loss: 0.7894 - val_accuracy: 0.8526
Epoch 59/110
 - 3s - loss: 0.1437 - accuracy: 0.9916 - val_loss: 0.7781 - val_accuracy: 0.8577
Epoch 60/110
 - 2s - loss: 0.1376 - accuracy: 0.9936 - val_loss: 0.8605 - val_accuracy: 0.8635
Epoch 61/110
 - 2s - loss: 0.1369 - accuracy: 0.9936 - val_loss: 0.8432 - val_accuracy: 0.8635
Epoch 62/110
 - 2s - loss: 0.1310 - accuracy: 0.9953 - val_loss: 0.8445 - val_accuracy: 0.8504
Epoch 63/110
 - 2s - loss: 0.1371 - accuracy: 0.9920 - val_loss: 0.8782 - val_accuracy: 0.8460
Epoch 64/110
 - 3s - loss: 0.1624 - accuracy: 0.9832 - val_loss: 0.9368 - val_accuracy: 0.8482
Epoch 65/110
 - 2s - loss: 0.1929 - accuracy: 0.9739 - val_loss: 0.8301 - val_accuracy: 0.8518
Epoch 66/110
 - 2s - loss: 0.1711 - accuracy: 0.9830 - val_loss: 0.7493 - val_accuracy: 0.8642
Epoch 67/110
 - 2s - loss: 0.1654 - accuracy: 0.9861 - val_loss: 0.7911 - val_accuracy: 0.8591
Epoch 68/110
 - 2s - loss: 0.1443 - accuracy: 0.9916 - val_loss: 0.7570 - val_accuracy: 0.8599
Epoch 69/110
 - 3s - loss: 0.1251 - accuracy: 0.9971 - val_loss: 0.7992 - val_accuracy: 0.8577
Epoch 70/110
 - 2s - loss: 0.1179 - accuracy: 0.9991 - val_loss: 0.7864 - val_accuracy: 0.8620
Epoch 71/110
 - 2s - loss: 0.1173 - accuracy: 0.9987 - val_loss: 0.8181 - val_accuracy: 0.8650
Epoch 72/110
 - 2s - loss: 0.1157 - accuracy: 0.9987 - val_loss: 0.8079 - val_accuracy: 0.8613
Epoch 73/110
 - 2s - loss: 0.1137 - accuracy: 0.9993 - val_loss: 0.8181 - val_accuracy: 0.8635
Epoch 74/110
 - 3s - loss: 0.1125 - accuracy: 0.9989 - val_loss: 0.8124 - val_accuracy: 0.8620
Epoch 75/110
 - 3s - loss: 0.1144 - accuracy: 0.9982 - val_loss: 0.8075 - val_accuracy: 0.8628
Epoch 76/110
 - 2s - loss: 0.1153 - accuracy: 0.9980 - val_loss: 0.8164 - val_accuracy: 0.8599
Epoch 77/110
 - 3s - loss: 0.1201 - accuracy: 0.9967 - val_loss: 0.8761 - val_accuracy: 0.8628
Epoch 78/110
 - 2s - loss: 0.1775 - accuracy: 0.9785 - val_loss: 0.8616 - val_accuracy: 0.8431
Epoch 79/110
 - 2s - loss: 0.2433 - accuracy: 0.9582 - val_loss: 0.8881 - val_accuracy: 0.8182
Epoch 80/110
 - 2s - loss: 0.2214 - accuracy: 0.9640 - val_loss: 0.8331 - val_accuracy: 0.8387
Epoch 81/110
 - 2s - loss: 0.1717 - accuracy: 0.9819 - val_loss: 0.7876 - val_accuracy: 0.8511
Epoch 82/110
 - 2s - loss: 0.1471 - accuracy: 0.9916 - val_loss: 0.7770 - val_accuracy: 0.8584
Epoch 83/110
 - 2s - loss: 0.1293 - accuracy: 0.9958 - val_loss: 0.7922 - val_accuracy: 0.8555
Epoch 84/110
 - 2s - loss: 0.1310 - accuracy: 0.9953 - val_loss: 0.7934 - val_accuracy: 0.8628
Epoch 85/110
 - 3s - loss: 0.1245 - accuracy: 0.9965 - val_loss: 0.8421 - val_accuracy: 0.8577
Epoch 86/110
 - 2s - loss: 0.1386 - accuracy: 0.9914 - val_loss: 0.8095 - val_accuracy: 0.8562
Epoch 87/110
 - 3s - loss: 0.1310 - accuracy: 0.9922 - val_loss: 0.8641 - val_accuracy: 0.8547
Epoch 88/110
 - 3s - loss: 0.1353 - accuracy: 0.9925 - val_loss: 0.8737 - val_accuracy: 0.8547
Epoch 89/110
 - 2s - loss: 0.1510 - accuracy: 0.9856 - val_loss: 0.8433 - val_accuracy: 0.8584
Epoch 90/110
 - 2s - loss: 0.1579 - accuracy: 0.9872 - val_loss: 0.8243 - val_accuracy: 0.8518
Epoch 91/110
 - 2s - loss: 0.1467 - accuracy: 0.9898 - val_loss: 0.8286 - val_accuracy: 0.8533
Epoch 92/110
 - 2s - loss: 0.1469 - accuracy: 0.9894 - val_loss: 0.8501 - val_accuracy: 0.8474
Epoch 93/110
 - 2s - loss: 0.1705 - accuracy: 0.9797 - val_loss: 0.8268 - val_accuracy: 0.8540
Epoch 94/110
 - 2s - loss: 0.1651 - accuracy: 0.9839 - val_loss: 0.7829 - val_accuracy: 0.8584
Epoch 95/110
 - 2s - loss: 0.1443 - accuracy: 0.9911 - val_loss: 0.8462 - val_accuracy: 0.8511
Epoch 96/110
 - 2s - loss: 0.2344 - accuracy: 0.9646 - val_loss: 0.8442 - val_accuracy: 0.8277
Epoch 97/110
 - 2s - loss: 0.1968 - accuracy: 0.9706 - val_loss: 0.8224 - val_accuracy: 0.8453
Epoch 98/110
 - 3s - loss: 0.1617 - accuracy: 0.9852 - val_loss: 0.8410 - val_accuracy: 0.8577
Epoch 99/110
 - 2s - loss: 0.1411 - accuracy: 0.9929 - val_loss: 0.8420 - val_accuracy: 0.8591
Epoch 100/110
 - 3s - loss: 0.1245 - accuracy: 0.9974 - val_loss: 0.8122 - val_accuracy: 0.8635
Epoch 101/110
 - 2s - loss: 0.1207 - accuracy: 0.9978 - val_loss: 0.8396 - val_accuracy: 0.8584
Epoch 102/110
 - 2s - loss: 0.1153 - accuracy: 0.9989 - val_loss: 0.8483 - val_accuracy: 0.8620
Epoch 103/110
 - 2s - loss: 0.1136 - accuracy: 0.9991 - val_loss: 0.8617 - val_accuracy: 0.8650
Epoch 104/110
 - 2s - loss: 0.1122 - accuracy: 0.9989 - val_loss: 0.8876 - val_accuracy: 0.8599
Epoch 105/110
 - 2s - loss: 0.1141 - accuracy: 0.9985 - val_loss: 0.8789 - val_accuracy: 0.8620
Epoch 106/110
 - 2s - loss: 0.1129 - accuracy: 0.9978 - val_loss: 0.8867 - val_accuracy: 0.8599
Epoch 107/110
 - 2s - loss: 0.1168 - accuracy: 0.9973 - val_loss: 0.9134 - val_accuracy: 0.8496
Epoch 108/110
 - 2s - loss: 0.1271 - accuracy: 0.9956 - val_loss: 0.8905 - val_accuracy: 0.8591
Epoch 109/110
 - 2s - loss: 0.1563 - accuracy: 0.9861 - val_loss: 0.8636 - val_accuracy: 0.8518
Epoch 110/110
 - 2s - loss: 0.2068 - accuracy: 0.9712 - val_loss: 0.8652 - val_accuracy: 0.8416
------------------------------------------------------------------------
Training for fold 4 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 2s - loss: 0.2053 - accuracy: 0.9679 - val_loss: 0.8579 - val_accuracy: 0.8431
Epoch 2/110
 - 2s - loss: 0.1573 - accuracy: 0.9825 - val_loss: 0.7863 - val_accuracy: 0.8533
Epoch 3/110
 - 2s - loss: 0.1410 - accuracy: 0.9894 - val_loss: 0.8520 - val_accuracy: 0.8496
Epoch 4/110
 - 2s - loss: 0.1241 - accuracy: 0.9967 - val_loss: 0.7888 - val_accuracy: 0.8642
Epoch 5/110
 - 2s - loss: 0.1214 - accuracy: 0.9963 - val_loss: 0.8125 - val_accuracy: 0.8555
Epoch 6/110
 - 3s - loss: 0.1254 - accuracy: 0.9953 - val_loss: 0.7863 - val_accuracy: 0.8642
Epoch 7/110
 - 3s - loss: 0.1135 - accuracy: 0.9985 - val_loss: 0.7878 - val_accuracy: 0.8686
Epoch 8/110
 - 2s - loss: 0.1113 - accuracy: 0.9982 - val_loss: 0.8459 - val_accuracy: 0.8569
Epoch 9/110
 - 3s - loss: 0.1119 - accuracy: 0.9978 - val_loss: 0.8239 - val_accuracy: 0.8620
Epoch 10/110
 - 2s - loss: 0.1168 - accuracy: 0.9969 - val_loss: 0.8584 - val_accuracy: 0.8504
Epoch 11/110
 - 2s - loss: 0.1389 - accuracy: 0.9914 - val_loss: 0.9111 - val_accuracy: 0.8518
Epoch 12/110
 - 3s - loss: 0.1835 - accuracy: 0.9766 - val_loss: 0.8632 - val_accuracy: 0.8416
Epoch 13/110
 - 2s - loss: 0.1805 - accuracy: 0.9757 - val_loss: 0.8434 - val_accuracy: 0.8365
Epoch 14/110
 - 2s - loss: 0.2098 - accuracy: 0.9642 - val_loss: 0.7794 - val_accuracy: 0.8474
Epoch 15/110
 - 2s - loss: 0.1700 - accuracy: 0.9792 - val_loss: 0.8196 - val_accuracy: 0.8504
Epoch 16/110
 - 3s - loss: 0.1553 - accuracy: 0.9850 - val_loss: 0.7279 - val_accuracy: 0.8599
Epoch 17/110
 - 2s - loss: 0.1275 - accuracy: 0.9954 - val_loss: 0.8324 - val_accuracy: 0.8562
Epoch 18/110
 - 2s - loss: 0.1209 - accuracy: 0.9962 - val_loss: 0.8062 - val_accuracy: 0.8577
Epoch 19/110
 - 2s - loss: 0.1179 - accuracy: 0.9971 - val_loss: 0.8289 - val_accuracy: 0.8657
Epoch 20/110
 - 2s - loss: 0.1167 - accuracy: 0.9974 - val_loss: 0.8253 - val_accuracy: 0.8620
Epoch 21/110
 - 3s - loss: 0.1146 - accuracy: 0.9969 - val_loss: 0.8067 - val_accuracy: 0.8715
Epoch 22/110
 - 2s - loss: 0.1140 - accuracy: 0.9980 - val_loss: 0.8391 - val_accuracy: 0.8628
Epoch 23/110
 - 3s - loss: 0.1096 - accuracy: 0.9984 - val_loss: 0.8516 - val_accuracy: 0.8679
Epoch 24/110
 - 2s - loss: 0.1130 - accuracy: 0.9978 - val_loss: 0.9299 - val_accuracy: 0.8577
Epoch 25/110
 - 2s - loss: 0.1358 - accuracy: 0.9911 - val_loss: 0.9284 - val_accuracy: 0.8474
Epoch 26/110
 - 2s - loss: 0.2790 - accuracy: 0.9533 - val_loss: 1.0615 - val_accuracy: 0.8153
Epoch 27/110
 - 2s - loss: 0.2281 - accuracy: 0.9597 - val_loss: 0.7556 - val_accuracy: 0.8460
Epoch 28/110
 - 2s - loss: 0.1544 - accuracy: 0.9852 - val_loss: 0.7518 - val_accuracy: 0.8569
Epoch 29/110
 - 2s - loss: 0.1311 - accuracy: 0.9927 - val_loss: 0.7539 - val_accuracy: 0.8613
Epoch 30/110
 - 2s - loss: 0.1194 - accuracy: 0.9967 - val_loss: 0.7774 - val_accuracy: 0.8635
Epoch 31/110
 - 2s - loss: 0.1124 - accuracy: 0.9993 - val_loss: 0.7802 - val_accuracy: 0.8613
Epoch 32/110
 - 2s - loss: 0.1087 - accuracy: 0.9996 - val_loss: 0.7978 - val_accuracy: 0.8628
Epoch 33/110
 - 2s - loss: 0.1082 - accuracy: 0.9993 - val_loss: 0.8174 - val_accuracy: 0.8650
Epoch 34/110
 - 2s - loss: 0.1100 - accuracy: 0.9989 - val_loss: 0.8229 - val_accuracy: 0.8679
Epoch 35/110
 - 2s - loss: 0.1087 - accuracy: 0.9982 - val_loss: 0.8420 - val_accuracy: 0.8613
Epoch 36/110
 - 3s - loss: 0.1296 - accuracy: 0.9936 - val_loss: 0.8249 - val_accuracy: 0.8635
Epoch 37/110
 - 2s - loss: 0.1118 - accuracy: 0.9978 - val_loss: 0.7920 - val_accuracy: 0.8555
Epoch 38/110
 - 3s - loss: 0.1220 - accuracy: 0.9960 - val_loss: 0.8780 - val_accuracy: 0.8628
Epoch 39/110
 - 2s - loss: 0.1572 - accuracy: 0.9861 - val_loss: 0.8220 - val_accuracy: 0.8431
Epoch 40/110
 - 2s - loss: 0.1980 - accuracy: 0.9681 - val_loss: 0.8811 - val_accuracy: 0.8350
Epoch 41/110
 - 3s - loss: 0.1865 - accuracy: 0.9730 - val_loss: 0.8703 - val_accuracy: 0.8394
Epoch 42/110
 - 3s - loss: 0.1788 - accuracy: 0.9788 - val_loss: 0.8367 - val_accuracy: 0.8431
Epoch 43/110
 - 2s - loss: 0.1940 - accuracy: 0.9757 - val_loss: 0.7307 - val_accuracy: 0.8518
Epoch 44/110
 - 3s - loss: 0.1335 - accuracy: 0.9920 - val_loss: 0.7612 - val_accuracy: 0.8562
Epoch 45/110
 - 3s - loss: 0.1171 - accuracy: 0.9967 - val_loss: 0.7923 - val_accuracy: 0.8599
Epoch 46/110
 - 2s - loss: 0.1131 - accuracy: 0.9974 - val_loss: 0.7750 - val_accuracy: 0.8569
Epoch 47/110
 - 2s - loss: 0.1139 - accuracy: 0.9973 - val_loss: 0.7714 - val_accuracy: 0.8577
Epoch 48/110
 - 3s - loss: 0.1148 - accuracy: 0.9973 - val_loss: 0.8247 - val_accuracy: 0.8547
Epoch 49/110
 - 3s - loss: 0.1235 - accuracy: 0.9945 - val_loss: 0.8482 - val_accuracy: 0.8577
Epoch 50/110
 - 3s - loss: 0.1220 - accuracy: 0.9929 - val_loss: 0.8151 - val_accuracy: 0.8547
Epoch 51/110
 - 3s - loss: 0.1343 - accuracy: 0.9905 - val_loss: 0.8839 - val_accuracy: 0.8511
Epoch 52/110
 - 2s - loss: 0.1352 - accuracy: 0.9911 - val_loss: 0.8137 - val_accuracy: 0.8584
Epoch 53/110
 - 2s - loss: 0.1474 - accuracy: 0.9863 - val_loss: 0.8079 - val_accuracy: 0.8504
Epoch 54/110
 - 2s - loss: 0.1869 - accuracy: 0.9739 - val_loss: 0.8959 - val_accuracy: 0.8248
Epoch 55/110
 - 2s - loss: 0.1580 - accuracy: 0.9816 - val_loss: 0.8509 - val_accuracy: 0.8489
Epoch 56/110
 - 2s - loss: 0.1504 - accuracy: 0.9841 - val_loss: 0.8475 - val_accuracy: 0.8380
Epoch 57/110
 - 2s - loss: 0.1492 - accuracy: 0.9845 - val_loss: 0.8674 - val_accuracy: 0.8526
Epoch 58/110
 - 2s - loss: 0.1672 - accuracy: 0.9819 - val_loss: 0.8245 - val_accuracy: 0.8314
Epoch 59/110
 - 2s - loss: 0.1964 - accuracy: 0.9715 - val_loss: 0.8178 - val_accuracy: 0.8540
Epoch 60/110
 - 2s - loss: 0.1376 - accuracy: 0.9901 - val_loss: 0.7475 - val_accuracy: 0.8613
Epoch 61/110
 - 2s - loss: 0.1270 - accuracy: 0.9942 - val_loss: 0.7632 - val_accuracy: 0.8606
Epoch 62/110
 - 2s - loss: 0.1159 - accuracy: 0.9974 - val_loss: 0.7968 - val_accuracy: 0.8664
Epoch 63/110
 - 2s - loss: 0.1095 - accuracy: 0.9985 - val_loss: 0.7741 - val_accuracy: 0.8620
Epoch 64/110
 - 2s - loss: 0.1080 - accuracy: 0.9989 - val_loss: 0.8128 - val_accuracy: 0.8606
Epoch 65/110
 - 2s - loss: 0.1072 - accuracy: 0.9991 - val_loss: 0.8087 - val_accuracy: 0.8657
Epoch 66/110
 - 2s - loss: 0.1049 - accuracy: 0.9991 - val_loss: 0.8273 - val_accuracy: 0.8635
Epoch 67/110
 - 2s - loss: 0.1042 - accuracy: 0.9991 - val_loss: 0.8197 - val_accuracy: 0.8642
Epoch 68/110
 - 2s - loss: 0.1034 - accuracy: 0.9991 - val_loss: 0.8311 - val_accuracy: 0.8620
Epoch 69/110
 - 3s - loss: 0.1038 - accuracy: 0.9989 - val_loss: 0.8120 - val_accuracy: 0.8650
Epoch 70/110
 - 3s - loss: 0.1034 - accuracy: 0.9987 - val_loss: 0.8181 - val_accuracy: 0.8730
Epoch 71/110
 - 2s - loss: 0.1022 - accuracy: 0.9987 - val_loss: 0.8198 - val_accuracy: 0.8664
Epoch 72/110
 - 2s - loss: 0.1003 - accuracy: 0.9989 - val_loss: 0.8322 - val_accuracy: 0.8628
Epoch 73/110
 - 2s - loss: 0.0985 - accuracy: 0.9993 - val_loss: 0.8354 - val_accuracy: 0.8664
Epoch 74/110
 - 2s - loss: 0.0974 - accuracy: 0.9991 - val_loss: 0.8510 - val_accuracy: 0.8620
Epoch 75/110
 - 3s - loss: 0.0984 - accuracy: 0.9987 - val_loss: 0.8674 - val_accuracy: 0.8635
Epoch 76/110
 - 2s - loss: 0.1356 - accuracy: 0.9896 - val_loss: 0.8972 - val_accuracy: 0.8255
Epoch 77/110
 - 2s - loss: 0.4198 - accuracy: 0.9027 - val_loss: 1.0176 - val_accuracy: 0.7766
Epoch 78/110
 - 2s - loss: 0.2733 - accuracy: 0.9412 - val_loss: 0.6950 - val_accuracy: 0.8562
Epoch 79/110
 - 2s - loss: 0.1614 - accuracy: 0.9805 - val_loss: 0.7382 - val_accuracy: 0.8540
Epoch 80/110
 - 2s - loss: 0.1279 - accuracy: 0.9932 - val_loss: 0.7536 - val_accuracy: 0.8606
Epoch 81/110
 - 2s - loss: 0.1158 - accuracy: 0.9963 - val_loss: 0.7553 - val_accuracy: 0.8642
Epoch 82/110
 - 3s - loss: 0.1103 - accuracy: 0.9984 - val_loss: 0.7705 - val_accuracy: 0.8591
Epoch 83/110
 - 3s - loss: 0.1060 - accuracy: 0.9987 - val_loss: 0.7926 - val_accuracy: 0.8664
Epoch 84/110
 - 2s - loss: 0.1048 - accuracy: 0.9989 - val_loss: 0.7993 - val_accuracy: 0.8606
Epoch 85/110
 - 2s - loss: 0.1049 - accuracy: 0.9989 - val_loss: 0.8217 - val_accuracy: 0.8613
Epoch 86/110
 - 2s - loss: 0.1045 - accuracy: 0.9982 - val_loss: 0.8178 - val_accuracy: 0.8547
Epoch 87/110
 - 2s - loss: 0.1116 - accuracy: 0.9958 - val_loss: 0.8316 - val_accuracy: 0.8577
Epoch 88/110
 - 2s - loss: 0.1310 - accuracy: 0.9896 - val_loss: 0.8896 - val_accuracy: 0.8445
Epoch 89/110
 - 3s - loss: 0.1794 - accuracy: 0.9728 - val_loss: 0.8625 - val_accuracy: 0.8277
Epoch 90/110
 - 2s - loss: 0.1692 - accuracy: 0.9752 - val_loss: 0.7913 - val_accuracy: 0.8387
Epoch 91/110
 - 3s - loss: 0.1607 - accuracy: 0.9832 - val_loss: 0.7139 - val_accuracy: 0.8584
Epoch 92/110
 - 2s - loss: 0.1337 - accuracy: 0.9900 - val_loss: 0.7736 - val_accuracy: 0.8657
Epoch 93/110
 - 3s - loss: 0.1197 - accuracy: 0.9936 - val_loss: 0.7662 - val_accuracy: 0.8540
Epoch 94/110
 - 3s - loss: 0.1111 - accuracy: 0.9958 - val_loss: 0.7628 - val_accuracy: 0.8591
Epoch 95/110
 - 3s - loss: 0.1136 - accuracy: 0.9960 - val_loss: 0.8011 - val_accuracy: 0.8540
Epoch 96/110
 - 3s - loss: 0.1146 - accuracy: 0.9958 - val_loss: 0.7363 - val_accuracy: 0.8577
Epoch 97/110
 - 3s - loss: 0.1052 - accuracy: 0.9971 - val_loss: 0.8282 - val_accuracy: 0.8591
Epoch 98/110
 - 3s - loss: 0.1454 - accuracy: 0.9858 - val_loss: 0.8400 - val_accuracy: 0.8438
Epoch 99/110
 - 2s - loss: 0.1993 - accuracy: 0.9653 - val_loss: 0.7921 - val_accuracy: 0.8453
Epoch 100/110
 - 2s - loss: 0.1800 - accuracy: 0.9728 - val_loss: 0.8055 - val_accuracy: 0.8328
Epoch 101/110
 - 2s - loss: 0.1706 - accuracy: 0.9794 - val_loss: 0.7825 - val_accuracy: 0.8409
Epoch 102/110
 - 2s - loss: 0.1349 - accuracy: 0.9876 - val_loss: 0.7748 - val_accuracy: 0.8518
Epoch 103/110
 - 2s - loss: 0.1311 - accuracy: 0.9907 - val_loss: 0.7793 - val_accuracy: 0.8569
Epoch 104/110
 - 2s - loss: 0.1189 - accuracy: 0.9953 - val_loss: 0.7582 - val_accuracy: 0.8562
Epoch 105/110
 - 3s - loss: 0.1132 - accuracy: 0.9965 - val_loss: 0.8055 - val_accuracy: 0.8584
Epoch 106/110
 - 2s - loss: 0.1276 - accuracy: 0.9914 - val_loss: 0.7488 - val_accuracy: 0.8599
Epoch 107/110
 - 3s - loss: 0.1109 - accuracy: 0.9954 - val_loss: 0.7375 - val_accuracy: 0.8635
Epoch 108/110
 - 3s - loss: 0.1096 - accuracy: 0.9953 - val_loss: 0.8107 - val_accuracy: 0.8591
Epoch 109/110
 - 2s - loss: 0.1101 - accuracy: 0.9969 - val_loss: 0.7742 - val_accuracy: 0.8628
Epoch 110/110
 - 3s - loss: 0.1136 - accuracy: 0.9953 - val_loss: 0.8460 - val_accuracy: 0.8577
------------------------------------------------------------------------
Training for fold 5 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 2s - loss: 0.1299 - accuracy: 0.9909 - val_loss: 0.8217 - val_accuracy: 0.8504
Epoch 2/110
 - 3s - loss: 0.1398 - accuracy: 0.9869 - val_loss: 0.8382 - val_accuracy: 0.8401
Epoch 3/110
 - 3s - loss: 0.1557 - accuracy: 0.9821 - val_loss: 0.8786 - val_accuracy: 0.8453
Epoch 4/110
 - 2s - loss: 0.1415 - accuracy: 0.9869 - val_loss: 0.8162 - val_accuracy: 0.8518
Epoch 5/110
 - 3s - loss: 0.1391 - accuracy: 0.9880 - val_loss: 0.7936 - val_accuracy: 0.8547
Epoch 6/110
 - 3s - loss: 0.1255 - accuracy: 0.9923 - val_loss: 0.8065 - val_accuracy: 0.8504
Epoch 7/110
 - 2s - loss: 0.1218 - accuracy: 0.9927 - val_loss: 0.8546 - val_accuracy: 0.8504
Epoch 8/110
 - 2s - loss: 0.1318 - accuracy: 0.9907 - val_loss: 0.8942 - val_accuracy: 0.8496
Epoch 9/110
 - 3s - loss: 0.1279 - accuracy: 0.9920 - val_loss: 0.8136 - val_accuracy: 0.8511
Epoch 10/110
 - 2s - loss: 0.1110 - accuracy: 0.9956 - val_loss: 0.8637 - val_accuracy: 0.8474
Epoch 11/110
 - 2s - loss: 0.1271 - accuracy: 0.9922 - val_loss: 0.9273 - val_accuracy: 0.8482
Epoch 12/110
 - 2s - loss: 0.1249 - accuracy: 0.9918 - val_loss: 0.8683 - val_accuracy: 0.8482
Epoch 13/110
 - 2s - loss: 0.1352 - accuracy: 0.9890 - val_loss: 0.8283 - val_accuracy: 0.8496
Epoch 14/110
 - 2s - loss: 0.1364 - accuracy: 0.9865 - val_loss: 0.8513 - val_accuracy: 0.8460
Epoch 15/110
 - 2s - loss: 0.1584 - accuracy: 0.9810 - val_loss: 0.8324 - val_accuracy: 0.8416
Epoch 16/110
 - 2s - loss: 0.1583 - accuracy: 0.9805 - val_loss: 0.7561 - val_accuracy: 0.8401
Epoch 17/110
 - 2s - loss: 0.1518 - accuracy: 0.9830 - val_loss: 0.8249 - val_accuracy: 0.8401
Epoch 18/110
 - 2s - loss: 0.1412 - accuracy: 0.9887 - val_loss: 0.7863 - val_accuracy: 0.8504
Epoch 19/110
 - 3s - loss: 0.1269 - accuracy: 0.9931 - val_loss: 0.8313 - val_accuracy: 0.8474
Epoch 20/110
 - 2s - loss: 0.1259 - accuracy: 0.9936 - val_loss: 0.8243 - val_accuracy: 0.8460
Epoch 21/110
 - 2s - loss: 0.1115 - accuracy: 0.9971 - val_loss: 0.8012 - val_accuracy: 0.8650
Epoch 22/110
 - 2s - loss: 0.1038 - accuracy: 0.9991 - val_loss: 0.8312 - val_accuracy: 0.8577
Epoch 23/110
 - 2s - loss: 0.1028 - accuracy: 0.9984 - val_loss: 0.8485 - val_accuracy: 0.8650
Epoch 24/110
 - 2s - loss: 0.1022 - accuracy: 0.9987 - val_loss: 0.8449 - val_accuracy: 0.8657
Epoch 25/110
 - 2s - loss: 0.1023 - accuracy: 0.9985 - val_loss: 0.8430 - val_accuracy: 0.8584
Epoch 26/110
 - 2s - loss: 0.0986 - accuracy: 0.9995 - val_loss: 0.8553 - val_accuracy: 0.8635
Epoch 27/110
 - 2s - loss: 0.0995 - accuracy: 0.9987 - val_loss: 0.8343 - val_accuracy: 0.8620
Epoch 28/110
 - 2s - loss: 0.0980 - accuracy: 0.9991 - val_loss: 0.8437 - val_accuracy: 0.8672
Epoch 29/110
 - 2s - loss: 0.0966 - accuracy: 0.9989 - val_loss: 0.8487 - val_accuracy: 0.8620
Epoch 30/110
 - 2s - loss: 0.0966 - accuracy: 0.9987 - val_loss: 0.8506 - val_accuracy: 0.8628
Epoch 31/110
 - 2s - loss: 0.0961 - accuracy: 0.9989 - val_loss: 0.8647 - val_accuracy: 0.8664
Epoch 32/110
 - 2s - loss: 0.0937 - accuracy: 0.9991 - val_loss: 0.8700 - val_accuracy: 0.8591
Epoch 33/110
 - 2s - loss: 0.0931 - accuracy: 0.9991 - val_loss: 0.8920 - val_accuracy: 0.8599
Epoch 34/110
 - 2s - loss: 0.0936 - accuracy: 0.9989 - val_loss: 0.8754 - val_accuracy: 0.8650
Epoch 35/110
 - 2s - loss: 0.0935 - accuracy: 0.9984 - val_loss: 0.8684 - val_accuracy: 0.8613
Epoch 36/110
 - 2s - loss: 0.1384 - accuracy: 0.9859 - val_loss: 0.9609 - val_accuracy: 0.8241
Epoch 37/110
 - 2s - loss: 0.3824 - accuracy: 0.9085 - val_loss: 0.8632 - val_accuracy: 0.8168
Epoch 38/110
 - 2s - loss: 0.2727 - accuracy: 0.9456 - val_loss: 0.7905 - val_accuracy: 0.8460
Epoch 39/110
 - 3s - loss: 0.2352 - accuracy: 0.9533 - val_loss: 0.7488 - val_accuracy: 0.8562
Epoch 40/110
 - 3s - loss: 0.1472 - accuracy: 0.9838 - val_loss: 0.7725 - val_accuracy: 0.8650
Epoch 41/110
 - 2s - loss: 0.1187 - accuracy: 0.9943 - val_loss: 0.8194 - val_accuracy: 0.8584
Epoch 42/110
 - 3s - loss: 0.1130 - accuracy: 0.9974 - val_loss: 0.8210 - val_accuracy: 0.8540
Epoch 43/110
 - 2s - loss: 0.1118 - accuracy: 0.9960 - val_loss: 0.8436 - val_accuracy: 0.8526
Epoch 44/110
 - 2s - loss: 0.1153 - accuracy: 0.9965 - val_loss: 0.8586 - val_accuracy: 0.8511
Epoch 45/110
 - 2s - loss: 0.1144 - accuracy: 0.9958 - val_loss: 0.8802 - val_accuracy: 0.8686
Epoch 46/110
 - 2s - loss: 0.1129 - accuracy: 0.9951 - val_loss: 0.8330 - val_accuracy: 0.8635
Epoch 47/110
 - 2s - loss: 0.1142 - accuracy: 0.9954 - val_loss: 0.8478 - val_accuracy: 0.8533
Epoch 48/110
 - 2s - loss: 0.1177 - accuracy: 0.9931 - val_loss: 0.8751 - val_accuracy: 0.8496
Epoch 49/110
 - 2s - loss: 0.1254 - accuracy: 0.9918 - val_loss: 0.9109 - val_accuracy: 0.8489
Epoch 50/110
 - 2s - loss: 0.1361 - accuracy: 0.9869 - val_loss: 0.9244 - val_accuracy: 0.8482
Epoch 51/110
 - 2s - loss: 0.1365 - accuracy: 0.9874 - val_loss: 0.8756 - val_accuracy: 0.8555
Epoch 52/110
 - 3s - loss: 0.1331 - accuracy: 0.9892 - val_loss: 0.8854 - val_accuracy: 0.8482
Epoch 53/110
 - 2s - loss: 0.1289 - accuracy: 0.9911 - val_loss: 0.8645 - val_accuracy: 0.8504
Epoch 54/110
 - 2s - loss: 0.1306 - accuracy: 0.9900 - val_loss: 0.8392 - val_accuracy: 0.8577
Epoch 55/110
 - 2s - loss: 0.1356 - accuracy: 0.9883 - val_loss: 0.8238 - val_accuracy: 0.8584
Epoch 56/110
 - 3s - loss: 0.1359 - accuracy: 0.9890 - val_loss: 0.7892 - val_accuracy: 0.8547
Epoch 57/110
 - 3s - loss: 0.1156 - accuracy: 0.9943 - val_loss: 0.7835 - val_accuracy: 0.8569
Epoch 58/110
 - 3s - loss: 0.1062 - accuracy: 0.9962 - val_loss: 0.8735 - val_accuracy: 0.8511
Epoch 59/110
 - 2s - loss: 0.1084 - accuracy: 0.9965 - val_loss: 0.8619 - val_accuracy: 0.8555
Epoch 60/110
 - 3s - loss: 0.1100 - accuracy: 0.9958 - val_loss: 0.8817 - val_accuracy: 0.8606
Epoch 61/110
 - 2s - loss: 0.1128 - accuracy: 0.9949 - val_loss: 0.8707 - val_accuracy: 0.8511
Epoch 62/110
 - 3s - loss: 0.1103 - accuracy: 0.9954 - val_loss: 0.8431 - val_accuracy: 0.8518
Epoch 63/110
 - 2s - loss: 0.1260 - accuracy: 0.9923 - val_loss: 0.8931 - val_accuracy: 0.8504
Epoch 64/110
 - 2s - loss: 0.1397 - accuracy: 0.9845 - val_loss: 0.9200 - val_accuracy: 0.8504
Epoch 65/110
 - 2s - loss: 0.1343 - accuracy: 0.9881 - val_loss: 0.8484 - val_accuracy: 0.8474
Epoch 66/110
 - 3s - loss: 0.1486 - accuracy: 0.9845 - val_loss: 0.8043 - val_accuracy: 0.8533
Epoch 67/110
 - 2s - loss: 0.1476 - accuracy: 0.9856 - val_loss: 0.7676 - val_accuracy: 0.8562
Epoch 68/110
 - 2s - loss: 0.1338 - accuracy: 0.9889 - val_loss: 0.7868 - val_accuracy: 0.8591
Epoch 69/110
 - 2s - loss: 0.1134 - accuracy: 0.9943 - val_loss: 0.8283 - val_accuracy: 0.8584
Epoch 70/110
 - 2s - loss: 0.1071 - accuracy: 0.9958 - val_loss: 0.7961 - val_accuracy: 0.8577
Epoch 71/110
 - 3s - loss: 0.1083 - accuracy: 0.9951 - val_loss: 0.8865 - val_accuracy: 0.8474
Epoch 72/110
 - 2s - loss: 0.1233 - accuracy: 0.9922 - val_loss: 0.8197 - val_accuracy: 0.8620
Epoch 73/110
 - 2s - loss: 0.1060 - accuracy: 0.9967 - val_loss: 0.8433 - val_accuracy: 0.8555
Epoch 74/110
 - 2s - loss: 0.1105 - accuracy: 0.9956 - val_loss: 0.8432 - val_accuracy: 0.8591
Epoch 75/110
 - 2s - loss: 0.1078 - accuracy: 0.9953 - val_loss: 0.8375 - val_accuracy: 0.8577
Epoch 76/110
 - 2s - loss: 0.1022 - accuracy: 0.9976 - val_loss: 0.8477 - val_accuracy: 0.8599
Epoch 77/110
 - 2s - loss: 0.1042 - accuracy: 0.9969 - val_loss: 0.8520 - val_accuracy: 0.8533
Epoch 78/110
 - 2s - loss: 0.1276 - accuracy: 0.9898 - val_loss: 0.8992 - val_accuracy: 0.8467
Epoch 79/110
 - 2s - loss: 0.1739 - accuracy: 0.9726 - val_loss: 0.8637 - val_accuracy: 0.8453
Epoch 80/110
 - 2s - loss: 0.1937 - accuracy: 0.9668 - val_loss: 0.9034 - val_accuracy: 0.8277
Epoch 81/110
 - 2s - loss: 0.1589 - accuracy: 0.9797 - val_loss: 0.8133 - val_accuracy: 0.8401
Epoch 82/110
 - 2s - loss: 0.1370 - accuracy: 0.9869 - val_loss: 0.8861 - val_accuracy: 0.8526
Epoch 83/110
 - 2s - loss: 0.1252 - accuracy: 0.9903 - val_loss: 0.8361 - val_accuracy: 0.8533
Epoch 84/110
 - 2s - loss: 0.1090 - accuracy: 0.9965 - val_loss: 0.8429 - val_accuracy: 0.8657
Epoch 85/110
 - 2s - loss: 0.1021 - accuracy: 0.9980 - val_loss: 0.8624 - val_accuracy: 0.8562
Epoch 86/110
 - 2s - loss: 0.0977 - accuracy: 0.9995 - val_loss: 0.8749 - val_accuracy: 0.8599
Epoch 87/110
 - 2s - loss: 0.1000 - accuracy: 0.9980 - val_loss: 0.8736 - val_accuracy: 0.8562
Epoch 88/110
 - 2s - loss: 0.0993 - accuracy: 0.9984 - val_loss: 0.8829 - val_accuracy: 0.8584
Epoch 89/110
 - 2s - loss: 0.1096 - accuracy: 0.9947 - val_loss: 0.8446 - val_accuracy: 0.8482
Epoch 90/110
 - 2s - loss: 0.1441 - accuracy: 0.9847 - val_loss: 0.9435 - val_accuracy: 0.8569
Epoch 91/110
 - 2s - loss: 0.2184 - accuracy: 0.9580 - val_loss: 0.8277 - val_accuracy: 0.8365
Epoch 92/110
 - 2s - loss: 0.1859 - accuracy: 0.9715 - val_loss: 0.8518 - val_accuracy: 0.8504
Epoch 93/110
 - 2s - loss: 0.1347 - accuracy: 0.9876 - val_loss: 0.7763 - val_accuracy: 0.8540
Epoch 94/110
 - 2s - loss: 0.1195 - accuracy: 0.9927 - val_loss: 0.7630 - val_accuracy: 0.8613
Epoch 95/110
 - 2s - loss: 0.1076 - accuracy: 0.9969 - val_loss: 0.7908 - val_accuracy: 0.8533
Epoch 96/110
 - 2s - loss: 0.1011 - accuracy: 0.9985 - val_loss: 0.7957 - val_accuracy: 0.8584
Epoch 97/110
 - 2s - loss: 0.0978 - accuracy: 0.9993 - val_loss: 0.8337 - val_accuracy: 0.8569
Epoch 98/110
 - 2s - loss: 0.0962 - accuracy: 0.9993 - val_loss: 0.8331 - val_accuracy: 0.8613
Epoch 99/110
 - 2s - loss: 0.0954 - accuracy: 0.9993 - val_loss: 0.8657 - val_accuracy: 0.8562
Epoch 100/110
 - 3s - loss: 0.0941 - accuracy: 0.9993 - val_loss: 0.8605 - val_accuracy: 0.8569
Epoch 101/110
 - 2s - loss: 0.0929 - accuracy: 0.9993 - val_loss: 0.8608 - val_accuracy: 0.8642
Epoch 102/110
 - 3s - loss: 0.0926 - accuracy: 0.9995 - val_loss: 0.8805 - val_accuracy: 0.8591
Epoch 103/110
 - 2s - loss: 0.0925 - accuracy: 0.9993 - val_loss: 0.8773 - val_accuracy: 0.8635
Epoch 104/110
 - 3s - loss: 0.0906 - accuracy: 0.9993 - val_loss: 0.8963 - val_accuracy: 0.8555
Epoch 105/110
 - 2s - loss: 0.0909 - accuracy: 0.9993 - val_loss: 0.8783 - val_accuracy: 0.8635
Epoch 106/110
 - 2s - loss: 0.0889 - accuracy: 0.9993 - val_loss: 0.8946 - val_accuracy: 0.8584
Epoch 107/110
 - 2s - loss: 0.0893 - accuracy: 0.9987 - val_loss: 0.8876 - val_accuracy: 0.8620
Epoch 108/110
 - 2s - loss: 0.0971 - accuracy: 0.9958 - val_loss: 0.9344 - val_accuracy: 0.8533
Epoch 109/110
 - 2s - loss: 0.1609 - accuracy: 0.9766 - val_loss: 0.9953 - val_accuracy: 0.8044
Epoch 110/110
 - 2s - loss: 0.2782 - accuracy: 0.9376 - val_loss: 0.8825 - val_accuracy: 0.8212
------------------------------------------------------------------------
Score per fold
------------------------------------------------------------------------
Score for fold 1
Accuracy_Train: 24.01%
Accuracy_Test: 23.89%
Loss_Train: 9.25
Loss_Test: 9.22
------------------------------------------------------------------------
Score for fold 2
Accuracy_Train: 21.44%
Accuracy_Test: 21.38%
Loss_Train: 24.00
Loss_Test: 23.80
------------------------------------------------------------------------
Score for fold 3
Accuracy_Train: 28.43%
Accuracy_Test: 28.15%
Loss_Train: 43.31
Loss_Test: 43.08
------------------------------------------------------------------------
Score for fold 4
Accuracy_Train: 21.17%
Accuracy_Test: 21.73%
Loss_Train: 31.54
Loss_Test: 31.12
------------------------------------------------------------------------
Score for fold 5
Accuracy_Train: 21.13%
Accuracy_Test: 21.67%
Loss_Train: 15.13
Loss_Test: 14.89
------------------------------------------------------------------------
Average scores for all folds:
Average_Accuracy_Train: 23.24%
	-> (+- 2.811112529677233 )
Average_Accuracy_Test: 23.36%
	-> (+- 2.5575844908657914 )
Average_Loss_Train: 24.65
	-> (+- 12.031045384025104 )
Average_Loss_Test: 24.42
	-> (+- 11.96295781637893 )
------------------------------------------------------------------------
