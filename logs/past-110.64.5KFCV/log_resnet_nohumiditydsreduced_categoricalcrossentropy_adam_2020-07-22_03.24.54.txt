Dataset used: ../../datasets/full_dataset_without_humidity_reduced.csv 

   Temperature  Sound  Heartbeat   X1  ...    Y2     Z2  Classification  Feedback
0           32      1         60 -680  ... -7424 -15596             100     Happy
1           32      1         60 -780  ... -7408 -15628             100     Happy
2           -1      1         60   -1  ... -7276 -15612             100     Happy
3           -1     -1         60   -1  ...    -1     -1             100     Happy
4           32      1         60 -860  ... -7340 -15720             100     Happy

[5 rows x 11 columns]

Objservations: 3760
Reshaping:  ((3008, 10), (3008, 4), (752, 10), (752, 4))  -> ((3008, 10, 1), (3008, 4), (752, 10, 1), (752, 4))

Layers:

{'batch_input_shape': (None, 10, 1), 'dtype': 'float32', 'sparse': False, 'name': 'input_13'} 

{'name': 'conv1d_253', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_229', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_229', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_254', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_230', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_230', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_255', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_231', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_109', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_231', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_256', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_232', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_232', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_257', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_233', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_110', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_233', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_258', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_234', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_234', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_259', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_235', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_111', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_235', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_260', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_236', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_236', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_261', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_262', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_237', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_112', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_237', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_263', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_238', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_238', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_264', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_239', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_113', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_239', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_265', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_240', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_240', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_266', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_241', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_114', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_241', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_267', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_242', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_242', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_268', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_269', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_243', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_115', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_243', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_270', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_244', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_244', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_271', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_245', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_116', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_245', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_272', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_246', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_246', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_273', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_247', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_117', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_247', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'average_pooling1d_13', 'trainable': True, 'dtype': 'float32', 'strides': (1,), 'pool_size': (1,), 'padding': 'valid', 'data_format': 'channels_last'} 

{'name': 'flatten_13', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'} 

{'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 5s - loss: 1.1486 - accuracy: 0.6584 - val_loss: 2.1718 - val_accuracy: 0.3289
Epoch 2/110
 - 1s - loss: 0.7922 - accuracy: 0.7727 - val_loss: 1.2631 - val_accuracy: 0.5449
Epoch 3/110
 - 1s - loss: 0.7019 - accuracy: 0.8026 - val_loss: 0.9885 - val_accuracy: 0.7043
Epoch 4/110
 - 1s - loss: 0.6536 - accuracy: 0.8113 - val_loss: 0.8308 - val_accuracy: 0.7674
Epoch 5/110
 - 1s - loss: 0.6288 - accuracy: 0.8180 - val_loss: 0.7377 - val_accuracy: 0.8140
Epoch 6/110
 - 1s - loss: 0.6091 - accuracy: 0.8267 - val_loss: 0.7170 - val_accuracy: 0.7824
Epoch 7/110
 - 1s - loss: 0.5844 - accuracy: 0.8313 - val_loss: 0.6983 - val_accuracy: 0.8156
Epoch 8/110
 - 1s - loss: 0.5669 - accuracy: 0.8429 - val_loss: 0.7133 - val_accuracy: 0.8123
Epoch 9/110
 - 1s - loss: 0.5628 - accuracy: 0.8362 - val_loss: 0.6949 - val_accuracy: 0.8106
Epoch 10/110
 - 1s - loss: 0.5511 - accuracy: 0.8458 - val_loss: 0.6947 - val_accuracy: 0.8040
Epoch 11/110
 - 1s - loss: 0.5422 - accuracy: 0.8454 - val_loss: 0.7308 - val_accuracy: 0.7990
Epoch 12/110
 - 1s - loss: 0.5398 - accuracy: 0.8412 - val_loss: 0.7282 - val_accuracy: 0.8007
Epoch 13/110
 - 1s - loss: 0.5218 - accuracy: 0.8566 - val_loss: 0.7246 - val_accuracy: 0.8090
Epoch 14/110
 - 1s - loss: 0.5021 - accuracy: 0.8612 - val_loss: 0.7429 - val_accuracy: 0.7907
Epoch 15/110
 - 1s - loss: 0.4866 - accuracy: 0.8724 - val_loss: 0.7957 - val_accuracy: 0.7724
Epoch 16/110
 - 1s - loss: 0.4901 - accuracy: 0.8608 - val_loss: 0.8019 - val_accuracy: 0.7874
Epoch 17/110
 - 1s - loss: 0.4934 - accuracy: 0.8695 - val_loss: 0.8527 - val_accuracy: 0.7525
Epoch 18/110
 - 1s - loss: 0.4828 - accuracy: 0.8724 - val_loss: 0.7925 - val_accuracy: 0.7890
Epoch 19/110
 - 1s - loss: 0.4758 - accuracy: 0.8691 - val_loss: 0.7756 - val_accuracy: 0.7973
Epoch 20/110
 - 1s - loss: 0.4876 - accuracy: 0.8579 - val_loss: 0.7713 - val_accuracy: 0.7973
Epoch 21/110
 - 1s - loss: 0.4692 - accuracy: 0.8732 - val_loss: 0.8082 - val_accuracy: 0.7807
Epoch 22/110
 - 1s - loss: 0.4637 - accuracy: 0.8736 - val_loss: 0.7824 - val_accuracy: 0.7940
Epoch 23/110
 - 1s - loss: 0.4709 - accuracy: 0.8699 - val_loss: 0.8415 - val_accuracy: 0.7924
Epoch 24/110
 - 1s - loss: 0.5093 - accuracy: 0.8587 - val_loss: 0.8667 - val_accuracy: 0.7625
Epoch 25/110
 - 1s - loss: 0.4882 - accuracy: 0.8666 - val_loss: 0.7813 - val_accuracy: 0.8123
Epoch 26/110
 - 1s - loss: 0.4807 - accuracy: 0.8670 - val_loss: 0.7703 - val_accuracy: 0.7990
Epoch 27/110
 - 1s - loss: 0.4801 - accuracy: 0.8741 - val_loss: 0.7148 - val_accuracy: 0.8189
Epoch 28/110
 - 1s - loss: 0.4655 - accuracy: 0.8770 - val_loss: 0.7464 - val_accuracy: 0.7924
Epoch 29/110
 - 1s - loss: 0.4572 - accuracy: 0.8803 - val_loss: 0.7552 - val_accuracy: 0.7973
Epoch 30/110
 - 1s - loss: 0.4353 - accuracy: 0.8840 - val_loss: 0.7704 - val_accuracy: 0.7990
Epoch 31/110
 - 1s - loss: 0.4414 - accuracy: 0.8853 - val_loss: 0.7765 - val_accuracy: 0.7907
Epoch 32/110
 - 1s - loss: 0.4192 - accuracy: 0.8919 - val_loss: 0.8156 - val_accuracy: 0.7841
Epoch 33/110
 - 1s - loss: 0.4254 - accuracy: 0.8911 - val_loss: 0.8583 - val_accuracy: 0.7608
Epoch 34/110
 - 1s - loss: 0.4495 - accuracy: 0.8869 - val_loss: 0.8098 - val_accuracy: 0.7757
Epoch 35/110
 - 1s - loss: 0.4253 - accuracy: 0.8915 - val_loss: 0.8301 - val_accuracy: 0.7907
Epoch 36/110
 - 1s - loss: 0.4260 - accuracy: 0.8865 - val_loss: 0.7517 - val_accuracy: 0.8140
Epoch 37/110
 - 1s - loss: 0.4350 - accuracy: 0.8878 - val_loss: 0.7651 - val_accuracy: 0.8090
Epoch 38/110
 - 1s - loss: 0.4154 - accuracy: 0.8969 - val_loss: 0.8851 - val_accuracy: 0.7691
Epoch 39/110
 - 1s - loss: 0.4430 - accuracy: 0.8807 - val_loss: 0.7836 - val_accuracy: 0.8156
Epoch 40/110
 - 1s - loss: 0.3961 - accuracy: 0.9032 - val_loss: 0.8060 - val_accuracy: 0.8007
Epoch 41/110
 - 1s - loss: 0.3762 - accuracy: 0.9156 - val_loss: 0.7610 - val_accuracy: 0.7990
Epoch 42/110
 - 1s - loss: 0.3755 - accuracy: 0.9077 - val_loss: 0.7716 - val_accuracy: 0.8256
Epoch 43/110
 - 1s - loss: 0.3661 - accuracy: 0.9135 - val_loss: 0.7629 - val_accuracy: 0.8007
Epoch 44/110
 - 1s - loss: 0.3772 - accuracy: 0.9052 - val_loss: 0.7195 - val_accuracy: 0.8339
Epoch 45/110
 - 1s - loss: 0.3772 - accuracy: 0.9048 - val_loss: 0.7790 - val_accuracy: 0.8007
Epoch 46/110
 - 1s - loss: 0.3672 - accuracy: 0.9090 - val_loss: 0.8022 - val_accuracy: 0.8007
Epoch 47/110
 - 1s - loss: 0.3740 - accuracy: 0.9098 - val_loss: 0.8266 - val_accuracy: 0.7940
Epoch 48/110
 - 1s - loss: 0.3984 - accuracy: 0.8998 - val_loss: 0.8070 - val_accuracy: 0.8090
Epoch 49/110
 - 1s - loss: 0.3841 - accuracy: 0.9094 - val_loss: 0.9288 - val_accuracy: 0.7924
Epoch 50/110
 - 1s - loss: 0.3771 - accuracy: 0.9065 - val_loss: 0.8016 - val_accuracy: 0.7890
Epoch 51/110
 - 1s - loss: 0.3541 - accuracy: 0.9127 - val_loss: 0.7823 - val_accuracy: 0.8056
Epoch 52/110
 - 1s - loss: 0.3504 - accuracy: 0.9210 - val_loss: 0.8381 - val_accuracy: 0.8007
Epoch 53/110
 - 1s - loss: 0.3457 - accuracy: 0.9202 - val_loss: 0.9545 - val_accuracy: 0.7874
Epoch 54/110
 - 1s - loss: 0.3592 - accuracy: 0.9106 - val_loss: 0.8016 - val_accuracy: 0.8156
Epoch 55/110
 - 1s - loss: 0.3174 - accuracy: 0.9347 - val_loss: 0.7994 - val_accuracy: 0.8372
Epoch 56/110
 - 1s - loss: 0.3237 - accuracy: 0.9335 - val_loss: 0.9316 - val_accuracy: 0.7957
Epoch 57/110
 - 1s - loss: 0.3692 - accuracy: 0.9152 - val_loss: 0.9243 - val_accuracy: 0.7990
Epoch 58/110
 - 1s - loss: 0.3101 - accuracy: 0.9339 - val_loss: 0.8526 - val_accuracy: 0.7841
Epoch 59/110
 - 1s - loss: 0.3299 - accuracy: 0.9318 - val_loss: 0.7976 - val_accuracy: 0.8073
Epoch 60/110
 - 1s - loss: 0.3460 - accuracy: 0.9210 - val_loss: 0.9063 - val_accuracy: 0.8123
Epoch 61/110
 - 1s - loss: 0.3276 - accuracy: 0.9327 - val_loss: 0.9177 - val_accuracy: 0.8073
Epoch 62/110
 - 1s - loss: 0.3081 - accuracy: 0.9426 - val_loss: 0.9503 - val_accuracy: 0.7907
Epoch 63/110
 - 1s - loss: 0.2872 - accuracy: 0.9451 - val_loss: 0.8940 - val_accuracy: 0.8007
Epoch 64/110
 - 1s - loss: 0.2971 - accuracy: 0.9401 - val_loss: 0.9686 - val_accuracy: 0.8023
Epoch 65/110
 - 1s - loss: 0.3077 - accuracy: 0.9360 - val_loss: 0.9756 - val_accuracy: 0.7757
Epoch 66/110
 - 1s - loss: 0.3122 - accuracy: 0.9343 - val_loss: 0.9477 - val_accuracy: 0.8040
Epoch 67/110
 - 1s - loss: 0.2940 - accuracy: 0.9510 - val_loss: 0.8493 - val_accuracy: 0.8189
Epoch 68/110
 - 1s - loss: 0.2839 - accuracy: 0.9456 - val_loss: 0.8182 - val_accuracy: 0.8289
Epoch 69/110
 - 1s - loss: 0.2990 - accuracy: 0.9435 - val_loss: 0.8966 - val_accuracy: 0.8173
Epoch 70/110
 - 1s - loss: 0.2985 - accuracy: 0.9443 - val_loss: 0.8908 - val_accuracy: 0.8106
Epoch 71/110
 - 1s - loss: 0.3358 - accuracy: 0.9268 - val_loss: 0.9465 - val_accuracy: 0.8023
Epoch 72/110
 - 1s - loss: 0.3323 - accuracy: 0.9343 - val_loss: 0.9086 - val_accuracy: 0.8056
Epoch 73/110
 - 1s - loss: 0.3291 - accuracy: 0.9289 - val_loss: 0.8486 - val_accuracy: 0.8223
Epoch 74/110
 - 1s - loss: 0.3097 - accuracy: 0.9393 - val_loss: 0.8768 - val_accuracy: 0.8140
Epoch 75/110
 - 1s - loss: 0.3119 - accuracy: 0.9364 - val_loss: 0.8445 - val_accuracy: 0.8173
Epoch 76/110
 - 1s - loss: 0.2815 - accuracy: 0.9505 - val_loss: 0.8483 - val_accuracy: 0.8239
Epoch 77/110
 - 1s - loss: 0.2828 - accuracy: 0.9493 - val_loss: 0.9339 - val_accuracy: 0.8173
Epoch 78/110
 - 1s - loss: 0.3142 - accuracy: 0.9364 - val_loss: 0.8877 - val_accuracy: 0.8023
Epoch 79/110
 - 1s - loss: 0.2911 - accuracy: 0.9439 - val_loss: 0.8636 - val_accuracy: 0.8123
Epoch 80/110
 - 1s - loss: 0.2602 - accuracy: 0.9564 - val_loss: 0.9324 - val_accuracy: 0.7940
Epoch 81/110
 - 1s - loss: 0.2990 - accuracy: 0.9472 - val_loss: 0.9703 - val_accuracy: 0.8040
Epoch 82/110
 - 1s - loss: 0.3035 - accuracy: 0.9460 - val_loss: 0.8747 - val_accuracy: 0.8372
Epoch 83/110
 - 1s - loss: 0.3199 - accuracy: 0.9360 - val_loss: 0.9570 - val_accuracy: 0.8389
Epoch 84/110
 - 1s - loss: 0.2855 - accuracy: 0.9439 - val_loss: 0.9140 - val_accuracy: 0.7824
Epoch 85/110
 - 1s - loss: 0.2754 - accuracy: 0.9489 - val_loss: 0.9512 - val_accuracy: 0.8056
Epoch 86/110
 - 1s - loss: 0.2787 - accuracy: 0.9543 - val_loss: 0.9328 - val_accuracy: 0.8090
Epoch 87/110
 - 1s - loss: 0.2997 - accuracy: 0.9476 - val_loss: 0.9428 - val_accuracy: 0.7857
Epoch 88/110
 - 1s - loss: 0.2832 - accuracy: 0.9456 - val_loss: 0.8711 - val_accuracy: 0.8306
Epoch 89/110
 - 1s - loss: 0.2855 - accuracy: 0.9489 - val_loss: 0.8630 - val_accuracy: 0.8355
Epoch 90/110
 - 1s - loss: 0.2711 - accuracy: 0.9518 - val_loss: 0.9168 - val_accuracy: 0.8140
Epoch 91/110
 - 1s - loss: 0.2726 - accuracy: 0.9539 - val_loss: 0.8742 - val_accuracy: 0.8156
Epoch 92/110
 - 1s - loss: 0.2762 - accuracy: 0.9526 - val_loss: 0.8392 - val_accuracy: 0.8322
Epoch 93/110
 - 1s - loss: 0.2820 - accuracy: 0.9485 - val_loss: 0.8757 - val_accuracy: 0.8405
Epoch 94/110
 - 1s - loss: 0.2945 - accuracy: 0.9456 - val_loss: 0.9435 - val_accuracy: 0.8156
Epoch 95/110
 - 1s - loss: 0.2932 - accuracy: 0.9460 - val_loss: 0.9235 - val_accuracy: 0.8090
Epoch 96/110
 - 1s - loss: 0.2792 - accuracy: 0.9489 - val_loss: 1.0175 - val_accuracy: 0.7940
Epoch 97/110
 - 1s - loss: 0.2813 - accuracy: 0.9464 - val_loss: 1.0576 - val_accuracy: 0.8007
Epoch 98/110
 - 1s - loss: 0.2723 - accuracy: 0.9514 - val_loss: 0.9558 - val_accuracy: 0.8372
Epoch 99/110
 - 1s - loss: 0.2998 - accuracy: 0.9439 - val_loss: 0.9107 - val_accuracy: 0.8322
Epoch 100/110
 - 1s - loss: 0.3317 - accuracy: 0.9352 - val_loss: 0.9560 - val_accuracy: 0.8106
Epoch 101/110
 - 1s - loss: 0.3094 - accuracy: 0.9352 - val_loss: 0.9181 - val_accuracy: 0.7757
Epoch 102/110
 - 1s - loss: 0.2831 - accuracy: 0.9431 - val_loss: 0.9248 - val_accuracy: 0.7973
Epoch 103/110
 - 1s - loss: 0.2790 - accuracy: 0.9526 - val_loss: 1.0217 - val_accuracy: 0.8007
Epoch 104/110
 - 1s - loss: 0.2971 - accuracy: 0.9464 - val_loss: 0.9788 - val_accuracy: 0.7973
Epoch 105/110
 - 1s - loss: 0.2643 - accuracy: 0.9559 - val_loss: 0.8674 - val_accuracy: 0.8289
Epoch 106/110
 - 1s - loss: 0.2525 - accuracy: 0.9593 - val_loss: 0.8313 - val_accuracy: 0.8355
Epoch 107/110
 - 1s - loss: 0.2539 - accuracy: 0.9572 - val_loss: 0.9258 - val_accuracy: 0.8439
Epoch 108/110
 - 1s - loss: 0.2398 - accuracy: 0.9647 - val_loss: 0.9888 - val_accuracy: 0.7874
Epoch 109/110
 - 1s - loss: 0.2573 - accuracy: 0.9618 - val_loss: 1.0010 - val_accuracy: 0.8040
Epoch 110/110
 - 1s - loss: 0.2689 - accuracy: 0.9510 - val_loss: 0.8845 - val_accuracy: 0.8405

Number of filters: 16 , Kernel Size: 3 , Strides: 1 Batch Normalization: True , Conv_First: True , Depth Value: 20

Fit: epochs= 110 , batch_size= 64 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "model_13"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 10, 1)        0                                            
__________________________________________________________________________________________________
conv1d_253 (Conv1D)             (None, 10, 16)       64          input_13[0][0]                   
__________________________________________________________________________________________________
batch_normalization_229 (BatchN (None, 10, 16)       64          conv1d_253[0][0]                 
__________________________________________________________________________________________________
activation_229 (Activation)     (None, 10, 16)       0           batch_normalization_229[0][0]    
__________________________________________________________________________________________________
conv1d_254 (Conv1D)             (None, 10, 16)       784         activation_229[0][0]             
__________________________________________________________________________________________________
batch_normalization_230 (BatchN (None, 10, 16)       64          conv1d_254[0][0]                 
__________________________________________________________________________________________________
activation_230 (Activation)     (None, 10, 16)       0           batch_normalization_230[0][0]    
__________________________________________________________________________________________________
conv1d_255 (Conv1D)             (None, 10, 16)       784         activation_230[0][0]             
__________________________________________________________________________________________________
batch_normalization_231 (BatchN (None, 10, 16)       64          conv1d_255[0][0]                 
__________________________________________________________________________________________________
add_109 (Add)                   (None, 10, 16)       0           activation_229[0][0]             
                                                                 batch_normalization_231[0][0]    
__________________________________________________________________________________________________
activation_231 (Activation)     (None, 10, 16)       0           add_109[0][0]                    
__________________________________________________________________________________________________
conv1d_256 (Conv1D)             (None, 10, 16)       784         activation_231[0][0]             
__________________________________________________________________________________________________
batch_normalization_232 (BatchN (None, 10, 16)       64          conv1d_256[0][0]                 
__________________________________________________________________________________________________
activation_232 (Activation)     (None, 10, 16)       0           batch_normalization_232[0][0]    
__________________________________________________________________________________________________
conv1d_257 (Conv1D)             (None, 10, 16)       784         activation_232[0][0]             
__________________________________________________________________________________________________
batch_normalization_233 (BatchN (None, 10, 16)       64          conv1d_257[0][0]                 
__________________________________________________________________________________________________
add_110 (Add)                   (None, 10, 16)       0           activation_231[0][0]             
                                                                 batch_normalization_233[0][0]    
__________________________________________________________________________________________________
activation_233 (Activation)     (None, 10, 16)       0           add_110[0][0]                    
__________________________________________________________________________________________________
conv1d_258 (Conv1D)             (None, 10, 16)       784         activation_233[0][0]             
__________________________________________________________________________________________________
batch_normalization_234 (BatchN (None, 10, 16)       64          conv1d_258[0][0]                 
__________________________________________________________________________________________________
activation_234 (Activation)     (None, 10, 16)       0           batch_normalization_234[0][0]    
__________________________________________________________________________________________________
conv1d_259 (Conv1D)             (None, 10, 16)       784         activation_234[0][0]             
__________________________________________________________________________________________________
batch_normalization_235 (BatchN (None, 10, 16)       64          conv1d_259[0][0]                 
__________________________________________________________________________________________________
add_111 (Add)                   (None, 10, 16)       0           activation_233[0][0]             
                                                                 batch_normalization_235[0][0]    
__________________________________________________________________________________________________
activation_235 (Activation)     (None, 10, 16)       0           add_111[0][0]                    
__________________________________________________________________________________________________
conv1d_260 (Conv1D)             (None, 5, 32)        1568        activation_235[0][0]             
__________________________________________________________________________________________________
batch_normalization_236 (BatchN (None, 5, 32)        128         conv1d_260[0][0]                 
__________________________________________________________________________________________________
activation_236 (Activation)     (None, 5, 32)        0           batch_normalization_236[0][0]    
__________________________________________________________________________________________________
conv1d_261 (Conv1D)             (None, 5, 32)        3104        activation_236[0][0]             
__________________________________________________________________________________________________
conv1d_262 (Conv1D)             (None, 5, 32)        544         activation_235[0][0]             
__________________________________________________________________________________________________
batch_normalization_237 (BatchN (None, 5, 32)        128         conv1d_261[0][0]                 
__________________________________________________________________________________________________
add_112 (Add)                   (None, 5, 32)        0           conv1d_262[0][0]                 
                                                                 batch_normalization_237[0][0]    
__________________________________________________________________________________________________
activation_237 (Activation)     (None, 5, 32)        0           add_112[0][0]                    
__________________________________________________________________________________________________
conv1d_263 (Conv1D)             (None, 5, 32)        3104        activation_237[0][0]             
__________________________________________________________________________________________________
batch_normalization_238 (BatchN (None, 5, 32)        128         conv1d_263[0][0]                 
__________________________________________________________________________________________________
activation_238 (Activation)     (None, 5, 32)        0           batch_normalization_238[0][0]    
__________________________________________________________________________________________________
conv1d_264 (Conv1D)             (None, 5, 32)        3104        activation_238[0][0]             
__________________________________________________________________________________________________
batch_normalization_239 (BatchN (None, 5, 32)        128         conv1d_264[0][0]                 
__________________________________________________________________________________________________
add_113 (Add)                   (None, 5, 32)        0           activation_237[0][0]             
                                                                 batch_normalization_239[0][0]    
__________________________________________________________________________________________________
activation_239 (Activation)     (None, 5, 32)        0           add_113[0][0]                    
__________________________________________________________________________________________________
conv1d_265 (Conv1D)             (None, 5, 32)        3104        activation_239[0][0]             
__________________________________________________________________________________________________
batch_normalization_240 (BatchN (None, 5, 32)        128         conv1d_265[0][0]                 
__________________________________________________________________________________________________
activation_240 (Activation)     (None, 5, 32)        0           batch_normalization_240[0][0]    
__________________________________________________________________________________________________
conv1d_266 (Conv1D)             (None, 5, 32)        3104        activation_240[0][0]             
__________________________________________________________________________________________________
batch_normalization_241 (BatchN (None, 5, 32)        128         conv1d_266[0][0]                 
__________________________________________________________________________________________________
add_114 (Add)                   (None, 5, 32)        0           activation_239[0][0]             
                                                                 batch_normalization_241[0][0]    
__________________________________________________________________________________________________
activation_241 (Activation)     (None, 5, 32)        0           add_114[0][0]                    
__________________________________________________________________________________________________
conv1d_267 (Conv1D)             (None, 3, 64)        6208        activation_241[0][0]             
__________________________________________________________________________________________________
batch_normalization_242 (BatchN (None, 3, 64)        256         conv1d_267[0][0]                 
__________________________________________________________________________________________________
activation_242 (Activation)     (None, 3, 64)        0           batch_normalization_242[0][0]    
__________________________________________________________________________________________________
conv1d_268 (Conv1D)             (None, 3, 64)        12352       activation_242[0][0]             
__________________________________________________________________________________________________
conv1d_269 (Conv1D)             (None, 3, 64)        2112        activation_241[0][0]             
__________________________________________________________________________________________________
batch_normalization_243 (BatchN (None, 3, 64)        256         conv1d_268[0][0]                 
__________________________________________________________________________________________________
add_115 (Add)                   (None, 3, 64)        0           conv1d_269[0][0]                 
                                                                 batch_normalization_243[0][0]    
__________________________________________________________________________________________________
activation_243 (Activation)     (None, 3, 64)        0           add_115[0][0]                    
__________________________________________________________________________________________________
conv1d_270 (Conv1D)             (None, 3, 64)        12352       activation_243[0][0]             
__________________________________________________________________________________________________
batch_normalization_244 (BatchN (None, 3, 64)        256         conv1d_270[0][0]                 
__________________________________________________________________________________________________
activation_244 (Activation)     (None, 3, 64)        0           batch_normalization_244[0][0]    
__________________________________________________________________________________________________
conv1d_271 (Conv1D)             (None, 3, 64)        12352       activation_244[0][0]             
__________________________________________________________________________________________________
batch_normalization_245 (BatchN (None, 3, 64)        256         conv1d_271[0][0]                 
__________________________________________________________________________________________________
add_116 (Add)                   (None, 3, 64)        0           activation_243[0][0]             
                                                                 batch_normalization_245[0][0]    
__________________________________________________________________________________________________
activation_245 (Activation)     (None, 3, 64)        0           add_116[0][0]                    
__________________________________________________________________________________________________
conv1d_272 (Conv1D)             (None, 3, 64)        12352       activation_245[0][0]             
__________________________________________________________________________________________________
batch_normalization_246 (BatchN (None, 3, 64)        256         conv1d_272[0][0]                 
__________________________________________________________________________________________________
activation_246 (Activation)     (None, 3, 64)        0           batch_normalization_246[0][0]    
__________________________________________________________________________________________________
conv1d_273 (Conv1D)             (None, 3, 64)        12352       activation_246[0][0]             
__________________________________________________________________________________________________
batch_normalization_247 (BatchN (None, 3, 64)        256         conv1d_273[0][0]                 
__________________________________________________________________________________________________
add_117 (Add)                   (None, 3, 64)        0           activation_245[0][0]             
                                                                 batch_normalization_247[0][0]    
__________________________________________________________________________________________________
activation_247 (Activation)     (None, 3, 64)        0           add_117[0][0]                    
__________________________________________________________________________________________________
average_pooling1d_13 (AveragePo (None, 3, 64)        0           activation_247[0][0]             
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 192)          0           average_pooling1d_13[0][0]       
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 4)            772         flatten_13[0][0]                 
==================================================================================================
Total params: 96,004
Trainable params: 94,628
Non-trainable params: 1,376
__________________________________________________________________________________________________
None

Accuracy Train: 86.67%
Accuracy Test: 80.59%
Loss Train: 0.65
Loss Test: 1.13
Numero dati esaminati: 752
True Positive 606
False Positive 146


------------------------------------------------------------------------
K-fold Cross Validation
------------------------------------------------------------------------
Training for fold 1 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 5s - loss: 1.5275 - accuracy: 0.6268 - val_loss: 5.8701 - val_accuracy: 0.2724
Epoch 2/110
 - 1s - loss: 0.7927 - accuracy: 0.7814 - val_loss: 2.3064 - val_accuracy: 0.3771
Epoch 3/110
 - 1s - loss: 0.6806 - accuracy: 0.8022 - val_loss: 1.3680 - val_accuracy: 0.5116
Epoch 4/110
 - 1s - loss: 0.6479 - accuracy: 0.8146 - val_loss: 1.1589 - val_accuracy: 0.5598
Epoch 5/110
 - 1s - loss: 0.6103 - accuracy: 0.8267 - val_loss: 1.0210 - val_accuracy: 0.6678
Epoch 6/110
 - 1s - loss: 0.5718 - accuracy: 0.8421 - val_loss: 0.9373 - val_accuracy: 0.7359
Epoch 7/110
 - 1s - loss: 0.5460 - accuracy: 0.8425 - val_loss: 0.8400 - val_accuracy: 0.7608
Epoch 8/110
 - 1s - loss: 0.5494 - accuracy: 0.8450 - val_loss: 0.8327 - val_accuracy: 0.7658
Epoch 9/110
 - 1s - loss: 0.5710 - accuracy: 0.8379 - val_loss: 0.7954 - val_accuracy: 0.7608
Epoch 10/110
 - 1s - loss: 0.5665 - accuracy: 0.8392 - val_loss: 0.8324 - val_accuracy: 0.7625
Epoch 11/110
 - 1s - loss: 0.5739 - accuracy: 0.8358 - val_loss: 0.7549 - val_accuracy: 0.7824
Epoch 12/110
 - 1s - loss: 0.5357 - accuracy: 0.8541 - val_loss: 0.7061 - val_accuracy: 0.7973
Epoch 13/110
 - 1s - loss: 0.5104 - accuracy: 0.8608 - val_loss: 0.7638 - val_accuracy: 0.7940
Epoch 14/110
 - 1s - loss: 0.5049 - accuracy: 0.8666 - val_loss: 0.7773 - val_accuracy: 0.7907
Epoch 15/110
 - 1s - loss: 0.4793 - accuracy: 0.8653 - val_loss: 0.7686 - val_accuracy: 0.7990
Epoch 16/110
 - 1s - loss: 0.4679 - accuracy: 0.8761 - val_loss: 0.7832 - val_accuracy: 0.7741
Epoch 17/110
 - 1s - loss: 0.4552 - accuracy: 0.8803 - val_loss: 0.7861 - val_accuracy: 0.7591
Epoch 18/110
 - 1s - loss: 0.4673 - accuracy: 0.8778 - val_loss: 0.8283 - val_accuracy: 0.7492
Epoch 19/110
 - 1s - loss: 0.4508 - accuracy: 0.8869 - val_loss: 0.7581 - val_accuracy: 0.8007
Epoch 20/110
 - 1s - loss: 0.4568 - accuracy: 0.8803 - val_loss: 0.8040 - val_accuracy: 0.7907
Epoch 21/110
 - 1s - loss: 0.4375 - accuracy: 0.8820 - val_loss: 0.8245 - val_accuracy: 0.7890
Epoch 22/110
 - 1s - loss: 0.4312 - accuracy: 0.8832 - val_loss: 0.8362 - val_accuracy: 0.7874
Epoch 23/110
 - 1s - loss: 0.4381 - accuracy: 0.8894 - val_loss: 0.8030 - val_accuracy: 0.7957
Epoch 24/110
 - 1s - loss: 0.4249 - accuracy: 0.8899 - val_loss: 0.8108 - val_accuracy: 0.8073
Epoch 25/110
 - 1s - loss: 0.4203 - accuracy: 0.8940 - val_loss: 0.8319 - val_accuracy: 0.7724
Epoch 26/110
 - 1s - loss: 0.4056 - accuracy: 0.9015 - val_loss: 0.8755 - val_accuracy: 0.7824
Epoch 27/110
 - 1s - loss: 0.3958 - accuracy: 0.9036 - val_loss: 0.8061 - val_accuracy: 0.8073
Epoch 28/110
 - 1s - loss: 0.3886 - accuracy: 0.9119 - val_loss: 0.8217 - val_accuracy: 0.7658
Epoch 29/110
 - 1s - loss: 0.3873 - accuracy: 0.9065 - val_loss: 0.8350 - val_accuracy: 0.7791
Epoch 30/110
 - 1s - loss: 0.3834 - accuracy: 0.9086 - val_loss: 0.8575 - val_accuracy: 0.7807
Epoch 31/110
 - 1s - loss: 0.3760 - accuracy: 0.9119 - val_loss: 0.8926 - val_accuracy: 0.7924
Epoch 32/110
 - 1s - loss: 0.3651 - accuracy: 0.9131 - val_loss: 0.8467 - val_accuracy: 0.7724
Epoch 33/110
 - 1s - loss: 0.3897 - accuracy: 0.9061 - val_loss: 0.8337 - val_accuracy: 0.7907
Epoch 34/110
 - 1s - loss: 0.3542 - accuracy: 0.9210 - val_loss: 0.8622 - val_accuracy: 0.8023
Epoch 35/110
 - 1s - loss: 0.3658 - accuracy: 0.9148 - val_loss: 0.8617 - val_accuracy: 0.7757
Epoch 36/110
 - 1s - loss: 0.3741 - accuracy: 0.9098 - val_loss: 0.9802 - val_accuracy: 0.7608
Epoch 37/110
 - 1s - loss: 0.4003 - accuracy: 0.9090 - val_loss: 0.9386 - val_accuracy: 0.7674
Epoch 38/110
 - 1s - loss: 0.3879 - accuracy: 0.9081 - val_loss: 0.9032 - val_accuracy: 0.7741
Epoch 39/110
 - 1s - loss: 0.3679 - accuracy: 0.9223 - val_loss: 0.8454 - val_accuracy: 0.7907
Epoch 40/110
 - 1s - loss: 0.3755 - accuracy: 0.9148 - val_loss: 1.0225 - val_accuracy: 0.7757
Epoch 41/110
 - 1s - loss: 0.3401 - accuracy: 0.9298 - val_loss: 0.8928 - val_accuracy: 0.7674
Epoch 42/110
 - 1s - loss: 0.3531 - accuracy: 0.9152 - val_loss: 0.9119 - val_accuracy: 0.7824
Epoch 43/110
 - 1s - loss: 0.3599 - accuracy: 0.9177 - val_loss: 0.9246 - val_accuracy: 0.7857
Epoch 44/110
 - 1s - loss: 0.3538 - accuracy: 0.9231 - val_loss: 0.9249 - val_accuracy: 0.7857
Epoch 45/110
 - 1s - loss: 0.3337 - accuracy: 0.9235 - val_loss: 0.8728 - val_accuracy: 0.7841
Epoch 46/110
 - 1s - loss: 0.3218 - accuracy: 0.9331 - val_loss: 0.8999 - val_accuracy: 0.8040
Epoch 47/110
 - 1s - loss: 0.3355 - accuracy: 0.9302 - val_loss: 0.9048 - val_accuracy: 0.8056
Epoch 48/110
 - 1s - loss: 0.3522 - accuracy: 0.9190 - val_loss: 0.9914 - val_accuracy: 0.7924
Epoch 49/110
 - 1s - loss: 0.3642 - accuracy: 0.9173 - val_loss: 0.8693 - val_accuracy: 0.8223
Epoch 50/110
 - 1s - loss: 0.3791 - accuracy: 0.9127 - val_loss: 0.8965 - val_accuracy: 0.8073
Epoch 51/110
 - 1s - loss: 0.3609 - accuracy: 0.9177 - val_loss: 0.8604 - val_accuracy: 0.8289
Epoch 52/110
 - 1s - loss: 0.3320 - accuracy: 0.9298 - val_loss: 0.8756 - val_accuracy: 0.8073
Epoch 53/110
 - 1s - loss: 0.3431 - accuracy: 0.9281 - val_loss: 0.8536 - val_accuracy: 0.8123
Epoch 54/110
 - 1s - loss: 0.2944 - accuracy: 0.9480 - val_loss: 0.8398 - val_accuracy: 0.8140
Epoch 55/110
 - 1s - loss: 0.2791 - accuracy: 0.9547 - val_loss: 0.8891 - val_accuracy: 0.8206
Epoch 56/110
 - 1s - loss: 0.3069 - accuracy: 0.9372 - val_loss: 0.9417 - val_accuracy: 0.8173
Epoch 57/110
 - 1s - loss: 0.3131 - accuracy: 0.9443 - val_loss: 0.8817 - val_accuracy: 0.8156
Epoch 58/110
 - 1s - loss: 0.3035 - accuracy: 0.9418 - val_loss: 0.9058 - val_accuracy: 0.8272
Epoch 59/110
 - 1s - loss: 0.3127 - accuracy: 0.9422 - val_loss: 0.8579 - val_accuracy: 0.8306
Epoch 60/110
 - 1s - loss: 0.3398 - accuracy: 0.9343 - val_loss: 0.9430 - val_accuracy: 0.8140
Epoch 61/110
 - 1s - loss: 0.3352 - accuracy: 0.9202 - val_loss: 1.0067 - val_accuracy: 0.7741
Epoch 62/110
 - 1s - loss: 0.3209 - accuracy: 0.9393 - val_loss: 1.0034 - val_accuracy: 0.8007
Epoch 63/110
 - 1s - loss: 0.3188 - accuracy: 0.9381 - val_loss: 0.9478 - val_accuracy: 0.8223
Epoch 64/110
 - 1s - loss: 0.3078 - accuracy: 0.9439 - val_loss: 1.0823 - val_accuracy: 0.7874
Epoch 65/110
 - 1s - loss: 0.3285 - accuracy: 0.9372 - val_loss: 1.0811 - val_accuracy: 0.7824
Epoch 66/110
 - 1s - loss: 0.3157 - accuracy: 0.9360 - val_loss: 1.0206 - val_accuracy: 0.7990
Epoch 67/110
 - 1s - loss: 0.2924 - accuracy: 0.9480 - val_loss: 0.9952 - val_accuracy: 0.7940
Epoch 68/110
 - 1s - loss: 0.2798 - accuracy: 0.9501 - val_loss: 0.9187 - val_accuracy: 0.8223
Epoch 69/110
 - 1s - loss: 0.2700 - accuracy: 0.9564 - val_loss: 1.0744 - val_accuracy: 0.7907
Epoch 70/110
 - 1s - loss: 0.2854 - accuracy: 0.9480 - val_loss: 1.0411 - val_accuracy: 0.8073
Epoch 71/110
 - 1s - loss: 0.2963 - accuracy: 0.9435 - val_loss: 1.0123 - val_accuracy: 0.7691
Epoch 72/110
 - 1s - loss: 0.3090 - accuracy: 0.9422 - val_loss: 0.9395 - val_accuracy: 0.8007
Epoch 73/110
 - 1s - loss: 0.2887 - accuracy: 0.9501 - val_loss: 1.0006 - val_accuracy: 0.7957
Epoch 74/110
 - 1s - loss: 0.2850 - accuracy: 0.9522 - val_loss: 0.9942 - val_accuracy: 0.8140
Epoch 75/110
 - 1s - loss: 0.2957 - accuracy: 0.9476 - val_loss: 1.0535 - val_accuracy: 0.8007
Epoch 76/110
 - 1s - loss: 0.3213 - accuracy: 0.9418 - val_loss: 0.9246 - val_accuracy: 0.8090
Epoch 77/110
 - 1s - loss: 0.3092 - accuracy: 0.9426 - val_loss: 1.0528 - val_accuracy: 0.7824
Epoch 78/110
 - 1s - loss: 0.2919 - accuracy: 0.9456 - val_loss: 1.0127 - val_accuracy: 0.8140
Epoch 79/110
 - 1s - loss: 0.3052 - accuracy: 0.9468 - val_loss: 1.0036 - val_accuracy: 0.7857
Epoch 80/110
 - 1s - loss: 0.3048 - accuracy: 0.9418 - val_loss: 1.0213 - val_accuracy: 0.7841
Epoch 81/110
 - 1s - loss: 0.3280 - accuracy: 0.9381 - val_loss: 1.1497 - val_accuracy: 0.7409
Epoch 82/110
 - 1s - loss: 0.3146 - accuracy: 0.9418 - val_loss: 1.0510 - val_accuracy: 0.7907
Epoch 83/110
 - 1s - loss: 0.2920 - accuracy: 0.9468 - val_loss: 0.9729 - val_accuracy: 0.8189
Epoch 84/110
 - 1s - loss: 0.2778 - accuracy: 0.9485 - val_loss: 1.1147 - val_accuracy: 0.7841
Epoch 85/110
 - 1s - loss: 0.2876 - accuracy: 0.9443 - val_loss: 1.0149 - val_accuracy: 0.8239
Epoch 86/110
 - 1s - loss: 0.2978 - accuracy: 0.9472 - val_loss: 1.0260 - val_accuracy: 0.8007
Epoch 87/110
 - 1s - loss: 0.2929 - accuracy: 0.9489 - val_loss: 1.0182 - val_accuracy: 0.8106
Epoch 88/110
 - 1s - loss: 0.2924 - accuracy: 0.9518 - val_loss: 0.9943 - val_accuracy: 0.7841
Epoch 89/110
 - 1s - loss: 0.2566 - accuracy: 0.9589 - val_loss: 1.0159 - val_accuracy: 0.7940
Epoch 90/110
 - 1s - loss: 0.2468 - accuracy: 0.9647 - val_loss: 1.1830 - val_accuracy: 0.7691
Epoch 91/110
 - 1s - loss: 0.2614 - accuracy: 0.9647 - val_loss: 0.9610 - val_accuracy: 0.7957
Epoch 92/110
 - 1s - loss: 0.2420 - accuracy: 0.9634 - val_loss: 0.9702 - val_accuracy: 0.8239
Epoch 93/110
 - 1s - loss: 0.2609 - accuracy: 0.9609 - val_loss: 1.1380 - val_accuracy: 0.7691
Epoch 94/110
 - 1s - loss: 0.2688 - accuracy: 0.9622 - val_loss: 0.9981 - val_accuracy: 0.8123
Epoch 95/110
 - 1s - loss: 0.2702 - accuracy: 0.9589 - val_loss: 1.0716 - val_accuracy: 0.7824
Epoch 96/110
 - 1s - loss: 0.2662 - accuracy: 0.9593 - val_loss: 1.0470 - val_accuracy: 0.8023
Epoch 97/110
 - 1s - loss: 0.2662 - accuracy: 0.9547 - val_loss: 1.0554 - val_accuracy: 0.7957
Epoch 98/110
 - 1s - loss: 0.2674 - accuracy: 0.9601 - val_loss: 1.1050 - val_accuracy: 0.8007
Epoch 99/110
 - 1s - loss: 0.2604 - accuracy: 0.9613 - val_loss: 1.1681 - val_accuracy: 0.8023
Epoch 100/110
 - 1s - loss: 0.2851 - accuracy: 0.9510 - val_loss: 1.0074 - val_accuracy: 0.8272
Epoch 101/110
 - 1s - loss: 0.2820 - accuracy: 0.9497 - val_loss: 1.1666 - val_accuracy: 0.7924
Epoch 102/110
 - 1s - loss: 0.3012 - accuracy: 0.9397 - val_loss: 1.2937 - val_accuracy: 0.7608
Epoch 103/110
 - 1s - loss: 0.2874 - accuracy: 0.9539 - val_loss: 1.1397 - val_accuracy: 0.7857
Epoch 104/110
 - 1s - loss: 0.2687 - accuracy: 0.9547 - val_loss: 1.0609 - val_accuracy: 0.8123
Epoch 105/110
 - 1s - loss: 0.2484 - accuracy: 0.9638 - val_loss: 0.9563 - val_accuracy: 0.8156
Epoch 106/110
 - 1s - loss: 0.2580 - accuracy: 0.9609 - val_loss: 1.1553 - val_accuracy: 0.7708
Epoch 107/110
 - 1s - loss: 0.2587 - accuracy: 0.9618 - val_loss: 1.0548 - val_accuracy: 0.7973
Epoch 108/110
 - 1s - loss: 0.2741 - accuracy: 0.9526 - val_loss: 1.0727 - val_accuracy: 0.8206
Epoch 109/110
 - 1s - loss: 0.2594 - accuracy: 0.9576 - val_loss: 1.1949 - val_accuracy: 0.7924
Epoch 110/110
 - 1s - loss: 0.2273 - accuracy: 0.9684 - val_loss: 1.0633 - val_accuracy: 0.7990
------------------------------------------------------------------------
Training for fold 2 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 5s - loss: 1.3478 - accuracy: 0.6401 - val_loss: 2.6348 - val_accuracy: 0.4452
Epoch 2/110
 - 1s - loss: 0.7657 - accuracy: 0.7718 - val_loss: 1.5984 - val_accuracy: 0.4684
Epoch 3/110
 - 1s - loss: 0.6812 - accuracy: 0.8071 - val_loss: 1.2426 - val_accuracy: 0.5648
Epoch 4/110
 - 1s - loss: 0.6296 - accuracy: 0.8196 - val_loss: 0.9262 - val_accuracy: 0.7193
Epoch 5/110
 - 1s - loss: 0.5993 - accuracy: 0.8383 - val_loss: 0.8245 - val_accuracy: 0.7691
Epoch 6/110
 - 1s - loss: 0.5881 - accuracy: 0.8379 - val_loss: 0.7316 - val_accuracy: 0.7940
Epoch 7/110
 - 1s - loss: 0.5820 - accuracy: 0.8362 - val_loss: 0.7585 - val_accuracy: 0.7691
Epoch 8/110
 - 1s - loss: 0.5695 - accuracy: 0.8392 - val_loss: 0.7358 - val_accuracy: 0.7907
Epoch 9/110
 - 1s - loss: 0.5367 - accuracy: 0.8512 - val_loss: 0.7347 - val_accuracy: 0.7924
Epoch 10/110
 - 1s - loss: 0.5056 - accuracy: 0.8653 - val_loss: 0.7159 - val_accuracy: 0.8140
Epoch 11/110
 - 1s - loss: 0.4814 - accuracy: 0.8774 - val_loss: 0.7235 - val_accuracy: 0.7990
Epoch 12/110
 - 1s - loss: 0.4825 - accuracy: 0.8770 - val_loss: 0.7435 - val_accuracy: 0.8106
Epoch 13/110
 - 1s - loss: 0.4894 - accuracy: 0.8687 - val_loss: 0.8064 - val_accuracy: 0.8090
Epoch 14/110
 - 1s - loss: 0.4777 - accuracy: 0.8778 - val_loss: 0.7358 - val_accuracy: 0.8156
Epoch 15/110
 - 1s - loss: 0.4815 - accuracy: 0.8728 - val_loss: 0.7514 - val_accuracy: 0.8056
Epoch 16/110
 - 1s - loss: 0.4764 - accuracy: 0.8670 - val_loss: 0.7541 - val_accuracy: 0.7957
Epoch 17/110
 - 1s - loss: 0.4555 - accuracy: 0.8807 - val_loss: 0.7496 - val_accuracy: 0.7907
Epoch 18/110
 - 1s - loss: 0.4398 - accuracy: 0.8836 - val_loss: 0.7269 - val_accuracy: 0.8056
Epoch 19/110
 - 1s - loss: 0.4334 - accuracy: 0.8894 - val_loss: 0.7062 - val_accuracy: 0.8140
Epoch 20/110
 - 1s - loss: 0.4254 - accuracy: 0.8957 - val_loss: 0.7568 - val_accuracy: 0.8090
Epoch 21/110
 - 1s - loss: 0.4180 - accuracy: 0.8982 - val_loss: 0.8111 - val_accuracy: 0.7791
Epoch 22/110
 - 1s - loss: 0.4452 - accuracy: 0.8865 - val_loss: 0.7502 - val_accuracy: 0.8073
Epoch 23/110
 - 1s - loss: 0.4338 - accuracy: 0.8899 - val_loss: 0.7889 - val_accuracy: 0.7857
Epoch 24/110
 - 1s - loss: 0.4457 - accuracy: 0.8832 - val_loss: 0.8331 - val_accuracy: 0.7708
Epoch 25/110
 - 1s - loss: 0.4272 - accuracy: 0.8878 - val_loss: 0.7691 - val_accuracy: 0.8106
Epoch 26/110
 - 1s - loss: 0.4246 - accuracy: 0.8874 - val_loss: 0.7928 - val_accuracy: 0.7940
Epoch 27/110
 - 1s - loss: 0.4327 - accuracy: 0.8845 - val_loss: 0.7530 - val_accuracy: 0.8007
Epoch 28/110
 - 1s - loss: 0.3915 - accuracy: 0.9011 - val_loss: 0.7721 - val_accuracy: 0.8073
Epoch 29/110
 - 1s - loss: 0.3843 - accuracy: 0.9065 - val_loss: 0.7707 - val_accuracy: 0.7973
Epoch 30/110
 - 1s - loss: 0.3833 - accuracy: 0.9090 - val_loss: 0.8109 - val_accuracy: 0.8106
Epoch 31/110
 - 1s - loss: 0.3657 - accuracy: 0.9135 - val_loss: 0.8688 - val_accuracy: 0.8056
Epoch 32/110
 - 1s - loss: 0.3746 - accuracy: 0.9065 - val_loss: 0.9207 - val_accuracy: 0.7807
Epoch 33/110
 - 1s - loss: 0.3790 - accuracy: 0.9106 - val_loss: 0.8940 - val_accuracy: 0.7791
Epoch 34/110
 - 1s - loss: 0.3879 - accuracy: 0.9094 - val_loss: 0.8072 - val_accuracy: 0.8073
Epoch 35/110
 - 1s - loss: 0.3913 - accuracy: 0.9123 - val_loss: 0.9016 - val_accuracy: 0.8040
Epoch 36/110
 - 1s - loss: 0.3753 - accuracy: 0.9185 - val_loss: 0.7988 - val_accuracy: 0.8040
Epoch 37/110
 - 1s - loss: 0.3769 - accuracy: 0.9086 - val_loss: 0.7890 - val_accuracy: 0.7957
Epoch 38/110
 - 1s - loss: 0.3842 - accuracy: 0.9086 - val_loss: 0.7557 - val_accuracy: 0.8239
Epoch 39/110
 - 1s - loss: 0.3581 - accuracy: 0.9190 - val_loss: 0.8250 - val_accuracy: 0.7940
Epoch 40/110
 - 1s - loss: 0.3713 - accuracy: 0.9177 - val_loss: 0.8360 - val_accuracy: 0.7824
Epoch 41/110
 - 1s - loss: 0.3692 - accuracy: 0.9173 - val_loss: 0.7932 - val_accuracy: 0.7990
Epoch 42/110
 - 1s - loss: 0.3591 - accuracy: 0.9165 - val_loss: 0.8295 - val_accuracy: 0.7907
Epoch 43/110
 - 1s - loss: 0.3381 - accuracy: 0.9281 - val_loss: 0.8812 - val_accuracy: 0.7874
Epoch 44/110
 - 1s - loss: 0.3363 - accuracy: 0.9277 - val_loss: 0.8898 - val_accuracy: 0.8056
Epoch 45/110
 - 1s - loss: 0.3425 - accuracy: 0.9281 - val_loss: 0.8777 - val_accuracy: 0.7857
Epoch 46/110
 - 1s - loss: 0.3304 - accuracy: 0.9293 - val_loss: 0.8480 - val_accuracy: 0.8106
Epoch 47/110
 - 1s - loss: 0.3167 - accuracy: 0.9368 - val_loss: 0.8710 - val_accuracy: 0.8040
Epoch 48/110
 - 1s - loss: 0.3446 - accuracy: 0.9231 - val_loss: 0.9192 - val_accuracy: 0.7841
Epoch 49/110
 - 1s - loss: 0.3449 - accuracy: 0.9273 - val_loss: 0.8734 - val_accuracy: 0.8189
Epoch 50/110
 - 1s - loss: 0.3455 - accuracy: 0.9219 - val_loss: 0.8311 - val_accuracy: 0.8156
Epoch 51/110
 - 1s - loss: 0.3534 - accuracy: 0.9235 - val_loss: 0.8549 - val_accuracy: 0.7940
Epoch 52/110
 - 1s - loss: 0.3480 - accuracy: 0.9239 - val_loss: 0.8261 - val_accuracy: 0.8140
Epoch 53/110
 - 1s - loss: 0.3212 - accuracy: 0.9293 - val_loss: 0.8510 - val_accuracy: 0.8256
Epoch 54/110
 - 1s - loss: 0.3117 - accuracy: 0.9393 - val_loss: 0.8596 - val_accuracy: 0.7924
Epoch 55/110
 - 1s - loss: 0.3027 - accuracy: 0.9464 - val_loss: 0.9094 - val_accuracy: 0.7957
Epoch 56/110
 - 1s - loss: 0.2955 - accuracy: 0.9431 - val_loss: 0.9115 - val_accuracy: 0.8056
Epoch 57/110
 - 1s - loss: 0.2993 - accuracy: 0.9439 - val_loss: 0.8584 - val_accuracy: 0.8289
Epoch 58/110
 - 1s - loss: 0.3169 - accuracy: 0.9381 - val_loss: 0.9218 - val_accuracy: 0.7940
Epoch 59/110
 - 1s - loss: 0.3272 - accuracy: 0.9298 - val_loss: 0.8466 - val_accuracy: 0.8056
Epoch 60/110
 - 1s - loss: 0.3229 - accuracy: 0.9414 - val_loss: 0.8552 - val_accuracy: 0.8073
Epoch 61/110
 - 1s - loss: 0.3245 - accuracy: 0.9377 - val_loss: 0.9453 - val_accuracy: 0.8073
Epoch 62/110
 - 1s - loss: 0.2968 - accuracy: 0.9418 - val_loss: 0.9039 - val_accuracy: 0.8056
Epoch 63/110
 - 1s - loss: 0.2894 - accuracy: 0.9526 - val_loss: 0.8297 - val_accuracy: 0.8256
Epoch 64/110
 - 1s - loss: 0.2890 - accuracy: 0.9472 - val_loss: 0.8799 - val_accuracy: 0.8289
Epoch 65/110
 - 1s - loss: 0.2915 - accuracy: 0.9435 - val_loss: 0.9689 - val_accuracy: 0.7841
Epoch 66/110
 - 1s - loss: 0.3067 - accuracy: 0.9414 - val_loss: 0.9387 - val_accuracy: 0.7940
Epoch 67/110
 - 1s - loss: 0.3006 - accuracy: 0.9476 - val_loss: 1.0191 - val_accuracy: 0.7907
Epoch 68/110
 - 1s - loss: 0.3482 - accuracy: 0.9214 - val_loss: 0.9204 - val_accuracy: 0.7907
Epoch 69/110
 - 1s - loss: 0.2978 - accuracy: 0.9410 - val_loss: 0.8425 - val_accuracy: 0.8339
Epoch 70/110
 - 1s - loss: 0.2893 - accuracy: 0.9526 - val_loss: 0.8433 - val_accuracy: 0.8206
Epoch 71/110
 - 1s - loss: 0.2660 - accuracy: 0.9559 - val_loss: 0.8434 - val_accuracy: 0.8306
Epoch 72/110
 - 1s - loss: 0.2763 - accuracy: 0.9551 - val_loss: 0.9321 - val_accuracy: 0.8173
Epoch 73/110
 - 1s - loss: 0.2850 - accuracy: 0.9493 - val_loss: 0.9982 - val_accuracy: 0.7940
Epoch 74/110
 - 1s - loss: 0.2889 - accuracy: 0.9435 - val_loss: 1.0313 - val_accuracy: 0.7824
Epoch 75/110
 - 1s - loss: 0.3236 - accuracy: 0.9381 - val_loss: 0.8662 - val_accuracy: 0.8189
Epoch 76/110
 - 1s - loss: 0.2969 - accuracy: 0.9422 - val_loss: 0.9772 - val_accuracy: 0.8073
Epoch 77/110
 - 1s - loss: 0.2887 - accuracy: 0.9501 - val_loss: 0.9992 - val_accuracy: 0.8073
Epoch 78/110
 - 1s - loss: 0.2751 - accuracy: 0.9534 - val_loss: 0.9685 - val_accuracy: 0.8140
Epoch 79/110
 - 1s - loss: 0.2688 - accuracy: 0.9564 - val_loss: 0.8251 - val_accuracy: 0.8306
Epoch 80/110
 - 1s - loss: 0.2870 - accuracy: 0.9456 - val_loss: 0.8442 - val_accuracy: 0.8223
Epoch 81/110
 - 1s - loss: 0.2875 - accuracy: 0.9493 - val_loss: 0.8543 - val_accuracy: 0.8256
Epoch 82/110
 - 1s - loss: 0.2677 - accuracy: 0.9543 - val_loss: 0.9028 - val_accuracy: 0.8256
Epoch 83/110
 - 1s - loss: 0.2688 - accuracy: 0.9543 - val_loss: 0.8950 - val_accuracy: 0.8256
Epoch 84/110
 - 1s - loss: 0.2635 - accuracy: 0.9593 - val_loss: 0.8882 - val_accuracy: 0.8073
Epoch 85/110
 - 1s - loss: 0.2533 - accuracy: 0.9618 - val_loss: 0.8683 - val_accuracy: 0.8289
Epoch 86/110
 - 1s - loss: 0.2519 - accuracy: 0.9626 - val_loss: 0.8674 - val_accuracy: 0.8206
Epoch 87/110
 - 1s - loss: 0.2636 - accuracy: 0.9593 - val_loss: 0.8790 - val_accuracy: 0.8272
Epoch 88/110
 - 1s - loss: 0.2530 - accuracy: 0.9597 - val_loss: 0.9075 - val_accuracy: 0.8206
Epoch 89/110
 - 1s - loss: 0.2582 - accuracy: 0.9613 - val_loss: 0.9067 - val_accuracy: 0.8322
Epoch 90/110
 - 1s - loss: 0.2586 - accuracy: 0.9622 - val_loss: 0.8971 - val_accuracy: 0.8156
Epoch 91/110
 - 1s - loss: 0.2739 - accuracy: 0.9539 - val_loss: 0.9439 - val_accuracy: 0.8306
Epoch 92/110
 - 1s - loss: 0.2926 - accuracy: 0.9464 - val_loss: 0.9571 - val_accuracy: 0.8173
Epoch 93/110
 - 1s - loss: 0.2634 - accuracy: 0.9584 - val_loss: 0.9716 - val_accuracy: 0.8372
Epoch 94/110
 - 1s - loss: 0.2655 - accuracy: 0.9605 - val_loss: 0.9334 - val_accuracy: 0.8189
Epoch 95/110
 - 1s - loss: 0.2536 - accuracy: 0.9572 - val_loss: 1.0093 - val_accuracy: 0.8239
Epoch 96/110
 - 1s - loss: 0.2741 - accuracy: 0.9593 - val_loss: 1.0250 - val_accuracy: 0.7990
Epoch 97/110
 - 1s - loss: 0.2730 - accuracy: 0.9593 - val_loss: 1.0271 - val_accuracy: 0.8056
Epoch 98/110
 - 1s - loss: 0.2596 - accuracy: 0.9543 - val_loss: 0.9585 - val_accuracy: 0.8156
Epoch 99/110
 - 1s - loss: 0.2434 - accuracy: 0.9659 - val_loss: 1.0128 - val_accuracy: 0.8239
Epoch 100/110
 - 1s - loss: 0.2346 - accuracy: 0.9659 - val_loss: 0.9380 - val_accuracy: 0.8239
Epoch 101/110
 - 1s - loss: 0.2214 - accuracy: 0.9742 - val_loss: 0.9593 - val_accuracy: 0.8372
Epoch 102/110
 - 1s - loss: 0.2181 - accuracy: 0.9746 - val_loss: 1.0705 - val_accuracy: 0.8023
Epoch 103/110
 - 1s - loss: 0.2537 - accuracy: 0.9601 - val_loss: 0.9621 - val_accuracy: 0.8106
Epoch 104/110
 - 1s - loss: 0.2674 - accuracy: 0.9576 - val_loss: 0.9561 - val_accuracy: 0.8007
Epoch 105/110
 - 1s - loss: 0.2322 - accuracy: 0.9705 - val_loss: 1.0602 - val_accuracy: 0.8173
Epoch 106/110
 - 1s - loss: 0.2457 - accuracy: 0.9630 - val_loss: 0.9542 - val_accuracy: 0.8289
Epoch 107/110
 - 1s - loss: 0.2566 - accuracy: 0.9589 - val_loss: 1.0365 - val_accuracy: 0.8073
Epoch 108/110
 - 1s - loss: 0.2857 - accuracy: 0.9510 - val_loss: 0.9880 - val_accuracy: 0.8206
Epoch 109/110
 - 1s - loss: 0.2508 - accuracy: 0.9597 - val_loss: 1.0366 - val_accuracy: 0.8073
Epoch 110/110
 - 1s - loss: 0.2757 - accuracy: 0.9555 - val_loss: 1.0498 - val_accuracy: 0.7907
------------------------------------------------------------------------
Training for fold 3 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 5s - loss: 1.1291 - accuracy: 0.6646 - val_loss: 4.2256 - val_accuracy: 0.2890
Epoch 2/110
 - 1s - loss: 0.7880 - accuracy: 0.7731 - val_loss: 1.6585 - val_accuracy: 0.4635
Epoch 3/110
 - 1s - loss: 0.6940 - accuracy: 0.8038 - val_loss: 1.1820 - val_accuracy: 0.5465
Epoch 4/110
 - 1s - loss: 0.6260 - accuracy: 0.8242 - val_loss: 0.9620 - val_accuracy: 0.6794
Epoch 5/110
 - 1s - loss: 0.6151 - accuracy: 0.8263 - val_loss: 0.8661 - val_accuracy: 0.7409
Epoch 6/110
 - 1s - loss: 0.5919 - accuracy: 0.8313 - val_loss: 0.7889 - val_accuracy: 0.7392
Epoch 7/110
 - 1s - loss: 0.5950 - accuracy: 0.8325 - val_loss: 0.7753 - val_accuracy: 0.7542
Epoch 8/110
 - 1s - loss: 0.5979 - accuracy: 0.8329 - val_loss: 0.7443 - val_accuracy: 0.8040
Epoch 9/110
 - 1s - loss: 0.5641 - accuracy: 0.8429 - val_loss: 0.7103 - val_accuracy: 0.7957
Epoch 10/110
 - 1s - loss: 0.5192 - accuracy: 0.8558 - val_loss: 0.7324 - val_accuracy: 0.7973
Epoch 11/110
 - 1s - loss: 0.5291 - accuracy: 0.8570 - val_loss: 0.7185 - val_accuracy: 0.8123
Epoch 12/110
 - 1s - loss: 0.5091 - accuracy: 0.8603 - val_loss: 0.7313 - val_accuracy: 0.7990
Epoch 13/110
 - 1s - loss: 0.4997 - accuracy: 0.8666 - val_loss: 0.7532 - val_accuracy: 0.7857
Epoch 14/110
 - 1s - loss: 0.4789 - accuracy: 0.8745 - val_loss: 0.7493 - val_accuracy: 0.8140
Epoch 15/110
 - 1s - loss: 0.4788 - accuracy: 0.8757 - val_loss: 0.7586 - val_accuracy: 0.7741
Epoch 16/110
 - 1s - loss: 0.4800 - accuracy: 0.8720 - val_loss: 0.7720 - val_accuracy: 0.8123
Epoch 17/110
 - 1s - loss: 0.4985 - accuracy: 0.8649 - val_loss: 0.8372 - val_accuracy: 0.7857
Epoch 18/110
 - 1s - loss: 0.4868 - accuracy: 0.8691 - val_loss: 0.7518 - val_accuracy: 0.8206
Epoch 19/110
 - 1s - loss: 0.4979 - accuracy: 0.8658 - val_loss: 0.8152 - val_accuracy: 0.7857
Epoch 20/110
 - 1s - loss: 0.4753 - accuracy: 0.8699 - val_loss: 0.8182 - val_accuracy: 0.7741
Epoch 21/110
 - 1s - loss: 0.4752 - accuracy: 0.8786 - val_loss: 0.8614 - val_accuracy: 0.7409
Epoch 22/110
 - 1s - loss: 0.4507 - accuracy: 0.8840 - val_loss: 0.8775 - val_accuracy: 0.7741
Epoch 23/110
 - 1s - loss: 0.4473 - accuracy: 0.8944 - val_loss: 0.7919 - val_accuracy: 0.7874
Epoch 24/110
 - 1s - loss: 0.4273 - accuracy: 0.8932 - val_loss: 0.8475 - val_accuracy: 0.7924
Epoch 25/110
 - 1s - loss: 0.4310 - accuracy: 0.8849 - val_loss: 0.9203 - val_accuracy: 0.7724
Epoch 26/110
 - 1s - loss: 0.4248 - accuracy: 0.8957 - val_loss: 0.8815 - val_accuracy: 0.7691
Epoch 27/110
 - 1s - loss: 0.4161 - accuracy: 0.8961 - val_loss: 0.7510 - val_accuracy: 0.8173
Epoch 28/110
 - 1s - loss: 0.4068 - accuracy: 0.8903 - val_loss: 0.7672 - val_accuracy: 0.7973
Epoch 29/110
 - 1s - loss: 0.4387 - accuracy: 0.8824 - val_loss: 0.8487 - val_accuracy: 0.7741
Epoch 30/110
 - 1s - loss: 0.4391 - accuracy: 0.8836 - val_loss: 0.7889 - val_accuracy: 0.8040
Epoch 31/110
 - 1s - loss: 0.4240 - accuracy: 0.8853 - val_loss: 0.8643 - val_accuracy: 0.7874
Epoch 32/110
 - 1s - loss: 0.4106 - accuracy: 0.9061 - val_loss: 0.8306 - val_accuracy: 0.7973
Epoch 33/110
 - 1s - loss: 0.4364 - accuracy: 0.8903 - val_loss: 0.8754 - val_accuracy: 0.7940
Epoch 34/110
 - 1s - loss: 0.4053 - accuracy: 0.9007 - val_loss: 0.9124 - val_accuracy: 0.7724
Epoch 35/110
 - 1s - loss: 0.4145 - accuracy: 0.8978 - val_loss: 0.8744 - val_accuracy: 0.7542
Epoch 36/110
 - 1s - loss: 0.4163 - accuracy: 0.9023 - val_loss: 0.9633 - val_accuracy: 0.7724
Epoch 37/110
 - 1s - loss: 0.4022 - accuracy: 0.9027 - val_loss: 0.8630 - val_accuracy: 0.7907
Epoch 38/110
 - 1s - loss: 0.4144 - accuracy: 0.8932 - val_loss: 0.9018 - val_accuracy: 0.7841
Epoch 39/110
 - 1s - loss: 0.3916 - accuracy: 0.9073 - val_loss: 0.8686 - val_accuracy: 0.8056
Epoch 40/110
 - 1s - loss: 0.3793 - accuracy: 0.9081 - val_loss: 0.8521 - val_accuracy: 0.7674
Epoch 41/110
 - 1s - loss: 0.3739 - accuracy: 0.9119 - val_loss: 0.8361 - val_accuracy: 0.8123
Epoch 42/110
 - 1s - loss: 0.3614 - accuracy: 0.9165 - val_loss: 0.8387 - val_accuracy: 0.8056
Epoch 43/110
 - 1s - loss: 0.3608 - accuracy: 0.9210 - val_loss: 0.9110 - val_accuracy: 0.8106
Epoch 44/110
 - 1s - loss: 0.3821 - accuracy: 0.9077 - val_loss: 1.0155 - val_accuracy: 0.7874
Epoch 45/110
 - 1s - loss: 0.3617 - accuracy: 0.9140 - val_loss: 1.0219 - val_accuracy: 0.7857
Epoch 46/110
 - 1s - loss: 0.3434 - accuracy: 0.9231 - val_loss: 0.8933 - val_accuracy: 0.8007
Epoch 47/110
 - 1s - loss: 0.3398 - accuracy: 0.9252 - val_loss: 0.8969 - val_accuracy: 0.7857
Epoch 48/110
 - 1s - loss: 0.3173 - accuracy: 0.9368 - val_loss: 0.9291 - val_accuracy: 0.8023
Epoch 49/110
 - 1s - loss: 0.3134 - accuracy: 0.9368 - val_loss: 0.9364 - val_accuracy: 0.7940
Epoch 50/110
 - 1s - loss: 0.3526 - accuracy: 0.9202 - val_loss: 0.9827 - val_accuracy: 0.7957
Epoch 51/110
 - 1s - loss: 0.3523 - accuracy: 0.9244 - val_loss: 0.9315 - val_accuracy: 0.8156
Epoch 52/110
 - 1s - loss: 0.3661 - accuracy: 0.9140 - val_loss: 0.9008 - val_accuracy: 0.8123
Epoch 53/110
 - 1s - loss: 0.3734 - accuracy: 0.9119 - val_loss: 0.9910 - val_accuracy: 0.8140
Epoch 54/110
 - 1s - loss: 0.3295 - accuracy: 0.9298 - val_loss: 0.9394 - val_accuracy: 0.7957
Epoch 55/110
 - 1s - loss: 0.3174 - accuracy: 0.9368 - val_loss: 0.9142 - val_accuracy: 0.8106
Epoch 56/110
 - 1s - loss: 0.3330 - accuracy: 0.9323 - val_loss: 0.9684 - val_accuracy: 0.7924
Epoch 57/110
 - 1s - loss: 0.3433 - accuracy: 0.9260 - val_loss: 0.9379 - val_accuracy: 0.8023
Epoch 58/110
 - 1s - loss: 0.3067 - accuracy: 0.9447 - val_loss: 0.8998 - val_accuracy: 0.7990
Epoch 59/110
 - 1s - loss: 0.3159 - accuracy: 0.9368 - val_loss: 0.9623 - val_accuracy: 0.8123
Epoch 60/110
 - 1s - loss: 0.3636 - accuracy: 0.9210 - val_loss: 1.0210 - val_accuracy: 0.7791
Epoch 61/110
 - 1s - loss: 0.3170 - accuracy: 0.9364 - val_loss: 0.9803 - val_accuracy: 0.8007
Epoch 62/110
 - 1s - loss: 0.3233 - accuracy: 0.9356 - val_loss: 0.9320 - val_accuracy: 0.8156
Epoch 63/110
 - 1s - loss: 0.3219 - accuracy: 0.9364 - val_loss: 0.9953 - val_accuracy: 0.7973
Epoch 64/110
 - 1s - loss: 0.3076 - accuracy: 0.9431 - val_loss: 1.0117 - val_accuracy: 0.8106
Epoch 65/110
 - 1s - loss: 0.3055 - accuracy: 0.9393 - val_loss: 0.9936 - val_accuracy: 0.7973
Epoch 66/110
 - 1s - loss: 0.2905 - accuracy: 0.9464 - val_loss: 0.9774 - val_accuracy: 0.7841
Epoch 67/110
 - 1s - loss: 0.2844 - accuracy: 0.9514 - val_loss: 0.9345 - val_accuracy: 0.8189
Epoch 68/110
 - 1s - loss: 0.2750 - accuracy: 0.9514 - val_loss: 0.9847 - val_accuracy: 0.7973
Epoch 69/110
 - 1s - loss: 0.3183 - accuracy: 0.9335 - val_loss: 1.0152 - val_accuracy: 0.8040
Epoch 70/110
 - 1s - loss: 0.3261 - accuracy: 0.9285 - val_loss: 1.0456 - val_accuracy: 0.8140
Epoch 71/110
 - 1s - loss: 0.3002 - accuracy: 0.9426 - val_loss: 1.0438 - val_accuracy: 0.7990
Epoch 72/110
 - 1s - loss: 0.2917 - accuracy: 0.9522 - val_loss: 1.0929 - val_accuracy: 0.8090
Epoch 73/110
 - 1s - loss: 0.3185 - accuracy: 0.9360 - val_loss: 0.9846 - val_accuracy: 0.7940
Epoch 74/110
 - 1s - loss: 0.2960 - accuracy: 0.9431 - val_loss: 0.9964 - val_accuracy: 0.7957
Epoch 75/110
 - 1s - loss: 0.2769 - accuracy: 0.9547 - val_loss: 1.0495 - val_accuracy: 0.7957
Epoch 76/110
 - 1s - loss: 0.2964 - accuracy: 0.9443 - val_loss: 1.0503 - val_accuracy: 0.8090
Epoch 77/110
 - 1s - loss: 0.2898 - accuracy: 0.9485 - val_loss: 1.0046 - val_accuracy: 0.8189
Epoch 78/110
 - 1s - loss: 0.2892 - accuracy: 0.9485 - val_loss: 0.9460 - val_accuracy: 0.8223
Epoch 79/110
 - 1s - loss: 0.2943 - accuracy: 0.9505 - val_loss: 1.0975 - val_accuracy: 0.8073
Epoch 80/110
 - 1s - loss: 0.2669 - accuracy: 0.9539 - val_loss: 1.0978 - val_accuracy: 0.8056
Epoch 81/110
 - 1s - loss: 0.2946 - accuracy: 0.9493 - val_loss: 1.1008 - val_accuracy: 0.7940
Epoch 82/110
 - 1s - loss: 0.2899 - accuracy: 0.9468 - val_loss: 1.0584 - val_accuracy: 0.8090
Epoch 83/110
 - 1s - loss: 0.2861 - accuracy: 0.9489 - val_loss: 1.0049 - val_accuracy: 0.8123
Epoch 84/110
 - 1s - loss: 0.2925 - accuracy: 0.9493 - val_loss: 1.0423 - val_accuracy: 0.8140
Epoch 85/110
 - 1s - loss: 0.3002 - accuracy: 0.9468 - val_loss: 1.0892 - val_accuracy: 0.7990
Epoch 86/110
 - 1s - loss: 0.3009 - accuracy: 0.9406 - val_loss: 1.0776 - val_accuracy: 0.7924
Epoch 87/110
 - 1s - loss: 0.3093 - accuracy: 0.9368 - val_loss: 0.9471 - val_accuracy: 0.8239
Epoch 88/110
 - 1s - loss: 0.3044 - accuracy: 0.9431 - val_loss: 0.9523 - val_accuracy: 0.7957
Epoch 89/110
 - 1s - loss: 0.2902 - accuracy: 0.9443 - val_loss: 0.9681 - val_accuracy: 0.8206
Epoch 90/110
 - 1s - loss: 0.2853 - accuracy: 0.9493 - val_loss: 0.9869 - val_accuracy: 0.8189
Epoch 91/110
 - 1s - loss: 0.2930 - accuracy: 0.9497 - val_loss: 1.0105 - val_accuracy: 0.7874
Epoch 92/110
 - 1s - loss: 0.2621 - accuracy: 0.9568 - val_loss: 0.9940 - val_accuracy: 0.7990
Epoch 93/110
 - 1s - loss: 0.2657 - accuracy: 0.9584 - val_loss: 0.9335 - val_accuracy: 0.8156
Epoch 94/110
 - 1s - loss: 0.2663 - accuracy: 0.9630 - val_loss: 1.0326 - val_accuracy: 0.8040
Epoch 95/110
 - 1s - loss: 0.2622 - accuracy: 0.9539 - val_loss: 1.0952 - val_accuracy: 0.7990
Epoch 96/110
 - 1s - loss: 0.2830 - accuracy: 0.9568 - val_loss: 1.0283 - val_accuracy: 0.7957
Epoch 97/110
 - 1s - loss: 0.3122 - accuracy: 0.9414 - val_loss: 1.0622 - val_accuracy: 0.8073
Epoch 98/110
 - 1s - loss: 0.3139 - accuracy: 0.9389 - val_loss: 0.9933 - val_accuracy: 0.7990
Epoch 99/110
 - 1s - loss: 0.2979 - accuracy: 0.9472 - val_loss: 1.0100 - val_accuracy: 0.8056
Epoch 100/110
 - 1s - loss: 0.2940 - accuracy: 0.9493 - val_loss: 0.9844 - val_accuracy: 0.8023
Epoch 101/110
 - 1s - loss: 0.2791 - accuracy: 0.9576 - val_loss: 1.0036 - val_accuracy: 0.8173
Epoch 102/110
 - 1s - loss: 0.2572 - accuracy: 0.9572 - val_loss: 1.0211 - val_accuracy: 0.7940
Epoch 103/110
 - 1s - loss: 0.2278 - accuracy: 0.9717 - val_loss: 1.0246 - val_accuracy: 0.8023
Epoch 104/110
 - 1s - loss: 0.2499 - accuracy: 0.9609 - val_loss: 1.0228 - val_accuracy: 0.7907
Epoch 105/110
 - 1s - loss: 0.2426 - accuracy: 0.9634 - val_loss: 1.1013 - val_accuracy: 0.8023
Epoch 106/110
 - 1s - loss: 0.2452 - accuracy: 0.9618 - val_loss: 1.0956 - val_accuracy: 0.7824
Epoch 107/110
 - 1s - loss: 0.2520 - accuracy: 0.9609 - val_loss: 1.0075 - val_accuracy: 0.8256
Epoch 108/110
 - 1s - loss: 0.2584 - accuracy: 0.9559 - val_loss: 1.0418 - val_accuracy: 0.7924
Epoch 109/110
 - 1s - loss: 0.2678 - accuracy: 0.9564 - val_loss: 1.0194 - val_accuracy: 0.8156
Epoch 110/110
 - 1s - loss: 0.2624 - accuracy: 0.9564 - val_loss: 1.1837 - val_accuracy: 0.7940
------------------------------------------------------------------------
Training for fold 4 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 5s - loss: 1.3321 - accuracy: 0.6766 - val_loss: 4.4593 - val_accuracy: 0.3588
Epoch 2/110
 - 1s - loss: 0.8199 - accuracy: 0.7598 - val_loss: 2.0048 - val_accuracy: 0.3638
Epoch 3/110
 - 1s - loss: 0.7145 - accuracy: 0.7884 - val_loss: 1.2913 - val_accuracy: 0.5365
Epoch 4/110
 - 1s - loss: 0.6622 - accuracy: 0.8113 - val_loss: 1.0005 - val_accuracy: 0.6827
Epoch 5/110
 - 1s - loss: 0.6164 - accuracy: 0.8213 - val_loss: 0.8272 - val_accuracy: 0.7691
Epoch 6/110
 - 1s - loss: 0.5988 - accuracy: 0.8275 - val_loss: 0.7595 - val_accuracy: 0.7874
Epoch 7/110
 - 1s - loss: 0.5686 - accuracy: 0.8404 - val_loss: 0.7272 - val_accuracy: 0.8073
Epoch 8/110
 - 1s - loss: 0.5616 - accuracy: 0.8375 - val_loss: 0.6917 - val_accuracy: 0.8223
Epoch 9/110
 - 1s - loss: 0.5574 - accuracy: 0.8400 - val_loss: 0.7538 - val_accuracy: 0.7824
Epoch 10/110
 - 1s - loss: 0.5535 - accuracy: 0.8458 - val_loss: 0.7797 - val_accuracy: 0.7957
Epoch 11/110
 - 1s - loss: 0.5647 - accuracy: 0.8354 - val_loss: 0.7866 - val_accuracy: 0.7890
Epoch 12/110
 - 1s - loss: 0.5382 - accuracy: 0.8446 - val_loss: 0.7988 - val_accuracy: 0.7973
Epoch 13/110
 - 1s - loss: 0.5166 - accuracy: 0.8533 - val_loss: 0.7659 - val_accuracy: 0.8140
Epoch 14/110
 - 1s - loss: 0.4928 - accuracy: 0.8599 - val_loss: 0.7656 - val_accuracy: 0.8007
Epoch 15/110
 - 1s - loss: 0.4695 - accuracy: 0.8724 - val_loss: 0.7500 - val_accuracy: 0.8090
Epoch 16/110
 - 1s - loss: 0.4418 - accuracy: 0.8836 - val_loss: 0.8351 - val_accuracy: 0.8056
Epoch 17/110
 - 1s - loss: 0.4341 - accuracy: 0.8845 - val_loss: 0.8721 - val_accuracy: 0.7724
Epoch 18/110
 - 1s - loss: 0.4362 - accuracy: 0.8869 - val_loss: 0.8172 - val_accuracy: 0.7874
Epoch 19/110
 - 1s - loss: 0.4572 - accuracy: 0.8757 - val_loss: 0.8034 - val_accuracy: 0.7973
Epoch 20/110
 - 1s - loss: 0.4684 - accuracy: 0.8695 - val_loss: 0.7768 - val_accuracy: 0.7890
Epoch 21/110
 - 1s - loss: 0.4772 - accuracy: 0.8666 - val_loss: 0.8462 - val_accuracy: 0.7924
Epoch 22/110
 - 1s - loss: 0.4709 - accuracy: 0.8720 - val_loss: 0.8177 - val_accuracy: 0.7791
Epoch 23/110
 - 1s - loss: 0.4349 - accuracy: 0.8899 - val_loss: 0.7779 - val_accuracy: 0.7957
Epoch 24/110
 - 1s - loss: 0.4618 - accuracy: 0.8741 - val_loss: 0.8880 - val_accuracy: 0.7890
Epoch 25/110
 - 1s - loss: 0.4563 - accuracy: 0.8824 - val_loss: 0.8297 - val_accuracy: 0.8090
Epoch 26/110
 - 1s - loss: 0.4477 - accuracy: 0.8778 - val_loss: 0.8990 - val_accuracy: 0.8173
Epoch 27/110
 - 1s - loss: 0.4169 - accuracy: 0.8953 - val_loss: 0.8235 - val_accuracy: 0.8073
Epoch 28/110
 - 1s - loss: 0.4264 - accuracy: 0.8915 - val_loss: 0.8596 - val_accuracy: 0.7841
Epoch 29/110
 - 1s - loss: 0.4382 - accuracy: 0.8869 - val_loss: 0.8018 - val_accuracy: 0.8073
Epoch 30/110
 - 1s - loss: 0.4165 - accuracy: 0.8986 - val_loss: 0.8008 - val_accuracy: 0.8056
Epoch 31/110
 - 1s - loss: 0.4253 - accuracy: 0.8836 - val_loss: 0.7915 - val_accuracy: 0.8223
Epoch 32/110
 - 1s - loss: 0.4167 - accuracy: 0.8899 - val_loss: 0.8367 - val_accuracy: 0.7957
Epoch 33/110
 - 1s - loss: 0.4210 - accuracy: 0.8940 - val_loss: 0.8230 - val_accuracy: 0.8056
Epoch 34/110
 - 1s - loss: 0.3957 - accuracy: 0.9007 - val_loss: 0.8496 - val_accuracy: 0.8173
Epoch 35/110
 - 1s - loss: 0.3936 - accuracy: 0.9015 - val_loss: 0.8516 - val_accuracy: 0.8073
Epoch 36/110
 - 1s - loss: 0.4078 - accuracy: 0.8982 - val_loss: 0.8302 - val_accuracy: 0.7990
Epoch 37/110
 - 1s - loss: 0.4097 - accuracy: 0.8944 - val_loss: 0.9014 - val_accuracy: 0.7973
Epoch 38/110
 - 1s - loss: 0.3833 - accuracy: 0.9057 - val_loss: 1.0102 - val_accuracy: 0.7791
Epoch 39/110
 - 1s - loss: 0.3995 - accuracy: 0.9073 - val_loss: 0.9041 - val_accuracy: 0.7940
Epoch 40/110
 - 1s - loss: 0.3772 - accuracy: 0.9131 - val_loss: 0.8634 - val_accuracy: 0.7973
Epoch 41/110
 - 1s - loss: 0.3824 - accuracy: 0.9007 - val_loss: 0.9855 - val_accuracy: 0.7757
Epoch 42/110
 - 1s - loss: 0.3785 - accuracy: 0.9057 - val_loss: 0.8945 - val_accuracy: 0.7774
Epoch 43/110
 - 1s - loss: 0.3858 - accuracy: 0.9094 - val_loss: 0.9188 - val_accuracy: 0.7791
Epoch 44/110
 - 1s - loss: 0.3661 - accuracy: 0.9119 - val_loss: 0.9015 - val_accuracy: 0.7957
Epoch 45/110
 - 1s - loss: 0.4017 - accuracy: 0.9007 - val_loss: 0.8628 - val_accuracy: 0.7940
Epoch 46/110
 - 1s - loss: 0.3671 - accuracy: 0.9135 - val_loss: 0.9119 - val_accuracy: 0.7757
Epoch 47/110
 - 1s - loss: 0.3714 - accuracy: 0.9123 - val_loss: 0.8593 - val_accuracy: 0.8023
Epoch 48/110
 - 1s - loss: 0.3525 - accuracy: 0.9210 - val_loss: 0.9560 - val_accuracy: 0.7691
Epoch 49/110
 - 1s - loss: 0.3471 - accuracy: 0.9190 - val_loss: 0.9617 - val_accuracy: 0.8123
Epoch 50/110
 - 1s - loss: 0.3403 - accuracy: 0.9244 - val_loss: 0.9740 - val_accuracy: 0.8073
Epoch 51/110
 - 1s - loss: 0.3300 - accuracy: 0.9302 - val_loss: 0.9441 - val_accuracy: 0.7940
Epoch 52/110
 - 1s - loss: 0.3391 - accuracy: 0.9248 - val_loss: 0.9478 - val_accuracy: 0.8090
Epoch 53/110
 - 1s - loss: 0.3392 - accuracy: 0.9306 - val_loss: 0.9766 - val_accuracy: 0.7791
Epoch 54/110
 - 1s - loss: 0.3503 - accuracy: 0.9248 - val_loss: 0.9579 - val_accuracy: 0.7973
Epoch 55/110
 - 1s - loss: 0.3277 - accuracy: 0.9289 - val_loss: 1.0114 - val_accuracy: 0.7774
Epoch 56/110
 - 1s - loss: 0.3443 - accuracy: 0.9169 - val_loss: 0.9256 - val_accuracy: 0.7641
Epoch 57/110
 - 1s - loss: 0.3212 - accuracy: 0.9302 - val_loss: 0.9567 - val_accuracy: 0.7841
Epoch 58/110
 - 1s - loss: 0.3145 - accuracy: 0.9323 - val_loss: 0.9825 - val_accuracy: 0.7857
Epoch 59/110
 - 1s - loss: 0.3345 - accuracy: 0.9235 - val_loss: 0.9706 - val_accuracy: 0.8023
Epoch 60/110
 - 1s - loss: 0.3259 - accuracy: 0.9323 - val_loss: 0.9911 - val_accuracy: 0.8007
Epoch 61/110
 - 1s - loss: 0.3430 - accuracy: 0.9219 - val_loss: 0.9942 - val_accuracy: 0.7857
Epoch 62/110
 - 1s - loss: 0.3334 - accuracy: 0.9302 - val_loss: 0.9968 - val_accuracy: 0.7990
Epoch 63/110
 - 1s - loss: 0.3222 - accuracy: 0.9352 - val_loss: 1.0447 - val_accuracy: 0.7841
Epoch 64/110
 - 1s - loss: 0.3290 - accuracy: 0.9268 - val_loss: 1.0859 - val_accuracy: 0.7741
Epoch 65/110
 - 1s - loss: 0.3242 - accuracy: 0.9285 - val_loss: 1.0081 - val_accuracy: 0.8140
Epoch 66/110
 - 1s - loss: 0.3105 - accuracy: 0.9364 - val_loss: 1.0004 - val_accuracy: 0.7874
Epoch 67/110
 - 1s - loss: 0.3359 - accuracy: 0.9273 - val_loss: 0.9459 - val_accuracy: 0.7907
Epoch 68/110
 - 1s - loss: 0.3131 - accuracy: 0.9352 - val_loss: 1.0085 - val_accuracy: 0.8040
Epoch 69/110
 - 1s - loss: 0.3201 - accuracy: 0.9343 - val_loss: 0.9847 - val_accuracy: 0.7874
Epoch 70/110
 - 1s - loss: 0.2928 - accuracy: 0.9426 - val_loss: 1.0603 - val_accuracy: 0.7791
Epoch 71/110
 - 1s - loss: 0.3336 - accuracy: 0.9327 - val_loss: 0.9631 - val_accuracy: 0.8073
Epoch 72/110
 - 1s - loss: 0.2907 - accuracy: 0.9456 - val_loss: 0.9946 - val_accuracy: 0.7890
Epoch 73/110
 - 1s - loss: 0.3107 - accuracy: 0.9377 - val_loss: 1.0219 - val_accuracy: 0.7990
Epoch 74/110
 - 1s - loss: 0.2904 - accuracy: 0.9401 - val_loss: 1.0314 - val_accuracy: 0.7924
Epoch 75/110
 - 1s - loss: 0.3131 - accuracy: 0.9360 - val_loss: 0.9871 - val_accuracy: 0.8056
Epoch 76/110
 - 1s - loss: 0.3226 - accuracy: 0.9314 - val_loss: 1.0519 - val_accuracy: 0.7774
Epoch 77/110
 - 1s - loss: 0.3563 - accuracy: 0.9293 - val_loss: 1.0047 - val_accuracy: 0.7957
Epoch 78/110
 - 1s - loss: 0.3063 - accuracy: 0.9389 - val_loss: 1.0459 - val_accuracy: 0.7824
Epoch 79/110
 - 1s - loss: 0.2943 - accuracy: 0.9464 - val_loss: 1.0944 - val_accuracy: 0.7542
Epoch 80/110
 - 1s - loss: 0.2811 - accuracy: 0.9518 - val_loss: 1.0551 - val_accuracy: 0.7791
Epoch 81/110
 - 1s - loss: 0.2919 - accuracy: 0.9476 - val_loss: 0.9971 - val_accuracy: 0.7741
Epoch 82/110
 - 1s - loss: 0.2917 - accuracy: 0.9431 - val_loss: 1.0130 - val_accuracy: 0.7757
Epoch 83/110
 - 1s - loss: 0.2992 - accuracy: 0.9480 - val_loss: 1.0705 - val_accuracy: 0.7990
Epoch 84/110
 - 1s - loss: 0.2801 - accuracy: 0.9539 - val_loss: 1.0194 - val_accuracy: 0.8007
Epoch 85/110
 - 1s - loss: 0.2751 - accuracy: 0.9460 - val_loss: 0.9757 - val_accuracy: 0.8140
Epoch 86/110
 - 1s - loss: 0.2830 - accuracy: 0.9493 - val_loss: 1.0046 - val_accuracy: 0.7774
Epoch 87/110
 - 1s - loss: 0.2806 - accuracy: 0.9464 - val_loss: 1.0308 - val_accuracy: 0.7924
Epoch 88/110
 - 1s - loss: 0.2896 - accuracy: 0.9451 - val_loss: 1.0259 - val_accuracy: 0.7907
Epoch 89/110
 - 1s - loss: 0.2918 - accuracy: 0.9439 - val_loss: 1.0487 - val_accuracy: 0.7890
Epoch 90/110
 - 1s - loss: 0.2503 - accuracy: 0.9597 - val_loss: 1.0093 - val_accuracy: 0.7890
Epoch 91/110
 - 1s - loss: 0.2721 - accuracy: 0.9564 - val_loss: 0.9972 - val_accuracy: 0.7757
Epoch 92/110
 - 1s - loss: 0.2725 - accuracy: 0.9580 - val_loss: 1.0725 - val_accuracy: 0.7874
Epoch 93/110
 - 1s - loss: 0.2761 - accuracy: 0.9547 - val_loss: 1.0561 - val_accuracy: 0.7973
Epoch 94/110
 - 1s - loss: 0.2779 - accuracy: 0.9489 - val_loss: 1.0217 - val_accuracy: 0.8073
Epoch 95/110
 - 1s - loss: 0.2578 - accuracy: 0.9539 - val_loss: 0.9439 - val_accuracy: 0.8256
Epoch 96/110
 - 1s - loss: 0.2766 - accuracy: 0.9530 - val_loss: 1.0054 - val_accuracy: 0.7940
Epoch 97/110
 - 1s - loss: 0.2668 - accuracy: 0.9551 - val_loss: 0.9846 - val_accuracy: 0.8140
Epoch 98/110
 - 1s - loss: 0.2630 - accuracy: 0.9547 - val_loss: 1.0325 - val_accuracy: 0.8106
Epoch 99/110
 - 1s - loss: 0.2923 - accuracy: 0.9472 - val_loss: 0.9335 - val_accuracy: 0.8322
Epoch 100/110
 - 1s - loss: 0.2845 - accuracy: 0.9501 - val_loss: 0.9250 - val_accuracy: 0.8455
Epoch 101/110
 - 1s - loss: 0.2699 - accuracy: 0.9514 - val_loss: 0.9201 - val_accuracy: 0.8206
Epoch 102/110
 - 1s - loss: 0.2541 - accuracy: 0.9618 - val_loss: 0.9774 - val_accuracy: 0.8140
Epoch 103/110
 - 1s - loss: 0.2540 - accuracy: 0.9622 - val_loss: 0.9931 - val_accuracy: 0.8173
Epoch 104/110
 - 1s - loss: 0.2697 - accuracy: 0.9493 - val_loss: 0.9742 - val_accuracy: 0.7973
Epoch 105/110
 - 1s - loss: 0.2607 - accuracy: 0.9543 - val_loss: 0.9846 - val_accuracy: 0.8123
Epoch 106/110
 - 1s - loss: 0.2752 - accuracy: 0.9534 - val_loss: 1.0784 - val_accuracy: 0.7973
Epoch 107/110
 - 1s - loss: 0.2663 - accuracy: 0.9539 - val_loss: 1.0023 - val_accuracy: 0.8040
Epoch 108/110
 - 1s - loss: 0.2542 - accuracy: 0.9597 - val_loss: 1.0182 - val_accuracy: 0.7957
Epoch 109/110
 - 1s - loss: 0.2440 - accuracy: 0.9597 - val_loss: 1.0864 - val_accuracy: 0.8040
Epoch 110/110
 - 1s - loss: 0.2682 - accuracy: 0.9580 - val_loss: 1.0762 - val_accuracy: 0.8123
------------------------------------------------------------------------
Training for fold 5 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 5s - loss: 1.5068 - accuracy: 0.6430 - val_loss: 5.3456 - val_accuracy: 0.2093
Epoch 2/110
 - 1s - loss: 0.7734 - accuracy: 0.7801 - val_loss: 1.4562 - val_accuracy: 0.4585
Epoch 3/110
 - 1s - loss: 0.6885 - accuracy: 0.7968 - val_loss: 1.0432 - val_accuracy: 0.6379
Epoch 4/110
 - 1s - loss: 0.6446 - accuracy: 0.8155 - val_loss: 0.8563 - val_accuracy: 0.7542
Epoch 5/110
 - 1s - loss: 0.6108 - accuracy: 0.8300 - val_loss: 0.8096 - val_accuracy: 0.7658
Epoch 6/110
 - 1s - loss: 0.5848 - accuracy: 0.8400 - val_loss: 0.7916 - val_accuracy: 0.7757
Epoch 7/110
 - 1s - loss: 0.5724 - accuracy: 0.8421 - val_loss: 0.7625 - val_accuracy: 0.7874
Epoch 8/110
 - 1s - loss: 0.5740 - accuracy: 0.8441 - val_loss: 0.8112 - val_accuracy: 0.7674
Epoch 9/110
 - 1s - loss: 0.5799 - accuracy: 0.8425 - val_loss: 0.7360 - val_accuracy: 0.8007
Epoch 10/110
 - 1s - loss: 0.5611 - accuracy: 0.8454 - val_loss: 0.7917 - val_accuracy: 0.7907
Epoch 11/110
 - 1s - loss: 0.5358 - accuracy: 0.8562 - val_loss: 0.7333 - val_accuracy: 0.7890
Epoch 12/110
 - 1s - loss: 0.5338 - accuracy: 0.8537 - val_loss: 0.7487 - val_accuracy: 0.7957
Epoch 13/110
 - 1s - loss: 0.5087 - accuracy: 0.8662 - val_loss: 0.7271 - val_accuracy: 0.8007
Epoch 14/110
 - 1s - loss: 0.5251 - accuracy: 0.8537 - val_loss: 0.7420 - val_accuracy: 0.7957
Epoch 15/110
 - 1s - loss: 0.5131 - accuracy: 0.8678 - val_loss: 0.7519 - val_accuracy: 0.7691
Epoch 16/110
 - 1s - loss: 0.4961 - accuracy: 0.8691 - val_loss: 0.7988 - val_accuracy: 0.7741
Epoch 17/110
 - 1s - loss: 0.5018 - accuracy: 0.8682 - val_loss: 0.8143 - val_accuracy: 0.7807
Epoch 18/110
 - 1s - loss: 0.4821 - accuracy: 0.8732 - val_loss: 0.8244 - val_accuracy: 0.7641
Epoch 19/110
 - 1s - loss: 0.4604 - accuracy: 0.8824 - val_loss: 0.8675 - val_accuracy: 0.7442
Epoch 20/110
 - 1s - loss: 0.4598 - accuracy: 0.8815 - val_loss: 0.7529 - val_accuracy: 0.7990
Epoch 21/110
 - 1s - loss: 0.4422 - accuracy: 0.8886 - val_loss: 0.7669 - val_accuracy: 0.7841
Epoch 22/110
 - 1s - loss: 0.4508 - accuracy: 0.8845 - val_loss: 0.8377 - val_accuracy: 0.7492
Epoch 23/110
 - 1s - loss: 0.4460 - accuracy: 0.8820 - val_loss: 0.8202 - val_accuracy: 0.7658
Epoch 24/110
 - 1s - loss: 0.4272 - accuracy: 0.8919 - val_loss: 0.8668 - val_accuracy: 0.7475
Epoch 25/110
 - 1s - loss: 0.4212 - accuracy: 0.8944 - val_loss: 0.8123 - val_accuracy: 0.7841
Epoch 26/110
 - 1s - loss: 0.4188 - accuracy: 0.8994 - val_loss: 0.9036 - val_accuracy: 0.7774
Epoch 27/110
 - 1s - loss: 0.4540 - accuracy: 0.8820 - val_loss: 0.8651 - val_accuracy: 0.7724
Epoch 28/110
 - 1s - loss: 0.4447 - accuracy: 0.8803 - val_loss: 0.8753 - val_accuracy: 0.7774
Epoch 29/110
 - 1s - loss: 0.4491 - accuracy: 0.8807 - val_loss: 0.8373 - val_accuracy: 0.7990
Epoch 30/110
 - 1s - loss: 0.4464 - accuracy: 0.8820 - val_loss: 0.8517 - val_accuracy: 0.7841
Epoch 31/110
 - 1s - loss: 0.4118 - accuracy: 0.8990 - val_loss: 0.8096 - val_accuracy: 0.7907
Epoch 32/110
 - 1s - loss: 0.4198 - accuracy: 0.8969 - val_loss: 0.7830 - val_accuracy: 0.7924
Epoch 33/110
 - 1s - loss: 0.4264 - accuracy: 0.8903 - val_loss: 0.9110 - val_accuracy: 0.7824
Epoch 34/110
 - 1s - loss: 0.4353 - accuracy: 0.8928 - val_loss: 0.8676 - val_accuracy: 0.7973
Epoch 35/110
 - 1s - loss: 0.4205 - accuracy: 0.8944 - val_loss: 0.9594 - val_accuracy: 0.7857
Epoch 36/110
 - 1s - loss: 0.4194 - accuracy: 0.8969 - val_loss: 0.8899 - val_accuracy: 0.7940
Epoch 37/110
 - 1s - loss: 0.3929 - accuracy: 0.8998 - val_loss: 0.8544 - val_accuracy: 0.7841
Epoch 38/110
 - 1s - loss: 0.3934 - accuracy: 0.9011 - val_loss: 0.8242 - val_accuracy: 0.7973
Epoch 39/110
 - 1s - loss: 0.3768 - accuracy: 0.9140 - val_loss: 0.8962 - val_accuracy: 0.7708
Epoch 40/110
 - 1s - loss: 0.3672 - accuracy: 0.9181 - val_loss: 0.8931 - val_accuracy: 0.7940
Epoch 41/110
 - 1s - loss: 0.3728 - accuracy: 0.9165 - val_loss: 0.8026 - val_accuracy: 0.8073
Epoch 42/110
 - 1s - loss: 0.3623 - accuracy: 0.9140 - val_loss: 0.8499 - val_accuracy: 0.8056
Epoch 43/110
 - 1s - loss: 0.3844 - accuracy: 0.9073 - val_loss: 0.9371 - val_accuracy: 0.7874
Epoch 44/110
 - 1s - loss: 0.3601 - accuracy: 0.9185 - val_loss: 0.8822 - val_accuracy: 0.8306
Epoch 45/110
 - 1s - loss: 0.3780 - accuracy: 0.9111 - val_loss: 0.9232 - val_accuracy: 0.8106
Epoch 46/110
 - 1s - loss: 0.3744 - accuracy: 0.9086 - val_loss: 0.8903 - val_accuracy: 0.7674
Epoch 47/110
 - 1s - loss: 0.3557 - accuracy: 0.9181 - val_loss: 0.9014 - val_accuracy: 0.7791
Epoch 48/110
 - 1s - loss: 0.3500 - accuracy: 0.9244 - val_loss: 0.9276 - val_accuracy: 0.7824
Epoch 49/110
 - 1s - loss: 0.3339 - accuracy: 0.9198 - val_loss: 0.9856 - val_accuracy: 0.7907
Epoch 50/110
 - 1s - loss: 0.3464 - accuracy: 0.9239 - val_loss: 0.9315 - val_accuracy: 0.8023
Epoch 51/110
 - 1s - loss: 0.3434 - accuracy: 0.9239 - val_loss: 0.9216 - val_accuracy: 0.8322
Epoch 52/110
 - 1s - loss: 0.3288 - accuracy: 0.9314 - val_loss: 0.9515 - val_accuracy: 0.8156
Epoch 53/110
 - 1s - loss: 0.3245 - accuracy: 0.9289 - val_loss: 0.9315 - val_accuracy: 0.8206
Epoch 54/110
 - 1s - loss: 0.3116 - accuracy: 0.9381 - val_loss: 1.1571 - val_accuracy: 0.7890
Epoch 55/110
 - 1s - loss: 0.3182 - accuracy: 0.9385 - val_loss: 0.9296 - val_accuracy: 0.8289
Epoch 56/110
 - 1s - loss: 0.3162 - accuracy: 0.9364 - val_loss: 1.0026 - val_accuracy: 0.8023
Epoch 57/110
 - 1s - loss: 0.3390 - accuracy: 0.9323 - val_loss: 1.0255 - val_accuracy: 0.7924
Epoch 58/110
 - 1s - loss: 0.3424 - accuracy: 0.9231 - val_loss: 0.9933 - val_accuracy: 0.8106
Epoch 59/110
 - 1s - loss: 0.3365 - accuracy: 0.9327 - val_loss: 0.9761 - val_accuracy: 0.8140
Epoch 60/110
 - 1s - loss: 0.3176 - accuracy: 0.9310 - val_loss: 0.9922 - val_accuracy: 0.7841
Epoch 61/110
 - 1s - loss: 0.3242 - accuracy: 0.9339 - val_loss: 0.9916 - val_accuracy: 0.8040
Epoch 62/110
 - 1s - loss: 0.3240 - accuracy: 0.9335 - val_loss: 1.0250 - val_accuracy: 0.7791
Epoch 63/110
 - 1s - loss: 0.3161 - accuracy: 0.9439 - val_loss: 0.9047 - val_accuracy: 0.8106
Epoch 64/110
 - 1s - loss: 0.3034 - accuracy: 0.9472 - val_loss: 1.0065 - val_accuracy: 0.7940
Epoch 65/110
 - 1s - loss: 0.2851 - accuracy: 0.9501 - val_loss: 0.9690 - val_accuracy: 0.7973
Epoch 66/110
 - 1s - loss: 0.3067 - accuracy: 0.9447 - val_loss: 0.9931 - val_accuracy: 0.8173
Epoch 67/110
 - 1s - loss: 0.2932 - accuracy: 0.9389 - val_loss: 1.0087 - val_accuracy: 0.8173
Epoch 68/110
 - 1s - loss: 0.2928 - accuracy: 0.9514 - val_loss: 0.9856 - val_accuracy: 0.8189
Epoch 69/110
 - 1s - loss: 0.3089 - accuracy: 0.9393 - val_loss: 1.0517 - val_accuracy: 0.7807
Epoch 70/110
 - 1s - loss: 0.3191 - accuracy: 0.9364 - val_loss: 0.9493 - val_accuracy: 0.8223
Epoch 71/110
 - 1s - loss: 0.2977 - accuracy: 0.9414 - val_loss: 0.9291 - val_accuracy: 0.8306
Epoch 72/110
 - 1s - loss: 0.2982 - accuracy: 0.9418 - val_loss: 1.0582 - val_accuracy: 0.8256
Epoch 73/110
 - 1s - loss: 0.2696 - accuracy: 0.9580 - val_loss: 1.0453 - val_accuracy: 0.8256
Epoch 74/110
 - 1s - loss: 0.2615 - accuracy: 0.9580 - val_loss: 0.9968 - val_accuracy: 0.8189
Epoch 75/110
 - 1s - loss: 0.2612 - accuracy: 0.9589 - val_loss: 1.1232 - val_accuracy: 0.7990
Epoch 76/110
 - 1s - loss: 0.3167 - accuracy: 0.9372 - val_loss: 1.1972 - val_accuracy: 0.7890
Epoch 77/110
 - 1s - loss: 0.3262 - accuracy: 0.9393 - val_loss: 1.2616 - val_accuracy: 0.8056
Epoch 78/110
 - 1s - loss: 0.3149 - accuracy: 0.9385 - val_loss: 0.9466 - val_accuracy: 0.8106
Epoch 79/110
 - 1s - loss: 0.2842 - accuracy: 0.9472 - val_loss: 1.1932 - val_accuracy: 0.8023
Epoch 80/110
 - 1s - loss: 0.2744 - accuracy: 0.9543 - val_loss: 1.2264 - val_accuracy: 0.8073
Epoch 81/110
 - 1s - loss: 0.3139 - accuracy: 0.9414 - val_loss: 1.1046 - val_accuracy: 0.7890
Epoch 82/110
 - 1s - loss: 0.3121 - accuracy: 0.9381 - val_loss: 1.2112 - val_accuracy: 0.7957
Epoch 83/110
 - 1s - loss: 0.2942 - accuracy: 0.9431 - val_loss: 1.0987 - val_accuracy: 0.8156
Epoch 84/110
 - 1s - loss: 0.2733 - accuracy: 0.9526 - val_loss: 1.0169 - val_accuracy: 0.8189
Epoch 85/110
 - 1s - loss: 0.2715 - accuracy: 0.9555 - val_loss: 1.0214 - val_accuracy: 0.8339
Epoch 86/110
 - 1s - loss: 0.2507 - accuracy: 0.9630 - val_loss: 1.0648 - val_accuracy: 0.8372
Epoch 87/110
 - 1s - loss: 0.2422 - accuracy: 0.9667 - val_loss: 1.0724 - val_accuracy: 0.8289
Epoch 88/110
 - 1s - loss: 0.2546 - accuracy: 0.9584 - val_loss: 1.1426 - val_accuracy: 0.8007
Epoch 89/110
 - 1s - loss: 0.2786 - accuracy: 0.9543 - val_loss: 1.0120 - val_accuracy: 0.8272
Epoch 90/110
 - 1s - loss: 0.2700 - accuracy: 0.9534 - val_loss: 1.0897 - val_accuracy: 0.8272
Epoch 91/110
 - 1s - loss: 0.2793 - accuracy: 0.9580 - val_loss: 1.0711 - val_accuracy: 0.8140
Epoch 92/110
 - 1s - loss: 0.2427 - accuracy: 0.9622 - val_loss: 0.9819 - val_accuracy: 0.8289
Epoch 93/110
 - 1s - loss: 0.2556 - accuracy: 0.9576 - val_loss: 1.1344 - val_accuracy: 0.8156
Epoch 94/110
 - 1s - loss: 0.2674 - accuracy: 0.9572 - val_loss: 1.0870 - val_accuracy: 0.8206
Epoch 95/110
 - 1s - loss: 0.2809 - accuracy: 0.9576 - val_loss: 1.2097 - val_accuracy: 0.7940
Epoch 96/110
 - 1s - loss: 0.2920 - accuracy: 0.9468 - val_loss: 1.1482 - val_accuracy: 0.8007
Epoch 97/110
 - 1s - loss: 0.2805 - accuracy: 0.9547 - val_loss: 1.0863 - val_accuracy: 0.8140
Epoch 98/110
 - 1s - loss: 0.2851 - accuracy: 0.9530 - val_loss: 0.9999 - val_accuracy: 0.8073
Epoch 99/110
 - 1s - loss: 0.2641 - accuracy: 0.9584 - val_loss: 1.2444 - val_accuracy: 0.8023
Epoch 100/110
 - 1s - loss: 0.2663 - accuracy: 0.9589 - val_loss: 1.2387 - val_accuracy: 0.8073
Epoch 101/110
 - 1s - loss: 0.2627 - accuracy: 0.9584 - val_loss: 1.3505 - val_accuracy: 0.8056
Epoch 102/110
 - 1s - loss: 0.2647 - accuracy: 0.9576 - val_loss: 1.2717 - val_accuracy: 0.7824
Epoch 103/110
 - 1s - loss: 0.2750 - accuracy: 0.9530 - val_loss: 1.2184 - val_accuracy: 0.8140
Epoch 104/110
 - 1s - loss: 0.2618 - accuracy: 0.9572 - val_loss: 1.0393 - val_accuracy: 0.8073
Epoch 105/110
 - 1s - loss: 0.2683 - accuracy: 0.9559 - val_loss: 1.0673 - val_accuracy: 0.8173
Epoch 106/110
 - 1s - loss: 0.2549 - accuracy: 0.9576 - val_loss: 1.3074 - val_accuracy: 0.8106
Epoch 107/110
 - 1s - loss: 0.2410 - accuracy: 0.9676 - val_loss: 1.0767 - val_accuracy: 0.8189
Epoch 108/110
 - 1s - loss: 0.2380 - accuracy: 0.9651 - val_loss: 1.0452 - val_accuracy: 0.8339
Epoch 109/110
 - 1s - loss: 0.2809 - accuracy: 0.9518 - val_loss: 1.1571 - val_accuracy: 0.8073
Epoch 110/110
 - 1s - loss: 0.2886 - accuracy: 0.9518 - val_loss: 1.1292 - val_accuracy: 0.7990
------------------------------------------------------------------------
Score per fold
------------------------------------------------------------------------
Score for fold 1
Accuracy_Train: 83.41%
Accuracy_Test: 82.45%
Loss_Train: 0.83
Loss_Test: 0.91
------------------------------------------------------------------------
Score for fold 2
Accuracy_Train: 82.68%
Accuracy_Test: 82.31%
Loss_Train: 0.84
Loss_Test: 0.87
------------------------------------------------------------------------
Score for fold 3
Accuracy_Train: 83.44%
Accuracy_Test: 83.91%
Loss_Train: 0.86
Loss_Test: 0.86
------------------------------------------------------------------------
Score for fold 4
Accuracy_Train: 82.85%
Accuracy_Test: 81.38%
Loss_Train: 0.82
Loss_Test: 0.85
------------------------------------------------------------------------
Score for fold 5
Accuracy_Train: 81.48%
Accuracy_Test: 81.52%
Loss_Train: 0.86
Loss_Test: 0.82
------------------------------------------------------------------------
Average scores for all folds:
Average_Accuracy_Train: 82.77%
	-> (+- 0.7122122668221413 )
Average_Accuracy_Test: 82.31%
	-> (+- 0.9019069254042619 )
Average_Loss_Train: 0.84
	-> (+- 0.016510662098111244 )
Average_Loss_Test: 0.86
	-> (+- 0.028147744651403687 )
------------------------------------------------------------------------
