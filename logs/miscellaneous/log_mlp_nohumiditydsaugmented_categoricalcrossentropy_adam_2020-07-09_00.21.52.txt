Dataset used: ../../datasets/train_dataset_for_augmentation.csv 

   Temperature  Sound  Heartbeat   X1  ...    Y2     Z2  Classification  Feedback
0           32      1         60 -680  ... -7424 -15596             100     Happy
1           32      1         60 -780  ... -7408 -15628             100     Happy
2           -1      1         60   -1  ... -7276 -15612             100     Happy
3           -1     -1         60   -1  ...    -1     -1             100     Happy
4           32      1         60 -860  ... -7340 -15720             100     Happy

[5 rows x 11 columns]

Objservations: 12276

Layers:

{'name': 'dense_1', 'trainable': True, 'batch_input_shape': (None, 10), 'dtype': 'float32', 'units': 10, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 500, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 300, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 50, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 7856 samples, validate on 1964 samples
Epoch 1/128
 - 2s - loss: 0.7500 - accuracy: 0.7233 - val_loss: 0.6296 - val_accuracy: 0.7719
Epoch 2/128
 - 1s - loss: 0.6446 - accuracy: 0.7730 - val_loss: 0.6129 - val_accuracy: 0.7826
Epoch 3/128
 - 1s - loss: 0.6170 - accuracy: 0.7790 - val_loss: 0.5846 - val_accuracy: 0.7882
Epoch 4/128
 - 1s - loss: 0.5931 - accuracy: 0.7846 - val_loss: 0.5706 - val_accuracy: 0.7923
Epoch 5/128
 - 1s - loss: 0.5769 - accuracy: 0.7928 - val_loss: 0.5637 - val_accuracy: 0.8019
Epoch 6/128
 - 2s - loss: 0.5623 - accuracy: 0.7988 - val_loss: 0.5522 - val_accuracy: 0.8024
Epoch 7/128
 - 1s - loss: 0.5493 - accuracy: 0.8023 - val_loss: 0.5451 - val_accuracy: 0.8024
Epoch 8/128
 - 1s - loss: 0.5387 - accuracy: 0.8046 - val_loss: 0.5399 - val_accuracy: 0.8055
Epoch 9/128
 - 1s - loss: 0.5281 - accuracy: 0.8093 - val_loss: 0.5336 - val_accuracy: 0.8030
Epoch 10/128
 - 1s - loss: 0.5182 - accuracy: 0.8121 - val_loss: 0.5402 - val_accuracy: 0.8070
Epoch 11/128
 - 1s - loss: 0.5101 - accuracy: 0.8125 - val_loss: 0.5245 - val_accuracy: 0.7984
Epoch 12/128
 - 1s - loss: 0.5001 - accuracy: 0.8166 - val_loss: 0.5221 - val_accuracy: 0.7912
Epoch 13/128
 - 1s - loss: 0.4870 - accuracy: 0.8220 - val_loss: 0.5191 - val_accuracy: 0.7999
Epoch 14/128
 - 1s - loss: 0.4788 - accuracy: 0.8222 - val_loss: 0.4999 - val_accuracy: 0.8070
Epoch 15/128
 - 1s - loss: 0.4729 - accuracy: 0.8212 - val_loss: 0.4856 - val_accuracy: 0.8116
Epoch 16/128
 - 1s - loss: 0.4656 - accuracy: 0.8234 - val_loss: 0.4832 - val_accuracy: 0.8101
Epoch 17/128
 - 1s - loss: 0.4591 - accuracy: 0.8237 - val_loss: 0.4914 - val_accuracy: 0.8004
Epoch 18/128
 - 1s - loss: 0.4477 - accuracy: 0.8293 - val_loss: 0.4857 - val_accuracy: 0.8106
Epoch 19/128
 - 1s - loss: 0.4417 - accuracy: 0.8311 - val_loss: 0.4785 - val_accuracy: 0.8152
Epoch 20/128
 - 1s - loss: 0.4356 - accuracy: 0.8311 - val_loss: 0.4617 - val_accuracy: 0.8213
Epoch 21/128
 - 1s - loss: 0.4256 - accuracy: 0.8349 - val_loss: 0.4697 - val_accuracy: 0.8167
Epoch 22/128
 - 1s - loss: 0.4251 - accuracy: 0.8336 - val_loss: 0.4766 - val_accuracy: 0.8121
Epoch 23/128
 - 1s - loss: 0.4155 - accuracy: 0.8369 - val_loss: 0.4484 - val_accuracy: 0.8284
Epoch 24/128
 - 1s - loss: 0.4065 - accuracy: 0.8401 - val_loss: 0.4405 - val_accuracy: 0.8274
Epoch 25/128
 - 1s - loss: 0.4018 - accuracy: 0.8425 - val_loss: 0.4292 - val_accuracy: 0.8269
Epoch 26/128
 - 1s - loss: 0.4025 - accuracy: 0.8442 - val_loss: 0.4321 - val_accuracy: 0.8381
Epoch 27/128
 - 1s - loss: 0.3941 - accuracy: 0.8448 - val_loss: 0.4216 - val_accuracy: 0.8310
Epoch 28/128
 - 1s - loss: 0.3863 - accuracy: 0.8504 - val_loss: 0.4349 - val_accuracy: 0.8274
Epoch 29/128
 - 1s - loss: 0.3797 - accuracy: 0.8534 - val_loss: 0.4120 - val_accuracy: 0.8381
Epoch 30/128
 - 1s - loss: 0.3800 - accuracy: 0.8530 - val_loss: 0.4199 - val_accuracy: 0.8396
Epoch 31/128
 - 1s - loss: 0.3730 - accuracy: 0.8527 - val_loss: 0.4114 - val_accuracy: 0.8350
Epoch 32/128
 - 1s - loss: 0.3732 - accuracy: 0.8537 - val_loss: 0.4020 - val_accuracy: 0.8447
Epoch 33/128
 - 1s - loss: 0.3692 - accuracy: 0.8569 - val_loss: 0.4207 - val_accuracy: 0.8325
Epoch 34/128
 - 1s - loss: 0.3694 - accuracy: 0.8551 - val_loss: 0.4032 - val_accuracy: 0.8437
Epoch 35/128
 - 1s - loss: 0.3605 - accuracy: 0.8599 - val_loss: 0.4085 - val_accuracy: 0.8442
Epoch 36/128
 - 1s - loss: 0.3518 - accuracy: 0.8620 - val_loss: 0.3826 - val_accuracy: 0.8498
Epoch 37/128
 - 1s - loss: 0.3459 - accuracy: 0.8646 - val_loss: 0.3824 - val_accuracy: 0.8539
Epoch 38/128
 - 1s - loss: 0.3421 - accuracy: 0.8634 - val_loss: 0.3937 - val_accuracy: 0.8498
Epoch 39/128
 - 1s - loss: 0.3418 - accuracy: 0.8643 - val_loss: 0.3890 - val_accuracy: 0.8508
Epoch 40/128
 - 1s - loss: 0.3398 - accuracy: 0.8637 - val_loss: 0.3794 - val_accuracy: 0.8544
Epoch 41/128
 - 1s - loss: 0.3341 - accuracy: 0.8684 - val_loss: 0.3817 - val_accuracy: 0.8605
Epoch 42/128
 - 1s - loss: 0.3284 - accuracy: 0.8676 - val_loss: 0.3889 - val_accuracy: 0.8513
Epoch 43/128
 - 1s - loss: 0.3268 - accuracy: 0.8671 - val_loss: 0.4004 - val_accuracy: 0.8549
Epoch 44/128
 - 1s - loss: 0.3452 - accuracy: 0.8601 - val_loss: 0.3590 - val_accuracy: 0.8574
Epoch 45/128
 - 1s - loss: 0.3210 - accuracy: 0.8675 - val_loss: 0.3618 - val_accuracy: 0.8564
Epoch 46/128
 - 1s - loss: 0.3138 - accuracy: 0.8694 - val_loss: 0.3617 - val_accuracy: 0.8615
Epoch 47/128
 - 1s - loss: 0.3124 - accuracy: 0.8717 - val_loss: 0.3595 - val_accuracy: 0.8661
Epoch 48/128
 - 1s - loss: 0.3119 - accuracy: 0.8718 - val_loss: 0.3571 - val_accuracy: 0.8605
Epoch 49/128
 - 2s - loss: 0.3053 - accuracy: 0.8727 - val_loss: 0.3620 - val_accuracy: 0.8641
Epoch 50/128
 - 1s - loss: 0.3128 - accuracy: 0.8691 - val_loss: 0.3617 - val_accuracy: 0.8641
Epoch 51/128
 - 1s - loss: 0.2970 - accuracy: 0.8758 - val_loss: 0.3592 - val_accuracy: 0.8676
Epoch 52/128
 - 1s - loss: 0.3032 - accuracy: 0.8737 - val_loss: 0.3733 - val_accuracy: 0.8620
Epoch 53/128
 - 1s - loss: 0.2981 - accuracy: 0.8761 - val_loss: 0.3551 - val_accuracy: 0.8635
Epoch 54/128
 - 1s - loss: 0.2914 - accuracy: 0.8770 - val_loss: 0.3804 - val_accuracy: 0.8620
Epoch 55/128
 - 1s - loss: 0.2960 - accuracy: 0.8769 - val_loss: 0.3840 - val_accuracy: 0.8630
Epoch 56/128
 - 1s - loss: 0.2942 - accuracy: 0.8746 - val_loss: 0.3877 - val_accuracy: 0.8554
Epoch 57/128
 - 2s - loss: 0.2925 - accuracy: 0.8767 - val_loss: 0.3904 - val_accuracy: 0.8595
Epoch 58/128
 - 1s - loss: 0.2850 - accuracy: 0.8773 - val_loss: 0.3854 - val_accuracy: 0.8503
Epoch 59/128
 - 1s - loss: 0.2812 - accuracy: 0.8809 - val_loss: 0.3806 - val_accuracy: 0.8610
Epoch 60/128
 - 2s - loss: 0.2857 - accuracy: 0.8809 - val_loss: 0.3803 - val_accuracy: 0.8554
Epoch 61/128
 - 2s - loss: 0.2839 - accuracy: 0.8801 - val_loss: 0.3576 - val_accuracy: 0.8671
Epoch 62/128
 - 2s - loss: 0.2992 - accuracy: 0.8779 - val_loss: 0.3662 - val_accuracy: 0.8498
Epoch 63/128
 - 2s - loss: 0.2868 - accuracy: 0.8793 - val_loss: 0.4180 - val_accuracy: 0.8473
Epoch 64/128
 - 2s - loss: 0.2897 - accuracy: 0.8782 - val_loss: 0.3518 - val_accuracy: 0.8697
Epoch 65/128
 - 1s - loss: 0.2768 - accuracy: 0.8842 - val_loss: 0.3766 - val_accuracy: 0.8539
Epoch 66/128
 - 1s - loss: 0.2715 - accuracy: 0.8843 - val_loss: 0.3670 - val_accuracy: 0.8732
Epoch 67/128
 - 2s - loss: 0.2729 - accuracy: 0.8821 - val_loss: 0.3673 - val_accuracy: 0.8595
Epoch 68/128
 - 2s - loss: 0.2804 - accuracy: 0.8835 - val_loss: 0.3390 - val_accuracy: 0.8727
Epoch 69/128
 - 1s - loss: 0.2681 - accuracy: 0.8886 - val_loss: 0.3453 - val_accuracy: 0.8671
Epoch 70/128
 - 2s - loss: 0.2703 - accuracy: 0.8868 - val_loss: 0.3478 - val_accuracy: 0.8722
Epoch 71/128
 - 2s - loss: 0.2678 - accuracy: 0.8858 - val_loss: 0.3477 - val_accuracy: 0.8686
Epoch 72/128
 - 1s - loss: 0.2664 - accuracy: 0.8886 - val_loss: 0.3546 - val_accuracy: 0.8737
Epoch 73/128
 - 1s - loss: 0.2675 - accuracy: 0.8879 - val_loss: 0.3592 - val_accuracy: 0.8707
Epoch 74/128
 - 1s - loss: 0.2630 - accuracy: 0.8875 - val_loss: 0.3666 - val_accuracy: 0.8686
Epoch 75/128
 - 1s - loss: 0.2740 - accuracy: 0.8844 - val_loss: 0.3808 - val_accuracy: 0.8681
Epoch 76/128
 - 1s - loss: 0.2750 - accuracy: 0.8838 - val_loss: 0.3717 - val_accuracy: 0.8732
Epoch 77/128
 - 1s - loss: 0.2670 - accuracy: 0.8859 - val_loss: 0.3489 - val_accuracy: 0.8747
Epoch 78/128
 - 1s - loss: 0.2570 - accuracy: 0.8907 - val_loss: 0.3339 - val_accuracy: 0.8712
Epoch 79/128
 - 1s - loss: 0.2633 - accuracy: 0.8881 - val_loss: 0.3350 - val_accuracy: 0.8681
Epoch 80/128
 - 1s - loss: 0.2636 - accuracy: 0.8875 - val_loss: 0.3406 - val_accuracy: 0.8722
Epoch 81/128
 - 1s - loss: 0.2611 - accuracy: 0.8903 - val_loss: 0.3201 - val_accuracy: 0.8717
Epoch 82/128
 - 1s - loss: 0.2761 - accuracy: 0.8848 - val_loss: 0.3438 - val_accuracy: 0.8737
Epoch 83/128
 - 1s - loss: 0.2622 - accuracy: 0.8885 - val_loss: 0.3438 - val_accuracy: 0.8671
Epoch 84/128
 - 1s - loss: 0.2621 - accuracy: 0.8893 - val_loss: 0.3347 - val_accuracy: 0.8717
Epoch 85/128
 - 1s - loss: 0.2693 - accuracy: 0.8870 - val_loss: 0.3282 - val_accuracy: 0.8656
Epoch 86/128
 - 1s - loss: 0.2561 - accuracy: 0.8899 - val_loss: 0.3427 - val_accuracy: 0.8691
Epoch 87/128
 - 1s - loss: 0.2526 - accuracy: 0.8924 - val_loss: 0.3438 - val_accuracy: 0.8707
Epoch 88/128
 - 1s - loss: 0.2561 - accuracy: 0.8931 - val_loss: 0.3483 - val_accuracy: 0.8722
Epoch 89/128
 - 1s - loss: 0.2641 - accuracy: 0.8885 - val_loss: 0.3338 - val_accuracy: 0.8651
Epoch 90/128
 - 1s - loss: 0.2638 - accuracy: 0.8884 - val_loss: 0.3379 - val_accuracy: 0.8717
Epoch 91/128
 - 1s - loss: 0.2556 - accuracy: 0.8895 - val_loss: 0.3386 - val_accuracy: 0.8697
Epoch 92/128
 - 1s - loss: 0.2497 - accuracy: 0.8936 - val_loss: 0.3489 - val_accuracy: 0.8763
Epoch 93/128
 - 1s - loss: 0.2467 - accuracy: 0.8927 - val_loss: 0.3370 - val_accuracy: 0.8778
Epoch 94/128
 - 1s - loss: 0.2397 - accuracy: 0.8975 - val_loss: 0.3504 - val_accuracy: 0.8747
Epoch 95/128
 - 1s - loss: 0.2541 - accuracy: 0.8903 - val_loss: 0.3340 - val_accuracy: 0.8753
Epoch 96/128
 - 1s - loss: 0.2458 - accuracy: 0.8955 - val_loss: 0.3511 - val_accuracy: 0.8783
Epoch 97/128
 - 1s - loss: 0.2561 - accuracy: 0.8917 - val_loss: 0.3570 - val_accuracy: 0.8742
Epoch 98/128
 - 1s - loss: 0.2488 - accuracy: 0.8924 - val_loss: 0.3506 - val_accuracy: 0.8681
Epoch 99/128
 - 1s - loss: 0.2530 - accuracy: 0.8952 - val_loss: 0.3159 - val_accuracy: 0.8742
Epoch 100/128
 - 1s - loss: 0.2535 - accuracy: 0.8928 - val_loss: 0.3417 - val_accuracy: 0.8753
Epoch 101/128
 - 1s - loss: 0.2504 - accuracy: 0.8945 - val_loss: 0.3365 - val_accuracy: 0.8722
Epoch 102/128
 - 1s - loss: 0.2420 - accuracy: 0.8966 - val_loss: 0.3280 - val_accuracy: 0.8727
Epoch 103/128
 - 1s - loss: 0.2438 - accuracy: 0.8952 - val_loss: 0.3226 - val_accuracy: 0.8758
Epoch 104/128
 - 1s - loss: 0.2337 - accuracy: 0.9010 - val_loss: 0.3272 - val_accuracy: 0.8788
Epoch 105/128
 - 1s - loss: 0.2405 - accuracy: 0.8984 - val_loss: 0.3391 - val_accuracy: 0.8747
Epoch 106/128
 - 1s - loss: 0.2382 - accuracy: 0.8960 - val_loss: 0.3170 - val_accuracy: 0.8732
Epoch 107/128
 - 1s - loss: 0.2533 - accuracy: 0.8914 - val_loss: 0.3634 - val_accuracy: 0.8549
Epoch 108/128
 - 1s - loss: 0.2641 - accuracy: 0.8873 - val_loss: 0.3523 - val_accuracy: 0.8661
Epoch 109/128
 - 1s - loss: 0.2442 - accuracy: 0.8966 - val_loss: 0.3476 - val_accuracy: 0.8676
Epoch 110/128
 - 1s - loss: 0.2372 - accuracy: 0.8975 - val_loss: 0.3326 - val_accuracy: 0.8778
Epoch 111/128
 - 1s - loss: 0.2411 - accuracy: 0.8959 - val_loss: 0.3372 - val_accuracy: 0.8737
Epoch 112/128
 - 1s - loss: 0.2389 - accuracy: 0.8961 - val_loss: 0.3409 - val_accuracy: 0.8753
Epoch 113/128
 - 1s - loss: 0.2411 - accuracy: 0.8968 - val_loss: 0.3412 - val_accuracy: 0.8758
Epoch 114/128
 - 1s - loss: 0.2370 - accuracy: 0.8997 - val_loss: 0.3464 - val_accuracy: 0.8641
Epoch 115/128
 - 1s - loss: 0.2481 - accuracy: 0.8940 - val_loss: 0.3282 - val_accuracy: 0.8783
Epoch 116/128
 - 1s - loss: 0.2416 - accuracy: 0.8957 - val_loss: 0.3339 - val_accuracy: 0.8819
Epoch 117/128
 - 1s - loss: 0.2575 - accuracy: 0.8900 - val_loss: 0.3372 - val_accuracy: 0.8712
Epoch 118/128
 - 1s - loss: 0.2389 - accuracy: 0.8959 - val_loss: 0.3226 - val_accuracy: 0.8753
Epoch 119/128
 - 1s - loss: 0.2365 - accuracy: 0.8980 - val_loss: 0.3407 - val_accuracy: 0.8722
Epoch 120/128
 - 1s - loss: 0.2397 - accuracy: 0.8960 - val_loss: 0.3267 - val_accuracy: 0.8753
Epoch 121/128
 - 1s - loss: 0.2331 - accuracy: 0.9005 - val_loss: 0.3317 - val_accuracy: 0.8783
Epoch 122/128
 - 1s - loss: 0.2345 - accuracy: 0.8991 - val_loss: 0.3381 - val_accuracy: 0.8778
Epoch 123/128
 - 1s - loss: 0.2364 - accuracy: 0.8980 - val_loss: 0.3467 - val_accuracy: 0.8722
Epoch 124/128
 - 1s - loss: 0.2321 - accuracy: 0.9007 - val_loss: 0.3358 - val_accuracy: 0.8727
Epoch 125/128
 - 1s - loss: 0.2385 - accuracy: 0.8982 - val_loss: 0.3712 - val_accuracy: 0.8768
Epoch 126/128
 - 1s - loss: 0.2359 - accuracy: 0.8955 - val_loss: 0.3394 - val_accuracy: 0.8722
Epoch 127/128
 - 1s - loss: 0.2559 - accuracy: 0.8927 - val_loss: 0.3518 - val_accuracy: 0.8788
Epoch 128/128
 - 1s - loss: 0.2493 - accuracy: 0.8946 - val_loss: 0.3696 - val_accuracy: 0.8727

Fit: epochs= 128 , batch_size= 32 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 10)                110       
_________________________________________________________________
dense_2 (Dense)              (None, 500)               5500      
_________________________________________________________________
dense_3 (Dense)              (None, 300)               150300    
_________________________________________________________________
dense_4 (Dense)              (None, 200)               60200     
_________________________________________________________________
dense_5 (Dense)              (None, 100)               20100     
_________________________________________________________________
dense_6 (Dense)              (None, 50)                5050      
_________________________________________________________________
dense_7 (Dense)              (None, 20)                1020      
_________________________________________________________________
dense_8 (Dense)              (None, 4)                 84        
=================================================================
Total params: 242,364
Trainable params: 242,364
Non-trainable params: 0
_________________________________________________________________
None

Accuracy Train: 88.48%
Accuracy Test: 87.21%
Loss Train: 0.30
Loss Test: 0.43
Numero dati esaminati: 2456
True Positive 2142
False Positive 314
