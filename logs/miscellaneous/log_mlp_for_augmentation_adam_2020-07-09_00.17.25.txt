Dataset used: ../../datasets/train_dataset_for_augmentation.csv 

   Temperature  Sound  Heartbeat   X1  ...    Y2     Z2  Classification  Feedback
0           32      1         60 -680  ... -7424 -15596             100     Happy
1           32      1         60 -780  ... -7408 -15628             100     Happy
2           -1      1         60   -1  ... -7276 -15612             100     Happy
3           -1     -1         60   -1  ...    -1     -1             100     Happy
4           32      1         60 -860  ... -7340 -15720             100     Happy

[5 rows x 11 columns]

Objservations: 12276
Dataset used: ../../datasets/test_dataset_for_augmentation.csv 

   Temperature  Sound  Heartbeat   X1  ...    Y2     Z2  Classification  Feedback
0           35      1         64  844  ... -7000 -15764             250       Sad
1           35     -1         64  832  ...    -1     -1             250       Sad
2           35      1         64  768  ... -7000 -15800             250       Sad
3           -1      1         64   -1  ... -7168 -15892             250       Sad
4           35     -1         64  692  ...    -1     -1             250       Sad

[5 rows x 11 columns]

Objservations: 4280

Layers:

{'name': 'dense_1', 'trainable': True, 'batch_input_shape': (None, 10), 'dtype': 'float32', 'units': 10, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 500, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 300, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 50, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 9820 samples, validate on 2456 samples
Epoch 1/128
 - 2s - loss: 0.9999 - accuracy: 0.5582 - val_loss: 0.6121 - val_accuracy: 0.8046
Epoch 2/128
 - 1s - loss: 0.7914 - accuracy: 0.7002 - val_loss: 0.5628 - val_accuracy: 0.8143
Epoch 3/128
 - 1s - loss: 0.7475 - accuracy: 0.7409 - val_loss: 0.5655 - val_accuracy: 0.8131
Epoch 4/128
 - 1s - loss: 0.7164 - accuracy: 0.7537 - val_loss: 0.5777 - val_accuracy: 0.8143
Epoch 5/128
 - 1s - loss: 0.7044 - accuracy: 0.7600 - val_loss: 0.5744 - val_accuracy: 0.8143
Epoch 6/128
 - 1s - loss: 0.6977 - accuracy: 0.7669 - val_loss: 0.5688 - val_accuracy: 0.8135
Epoch 7/128
 - 1s - loss: 0.6899 - accuracy: 0.7714 - val_loss: 0.5801 - val_accuracy: 0.8147
Epoch 8/128
 - 1s - loss: 0.6769 - accuracy: 0.7717 - val_loss: 0.5811 - val_accuracy: 0.8123
Epoch 9/128
 - 1s - loss: 0.6745 - accuracy: 0.7707 - val_loss: 0.5903 - val_accuracy: 0.8131
Epoch 10/128
 - 1s - loss: 0.6693 - accuracy: 0.7723 - val_loss: 0.5974 - val_accuracy: 0.8054
Epoch 11/128
 - 1s - loss: 0.6627 - accuracy: 0.7734 - val_loss: 0.5714 - val_accuracy: 0.8123
Epoch 12/128
 - 1s - loss: 0.6543 - accuracy: 0.7729 - val_loss: 0.6041 - val_accuracy: 0.8107
Epoch 13/128
 - 1s - loss: 0.6500 - accuracy: 0.7753 - val_loss: 0.5992 - val_accuracy: 0.8111
Epoch 14/128
 - 1s - loss: 0.6450 - accuracy: 0.7797 - val_loss: 0.6015 - val_accuracy: 0.8103
Epoch 15/128
 - 1s - loss: 0.6493 - accuracy: 0.7753 - val_loss: 0.6245 - val_accuracy: 0.8050
Epoch 16/128
 - 1s - loss: 0.6545 - accuracy: 0.7660 - val_loss: 0.5990 - val_accuracy: 0.8127
Epoch 17/128
 - 1s - loss: 0.6399 - accuracy: 0.7782 - val_loss: 0.5922 - val_accuracy: 0.8131
Epoch 18/128
 - 1s - loss: 0.6232 - accuracy: 0.7846 - val_loss: 0.5887 - val_accuracy: 0.8115
Epoch 19/128
 - 1s - loss: 0.6128 - accuracy: 0.7859 - val_loss: 0.5749 - val_accuracy: 0.8131
Epoch 20/128
 - 1s - loss: 0.6103 - accuracy: 0.7855 - val_loss: 0.5715 - val_accuracy: 0.8147
Epoch 21/128
 - 1s - loss: 0.6112 - accuracy: 0.7888 - val_loss: 0.5880 - val_accuracy: 0.8090
Epoch 22/128
 - 1s - loss: 0.6215 - accuracy: 0.7810 - val_loss: 0.5730 - val_accuracy: 0.8135
Epoch 23/128
 - 1s - loss: 0.6165 - accuracy: 0.7778 - val_loss: 0.5856 - val_accuracy: 0.8107
Epoch 24/128
 - 1s - loss: 0.5993 - accuracy: 0.7880 - val_loss: 0.5869 - val_accuracy: 0.8103
Epoch 25/128
 - 1s - loss: 0.5860 - accuracy: 0.7905 - val_loss: 0.5667 - val_accuracy: 0.8123
Epoch 26/128
 - 1s - loss: 0.5721 - accuracy: 0.7928 - val_loss: 0.5639 - val_accuracy: 0.8143
Epoch 27/128
 - 1s - loss: 0.5658 - accuracy: 0.7990 - val_loss: 0.5552 - val_accuracy: 0.8119
Epoch 28/128
 - 1s - loss: 0.5594 - accuracy: 0.8013 - val_loss: 0.5427 - val_accuracy: 0.8131
Epoch 29/128
 - 1s - loss: 0.5593 - accuracy: 0.7996 - val_loss: 0.5638 - val_accuracy: 0.8119
Epoch 30/128
 - 1s - loss: 0.5611 - accuracy: 0.7956 - val_loss: 0.5582 - val_accuracy: 0.8147
Epoch 31/128
 - 1s - loss: 0.5648 - accuracy: 0.7954 - val_loss: 0.5568 - val_accuracy: 0.8119
Epoch 32/128
 - 1s - loss: 0.5749 - accuracy: 0.7947 - val_loss: 0.5575 - val_accuracy: 0.8119
Epoch 33/128
 - 1s - loss: 0.5474 - accuracy: 0.8017 - val_loss: 0.5460 - val_accuracy: 0.8139
Epoch 34/128
 - 1s - loss: 0.5397 - accuracy: 0.8033 - val_loss: 0.5469 - val_accuracy: 0.8131
Epoch 35/128
 - 1s - loss: 0.5264 - accuracy: 0.8077 - val_loss: 0.5671 - val_accuracy: 0.8094
Epoch 36/128
 - 1s - loss: 0.5164 - accuracy: 0.8144 - val_loss: 0.5532 - val_accuracy: 0.8058
Epoch 37/128
 - 1s - loss: 0.5177 - accuracy: 0.8092 - val_loss: 0.5664 - val_accuracy: 0.8058
Epoch 38/128
 - 1s - loss: 0.5166 - accuracy: 0.8131 - val_loss: 0.5550 - val_accuracy: 0.8111
Epoch 39/128
 - 1s - loss: 0.5195 - accuracy: 0.8142 - val_loss: 0.5707 - val_accuracy: 0.8033
Epoch 40/128
 - 1s - loss: 0.5282 - accuracy: 0.8041 - val_loss: 0.5510 - val_accuracy: 0.8139
Epoch 41/128
 - 1s - loss: 0.5268 - accuracy: 0.8067 - val_loss: 0.5654 - val_accuracy: 0.8111
Epoch 42/128
 - 1s - loss: 0.5000 - accuracy: 0.8171 - val_loss: 0.5685 - val_accuracy: 0.8078
Epoch 43/128
 - 1s - loss: 0.5000 - accuracy: 0.8182 - val_loss: 0.5673 - val_accuracy: 0.8025
Epoch 44/128
 - 1s - loss: 0.5033 - accuracy: 0.8185 - val_loss: 0.5359 - val_accuracy: 0.8131
Epoch 45/128
 - 1s - loss: 0.4945 - accuracy: 0.8173 - val_loss: 0.5621 - val_accuracy: 0.8029
Epoch 46/128
 - 1s - loss: 0.4876 - accuracy: 0.8227 - val_loss: 0.5716 - val_accuracy: 0.8127
Epoch 47/128
 - 1s - loss: 0.4949 - accuracy: 0.8199 - val_loss: 0.5589 - val_accuracy: 0.8111
Epoch 48/128
 - 1s - loss: 0.4991 - accuracy: 0.8131 - val_loss: 0.5580 - val_accuracy: 0.8115
Epoch 49/128
 - 1s - loss: 0.4761 - accuracy: 0.8203 - val_loss: 0.5549 - val_accuracy: 0.8094
Epoch 50/128
 - 1s - loss: 0.4813 - accuracy: 0.8198 - val_loss: 0.5707 - val_accuracy: 0.8050
Epoch 51/128
 - 1s - loss: 0.4863 - accuracy: 0.8177 - val_loss: 0.5527 - val_accuracy: 0.8103
Epoch 52/128
 - 1s - loss: 0.4882 - accuracy: 0.8189 - val_loss: 0.5425 - val_accuracy: 0.8156
Epoch 53/128
 - 1s - loss: 0.4884 - accuracy: 0.8178 - val_loss: 0.5344 - val_accuracy: 0.8119
Epoch 54/128
 - 1s - loss: 0.4674 - accuracy: 0.8249 - val_loss: 0.5533 - val_accuracy: 0.8017
Epoch 55/128
 - 1s - loss: 0.4583 - accuracy: 0.8279 - val_loss: 0.5600 - val_accuracy: 0.8078
Epoch 56/128
 - 1s - loss: 0.4571 - accuracy: 0.8264 - val_loss: 0.5553 - val_accuracy: 0.8070
Epoch 57/128
 - 1s - loss: 0.4576 - accuracy: 0.8270 - val_loss: 0.5315 - val_accuracy: 0.8123
Epoch 58/128
 - 1s - loss: 0.4501 - accuracy: 0.8259 - val_loss: 0.5595 - val_accuracy: 0.8050
Epoch 59/128
 - 1s - loss: 0.4406 - accuracy: 0.8297 - val_loss: 0.5382 - val_accuracy: 0.8143
Epoch 60/128
 - 1s - loss: 0.4396 - accuracy: 0.8299 - val_loss: 0.5612 - val_accuracy: 0.8017
Epoch 61/128
 - 1s - loss: 0.4456 - accuracy: 0.8297 - val_loss: 0.5347 - val_accuracy: 0.8135
Epoch 62/128
 - 1s - loss: 0.4765 - accuracy: 0.8161 - val_loss: 0.5498 - val_accuracy: 0.8151
Epoch 63/128
 - 1s - loss: 0.4507 - accuracy: 0.8262 - val_loss: 0.5202 - val_accuracy: 0.8143
Epoch 64/128
 - 1s - loss: 0.4204 - accuracy: 0.8366 - val_loss: 0.5225 - val_accuracy: 0.8172
Epoch 65/128
 - 1s - loss: 0.4128 - accuracy: 0.8424 - val_loss: 0.5435 - val_accuracy: 0.8151
Epoch 66/128
 - 1s - loss: 0.4078 - accuracy: 0.8407 - val_loss: 0.5391 - val_accuracy: 0.8131
Epoch 67/128
 - 1s - loss: 0.4112 - accuracy: 0.8398 - val_loss: 0.6068 - val_accuracy: 0.8017
Epoch 68/128
 - 1s - loss: 0.4027 - accuracy: 0.8433 - val_loss: 0.5343 - val_accuracy: 0.8172
Epoch 69/128
 - 1s - loss: 0.4123 - accuracy: 0.8411 - val_loss: 0.5626 - val_accuracy: 0.8058
Epoch 70/128
 - 1s - loss: 0.4095 - accuracy: 0.8429 - val_loss: 0.5699 - val_accuracy: 0.8107
Epoch 71/128
 - 1s - loss: 0.4106 - accuracy: 0.8407 - val_loss: 0.5558 - val_accuracy: 0.8115
Epoch 72/128
 - 1s - loss: 0.4259 - accuracy: 0.8327 - val_loss: 0.5269 - val_accuracy: 0.8147
Epoch 73/128
 - 1s - loss: 0.4175 - accuracy: 0.8372 - val_loss: 0.5036 - val_accuracy: 0.8180
Epoch 74/128
 - 1s - loss: 0.3963 - accuracy: 0.8426 - val_loss: 0.5347 - val_accuracy: 0.8217
Epoch 75/128
 - 1s - loss: 0.3835 - accuracy: 0.8461 - val_loss: 0.5905 - val_accuracy: 0.8103
Epoch 76/128
 - 1s - loss: 0.3789 - accuracy: 0.8501 - val_loss: 0.5499 - val_accuracy: 0.8139
Epoch 77/128
 - 1s - loss: 0.3784 - accuracy: 0.8480 - val_loss: 0.5713 - val_accuracy: 0.8143
Epoch 78/128
 - 1s - loss: 0.3978 - accuracy: 0.8397 - val_loss: 0.5225 - val_accuracy: 0.8184
Epoch 79/128
 - 1s - loss: 0.3782 - accuracy: 0.8498 - val_loss: 0.5547 - val_accuracy: 0.8131
Epoch 80/128
 - 1s - loss: 0.3941 - accuracy: 0.8453 - val_loss: 0.5384 - val_accuracy: 0.8229
Epoch 81/128
 - 1s - loss: 0.3940 - accuracy: 0.8479 - val_loss: 0.5259 - val_accuracy: 0.8257
Epoch 82/128
 - 1s - loss: 0.3889 - accuracy: 0.8510 - val_loss: 0.5545 - val_accuracy: 0.8233
Epoch 83/128
 - 1s - loss: 0.3862 - accuracy: 0.8516 - val_loss: 0.5590 - val_accuracy: 0.8327
Epoch 84/128
 - 1s - loss: 0.3758 - accuracy: 0.8554 - val_loss: 0.5792 - val_accuracy: 0.8103
Epoch 85/128
 - 2s - loss: 0.3700 - accuracy: 0.8544 - val_loss: 0.5531 - val_accuracy: 0.8204
Epoch 86/128
 - 2s - loss: 0.3590 - accuracy: 0.8592 - val_loss: 0.5968 - val_accuracy: 0.8217
Epoch 87/128
 - 2s - loss: 0.3634 - accuracy: 0.8558 - val_loss: 0.5810 - val_accuracy: 0.8135
Epoch 88/128
 - 1s - loss: 0.3571 - accuracy: 0.8584 - val_loss: 0.5741 - val_accuracy: 0.8168
Epoch 89/128
 - 1s - loss: 0.3566 - accuracy: 0.8608 - val_loss: 0.5825 - val_accuracy: 0.8107
Epoch 90/128
 - 1s - loss: 0.3735 - accuracy: 0.8501 - val_loss: 0.5322 - val_accuracy: 0.8318
Epoch 91/128
 - 2s - loss: 0.3749 - accuracy: 0.8568 - val_loss: 0.5660 - val_accuracy: 0.8139
Epoch 92/128
 - 1s - loss: 0.3711 - accuracy: 0.8542 - val_loss: 0.5346 - val_accuracy: 0.8184
Epoch 93/128
 - 1s - loss: 0.3626 - accuracy: 0.8567 - val_loss: 0.5077 - val_accuracy: 0.8229
Epoch 94/128
 - 1s - loss: 0.3514 - accuracy: 0.8595 - val_loss: 0.5058 - val_accuracy: 0.8107
Epoch 95/128
 - 1s - loss: 0.3420 - accuracy: 0.8601 - val_loss: 0.5565 - val_accuracy: 0.8090
Epoch 96/128
 - 1s - loss: 0.3578 - accuracy: 0.8556 - val_loss: 0.5754 - val_accuracy: 0.8123
Epoch 97/128
 - 1s - loss: 0.3505 - accuracy: 0.8588 - val_loss: 0.5731 - val_accuracy: 0.8082
Epoch 98/128
 - 1s - loss: 0.3328 - accuracy: 0.8655 - val_loss: 0.5579 - val_accuracy: 0.8327
Epoch 99/128
 - 2s - loss: 0.3316 - accuracy: 0.8690 - val_loss: 0.5441 - val_accuracy: 0.8164
Epoch 100/128
 - 1s - loss: 0.3535 - accuracy: 0.8594 - val_loss: 0.5374 - val_accuracy: 0.8143
Epoch 101/128
 - 1s - loss: 0.3582 - accuracy: 0.8549 - val_loss: 0.5236 - val_accuracy: 0.8343
Epoch 102/128
 - 2s - loss: 0.3461 - accuracy: 0.8622 - val_loss: 0.5821 - val_accuracy: 0.8131
Epoch 103/128
 - 2s - loss: 0.3486 - accuracy: 0.8640 - val_loss: 0.5532 - val_accuracy: 0.8204
Epoch 104/128
 - 1s - loss: 0.3440 - accuracy: 0.8596 - val_loss: 0.5999 - val_accuracy: 0.8200
Epoch 105/128
 - 1s - loss: 0.3352 - accuracy: 0.8626 - val_loss: 0.5829 - val_accuracy: 0.8208
Epoch 106/128
 - 1s - loss: 0.3204 - accuracy: 0.8687 - val_loss: 0.6742 - val_accuracy: 0.8025
Epoch 107/128
 - 1s - loss: 0.3727 - accuracy: 0.8505 - val_loss: 0.5508 - val_accuracy: 0.8229
Epoch 108/128
 - 1s - loss: 0.3647 - accuracy: 0.8529 - val_loss: 0.5434 - val_accuracy: 0.8249
Epoch 109/128
 - 2s - loss: 0.3356 - accuracy: 0.8672 - val_loss: 0.5016 - val_accuracy: 0.8367
Epoch 110/128
 - 1s - loss: 0.3283 - accuracy: 0.8666 - val_loss: 0.5193 - val_accuracy: 0.8184
Epoch 111/128
 - 2s - loss: 0.3279 - accuracy: 0.8663 - val_loss: 0.5104 - val_accuracy: 0.8318
Epoch 112/128
 - 1s - loss: 0.3209 - accuracy: 0.8720 - val_loss: 0.5026 - val_accuracy: 0.8379
Epoch 113/128
 - 1s - loss: 0.3277 - accuracy: 0.8660 - val_loss: 0.6175 - val_accuracy: 0.8017
Epoch 114/128
 - 2s - loss: 0.3414 - accuracy: 0.8581 - val_loss: 0.5901 - val_accuracy: 0.8090
Epoch 115/128
 - 1s - loss: 0.3493 - accuracy: 0.8579 - val_loss: 0.5307 - val_accuracy: 0.8298
Epoch 116/128
 - 2s - loss: 0.3213 - accuracy: 0.8669 - val_loss: 0.5282 - val_accuracy: 0.8347
Epoch 117/128
 - 2s - loss: 0.3259 - accuracy: 0.8668 - val_loss: 0.5367 - val_accuracy: 0.8290
Epoch 118/128
 - 1s - loss: 0.3280 - accuracy: 0.8673 - val_loss: 0.5693 - val_accuracy: 0.8184
Epoch 119/128
 - 1s - loss: 0.3233 - accuracy: 0.8687 - val_loss: 0.5822 - val_accuracy: 0.8274
Epoch 120/128
 - 1s - loss: 0.3319 - accuracy: 0.8628 - val_loss: 0.6065 - val_accuracy: 0.8156
Epoch 121/128
 - 1s - loss: 0.3150 - accuracy: 0.8709 - val_loss: 0.5704 - val_accuracy: 0.8017
Epoch 122/128
 - 1s - loss: 0.3129 - accuracy: 0.8725 - val_loss: 0.5525 - val_accuracy: 0.8278
Epoch 123/128
 - 2s - loss: 0.3575 - accuracy: 0.8588 - val_loss: 0.5756 - val_accuracy: 0.8143
Epoch 124/128
 - 1s - loss: 0.3336 - accuracy: 0.8631 - val_loss: 0.5080 - val_accuracy: 0.8363
Epoch 125/128
 - 1s - loss: 0.3058 - accuracy: 0.8738 - val_loss: 0.5552 - val_accuracy: 0.8294
Epoch 126/128
 - 1s - loss: 0.2971 - accuracy: 0.8761 - val_loss: 0.6028 - val_accuracy: 0.8188
Epoch 127/128
 - 1s - loss: 0.3043 - accuracy: 0.8738 - val_loss: 0.6060 - val_accuracy: 0.8221
Epoch 128/128
 - 1s - loss: 0.4110 - accuracy: 0.8349 - val_loss: 0.5053 - val_accuracy: 0.8156

Fit: epochs= 128 , batch_size= 32 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 10)                110       
_________________________________________________________________
dense_2 (Dense)              (None, 500)               5500      
_________________________________________________________________
dense_3 (Dense)              (None, 300)               150300    
_________________________________________________________________
dense_4 (Dense)              (None, 200)               60200     
_________________________________________________________________
dense_5 (Dense)              (None, 100)               20100     
_________________________________________________________________
dense_6 (Dense)              (None, 50)                5050      
_________________________________________________________________
dense_7 (Dense)              (None, 20)                1020      
_________________________________________________________________
dense_8 (Dense)              (None, 4)                 84        
=================================================================
Total params: 242,364
Trainable params: 242,364
Non-trainable params: 0
_________________________________________________________________
None

Accuracy Train: 84.25%
Accuracy Test: 41.40%
Loss Train: 0.40
Loss Test: 6.58
Numero dati esaminati: 4280
True Positive 1772
False Positive 2508
