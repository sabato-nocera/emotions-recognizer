Dataset used: ../../datasets/full_dataset_without_humidity.csv 

   Temperature  Sound  Heartbeat   X1  ...    Y2     Z2  Classification  Feedback
0           32      1         60 -680  ... -7424 -15596             100     Happy
1           32      1         60 -780  ... -7408 -15628             100     Happy
2           -1      1         60   -1  ... -7276 -15612             100     Happy
3           -1     -1         60   -1  ...    -1     -1             100     Happy
4           32      1         60 -860  ... -7340 -15720             100     Happy

[5 rows x 11 columns]

Objservations: 8560
Reshaping:  ((6848, 10), (6848, 4), (1712, 10), (1712, 4))  -> ((6848, 10, 1), (6848, 4), (1712, 10, 1), (1712, 4))

Layers:

{'batch_input_shape': (None, 10, 1), 'dtype': 'float32', 'sparse': False, 'name': 'input_19'} 

{'name': 'conv1d_379', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_343', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_343', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_380', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_344', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_344', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_381', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_345', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_163', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_345', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_382', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_346', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_346', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_383', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_347', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_164', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_347', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_384', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_348', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_348', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_385', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_349', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_165', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_349', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_386', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_350', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_350', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_387', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_388', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_351', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_166', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_351', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_389', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_352', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_352', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_390', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_353', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_167', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_353', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_391', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_354', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_354', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_392', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_355', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_168', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_355', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_393', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_356', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_356', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_394', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_395', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_357', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_169', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_357', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_396', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_358', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_358', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_397', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_359', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_170', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_359', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_398', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_360', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_360', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_399', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_361', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_171', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_361', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'average_pooling1d_19', 'trainable': True, 'dtype': 'float32', 'strides': (1,), 'pool_size': (1,), 'padding': 'valid', 'data_format': 'channels_last'} 

{'name': 'flatten_19', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'} 

{'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 6s - loss: 1.1739 - accuracy: 0.6181 - val_loss: 2.1027 - val_accuracy: 0.3956
Epoch 2/110
 - 3s - loss: 0.7365 - accuracy: 0.7820 - val_loss: 0.9897 - val_accuracy: 0.6723
Epoch 3/110
 - 3s - loss: 0.6198 - accuracy: 0.8286 - val_loss: 0.8206 - val_accuracy: 0.7496
Epoch 4/110
 - 3s - loss: 0.5579 - accuracy: 0.8523 - val_loss: 0.7746 - val_accuracy: 0.7693
Epoch 5/110
 - 3s - loss: 0.5238 - accuracy: 0.8662 - val_loss: 0.7627 - val_accuracy: 0.7788
Epoch 6/110
 - 3s - loss: 0.5015 - accuracy: 0.8708 - val_loss: 0.8146 - val_accuracy: 0.7679
Epoch 7/110
 - 3s - loss: 0.4847 - accuracy: 0.8762 - val_loss: 0.8751 - val_accuracy: 0.7730
Epoch 8/110
 - 3s - loss: 0.4762 - accuracy: 0.8797 - val_loss: 0.7630 - val_accuracy: 0.7912
Epoch 9/110
 - 3s - loss: 0.4584 - accuracy: 0.8837 - val_loss: 0.7320 - val_accuracy: 0.7869
Epoch 10/110
 - 3s - loss: 0.4583 - accuracy: 0.8804 - val_loss: 0.7529 - val_accuracy: 0.8058
Epoch 11/110
 - 3s - loss: 0.4543 - accuracy: 0.8837 - val_loss: 0.7773 - val_accuracy: 0.7964
Epoch 12/110
 - 3s - loss: 0.4463 - accuracy: 0.8879 - val_loss: 0.7599 - val_accuracy: 0.7912
Epoch 13/110
 - 3s - loss: 0.4136 - accuracy: 0.9003 - val_loss: 0.7997 - val_accuracy: 0.7956
Epoch 14/110
 - 3s - loss: 0.4012 - accuracy: 0.9091 - val_loss: 0.8267 - val_accuracy: 0.7971
Epoch 15/110
 - 3s - loss: 0.3959 - accuracy: 0.9065 - val_loss: 0.8084 - val_accuracy: 0.7934
Epoch 16/110
 - 3s - loss: 0.3961 - accuracy: 0.9089 - val_loss: 0.7744 - val_accuracy: 0.8029
Epoch 17/110
 - 3s - loss: 0.3830 - accuracy: 0.9184 - val_loss: 0.7874 - val_accuracy: 0.8058
Epoch 18/110
 - 3s - loss: 0.3995 - accuracy: 0.9065 - val_loss: 0.8314 - val_accuracy: 0.8095
Epoch 19/110
 - 3s - loss: 0.4145 - accuracy: 0.9036 - val_loss: 0.8375 - val_accuracy: 0.8007
Epoch 20/110
 - 3s - loss: 0.3868 - accuracy: 0.9100 - val_loss: 0.8186 - val_accuracy: 0.8153
Epoch 21/110
 - 3s - loss: 0.3679 - accuracy: 0.9197 - val_loss: 0.7982 - val_accuracy: 0.8131
Epoch 22/110
 - 3s - loss: 0.3695 - accuracy: 0.9206 - val_loss: 0.8395 - val_accuracy: 0.8058
Epoch 23/110
 - 3s - loss: 0.3618 - accuracy: 0.9213 - val_loss: 0.8295 - val_accuracy: 0.8139
Epoch 24/110
 - 3s - loss: 0.3411 - accuracy: 0.9323 - val_loss: 0.8410 - val_accuracy: 0.8175
Epoch 25/110
 - 3s - loss: 0.3562 - accuracy: 0.9184 - val_loss: 0.8211 - val_accuracy: 0.8022
Epoch 26/110
 - 3s - loss: 0.3496 - accuracy: 0.9275 - val_loss: 0.8212 - val_accuracy: 0.8117
Epoch 27/110
 - 3s - loss: 0.3368 - accuracy: 0.9354 - val_loss: 0.8237 - val_accuracy: 0.7971
Epoch 28/110
 - 3s - loss: 0.3523 - accuracy: 0.9259 - val_loss: 0.8413 - val_accuracy: 0.8088
Epoch 29/110
 - 3s - loss: 0.3419 - accuracy: 0.9283 - val_loss: 0.8203 - val_accuracy: 0.8066
Epoch 30/110
 - 3s - loss: 0.3236 - accuracy: 0.9345 - val_loss: 0.8200 - val_accuracy: 0.8095
Epoch 31/110
 - 3s - loss: 0.3403 - accuracy: 0.9288 - val_loss: 0.8624 - val_accuracy: 0.8007
Epoch 32/110
 - 3s - loss: 0.3362 - accuracy: 0.9323 - val_loss: 0.9231 - val_accuracy: 0.7788
Epoch 33/110
 - 3s - loss: 0.3413 - accuracy: 0.9284 - val_loss: 0.8572 - val_accuracy: 0.8139
Epoch 34/110
 - 3s - loss: 0.3232 - accuracy: 0.9352 - val_loss: 0.8122 - val_accuracy: 0.8131
Epoch 35/110
 - 3s - loss: 0.3138 - accuracy: 0.9388 - val_loss: 0.7779 - val_accuracy: 0.8190
Epoch 36/110
 - 3s - loss: 0.3219 - accuracy: 0.9379 - val_loss: 0.7497 - val_accuracy: 0.8394
Epoch 37/110
 - 3s - loss: 0.3060 - accuracy: 0.9443 - val_loss: 0.8435 - val_accuracy: 0.8168
Epoch 38/110
 - 3s - loss: 0.3108 - accuracy: 0.9378 - val_loss: 0.7989 - val_accuracy: 0.8387
Epoch 39/110
 - 3s - loss: 0.3142 - accuracy: 0.9379 - val_loss: 0.8187 - val_accuracy: 0.8168
Epoch 40/110
 - 3s - loss: 0.3046 - accuracy: 0.9454 - val_loss: 0.8455 - val_accuracy: 0.8219
Epoch 41/110
 - 3s - loss: 0.3057 - accuracy: 0.9430 - val_loss: 0.8712 - val_accuracy: 0.8124
Epoch 42/110
 - 3s - loss: 0.2834 - accuracy: 0.9527 - val_loss: 0.7991 - val_accuracy: 0.8307
Epoch 43/110
 - 3s - loss: 0.2773 - accuracy: 0.9540 - val_loss: 0.8406 - val_accuracy: 0.8292
Epoch 44/110
 - 3s - loss: 0.2958 - accuracy: 0.9489 - val_loss: 0.8446 - val_accuracy: 0.8219
Epoch 45/110
 - 3s - loss: 0.2923 - accuracy: 0.9500 - val_loss: 0.8421 - val_accuracy: 0.8234
Epoch 46/110
 - 3s - loss: 0.2921 - accuracy: 0.9474 - val_loss: 0.8409 - val_accuracy: 0.8307
Epoch 47/110
 - 3s - loss: 0.2836 - accuracy: 0.9549 - val_loss: 0.7537 - val_accuracy: 0.8394
Epoch 48/110
 - 3s - loss: 0.2827 - accuracy: 0.9518 - val_loss: 0.7765 - val_accuracy: 0.8380
Epoch 49/110
 - 3s - loss: 0.2774 - accuracy: 0.9544 - val_loss: 0.8374 - val_accuracy: 0.8248
Epoch 50/110
 - 3s - loss: 0.2659 - accuracy: 0.9615 - val_loss: 0.7795 - val_accuracy: 0.8504
Epoch 51/110
 - 3s - loss: 0.2746 - accuracy: 0.9547 - val_loss: 0.7859 - val_accuracy: 0.8431
Epoch 52/110
 - 3s - loss: 0.2556 - accuracy: 0.9618 - val_loss: 0.8400 - val_accuracy: 0.8394
Epoch 53/110
 - 3s - loss: 0.2765 - accuracy: 0.9569 - val_loss: 0.8462 - val_accuracy: 0.8263
Epoch 54/110
 - 3s - loss: 0.2843 - accuracy: 0.9511 - val_loss: 0.8562 - val_accuracy: 0.8285
Epoch 55/110
 - 3s - loss: 0.2803 - accuracy: 0.9586 - val_loss: 0.8724 - val_accuracy: 0.8263
Epoch 56/110
 - 3s - loss: 0.2512 - accuracy: 0.9668 - val_loss: 0.8208 - val_accuracy: 0.8423
Epoch 57/110
 - 3s - loss: 0.2475 - accuracy: 0.9668 - val_loss: 0.8111 - val_accuracy: 0.8606
Epoch 58/110
 - 3s - loss: 0.2555 - accuracy: 0.9657 - val_loss: 0.8228 - val_accuracy: 0.8474
Epoch 59/110
 - 3s - loss: 0.2580 - accuracy: 0.9626 - val_loss: 0.8379 - val_accuracy: 0.8380
Epoch 60/110
 - 3s - loss: 0.2682 - accuracy: 0.9595 - val_loss: 0.8594 - val_accuracy: 0.8504
Epoch 61/110
 - 3s - loss: 0.2541 - accuracy: 0.9653 - val_loss: 0.8498 - val_accuracy: 0.8467
Epoch 62/110
 - 3s - loss: 0.2644 - accuracy: 0.9593 - val_loss: 0.8839 - val_accuracy: 0.8328
Epoch 63/110
 - 3s - loss: 0.2538 - accuracy: 0.9617 - val_loss: 0.8529 - val_accuracy: 0.8380
Epoch 64/110
 - 3s - loss: 0.2702 - accuracy: 0.9571 - val_loss: 0.8955 - val_accuracy: 0.8292
Epoch 65/110
 - 3s - loss: 0.2924 - accuracy: 0.9538 - val_loss: 0.7967 - val_accuracy: 0.8445
Epoch 66/110
 - 3s - loss: 0.2583 - accuracy: 0.9629 - val_loss: 0.8113 - val_accuracy: 0.8394
Epoch 67/110
 - 3s - loss: 0.2510 - accuracy: 0.9633 - val_loss: 0.7815 - val_accuracy: 0.8504
Epoch 68/110
 - 3s - loss: 0.2420 - accuracy: 0.9677 - val_loss: 0.7858 - val_accuracy: 0.8584
Epoch 69/110
 - 3s - loss: 0.2343 - accuracy: 0.9746 - val_loss: 0.8355 - val_accuracy: 0.8555
Epoch 70/110
 - 3s - loss: 0.2465 - accuracy: 0.9688 - val_loss: 0.8874 - val_accuracy: 0.8285
Epoch 71/110
 - 3s - loss: 0.2430 - accuracy: 0.9668 - val_loss: 0.9231 - val_accuracy: 0.8438
Epoch 72/110
 - 3s - loss: 0.2386 - accuracy: 0.9697 - val_loss: 0.8056 - val_accuracy: 0.8482
Epoch 73/110
 - 3s - loss: 0.2396 - accuracy: 0.9686 - val_loss: 0.8730 - val_accuracy: 0.8445
Epoch 74/110
 - 3s - loss: 0.2475 - accuracy: 0.9655 - val_loss: 0.8793 - val_accuracy: 0.8540
Epoch 75/110
 - 3s - loss: 0.2551 - accuracy: 0.9662 - val_loss: 0.9677 - val_accuracy: 0.8285
Epoch 76/110
 - 3s - loss: 0.2478 - accuracy: 0.9673 - val_loss: 0.8172 - val_accuracy: 0.8423
Epoch 77/110
 - 3s - loss: 0.2322 - accuracy: 0.9724 - val_loss: 0.8919 - val_accuracy: 0.8460
Epoch 78/110
 - 3s - loss: 0.2231 - accuracy: 0.9755 - val_loss: 0.8763 - val_accuracy: 0.8431
Epoch 79/110
 - 3s - loss: 0.2361 - accuracy: 0.9695 - val_loss: 0.9114 - val_accuracy: 0.8438
Epoch 80/110
 - 3s - loss: 0.2704 - accuracy: 0.9575 - val_loss: 0.8805 - val_accuracy: 0.8474
Epoch 81/110
 - 3s - loss: 0.2448 - accuracy: 0.9681 - val_loss: 0.8633 - val_accuracy: 0.8511
Epoch 82/110
 - 3s - loss: 0.2497 - accuracy: 0.9629 - val_loss: 0.8231 - val_accuracy: 0.8416
Epoch 83/110
 - 3s - loss: 0.2511 - accuracy: 0.9668 - val_loss: 0.8178 - val_accuracy: 0.8482
Epoch 84/110
 - 3s - loss: 0.2489 - accuracy: 0.9666 - val_loss: 0.8889 - val_accuracy: 0.8401
Epoch 85/110
 - 3s - loss: 0.2448 - accuracy: 0.9673 - val_loss: 0.7909 - val_accuracy: 0.8489
Epoch 86/110
 - 3s - loss: 0.2429 - accuracy: 0.9659 - val_loss: 0.8312 - val_accuracy: 0.8518
Epoch 87/110
 - 3s - loss: 0.2484 - accuracy: 0.9651 - val_loss: 0.8580 - val_accuracy: 0.8387
Epoch 88/110
 - 3s - loss: 0.2503 - accuracy: 0.9664 - val_loss: 0.8421 - val_accuracy: 0.8518
Epoch 89/110
 - 3s - loss: 0.2308 - accuracy: 0.9730 - val_loss: 0.7809 - val_accuracy: 0.8606
Epoch 90/110
 - 3s - loss: 0.2229 - accuracy: 0.9754 - val_loss: 0.8027 - val_accuracy: 0.8540
Epoch 91/110
 - 3s - loss: 0.2208 - accuracy: 0.9759 - val_loss: 0.8453 - val_accuracy: 0.8606
Epoch 92/110
 - 3s - loss: 0.2193 - accuracy: 0.9743 - val_loss: 0.8097 - val_accuracy: 0.8620
Epoch 93/110
 - 3s - loss: 0.2244 - accuracy: 0.9730 - val_loss: 0.8339 - val_accuracy: 0.8577
Epoch 94/110
 - 3s - loss: 0.2309 - accuracy: 0.9732 - val_loss: 0.8809 - val_accuracy: 0.8518
Epoch 95/110
 - 3s - loss: 0.2259 - accuracy: 0.9721 - val_loss: 0.8182 - val_accuracy: 0.8445
Epoch 96/110
 - 3s - loss: 0.2243 - accuracy: 0.9761 - val_loss: 0.8914 - val_accuracy: 0.8453
Epoch 97/110
 - 3s - loss: 0.2147 - accuracy: 0.9786 - val_loss: 0.9399 - val_accuracy: 0.8474
Epoch 98/110
 - 3s - loss: 0.2309 - accuracy: 0.9702 - val_loss: 0.8273 - val_accuracy: 0.8547
Epoch 99/110
 - 3s - loss: 0.2209 - accuracy: 0.9759 - val_loss: 0.8588 - val_accuracy: 0.8664
Epoch 100/110
 - 3s - loss: 0.2165 - accuracy: 0.9777 - val_loss: 0.9349 - val_accuracy: 0.8518
Epoch 101/110
 - 3s - loss: 0.2183 - accuracy: 0.9759 - val_loss: 0.8049 - val_accuracy: 0.8496
Epoch 102/110
 - 3s - loss: 0.2184 - accuracy: 0.9768 - val_loss: 0.9168 - val_accuracy: 0.8460
Epoch 103/110
 - 3s - loss: 0.2235 - accuracy: 0.9735 - val_loss: 0.8957 - val_accuracy: 0.8431
Epoch 104/110
 - 3s - loss: 0.2270 - accuracy: 0.9728 - val_loss: 0.9330 - val_accuracy: 0.8453
Epoch 105/110
 - 3s - loss: 0.2243 - accuracy: 0.9752 - val_loss: 0.8835 - val_accuracy: 0.8496
Epoch 106/110
 - 3s - loss: 0.2312 - accuracy: 0.9713 - val_loss: 0.9337 - val_accuracy: 0.8489
Epoch 107/110
 - 3s - loss: 0.2505 - accuracy: 0.9646 - val_loss: 0.8969 - val_accuracy: 0.8409
Epoch 108/110
 - 3s - loss: 0.2345 - accuracy: 0.9701 - val_loss: 0.8828 - val_accuracy: 0.8474
Epoch 109/110
 - 3s - loss: 0.2259 - accuracy: 0.9724 - val_loss: 0.8866 - val_accuracy: 0.8496
Epoch 110/110
 - 3s - loss: 0.2268 - accuracy: 0.9728 - val_loss: 0.8560 - val_accuracy: 0.8533

Number of filters: 16 , Kernel Size: 3 , Strides: 1 Batch Normalization: True , Conv_First: True , Depth Value: 20

Fit: epochs= 110 , batch_size= 64 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "model_19"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_19 (InputLayer)           (None, 10, 1)        0                                            
__________________________________________________________________________________________________
conv1d_379 (Conv1D)             (None, 10, 16)       64          input_19[0][0]                   
__________________________________________________________________________________________________
batch_normalization_343 (BatchN (None, 10, 16)       64          conv1d_379[0][0]                 
__________________________________________________________________________________________________
activation_343 (Activation)     (None, 10, 16)       0           batch_normalization_343[0][0]    
__________________________________________________________________________________________________
conv1d_380 (Conv1D)             (None, 10, 16)       784         activation_343[0][0]             
__________________________________________________________________________________________________
batch_normalization_344 (BatchN (None, 10, 16)       64          conv1d_380[0][0]                 
__________________________________________________________________________________________________
activation_344 (Activation)     (None, 10, 16)       0           batch_normalization_344[0][0]    
__________________________________________________________________________________________________
conv1d_381 (Conv1D)             (None, 10, 16)       784         activation_344[0][0]             
__________________________________________________________________________________________________
batch_normalization_345 (BatchN (None, 10, 16)       64          conv1d_381[0][0]                 
__________________________________________________________________________________________________
add_163 (Add)                   (None, 10, 16)       0           activation_343[0][0]             
                                                                 batch_normalization_345[0][0]    
__________________________________________________________________________________________________
activation_345 (Activation)     (None, 10, 16)       0           add_163[0][0]                    
__________________________________________________________________________________________________
conv1d_382 (Conv1D)             (None, 10, 16)       784         activation_345[0][0]             
__________________________________________________________________________________________________
batch_normalization_346 (BatchN (None, 10, 16)       64          conv1d_382[0][0]                 
__________________________________________________________________________________________________
activation_346 (Activation)     (None, 10, 16)       0           batch_normalization_346[0][0]    
__________________________________________________________________________________________________
conv1d_383 (Conv1D)             (None, 10, 16)       784         activation_346[0][0]             
__________________________________________________________________________________________________
batch_normalization_347 (BatchN (None, 10, 16)       64          conv1d_383[0][0]                 
__________________________________________________________________________________________________
add_164 (Add)                   (None, 10, 16)       0           activation_345[0][0]             
                                                                 batch_normalization_347[0][0]    
__________________________________________________________________________________________________
activation_347 (Activation)     (None, 10, 16)       0           add_164[0][0]                    
__________________________________________________________________________________________________
conv1d_384 (Conv1D)             (None, 10, 16)       784         activation_347[0][0]             
__________________________________________________________________________________________________
batch_normalization_348 (BatchN (None, 10, 16)       64          conv1d_384[0][0]                 
__________________________________________________________________________________________________
activation_348 (Activation)     (None, 10, 16)       0           batch_normalization_348[0][0]    
__________________________________________________________________________________________________
conv1d_385 (Conv1D)             (None, 10, 16)       784         activation_348[0][0]             
__________________________________________________________________________________________________
batch_normalization_349 (BatchN (None, 10, 16)       64          conv1d_385[0][0]                 
__________________________________________________________________________________________________
add_165 (Add)                   (None, 10, 16)       0           activation_347[0][0]             
                                                                 batch_normalization_349[0][0]    
__________________________________________________________________________________________________
activation_349 (Activation)     (None, 10, 16)       0           add_165[0][0]                    
__________________________________________________________________________________________________
conv1d_386 (Conv1D)             (None, 5, 32)        1568        activation_349[0][0]             
__________________________________________________________________________________________________
batch_normalization_350 (BatchN (None, 5, 32)        128         conv1d_386[0][0]                 
__________________________________________________________________________________________________
activation_350 (Activation)     (None, 5, 32)        0           batch_normalization_350[0][0]    
__________________________________________________________________________________________________
conv1d_387 (Conv1D)             (None, 5, 32)        3104        activation_350[0][0]             
__________________________________________________________________________________________________
conv1d_388 (Conv1D)             (None, 5, 32)        544         activation_349[0][0]             
__________________________________________________________________________________________________
batch_normalization_351 (BatchN (None, 5, 32)        128         conv1d_387[0][0]                 
__________________________________________________________________________________________________
add_166 (Add)                   (None, 5, 32)        0           conv1d_388[0][0]                 
                                                                 batch_normalization_351[0][0]    
__________________________________________________________________________________________________
activation_351 (Activation)     (None, 5, 32)        0           add_166[0][0]                    
__________________________________________________________________________________________________
conv1d_389 (Conv1D)             (None, 5, 32)        3104        activation_351[0][0]             
__________________________________________________________________________________________________
batch_normalization_352 (BatchN (None, 5, 32)        128         conv1d_389[0][0]                 
__________________________________________________________________________________________________
activation_352 (Activation)     (None, 5, 32)        0           batch_normalization_352[0][0]    
__________________________________________________________________________________________________
conv1d_390 (Conv1D)             (None, 5, 32)        3104        activation_352[0][0]             
__________________________________________________________________________________________________
batch_normalization_353 (BatchN (None, 5, 32)        128         conv1d_390[0][0]                 
__________________________________________________________________________________________________
add_167 (Add)                   (None, 5, 32)        0           activation_351[0][0]             
                                                                 batch_normalization_353[0][0]    
__________________________________________________________________________________________________
activation_353 (Activation)     (None, 5, 32)        0           add_167[0][0]                    
__________________________________________________________________________________________________
conv1d_391 (Conv1D)             (None, 5, 32)        3104        activation_353[0][0]             
__________________________________________________________________________________________________
batch_normalization_354 (BatchN (None, 5, 32)        128         conv1d_391[0][0]                 
__________________________________________________________________________________________________
activation_354 (Activation)     (None, 5, 32)        0           batch_normalization_354[0][0]    
__________________________________________________________________________________________________
conv1d_392 (Conv1D)             (None, 5, 32)        3104        activation_354[0][0]             
__________________________________________________________________________________________________
batch_normalization_355 (BatchN (None, 5, 32)        128         conv1d_392[0][0]                 
__________________________________________________________________________________________________
add_168 (Add)                   (None, 5, 32)        0           activation_353[0][0]             
                                                                 batch_normalization_355[0][0]    
__________________________________________________________________________________________________
activation_355 (Activation)     (None, 5, 32)        0           add_168[0][0]                    
__________________________________________________________________________________________________
conv1d_393 (Conv1D)             (None, 3, 64)        6208        activation_355[0][0]             
__________________________________________________________________________________________________
batch_normalization_356 (BatchN (None, 3, 64)        256         conv1d_393[0][0]                 
__________________________________________________________________________________________________
activation_356 (Activation)     (None, 3, 64)        0           batch_normalization_356[0][0]    
__________________________________________________________________________________________________
conv1d_394 (Conv1D)             (None, 3, 64)        12352       activation_356[0][0]             
__________________________________________________________________________________________________
conv1d_395 (Conv1D)             (None, 3, 64)        2112        activation_355[0][0]             
__________________________________________________________________________________________________
batch_normalization_357 (BatchN (None, 3, 64)        256         conv1d_394[0][0]                 
__________________________________________________________________________________________________
add_169 (Add)                   (None, 3, 64)        0           conv1d_395[0][0]                 
                                                                 batch_normalization_357[0][0]    
__________________________________________________________________________________________________
activation_357 (Activation)     (None, 3, 64)        0           add_169[0][0]                    
__________________________________________________________________________________________________
conv1d_396 (Conv1D)             (None, 3, 64)        12352       activation_357[0][0]             
__________________________________________________________________________________________________
batch_normalization_358 (BatchN (None, 3, 64)        256         conv1d_396[0][0]                 
__________________________________________________________________________________________________
activation_358 (Activation)     (None, 3, 64)        0           batch_normalization_358[0][0]    
__________________________________________________________________________________________________
conv1d_397 (Conv1D)             (None, 3, 64)        12352       activation_358[0][0]             
__________________________________________________________________________________________________
batch_normalization_359 (BatchN (None, 3, 64)        256         conv1d_397[0][0]                 
__________________________________________________________________________________________________
add_170 (Add)                   (None, 3, 64)        0           activation_357[0][0]             
                                                                 batch_normalization_359[0][0]    
__________________________________________________________________________________________________
activation_359 (Activation)     (None, 3, 64)        0           add_170[0][0]                    
__________________________________________________________________________________________________
conv1d_398 (Conv1D)             (None, 3, 64)        12352       activation_359[0][0]             
__________________________________________________________________________________________________
batch_normalization_360 (BatchN (None, 3, 64)        256         conv1d_398[0][0]                 
__________________________________________________________________________________________________
activation_360 (Activation)     (None, 3, 64)        0           batch_normalization_360[0][0]    
__________________________________________________________________________________________________
conv1d_399 (Conv1D)             (None, 3, 64)        12352       activation_360[0][0]             
__________________________________________________________________________________________________
batch_normalization_361 (BatchN (None, 3, 64)        256         conv1d_399[0][0]                 
__________________________________________________________________________________________________
add_171 (Add)                   (None, 3, 64)        0           activation_359[0][0]             
                                                                 batch_normalization_361[0][0]    
__________________________________________________________________________________________________
activation_361 (Activation)     (None, 3, 64)        0           add_171[0][0]                    
__________________________________________________________________________________________________
average_pooling1d_19 (AveragePo (None, 3, 64)        0           activation_361[0][0]             
__________________________________________________________________________________________________
flatten_19 (Flatten)            (None, 192)          0           average_pooling1d_19[0][0]       
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 4)            772         flatten_19[0][0]                 
==================================================================================================
Total params: 96,004
Trainable params: 94,628
Non-trainable params: 1,376
__________________________________________________________________________________________________
None

Accuracy Train: 90.44%
Accuracy Test: 84.70%
Loss Train: 0.49
Loss Test: 0.82
Numero dati esaminati: 1712
True Positive 1450
False Positive 262


------------------------------------------------------------------------
K-fold Cross Validation
------------------------------------------------------------------------
Training for fold 1 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 7s - loss: 1.1800 - accuracy: 0.6329 - val_loss: 1.9747 - val_accuracy: 0.4226
Epoch 2/110
 - 3s - loss: 0.7423 - accuracy: 0.7778 - val_loss: 1.0822 - val_accuracy: 0.5985
Epoch 3/110
 - 3s - loss: 0.6505 - accuracy: 0.8158 - val_loss: 0.8107 - val_accuracy: 0.7445
Epoch 4/110
 - 3s - loss: 0.5890 - accuracy: 0.8405 - val_loss: 0.7582 - val_accuracy: 0.7664
Epoch 5/110
 - 3s - loss: 0.5595 - accuracy: 0.8536 - val_loss: 0.7674 - val_accuracy: 0.7642
Epoch 6/110
 - 3s - loss: 0.5204 - accuracy: 0.8662 - val_loss: 0.7212 - val_accuracy: 0.7942
Epoch 7/110
 - 3s - loss: 0.4993 - accuracy: 0.8695 - val_loss: 0.7716 - val_accuracy: 0.7818
Epoch 8/110
 - 3s - loss: 0.4961 - accuracy: 0.8667 - val_loss: 0.7933 - val_accuracy: 0.7788
Epoch 9/110
 - 3s - loss: 0.5016 - accuracy: 0.8638 - val_loss: 0.7706 - val_accuracy: 0.7825
Epoch 10/110
 - 3s - loss: 0.4881 - accuracy: 0.8706 - val_loss: 0.7606 - val_accuracy: 0.7818
Epoch 11/110
 - 3s - loss: 0.4544 - accuracy: 0.8850 - val_loss: 0.7742 - val_accuracy: 0.7949
Epoch 12/110
 - 3s - loss: 0.4506 - accuracy: 0.8788 - val_loss: 0.7503 - val_accuracy: 0.8015
Epoch 13/110
 - 3s - loss: 0.4277 - accuracy: 0.8976 - val_loss: 0.7433 - val_accuracy: 0.8000
Epoch 14/110
 - 3s - loss: 0.4186 - accuracy: 0.8941 - val_loss: 0.8358 - val_accuracy: 0.7861
Epoch 15/110
 - 3s - loss: 0.4118 - accuracy: 0.9000 - val_loss: 0.7896 - val_accuracy: 0.7978
Epoch 16/110
 - 3s - loss: 0.3970 - accuracy: 0.9078 - val_loss: 0.7898 - val_accuracy: 0.8015
Epoch 17/110
 - 3s - loss: 0.3828 - accuracy: 0.9157 - val_loss: 0.7749 - val_accuracy: 0.7971
Epoch 18/110
 - 3s - loss: 0.3856 - accuracy: 0.9095 - val_loss: 0.7576 - val_accuracy: 0.8051
Epoch 19/110
 - 3s - loss: 0.3857 - accuracy: 0.9131 - val_loss: 0.7536 - val_accuracy: 0.8015
Epoch 20/110
 - 3s - loss: 0.3712 - accuracy: 0.9131 - val_loss: 0.7839 - val_accuracy: 0.7876
Epoch 21/110
 - 3s - loss: 0.3663 - accuracy: 0.9180 - val_loss: 0.8136 - val_accuracy: 0.8007
Epoch 22/110
 - 3s - loss: 0.3650 - accuracy: 0.9213 - val_loss: 0.8058 - val_accuracy: 0.7993
Epoch 23/110
 - 3s - loss: 0.3522 - accuracy: 0.9217 - val_loss: 0.8575 - val_accuracy: 0.7898
Epoch 24/110
 - 3s - loss: 0.3785 - accuracy: 0.9116 - val_loss: 0.8765 - val_accuracy: 0.7898
Epoch 25/110
 - 3s - loss: 0.3662 - accuracy: 0.9204 - val_loss: 0.7752 - val_accuracy: 0.8175
Epoch 26/110
 - 3s - loss: 0.3447 - accuracy: 0.9250 - val_loss: 0.8592 - val_accuracy: 0.7927
Epoch 27/110
 - 3s - loss: 0.3754 - accuracy: 0.9195 - val_loss: 0.8664 - val_accuracy: 0.7869
Epoch 28/110
 - 3s - loss: 0.3601 - accuracy: 0.9202 - val_loss: 0.7931 - val_accuracy: 0.8182
Epoch 29/110
 - 3s - loss: 0.3357 - accuracy: 0.9292 - val_loss: 0.7683 - val_accuracy: 0.8182
Epoch 30/110
 - 3s - loss: 0.3176 - accuracy: 0.9370 - val_loss: 0.7826 - val_accuracy: 0.8270
Epoch 31/110
 - 3s - loss: 0.3426 - accuracy: 0.9264 - val_loss: 0.8250 - val_accuracy: 0.8058
Epoch 32/110
 - 3s - loss: 0.3539 - accuracy: 0.9211 - val_loss: 0.7757 - val_accuracy: 0.8307
Epoch 33/110
 - 3s - loss: 0.3483 - accuracy: 0.9257 - val_loss: 0.8562 - val_accuracy: 0.8161
Epoch 34/110
 - 3s - loss: 0.3565 - accuracy: 0.9257 - val_loss: 0.8031 - val_accuracy: 0.8234
Epoch 35/110
 - 3s - loss: 0.3415 - accuracy: 0.9284 - val_loss: 0.7469 - val_accuracy: 0.8423
Epoch 36/110
 - 3s - loss: 0.3276 - accuracy: 0.9368 - val_loss: 0.7582 - val_accuracy: 0.8153
Epoch 37/110
 - 3s - loss: 0.3134 - accuracy: 0.9387 - val_loss: 0.8065 - val_accuracy: 0.8131
Epoch 38/110
 - 3s - loss: 0.3023 - accuracy: 0.9423 - val_loss: 0.8787 - val_accuracy: 0.8036
Epoch 39/110
 - 3s - loss: 0.3195 - accuracy: 0.9361 - val_loss: 0.7631 - val_accuracy: 0.8401
Epoch 40/110
 - 3s - loss: 0.2982 - accuracy: 0.9469 - val_loss: 0.8650 - val_accuracy: 0.8153
Epoch 41/110
 - 3s - loss: 0.3195 - accuracy: 0.9409 - val_loss: 0.7761 - val_accuracy: 0.8270
Epoch 42/110
 - 3s - loss: 0.3045 - accuracy: 0.9441 - val_loss: 0.7529 - val_accuracy: 0.8328
Epoch 43/110
 - 3s - loss: 0.2894 - accuracy: 0.9476 - val_loss: 0.7996 - val_accuracy: 0.8292
Epoch 44/110
 - 3s - loss: 0.3130 - accuracy: 0.9396 - val_loss: 0.8103 - val_accuracy: 0.8394
Epoch 45/110
 - 3s - loss: 0.2893 - accuracy: 0.9522 - val_loss: 0.7651 - val_accuracy: 0.8453
Epoch 46/110
 - 3s - loss: 0.2955 - accuracy: 0.9418 - val_loss: 0.8376 - val_accuracy: 0.8409
Epoch 47/110
 - 3s - loss: 0.2927 - accuracy: 0.9505 - val_loss: 0.8109 - val_accuracy: 0.8343
Epoch 48/110
 - 3s - loss: 0.2830 - accuracy: 0.9516 - val_loss: 0.8212 - val_accuracy: 0.8270
Epoch 49/110
 - 3s - loss: 0.2825 - accuracy: 0.9533 - val_loss: 0.8507 - val_accuracy: 0.8234
Epoch 50/110
 - 3s - loss: 0.2805 - accuracy: 0.9533 - val_loss: 0.8886 - val_accuracy: 0.8197
Epoch 51/110
 - 3s - loss: 0.2766 - accuracy: 0.9551 - val_loss: 0.7905 - val_accuracy: 0.8445
Epoch 52/110
 - 3s - loss: 0.2965 - accuracy: 0.9487 - val_loss: 0.8822 - val_accuracy: 0.8029
Epoch 53/110
 - 3s - loss: 0.2877 - accuracy: 0.9493 - val_loss: 0.8409 - val_accuracy: 0.8255
Epoch 54/110
 - 3s - loss: 0.2621 - accuracy: 0.9622 - val_loss: 0.8285 - val_accuracy: 0.8460
Epoch 55/110
 - 3s - loss: 0.2716 - accuracy: 0.9606 - val_loss: 0.8469 - val_accuracy: 0.8423
Epoch 56/110
 - 3s - loss: 0.2756 - accuracy: 0.9573 - val_loss: 0.8255 - val_accuracy: 0.8394
Epoch 57/110
 - 3s - loss: 0.2646 - accuracy: 0.9597 - val_loss: 0.8363 - val_accuracy: 0.8248
Epoch 58/110
 - 3s - loss: 0.2620 - accuracy: 0.9622 - val_loss: 0.8290 - val_accuracy: 0.8263
Epoch 59/110
 - 3s - loss: 0.2387 - accuracy: 0.9704 - val_loss: 0.8037 - val_accuracy: 0.8467
Epoch 60/110
 - 3s - loss: 0.2691 - accuracy: 0.9586 - val_loss: 0.8836 - val_accuracy: 0.8161
Epoch 61/110
 - 3s - loss: 0.2783 - accuracy: 0.9549 - val_loss: 0.8973 - val_accuracy: 0.8255
Epoch 62/110
 - 3s - loss: 0.2859 - accuracy: 0.9525 - val_loss: 0.9038 - val_accuracy: 0.8175
Epoch 63/110
 - 3s - loss: 0.2853 - accuracy: 0.9536 - val_loss: 0.7965 - val_accuracy: 0.8394
Epoch 64/110
 - 3s - loss: 0.2887 - accuracy: 0.9503 - val_loss: 0.7665 - val_accuracy: 0.8496
Epoch 65/110
 - 3s - loss: 0.2607 - accuracy: 0.9631 - val_loss: 0.8755 - val_accuracy: 0.8372
Epoch 66/110
 - 3s - loss: 0.2595 - accuracy: 0.9606 - val_loss: 0.8545 - val_accuracy: 0.8219
Epoch 67/110
 - 3s - loss: 0.2228 - accuracy: 0.9766 - val_loss: 0.7986 - val_accuracy: 0.8438
Epoch 68/110
 - 3s - loss: 0.2292 - accuracy: 0.9754 - val_loss: 0.8340 - val_accuracy: 0.8321
Epoch 69/110
 - 3s - loss: 0.2374 - accuracy: 0.9684 - val_loss: 0.8411 - val_accuracy: 0.8336
Epoch 70/110
 - 3s - loss: 0.2466 - accuracy: 0.9677 - val_loss: 0.8357 - val_accuracy: 0.8416
Epoch 71/110
 - 3s - loss: 0.2648 - accuracy: 0.9611 - val_loss: 0.8612 - val_accuracy: 0.8358
Epoch 72/110
 - 3s - loss: 0.2585 - accuracy: 0.9604 - val_loss: 0.9324 - val_accuracy: 0.8190
Epoch 73/110
 - 3s - loss: 0.2846 - accuracy: 0.9509 - val_loss: 0.7774 - val_accuracy: 0.8416
Epoch 74/110
 - 3s - loss: 0.2719 - accuracy: 0.9573 - val_loss: 0.7902 - val_accuracy: 0.8292
Epoch 75/110
 - 3s - loss: 0.2674 - accuracy: 0.9571 - val_loss: 0.7978 - val_accuracy: 0.8460
Epoch 76/110
 - 3s - loss: 0.2613 - accuracy: 0.9622 - val_loss: 0.8379 - val_accuracy: 0.8387
Epoch 77/110
 - 3s - loss: 0.2457 - accuracy: 0.9686 - val_loss: 0.7796 - val_accuracy: 0.8562
Epoch 78/110
 - 3s - loss: 0.2439 - accuracy: 0.9691 - val_loss: 0.8932 - val_accuracy: 0.8453
Epoch 79/110
 - 3s - loss: 0.2593 - accuracy: 0.9648 - val_loss: 0.8535 - val_accuracy: 0.8394
Epoch 80/110
 - 3s - loss: 0.2264 - accuracy: 0.9732 - val_loss: 0.8399 - val_accuracy: 0.8467
Epoch 81/110
 - 3s - loss: 0.2347 - accuracy: 0.9719 - val_loss: 0.7947 - val_accuracy: 0.8526
Epoch 82/110
 - 3s - loss: 0.2307 - accuracy: 0.9719 - val_loss: 0.8445 - val_accuracy: 0.8438
Epoch 83/110
 - 3s - loss: 0.2323 - accuracy: 0.9724 - val_loss: 0.7856 - val_accuracy: 0.8365
Epoch 84/110
 - 3s - loss: 0.2345 - accuracy: 0.9701 - val_loss: 0.8815 - val_accuracy: 0.8409
Epoch 85/110
 - 3s - loss: 0.2359 - accuracy: 0.9684 - val_loss: 0.8035 - val_accuracy: 0.8416
Epoch 86/110
 - 3s - loss: 0.2519 - accuracy: 0.9653 - val_loss: 0.8467 - val_accuracy: 0.8409
Epoch 87/110
 - 3s - loss: 0.2490 - accuracy: 0.9671 - val_loss: 0.8567 - val_accuracy: 0.8460
Epoch 88/110
 - 3s - loss: 0.2639 - accuracy: 0.9584 - val_loss: 0.8339 - val_accuracy: 0.8307
Epoch 89/110
 - 3s - loss: 0.2406 - accuracy: 0.9648 - val_loss: 0.8405 - val_accuracy: 0.8299
Epoch 90/110
 - 3s - loss: 0.2341 - accuracy: 0.9702 - val_loss: 0.8290 - val_accuracy: 0.8387
Epoch 91/110
 - 3s - loss: 0.2496 - accuracy: 0.9657 - val_loss: 0.9311 - val_accuracy: 0.8474
Epoch 92/110
 - 3s - loss: 0.2624 - accuracy: 0.9640 - val_loss: 0.7947 - val_accuracy: 0.8489
Epoch 93/110
 - 3s - loss: 0.2029 - accuracy: 0.9823 - val_loss: 0.8114 - val_accuracy: 0.8511
Epoch 94/110
 - 3s - loss: 0.2158 - accuracy: 0.9759 - val_loss: 0.8730 - val_accuracy: 0.8533
Epoch 95/110
 - 3s - loss: 0.2403 - accuracy: 0.9690 - val_loss: 0.7920 - val_accuracy: 0.8504
Epoch 96/110
 - 3s - loss: 0.2232 - accuracy: 0.9728 - val_loss: 0.8640 - val_accuracy: 0.8175
Epoch 97/110
 - 3s - loss: 0.2110 - accuracy: 0.9785 - val_loss: 0.8546 - val_accuracy: 0.8336
Epoch 98/110
 - 3s - loss: 0.2329 - accuracy: 0.9715 - val_loss: 0.9028 - val_accuracy: 0.8314
Epoch 99/110
 - 3s - loss: 0.2355 - accuracy: 0.9695 - val_loss: 0.8521 - val_accuracy: 0.8423
Epoch 100/110
 - 3s - loss: 0.2375 - accuracy: 0.9684 - val_loss: 0.9035 - val_accuracy: 0.8365
Epoch 101/110
 - 3s - loss: 0.2464 - accuracy: 0.9673 - val_loss: 0.8861 - val_accuracy: 0.8489
Epoch 102/110
 - 3s - loss: 0.2295 - accuracy: 0.9715 - val_loss: 0.8085 - val_accuracy: 0.8467
Epoch 103/110
 - 3s - loss: 0.2363 - accuracy: 0.9702 - val_loss: 0.8906 - val_accuracy: 0.8372
Epoch 104/110
 - 3s - loss: 0.2213 - accuracy: 0.9741 - val_loss: 0.8702 - val_accuracy: 0.8409
Epoch 105/110
 - 3s - loss: 0.2357 - accuracy: 0.9699 - val_loss: 0.8543 - val_accuracy: 0.8314
Epoch 106/110
 - 3s - loss: 0.2123 - accuracy: 0.9757 - val_loss: 0.8142 - val_accuracy: 0.8409
Epoch 107/110
 - 3s - loss: 0.2148 - accuracy: 0.9772 - val_loss: 0.8857 - val_accuracy: 0.8285
Epoch 108/110
 - 3s - loss: 0.2370 - accuracy: 0.9697 - val_loss: 0.8005 - val_accuracy: 0.8504
Epoch 109/110
 - 3s - loss: 0.2180 - accuracy: 0.9772 - val_loss: 0.9086 - val_accuracy: 0.8431
Epoch 110/110
 - 3s - loss: 0.2127 - accuracy: 0.9768 - val_loss: 0.8738 - val_accuracy: 0.8599
------------------------------------------------------------------------
Training for fold 2 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 7s - loss: 1.1090 - accuracy: 0.6365 - val_loss: 2.4092 - val_accuracy: 0.3474
Epoch 2/110
 - 3s - loss: 0.7453 - accuracy: 0.7789 - val_loss: 1.1046 - val_accuracy: 0.6095
Epoch 3/110
 - 3s - loss: 0.6327 - accuracy: 0.8222 - val_loss: 0.7922 - val_accuracy: 0.7569
Epoch 4/110
 - 3s - loss: 0.5678 - accuracy: 0.8459 - val_loss: 0.7474 - val_accuracy: 0.7774
Epoch 5/110
 - 3s - loss: 0.5285 - accuracy: 0.8633 - val_loss: 0.7468 - val_accuracy: 0.7766
Epoch 6/110
 - 3s - loss: 0.5198 - accuracy: 0.8591 - val_loss: 0.8022 - val_accuracy: 0.7555
Epoch 7/110
 - 3s - loss: 0.5152 - accuracy: 0.8640 - val_loss: 0.7807 - val_accuracy: 0.7818
Epoch 8/110
 - 3s - loss: 0.4815 - accuracy: 0.8782 - val_loss: 0.8378 - val_accuracy: 0.7723
Epoch 9/110
 - 3s - loss: 0.4716 - accuracy: 0.8770 - val_loss: 0.8624 - val_accuracy: 0.7642
Epoch 10/110
 - 3s - loss: 0.4667 - accuracy: 0.8806 - val_loss: 0.8372 - val_accuracy: 0.7555
Epoch 11/110
 - 3s - loss: 0.4632 - accuracy: 0.8804 - val_loss: 0.8041 - val_accuracy: 0.7555
Epoch 12/110
 - 3s - loss: 0.4600 - accuracy: 0.8795 - val_loss: 0.7561 - val_accuracy: 0.7912
Epoch 13/110
 - 3s - loss: 0.4396 - accuracy: 0.8868 - val_loss: 0.7394 - val_accuracy: 0.7898
Epoch 14/110
 - 3s - loss: 0.4237 - accuracy: 0.8956 - val_loss: 0.7729 - val_accuracy: 0.8015
Epoch 15/110
 - 3s - loss: 0.4296 - accuracy: 0.8939 - val_loss: 0.7978 - val_accuracy: 0.7905
Epoch 16/110
 - 3s - loss: 0.4137 - accuracy: 0.8983 - val_loss: 0.7929 - val_accuracy: 0.7905
Epoch 17/110
 - 3s - loss: 0.4120 - accuracy: 0.9022 - val_loss: 0.7883 - val_accuracy: 0.7912
Epoch 18/110
 - 3s - loss: 0.4018 - accuracy: 0.9043 - val_loss: 0.8038 - val_accuracy: 0.7964
Epoch 19/110
 - 3s - loss: 0.3843 - accuracy: 0.9078 - val_loss: 0.7995 - val_accuracy: 0.7993
Epoch 20/110
 - 3s - loss: 0.4040 - accuracy: 0.9027 - val_loss: 0.8403 - val_accuracy: 0.7927
Epoch 21/110
 - 3s - loss: 0.3929 - accuracy: 0.9076 - val_loss: 0.7370 - val_accuracy: 0.8153
Epoch 22/110
 - 3s - loss: 0.3831 - accuracy: 0.9120 - val_loss: 0.7851 - val_accuracy: 0.7978
Epoch 23/110
 - 3s - loss: 0.3566 - accuracy: 0.9175 - val_loss: 0.7761 - val_accuracy: 0.8117
Epoch 24/110
 - 3s - loss: 0.3477 - accuracy: 0.9250 - val_loss: 0.7766 - val_accuracy: 0.8197
Epoch 25/110
 - 3s - loss: 0.3559 - accuracy: 0.9204 - val_loss: 0.7834 - val_accuracy: 0.8226
Epoch 26/110
 - 3s - loss: 0.3427 - accuracy: 0.9290 - val_loss: 0.7765 - val_accuracy: 0.8190
Epoch 27/110
 - 3s - loss: 0.3473 - accuracy: 0.9277 - val_loss: 0.7497 - val_accuracy: 0.8255
Epoch 28/110
 - 3s - loss: 0.3172 - accuracy: 0.9359 - val_loss: 0.7863 - val_accuracy: 0.8226
Epoch 29/110
 - 3s - loss: 0.3272 - accuracy: 0.9343 - val_loss: 0.7486 - val_accuracy: 0.8263
Epoch 30/110
 - 3s - loss: 0.3429 - accuracy: 0.9279 - val_loss: 0.8551 - val_accuracy: 0.8000
Epoch 31/110
 - 3s - loss: 0.3348 - accuracy: 0.9314 - val_loss: 0.8324 - val_accuracy: 0.8204
Epoch 32/110
 - 3s - loss: 0.3341 - accuracy: 0.9321 - val_loss: 0.8083 - val_accuracy: 0.8044
Epoch 33/110
 - 3s - loss: 0.3242 - accuracy: 0.9346 - val_loss: 0.8181 - val_accuracy: 0.8263
Epoch 34/110
 - 3s - loss: 0.3092 - accuracy: 0.9430 - val_loss: 0.8074 - val_accuracy: 0.8212
Epoch 35/110
 - 3s - loss: 0.3031 - accuracy: 0.9434 - val_loss: 0.8773 - val_accuracy: 0.8190
Epoch 36/110
 - 3s - loss: 0.3027 - accuracy: 0.9432 - val_loss: 0.7999 - val_accuracy: 0.8263
Epoch 37/110
 - 3s - loss: 0.3168 - accuracy: 0.9394 - val_loss: 0.8669 - val_accuracy: 0.8139
Epoch 38/110
 - 3s - loss: 0.3157 - accuracy: 0.9365 - val_loss: 0.8409 - val_accuracy: 0.8263
Epoch 39/110
 - 3s - loss: 0.3084 - accuracy: 0.9425 - val_loss: 0.8599 - val_accuracy: 0.8168
Epoch 40/110
 - 3s - loss: 0.2978 - accuracy: 0.9443 - val_loss: 0.8664 - val_accuracy: 0.8095
Epoch 41/110
 - 3s - loss: 0.3034 - accuracy: 0.9438 - val_loss: 0.8103 - val_accuracy: 0.8328
Epoch 42/110
 - 3s - loss: 0.2997 - accuracy: 0.9458 - val_loss: 0.8900 - val_accuracy: 0.8146
Epoch 43/110
 - 3s - loss: 0.3028 - accuracy: 0.9418 - val_loss: 0.8817 - val_accuracy: 0.8226
Epoch 44/110
 - 3s - loss: 0.3035 - accuracy: 0.9414 - val_loss: 0.8827 - val_accuracy: 0.8073
Epoch 45/110
 - 3s - loss: 0.2822 - accuracy: 0.9502 - val_loss: 0.8271 - val_accuracy: 0.8241
Epoch 46/110
 - 3s - loss: 0.2984 - accuracy: 0.9454 - val_loss: 0.9015 - val_accuracy: 0.8088
Epoch 47/110
 - 3s - loss: 0.2956 - accuracy: 0.9487 - val_loss: 0.8212 - val_accuracy: 0.8387
Epoch 48/110
 - 3s - loss: 0.2782 - accuracy: 0.9553 - val_loss: 0.8518 - val_accuracy: 0.8263
Epoch 49/110
 - 3s - loss: 0.3174 - accuracy: 0.9412 - val_loss: 0.9013 - val_accuracy: 0.8036
Epoch 50/110
 - 3s - loss: 0.2967 - accuracy: 0.9491 - val_loss: 0.9448 - val_accuracy: 0.8044
Epoch 51/110
 - 3s - loss: 0.2992 - accuracy: 0.9445 - val_loss: 0.8028 - val_accuracy: 0.8482
Epoch 52/110
 - 3s - loss: 0.2773 - accuracy: 0.9549 - val_loss: 0.8501 - val_accuracy: 0.8234
Epoch 53/110
 - 3s - loss: 0.2837 - accuracy: 0.9536 - val_loss: 0.9609 - val_accuracy: 0.8007
Epoch 54/110
 - 3s - loss: 0.2972 - accuracy: 0.9460 - val_loss: 0.8199 - val_accuracy: 0.8336
Epoch 55/110
 - 3s - loss: 0.2952 - accuracy: 0.9516 - val_loss: 0.9212 - val_accuracy: 0.8212
Epoch 56/110
 - 3s - loss: 0.2909 - accuracy: 0.9514 - val_loss: 0.8469 - val_accuracy: 0.8234
Epoch 57/110
 - 3s - loss: 0.2741 - accuracy: 0.9566 - val_loss: 0.8932 - val_accuracy: 0.8022
Epoch 58/110
 - 3s - loss: 0.2676 - accuracy: 0.9573 - val_loss: 0.8540 - val_accuracy: 0.8372
Epoch 59/110
 - 3s - loss: 0.2647 - accuracy: 0.9624 - val_loss: 0.9165 - val_accuracy: 0.8146
Epoch 60/110
 - 3s - loss: 0.2793 - accuracy: 0.9547 - val_loss: 0.8855 - val_accuracy: 0.8314
Epoch 61/110
 - 3s - loss: 0.2951 - accuracy: 0.9529 - val_loss: 0.8913 - val_accuracy: 0.8204
Epoch 62/110
 - 3s - loss: 0.2688 - accuracy: 0.9598 - val_loss: 0.7799 - val_accuracy: 0.8445
Epoch 63/110
 - 3s - loss: 0.2553 - accuracy: 0.9651 - val_loss: 0.7841 - val_accuracy: 0.8489
Epoch 64/110
 - 3s - loss: 0.2714 - accuracy: 0.9545 - val_loss: 0.8942 - val_accuracy: 0.8234
Epoch 65/110
 - 3s - loss: 0.2613 - accuracy: 0.9609 - val_loss: 0.8337 - val_accuracy: 0.8431
Epoch 66/110
 - 3s - loss: 0.2510 - accuracy: 0.9642 - val_loss: 0.8013 - val_accuracy: 0.8496
Epoch 67/110
 - 3s - loss: 0.2769 - accuracy: 0.9576 - val_loss: 0.8021 - val_accuracy: 0.8387
Epoch 68/110
 - 3s - loss: 0.2503 - accuracy: 0.9655 - val_loss: 0.7568 - val_accuracy: 0.8620
Epoch 69/110
 - 3s - loss: 0.2542 - accuracy: 0.9622 - val_loss: 0.8517 - val_accuracy: 0.8445
Epoch 70/110
 - 3s - loss: 0.2346 - accuracy: 0.9712 - val_loss: 0.8375 - val_accuracy: 0.8482
Epoch 71/110
 - 3s - loss: 0.2351 - accuracy: 0.9686 - val_loss: 0.8207 - val_accuracy: 0.8489
Epoch 72/110
 - 3s - loss: 0.2397 - accuracy: 0.9699 - val_loss: 0.7772 - val_accuracy: 0.8533
Epoch 73/110
 - 3s - loss: 0.2388 - accuracy: 0.9690 - val_loss: 0.8273 - val_accuracy: 0.8387
Epoch 74/110
 - 3s - loss: 0.2454 - accuracy: 0.9662 - val_loss: 0.8832 - val_accuracy: 0.8372
Epoch 75/110
 - 3s - loss: 0.2628 - accuracy: 0.9586 - val_loss: 0.8688 - val_accuracy: 0.8299
Epoch 76/110
 - 3s - loss: 0.2638 - accuracy: 0.9604 - val_loss: 0.8859 - val_accuracy: 0.8365
Epoch 77/110
 - 3s - loss: 0.2415 - accuracy: 0.9679 - val_loss: 0.8050 - val_accuracy: 0.8467
Epoch 78/110
 - 3s - loss: 0.2403 - accuracy: 0.9715 - val_loss: 0.7970 - val_accuracy: 0.8591
Epoch 79/110
 - 3s - loss: 0.2265 - accuracy: 0.9750 - val_loss: 0.8843 - val_accuracy: 0.8409
Epoch 80/110
 - 3s - loss: 0.2714 - accuracy: 0.9604 - val_loss: 0.9216 - val_accuracy: 0.8365
Epoch 81/110
 - 3s - loss: 0.2491 - accuracy: 0.9679 - val_loss: 0.9293 - val_accuracy: 0.8380
Epoch 82/110
 - 3s - loss: 0.2443 - accuracy: 0.9684 - val_loss: 0.9702 - val_accuracy: 0.8190
Epoch 83/110
 - 3s - loss: 0.2561 - accuracy: 0.9598 - val_loss: 0.8801 - val_accuracy: 0.8299
Epoch 84/110
 - 3s - loss: 0.2839 - accuracy: 0.9535 - val_loss: 0.9430 - val_accuracy: 0.8182
Epoch 85/110
 - 3s - loss: 0.2577 - accuracy: 0.9608 - val_loss: 0.9259 - val_accuracy: 0.8277
Epoch 86/110
 - 3s - loss: 0.2603 - accuracy: 0.9633 - val_loss: 0.8533 - val_accuracy: 0.8460
Epoch 87/110
 - 3s - loss: 0.2311 - accuracy: 0.9728 - val_loss: 0.8523 - val_accuracy: 0.8504
Epoch 88/110
 - 3s - loss: 0.2355 - accuracy: 0.9712 - val_loss: 1.0318 - val_accuracy: 0.8146
Epoch 89/110
 - 3s - loss: 0.2291 - accuracy: 0.9726 - val_loss: 0.8976 - val_accuracy: 0.8474
Epoch 90/110
 - 3s - loss: 0.2273 - accuracy: 0.9708 - val_loss: 0.9216 - val_accuracy: 0.8438
Epoch 91/110
 - 3s - loss: 0.2176 - accuracy: 0.9768 - val_loss: 0.8827 - val_accuracy: 0.8460
Epoch 92/110
 - 3s - loss: 0.2329 - accuracy: 0.9715 - val_loss: 0.8559 - val_accuracy: 0.8431
Epoch 93/110
 - 3s - loss: 0.2283 - accuracy: 0.9752 - val_loss: 0.8870 - val_accuracy: 0.8394
Epoch 94/110
 - 3s - loss: 0.2261 - accuracy: 0.9748 - val_loss: 0.8562 - val_accuracy: 0.8504
Epoch 95/110
 - 3s - loss: 0.2386 - accuracy: 0.9675 - val_loss: 0.9211 - val_accuracy: 0.8504
Epoch 96/110
 - 3s - loss: 0.2251 - accuracy: 0.9737 - val_loss: 0.9212 - val_accuracy: 0.8453
Epoch 97/110
 - 3s - loss: 0.2281 - accuracy: 0.9744 - val_loss: 0.8377 - val_accuracy: 0.8555
Epoch 98/110
 - 3s - loss: 0.2456 - accuracy: 0.9686 - val_loss: 0.9841 - val_accuracy: 0.8095
Epoch 99/110
 - 3s - loss: 0.2489 - accuracy: 0.9660 - val_loss: 0.8381 - val_accuracy: 0.8328
Epoch 100/110
 - 3s - loss: 0.2273 - accuracy: 0.9704 - val_loss: 0.9080 - val_accuracy: 0.8277
Epoch 101/110
 - 3s - loss: 0.2355 - accuracy: 0.9693 - val_loss: 0.8706 - val_accuracy: 0.8467
Epoch 102/110
 - 3s - loss: 0.2284 - accuracy: 0.9743 - val_loss: 0.8685 - val_accuracy: 0.8467
Epoch 103/110
 - 3s - loss: 0.2188 - accuracy: 0.9777 - val_loss: 0.8140 - val_accuracy: 0.8613
Epoch 104/110
 - 3s - loss: 0.2171 - accuracy: 0.9783 - val_loss: 0.8048 - val_accuracy: 0.8599
Epoch 105/110
 - 3s - loss: 0.2262 - accuracy: 0.9726 - val_loss: 0.8294 - val_accuracy: 0.8540
Epoch 106/110
 - 3s - loss: 0.2381 - accuracy: 0.9682 - val_loss: 0.8727 - val_accuracy: 0.8467
Epoch 107/110
 - 3s - loss: 0.2398 - accuracy: 0.9704 - val_loss: 0.8260 - val_accuracy: 0.8584
Epoch 108/110
 - 3s - loss: 0.2276 - accuracy: 0.9721 - val_loss: 0.9025 - val_accuracy: 0.8474
Epoch 109/110
 - 3s - loss: 0.2481 - accuracy: 0.9675 - val_loss: 0.9199 - val_accuracy: 0.8241
Epoch 110/110
 - 3s - loss: 0.2386 - accuracy: 0.9701 - val_loss: 0.8034 - val_accuracy: 0.8489
------------------------------------------------------------------------
Training for fold 3 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 7s - loss: 1.1783 - accuracy: 0.6291 - val_loss: 2.6529 - val_accuracy: 0.3745
Epoch 2/110
 - 3s - loss: 0.7673 - accuracy: 0.7636 - val_loss: 1.3111 - val_accuracy: 0.5460
Epoch 3/110
 - 3s - loss: 0.6672 - accuracy: 0.8016 - val_loss: 0.9652 - val_accuracy: 0.6956
Epoch 4/110
 - 3s - loss: 0.6090 - accuracy: 0.8304 - val_loss: 0.8658 - val_accuracy: 0.7080
Epoch 5/110
 - 3s - loss: 0.5597 - accuracy: 0.8483 - val_loss: 0.8813 - val_accuracy: 0.7080
Epoch 6/110
 - 3s - loss: 0.5369 - accuracy: 0.8530 - val_loss: 0.7742 - val_accuracy: 0.7496
Epoch 7/110
 - 3s - loss: 0.5140 - accuracy: 0.8611 - val_loss: 0.7632 - val_accuracy: 0.7693
Epoch 8/110
 - 3s - loss: 0.4871 - accuracy: 0.8746 - val_loss: 0.8004 - val_accuracy: 0.7445
Epoch 9/110
 - 3s - loss: 0.4915 - accuracy: 0.8724 - val_loss: 0.8374 - val_accuracy: 0.7679
Epoch 10/110
 - 3s - loss: 0.4763 - accuracy: 0.8823 - val_loss: 0.8721 - val_accuracy: 0.7372
Epoch 11/110
 - 3s - loss: 0.4539 - accuracy: 0.8883 - val_loss: 0.7745 - val_accuracy: 0.7818
Epoch 12/110
 - 3s - loss: 0.4347 - accuracy: 0.8936 - val_loss: 0.7659 - val_accuracy: 0.7920
Epoch 13/110
 - 3s - loss: 0.4293 - accuracy: 0.8969 - val_loss: 0.7629 - val_accuracy: 0.8007
Epoch 14/110
 - 3s - loss: 0.4127 - accuracy: 0.9049 - val_loss: 0.7226 - val_accuracy: 0.8036
Epoch 15/110
 - 3s - loss: 0.4048 - accuracy: 0.9053 - val_loss: 0.7671 - val_accuracy: 0.8022
Epoch 16/110
 - 3s - loss: 0.4155 - accuracy: 0.9029 - val_loss: 0.8091 - val_accuracy: 0.8058
Epoch 17/110
 - 3s - loss: 0.4134 - accuracy: 0.9022 - val_loss: 0.7658 - val_accuracy: 0.8044
Epoch 18/110
 - 3s - loss: 0.4009 - accuracy: 0.9091 - val_loss: 0.7643 - val_accuracy: 0.8088
Epoch 19/110
 - 3s - loss: 0.3803 - accuracy: 0.9158 - val_loss: 0.7854 - val_accuracy: 0.8139
Epoch 20/110
 - 3s - loss: 0.4044 - accuracy: 0.9011 - val_loss: 0.8419 - val_accuracy: 0.7861
Epoch 21/110
 - 3s - loss: 0.3964 - accuracy: 0.9064 - val_loss: 0.8207 - val_accuracy: 0.8022
Epoch 22/110
 - 3s - loss: 0.3953 - accuracy: 0.9067 - val_loss: 0.7735 - val_accuracy: 0.8058
Epoch 23/110
 - 3s - loss: 0.3783 - accuracy: 0.9115 - val_loss: 0.8132 - val_accuracy: 0.7956
Epoch 24/110
 - 3s - loss: 0.3762 - accuracy: 0.9160 - val_loss: 0.7803 - val_accuracy: 0.8088
Epoch 25/110
 - 3s - loss: 0.3709 - accuracy: 0.9211 - val_loss: 0.8159 - val_accuracy: 0.8117
Epoch 26/110
 - 3s - loss: 0.3712 - accuracy: 0.9206 - val_loss: 0.8225 - val_accuracy: 0.8036
Epoch 27/110
 - 3s - loss: 0.3527 - accuracy: 0.9233 - val_loss: 0.8210 - val_accuracy: 0.8080
Epoch 28/110
 - 3s - loss: 0.3552 - accuracy: 0.9250 - val_loss: 0.8052 - val_accuracy: 0.8095
Epoch 29/110
 - 3s - loss: 0.3420 - accuracy: 0.9308 - val_loss: 0.8724 - val_accuracy: 0.8051
Epoch 30/110
 - 3s - loss: 0.3301 - accuracy: 0.9341 - val_loss: 0.8181 - val_accuracy: 0.8212
Epoch 31/110
 - 3s - loss: 0.3185 - accuracy: 0.9421 - val_loss: 0.8136 - val_accuracy: 0.8190
Epoch 32/110
 - 3s - loss: 0.3274 - accuracy: 0.9343 - val_loss: 0.8951 - val_accuracy: 0.8088
Epoch 33/110
 - 3s - loss: 0.3474 - accuracy: 0.9259 - val_loss: 0.9413 - val_accuracy: 0.8095
Epoch 34/110
 - 3s - loss: 0.3447 - accuracy: 0.9266 - val_loss: 0.8315 - val_accuracy: 0.8277
Epoch 35/110
 - 3s - loss: 0.3155 - accuracy: 0.9396 - val_loss: 0.7833 - val_accuracy: 0.8307
Epoch 36/110
 - 3s - loss: 0.3264 - accuracy: 0.9341 - val_loss: 0.8649 - val_accuracy: 0.8044
Epoch 37/110
 - 3s - loss: 0.3254 - accuracy: 0.9352 - val_loss: 0.7801 - val_accuracy: 0.8219
Epoch 38/110
 - 3s - loss: 0.3528 - accuracy: 0.9272 - val_loss: 0.8810 - val_accuracy: 0.7971
Epoch 39/110
 - 3s - loss: 0.3309 - accuracy: 0.9330 - val_loss: 0.7719 - val_accuracy: 0.8241
Epoch 40/110
 - 3s - loss: 0.3260 - accuracy: 0.9330 - val_loss: 0.8202 - val_accuracy: 0.8270
Epoch 41/110
 - 3s - loss: 0.3203 - accuracy: 0.9374 - val_loss: 0.8733 - val_accuracy: 0.8073
Epoch 42/110
 - 3s - loss: 0.3150 - accuracy: 0.9383 - val_loss: 0.8866 - val_accuracy: 0.8066
Epoch 43/110
 - 3s - loss: 0.3143 - accuracy: 0.9370 - val_loss: 0.8150 - val_accuracy: 0.8066
Epoch 44/110
 - 3s - loss: 0.3277 - accuracy: 0.9330 - val_loss: 0.8525 - val_accuracy: 0.8066
Epoch 45/110
 - 3s - loss: 0.3208 - accuracy: 0.9398 - val_loss: 0.8175 - val_accuracy: 0.8161
Epoch 46/110
 - 3s - loss: 0.3077 - accuracy: 0.9438 - val_loss: 0.8767 - val_accuracy: 0.8124
Epoch 47/110
 - 3s - loss: 0.3035 - accuracy: 0.9456 - val_loss: 0.8469 - val_accuracy: 0.8270
Epoch 48/110
 - 3s - loss: 0.2951 - accuracy: 0.9452 - val_loss: 0.8925 - val_accuracy: 0.8058
Epoch 49/110
 - 3s - loss: 0.2912 - accuracy: 0.9498 - val_loss: 0.8489 - val_accuracy: 0.8190
Epoch 50/110
 - 3s - loss: 0.2827 - accuracy: 0.9522 - val_loss: 0.8235 - val_accuracy: 0.8095
Epoch 51/110
 - 3s - loss: 0.2986 - accuracy: 0.9445 - val_loss: 0.7491 - val_accuracy: 0.8394
Epoch 52/110
 - 3s - loss: 0.2896 - accuracy: 0.9476 - val_loss: 0.8154 - val_accuracy: 0.8263
Epoch 53/110
 - 3s - loss: 0.2764 - accuracy: 0.9551 - val_loss: 0.7909 - val_accuracy: 0.8358
Epoch 54/110
 - 3s - loss: 0.3081 - accuracy: 0.9414 - val_loss: 0.8113 - val_accuracy: 0.8255
Epoch 55/110
 - 3s - loss: 0.2917 - accuracy: 0.9503 - val_loss: 0.7901 - val_accuracy: 0.8321
Epoch 56/110
 - 3s - loss: 0.2782 - accuracy: 0.9524 - val_loss: 0.7939 - val_accuracy: 0.8314
Epoch 57/110
 - 3s - loss: 0.2662 - accuracy: 0.9556 - val_loss: 0.8377 - val_accuracy: 0.8263
Epoch 58/110
 - 3s - loss: 0.2918 - accuracy: 0.9494 - val_loss: 0.8182 - val_accuracy: 0.8299
Epoch 59/110
 - 3s - loss: 0.2891 - accuracy: 0.9480 - val_loss: 0.8526 - val_accuracy: 0.8197
Epoch 60/110
 - 3s - loss: 0.2947 - accuracy: 0.9514 - val_loss: 0.8699 - val_accuracy: 0.8277
Epoch 61/110
 - 3s - loss: 0.2766 - accuracy: 0.9542 - val_loss: 0.7734 - val_accuracy: 0.8350
Epoch 62/110
 - 3s - loss: 0.2763 - accuracy: 0.9576 - val_loss: 0.8540 - val_accuracy: 0.8328
Epoch 63/110
 - 3s - loss: 0.2843 - accuracy: 0.9522 - val_loss: 0.8723 - val_accuracy: 0.8088
Epoch 64/110
 - 3s - loss: 0.2608 - accuracy: 0.9606 - val_loss: 0.8402 - val_accuracy: 0.8197
Epoch 65/110
 - 3s - loss: 0.2630 - accuracy: 0.9582 - val_loss: 0.8340 - val_accuracy: 0.8248
Epoch 66/110
 - 3s - loss: 0.2628 - accuracy: 0.9617 - val_loss: 0.8141 - val_accuracy: 0.8401
Epoch 67/110
 - 3s - loss: 0.2569 - accuracy: 0.9635 - val_loss: 0.8707 - val_accuracy: 0.8416
Epoch 68/110
 - 3s - loss: 0.2717 - accuracy: 0.9562 - val_loss: 0.9165 - val_accuracy: 0.8277
Epoch 69/110
 - 3s - loss: 0.2767 - accuracy: 0.9545 - val_loss: 0.9166 - val_accuracy: 0.8328
Epoch 70/110
 - 3s - loss: 0.2706 - accuracy: 0.9562 - val_loss: 0.8497 - val_accuracy: 0.8328
Epoch 71/110
 - 3s - loss: 0.2523 - accuracy: 0.9650 - val_loss: 0.8799 - val_accuracy: 0.8380
Epoch 72/110
 - 3s - loss: 0.2661 - accuracy: 0.9602 - val_loss: 0.8610 - val_accuracy: 0.8307
Epoch 73/110
 - 3s - loss: 0.2566 - accuracy: 0.9604 - val_loss: 0.8214 - val_accuracy: 0.8372
Epoch 74/110
 - 3s - loss: 0.2505 - accuracy: 0.9651 - val_loss: 0.8681 - val_accuracy: 0.8431
Epoch 75/110
 - 3s - loss: 0.2516 - accuracy: 0.9646 - val_loss: 0.7939 - val_accuracy: 0.8482
Epoch 76/110
 - 3s - loss: 0.2469 - accuracy: 0.9653 - val_loss: 0.9576 - val_accuracy: 0.8314
Epoch 77/110
 - 3s - loss: 0.2620 - accuracy: 0.9631 - val_loss: 0.8988 - val_accuracy: 0.8365
Epoch 78/110
 - 3s - loss: 0.2396 - accuracy: 0.9701 - val_loss: 0.8801 - val_accuracy: 0.8328
Epoch 79/110
 - 3s - loss: 0.2363 - accuracy: 0.9710 - val_loss: 0.9375 - val_accuracy: 0.8277
Epoch 80/110
 - 3s - loss: 0.2515 - accuracy: 0.9620 - val_loss: 0.8199 - val_accuracy: 0.8438
Epoch 81/110
 - 3s - loss: 0.2529 - accuracy: 0.9633 - val_loss: 0.8258 - val_accuracy: 0.8489
Epoch 82/110
 - 3s - loss: 0.2355 - accuracy: 0.9697 - val_loss: 0.8885 - val_accuracy: 0.8343
Epoch 83/110
 - 3s - loss: 0.2459 - accuracy: 0.9666 - val_loss: 0.8152 - val_accuracy: 0.8307
Epoch 84/110
 - 3s - loss: 0.2494 - accuracy: 0.9650 - val_loss: 0.8033 - val_accuracy: 0.8547
Epoch 85/110
 - 3s - loss: 0.2568 - accuracy: 0.9615 - val_loss: 0.8755 - val_accuracy: 0.8409
Epoch 86/110
 - 3s - loss: 0.2621 - accuracy: 0.9646 - val_loss: 0.8656 - val_accuracy: 0.8423
Epoch 87/110
 - 3s - loss: 0.2405 - accuracy: 0.9675 - val_loss: 0.8675 - val_accuracy: 0.8285
Epoch 88/110
 - 3s - loss: 0.2329 - accuracy: 0.9733 - val_loss: 0.8489 - val_accuracy: 0.8358
Epoch 89/110
 - 3s - loss: 0.2356 - accuracy: 0.9688 - val_loss: 0.8668 - val_accuracy: 0.8401
Epoch 90/110
 - 3s - loss: 0.2575 - accuracy: 0.9657 - val_loss: 0.8325 - val_accuracy: 0.8401
Epoch 91/110
 - 3s - loss: 0.2490 - accuracy: 0.9660 - val_loss: 0.8708 - val_accuracy: 0.8343
Epoch 92/110
 - 3s - loss: 0.2351 - accuracy: 0.9684 - val_loss: 0.8111 - val_accuracy: 0.8496
Epoch 93/110
 - 3s - loss: 0.2213 - accuracy: 0.9754 - val_loss: 0.8446 - val_accuracy: 0.8511
Epoch 94/110
 - 3s - loss: 0.2262 - accuracy: 0.9728 - val_loss: 0.7630 - val_accuracy: 0.8584
Epoch 95/110
 - 3s - loss: 0.2284 - accuracy: 0.9730 - val_loss: 0.7745 - val_accuracy: 0.8613
Epoch 96/110
 - 3s - loss: 0.2171 - accuracy: 0.9739 - val_loss: 0.8608 - val_accuracy: 0.8504
Epoch 97/110
 - 3s - loss: 0.2322 - accuracy: 0.9708 - val_loss: 0.9155 - val_accuracy: 0.8453
Epoch 98/110
 - 3s - loss: 0.2385 - accuracy: 0.9699 - val_loss: 0.8985 - val_accuracy: 0.8438
Epoch 99/110
 - 3s - loss: 0.2218 - accuracy: 0.9748 - val_loss: 0.8522 - val_accuracy: 0.8467
Epoch 100/110
 - 3s - loss: 0.2410 - accuracy: 0.9702 - val_loss: 0.8494 - val_accuracy: 0.8504
Epoch 101/110
 - 3s - loss: 0.2443 - accuracy: 0.9666 - val_loss: 0.8414 - val_accuracy: 0.8467
Epoch 102/110
 - 3s - loss: 0.2495 - accuracy: 0.9655 - val_loss: 0.8749 - val_accuracy: 0.8438
Epoch 103/110
 - 3s - loss: 0.2569 - accuracy: 0.9635 - val_loss: 0.8589 - val_accuracy: 0.8394
Epoch 104/110
 - 3s - loss: 0.2310 - accuracy: 0.9728 - val_loss: 0.7790 - val_accuracy: 0.8453
Epoch 105/110
 - 3s - loss: 0.2101 - accuracy: 0.9792 - val_loss: 0.7846 - val_accuracy: 0.8504
Epoch 106/110
 - 3s - loss: 0.2102 - accuracy: 0.9806 - val_loss: 0.8399 - val_accuracy: 0.8467
Epoch 107/110
 - 3s - loss: 0.2248 - accuracy: 0.9748 - val_loss: 0.8934 - val_accuracy: 0.8467
Epoch 108/110
 - 3s - loss: 0.2287 - accuracy: 0.9726 - val_loss: 0.8365 - val_accuracy: 0.8482
Epoch 109/110
 - 3s - loss: 0.2473 - accuracy: 0.9640 - val_loss: 0.9066 - val_accuracy: 0.8365
Epoch 110/110
 - 3s - loss: 0.2509 - accuracy: 0.9635 - val_loss: 0.8701 - val_accuracy: 0.8285
------------------------------------------------------------------------
Training for fold 4 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 7s - loss: 1.2839 - accuracy: 0.5975 - val_loss: 1.8748 - val_accuracy: 0.3460
Epoch 2/110
 - 3s - loss: 0.7432 - accuracy: 0.7788 - val_loss: 1.2140 - val_accuracy: 0.6015
Epoch 3/110
 - 3s - loss: 0.6476 - accuracy: 0.8143 - val_loss: 0.8931 - val_accuracy: 0.7066
Epoch 4/110
 - 3s - loss: 0.5749 - accuracy: 0.8465 - val_loss: 0.7963 - val_accuracy: 0.7635
Epoch 5/110
 - 3s - loss: 0.5396 - accuracy: 0.8567 - val_loss: 0.8081 - val_accuracy: 0.7737
Epoch 6/110
 - 3s - loss: 0.5348 - accuracy: 0.8538 - val_loss: 0.8483 - val_accuracy: 0.7693
Epoch 7/110
 - 3s - loss: 0.5483 - accuracy: 0.8421 - val_loss: 0.7835 - val_accuracy: 0.7883
Epoch 8/110
 - 3s - loss: 0.5048 - accuracy: 0.8644 - val_loss: 0.7784 - val_accuracy: 0.7869
Epoch 9/110
 - 3s - loss: 0.4787 - accuracy: 0.8777 - val_loss: 0.8068 - val_accuracy: 0.7818
Epoch 10/110
 - 3s - loss: 0.4751 - accuracy: 0.8779 - val_loss: 0.7914 - val_accuracy: 0.7891
Epoch 11/110
 - 3s - loss: 0.4565 - accuracy: 0.8876 - val_loss: 0.8174 - val_accuracy: 0.7818
Epoch 12/110
 - 3s - loss: 0.4330 - accuracy: 0.8907 - val_loss: 0.8765 - val_accuracy: 0.7839
Epoch 13/110
 - 3s - loss: 0.4294 - accuracy: 0.8939 - val_loss: 0.8103 - val_accuracy: 0.7949
Epoch 14/110
 - 3s - loss: 0.4170 - accuracy: 0.8974 - val_loss: 0.9042 - val_accuracy: 0.7606
Epoch 15/110
 - 3s - loss: 0.4102 - accuracy: 0.9043 - val_loss: 0.7920 - val_accuracy: 0.8022
Epoch 16/110
 - 3s - loss: 0.4109 - accuracy: 0.9069 - val_loss: 0.7930 - val_accuracy: 0.7912
Epoch 17/110
 - 3s - loss: 0.3995 - accuracy: 0.9065 - val_loss: 0.7835 - val_accuracy: 0.8204
Epoch 18/110
 - 3s - loss: 0.3957 - accuracy: 0.9069 - val_loss: 0.8257 - val_accuracy: 0.8051
Epoch 19/110
 - 3s - loss: 0.4057 - accuracy: 0.9043 - val_loss: 0.8641 - val_accuracy: 0.7920
Epoch 20/110
 - 3s - loss: 0.3967 - accuracy: 0.9056 - val_loss: 0.8437 - val_accuracy: 0.7912
Epoch 21/110
 - 3s - loss: 0.3726 - accuracy: 0.9149 - val_loss: 0.8188 - val_accuracy: 0.8073
Epoch 22/110
 - 3s - loss: 0.3794 - accuracy: 0.9162 - val_loss: 0.9144 - val_accuracy: 0.7869
Epoch 23/110
 - 3s - loss: 0.3881 - accuracy: 0.9151 - val_loss: 0.8542 - val_accuracy: 0.7869
Epoch 24/110
 - 3s - loss: 0.3824 - accuracy: 0.9149 - val_loss: 0.8174 - val_accuracy: 0.8022
Epoch 25/110
 - 3s - loss: 0.3537 - accuracy: 0.9219 - val_loss: 0.8051 - val_accuracy: 0.8058
Epoch 26/110
 - 3s - loss: 0.3491 - accuracy: 0.9281 - val_loss: 0.8536 - val_accuracy: 0.8080
Epoch 27/110
 - 3s - loss: 0.3356 - accuracy: 0.9304 - val_loss: 0.8075 - val_accuracy: 0.8219
Epoch 28/110
 - 3s - loss: 0.3398 - accuracy: 0.9304 - val_loss: 0.8570 - val_accuracy: 0.8058
Epoch 29/110
 - 3s - loss: 0.3509 - accuracy: 0.9284 - val_loss: 0.8738 - val_accuracy: 0.7949
Epoch 30/110
 - 3s - loss: 0.3313 - accuracy: 0.9346 - val_loss: 0.8731 - val_accuracy: 0.8066
Epoch 31/110
 - 3s - loss: 0.3243 - accuracy: 0.9339 - val_loss: 0.8746 - val_accuracy: 0.8044
Epoch 32/110
 - 3s - loss: 0.3428 - accuracy: 0.9286 - val_loss: 0.8138 - val_accuracy: 0.8146
Epoch 33/110
 - 3s - loss: 0.3242 - accuracy: 0.9376 - val_loss: 0.8492 - val_accuracy: 0.7971
Epoch 34/110
 - 3s - loss: 0.3326 - accuracy: 0.9341 - val_loss: 0.8847 - val_accuracy: 0.7993
Epoch 35/110
 - 3s - loss: 0.3329 - accuracy: 0.9301 - val_loss: 0.8675 - val_accuracy: 0.8044
Epoch 36/110
 - 3s - loss: 0.3271 - accuracy: 0.9379 - val_loss: 0.9692 - val_accuracy: 0.8036
Epoch 37/110
 - 3s - loss: 0.3232 - accuracy: 0.9346 - val_loss: 0.8221 - val_accuracy: 0.8219
Epoch 38/110
 - 3s - loss: 0.3351 - accuracy: 0.9295 - val_loss: 0.8915 - val_accuracy: 0.8007
Epoch 39/110
 - 3s - loss: 0.3405 - accuracy: 0.9284 - val_loss: 0.9816 - val_accuracy: 0.7730
Epoch 40/110
 - 3s - loss: 0.3363 - accuracy: 0.9336 - val_loss: 0.8721 - val_accuracy: 0.8044
Epoch 41/110
 - 3s - loss: 0.3485 - accuracy: 0.9332 - val_loss: 0.8043 - val_accuracy: 0.8248
Epoch 42/110
 - 3s - loss: 0.3307 - accuracy: 0.9379 - val_loss: 0.7858 - val_accuracy: 0.8328
Epoch 43/110
 - 3s - loss: 0.3200 - accuracy: 0.9398 - val_loss: 0.8831 - val_accuracy: 0.8139
Epoch 44/110
 - 3s - loss: 0.3131 - accuracy: 0.9407 - val_loss: 0.7908 - val_accuracy: 0.8343
Epoch 45/110
 - 3s - loss: 0.3174 - accuracy: 0.9401 - val_loss: 0.8461 - val_accuracy: 0.8153
Epoch 46/110
 - 3s - loss: 0.3257 - accuracy: 0.9359 - val_loss: 0.8921 - val_accuracy: 0.8182
Epoch 47/110
 - 3s - loss: 0.3257 - accuracy: 0.9423 - val_loss: 0.8262 - val_accuracy: 0.8350
Epoch 48/110
 - 3s - loss: 0.3026 - accuracy: 0.9441 - val_loss: 0.8292 - val_accuracy: 0.8117
Epoch 49/110
 - 3s - loss: 0.3035 - accuracy: 0.9440 - val_loss: 0.8754 - val_accuracy: 0.8204
Epoch 50/110
 - 3s - loss: 0.3020 - accuracy: 0.9482 - val_loss: 0.8062 - val_accuracy: 0.8350
Epoch 51/110
 - 3s - loss: 0.2920 - accuracy: 0.9476 - val_loss: 0.9533 - val_accuracy: 0.8029
Epoch 52/110
 - 3s - loss: 0.3045 - accuracy: 0.9447 - val_loss: 0.8258 - val_accuracy: 0.8255
Epoch 53/110
 - 3s - loss: 0.2951 - accuracy: 0.9478 - val_loss: 0.8140 - val_accuracy: 0.8314
Epoch 54/110
 - 3s - loss: 0.2963 - accuracy: 0.9460 - val_loss: 0.8831 - val_accuracy: 0.8146
Epoch 55/110
 - 3s - loss: 0.3087 - accuracy: 0.9461 - val_loss: 0.7913 - val_accuracy: 0.8219
Epoch 56/110
 - 3s - loss: 0.2713 - accuracy: 0.9573 - val_loss: 0.8067 - val_accuracy: 0.8365
Epoch 57/110
 - 3s - loss: 0.2686 - accuracy: 0.9571 - val_loss: 0.8093 - val_accuracy: 0.8350
Epoch 58/110
 - 3s - loss: 0.2720 - accuracy: 0.9578 - val_loss: 0.8613 - val_accuracy: 0.8292
Epoch 59/110
 - 3s - loss: 0.2534 - accuracy: 0.9626 - val_loss: 0.8376 - val_accuracy: 0.8416
Epoch 60/110
 - 3s - loss: 0.2777 - accuracy: 0.9578 - val_loss: 0.7815 - val_accuracy: 0.8445
Epoch 61/110
 - 3s - loss: 0.2800 - accuracy: 0.9542 - val_loss: 0.8401 - val_accuracy: 0.8343
Epoch 62/110
 - 3s - loss: 0.2694 - accuracy: 0.9600 - val_loss: 0.8225 - val_accuracy: 0.8241
Epoch 63/110
 - 3s - loss: 0.2799 - accuracy: 0.9529 - val_loss: 0.8648 - val_accuracy: 0.8299
Epoch 64/110
 - 3s - loss: 0.2804 - accuracy: 0.9520 - val_loss: 0.9509 - val_accuracy: 0.8146
Epoch 65/110
 - 3s - loss: 0.3000 - accuracy: 0.9480 - val_loss: 0.7840 - val_accuracy: 0.8474
Epoch 66/110
 - 3s - loss: 0.2827 - accuracy: 0.9496 - val_loss: 0.8117 - val_accuracy: 0.8372
Epoch 67/110
 - 3s - loss: 0.2657 - accuracy: 0.9586 - val_loss: 0.8338 - val_accuracy: 0.8299
Epoch 68/110
 - 3s - loss: 0.2477 - accuracy: 0.9681 - val_loss: 0.7875 - val_accuracy: 0.8416
Epoch 69/110
 - 3s - loss: 0.2413 - accuracy: 0.9690 - val_loss: 0.8125 - val_accuracy: 0.8453
Epoch 70/110
 - 3s - loss: 0.2521 - accuracy: 0.9660 - val_loss: 0.8704 - val_accuracy: 0.8453
Epoch 71/110
 - 3s - loss: 0.2530 - accuracy: 0.9624 - val_loss: 0.8742 - val_accuracy: 0.8277
Epoch 72/110
 - 3s - loss: 0.2365 - accuracy: 0.9679 - val_loss: 0.8296 - val_accuracy: 0.8453
Epoch 73/110
 - 3s - loss: 0.2490 - accuracy: 0.9633 - val_loss: 0.8011 - val_accuracy: 0.8350
Epoch 74/110
 - 3s - loss: 0.2643 - accuracy: 0.9586 - val_loss: 0.8446 - val_accuracy: 0.8365
Epoch 75/110
 - 3s - loss: 0.2696 - accuracy: 0.9578 - val_loss: 0.8689 - val_accuracy: 0.8248
Epoch 76/110
 - 3s - loss: 0.2530 - accuracy: 0.9629 - val_loss: 0.8725 - val_accuracy: 0.8401
Epoch 77/110
 - 3s - loss: 0.2656 - accuracy: 0.9597 - val_loss: 0.8302 - val_accuracy: 0.8460
Epoch 78/110
 - 3s - loss: 0.2702 - accuracy: 0.9580 - val_loss: 0.8093 - val_accuracy: 0.8474
Epoch 79/110
 - 3s - loss: 0.2556 - accuracy: 0.9593 - val_loss: 0.8511 - val_accuracy: 0.8380
Epoch 80/110
 - 3s - loss: 0.2519 - accuracy: 0.9655 - val_loss: 0.8153 - val_accuracy: 0.8547
Epoch 81/110
 - 3s - loss: 0.2565 - accuracy: 0.9644 - val_loss: 0.8596 - val_accuracy: 0.8314
Epoch 82/110
 - 3s - loss: 0.2547 - accuracy: 0.9624 - val_loss: 0.8393 - val_accuracy: 0.8467
Epoch 83/110
 - 3s - loss: 0.2302 - accuracy: 0.9723 - val_loss: 0.8332 - val_accuracy: 0.8467
Epoch 84/110
 - 3s - loss: 0.2426 - accuracy: 0.9659 - val_loss: 0.8395 - val_accuracy: 0.8343
Epoch 85/110
 - 3s - loss: 0.2525 - accuracy: 0.9651 - val_loss: 0.8224 - val_accuracy: 0.8409
Epoch 86/110
 - 3s - loss: 0.2429 - accuracy: 0.9697 - val_loss: 0.8298 - val_accuracy: 0.8489
Epoch 87/110
 - 3s - loss: 0.2413 - accuracy: 0.9695 - val_loss: 0.8217 - val_accuracy: 0.8431
Epoch 88/110
 - 3s - loss: 0.2541 - accuracy: 0.9609 - val_loss: 0.7980 - val_accuracy: 0.8526
Epoch 89/110
 - 3s - loss: 0.2490 - accuracy: 0.9650 - val_loss: 0.8944 - val_accuracy: 0.8409
Epoch 90/110
 - 3s - loss: 0.2694 - accuracy: 0.9560 - val_loss: 0.8832 - val_accuracy: 0.8234
Epoch 91/110
 - 3s - loss: 0.2614 - accuracy: 0.9598 - val_loss: 0.8745 - val_accuracy: 0.8474
Epoch 92/110
 - 3s - loss: 0.2353 - accuracy: 0.9701 - val_loss: 0.8467 - val_accuracy: 0.8431
Epoch 93/110
 - 3s - loss: 0.2371 - accuracy: 0.9702 - val_loss: 0.9067 - val_accuracy: 0.8277
Epoch 94/110
 - 3s - loss: 0.2481 - accuracy: 0.9637 - val_loss: 0.7926 - val_accuracy: 0.8540
Epoch 95/110
 - 3s - loss: 0.2194 - accuracy: 0.9739 - val_loss: 0.8218 - val_accuracy: 0.8504
Epoch 96/110
 - 3s - loss: 0.2133 - accuracy: 0.9765 - val_loss: 0.8540 - val_accuracy: 0.8438
Epoch 97/110
 - 3s - loss: 0.2275 - accuracy: 0.9717 - val_loss: 0.9123 - val_accuracy: 0.8314
Epoch 98/110
 - 3s - loss: 0.2590 - accuracy: 0.9624 - val_loss: 0.8410 - val_accuracy: 0.8533
Epoch 99/110
 - 3s - loss: 0.2356 - accuracy: 0.9697 - val_loss: 0.8221 - val_accuracy: 0.8350
Epoch 100/110
 - 3s - loss: 0.2464 - accuracy: 0.9653 - val_loss: 0.8400 - val_accuracy: 0.8387
Epoch 101/110
 - 3s - loss: 0.2189 - accuracy: 0.9743 - val_loss: 0.8908 - val_accuracy: 0.8613
Epoch 102/110
 - 3s - loss: 0.2370 - accuracy: 0.9710 - val_loss: 0.8619 - val_accuracy: 0.8489
Epoch 103/110
 - 3s - loss: 0.2494 - accuracy: 0.9631 - val_loss: 0.8693 - val_accuracy: 0.8365
Epoch 104/110
 - 3s - loss: 0.2359 - accuracy: 0.9686 - val_loss: 0.7859 - val_accuracy: 0.8547
Epoch 105/110
 - 3s - loss: 0.2177 - accuracy: 0.9761 - val_loss: 0.7981 - val_accuracy: 0.8591
Epoch 106/110
 - 3s - loss: 0.2407 - accuracy: 0.9713 - val_loss: 0.9255 - val_accuracy: 0.8255
Epoch 107/110
 - 3s - loss: 0.2415 - accuracy: 0.9693 - val_loss: 0.8178 - val_accuracy: 0.8511
Epoch 108/110
 - 3s - loss: 0.2393 - accuracy: 0.9688 - val_loss: 0.8798 - val_accuracy: 0.8343
Epoch 109/110
 - 3s - loss: 0.2239 - accuracy: 0.9759 - val_loss: 0.7923 - val_accuracy: 0.8533
Epoch 110/110
 - 3s - loss: 0.2291 - accuracy: 0.9732 - val_loss: 0.8378 - val_accuracy: 0.8496
------------------------------------------------------------------------
Training for fold 5 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 7s - loss: 1.2290 - accuracy: 0.6106 - val_loss: 2.0300 - val_accuracy: 0.3292
Epoch 2/110
 - 3s - loss: 0.7582 - accuracy: 0.7702 - val_loss: 1.2587 - val_accuracy: 0.5307
Epoch 3/110
 - 3s - loss: 0.6398 - accuracy: 0.8198 - val_loss: 1.0634 - val_accuracy: 0.6438
Epoch 4/110
 - 3s - loss: 0.5762 - accuracy: 0.8439 - val_loss: 0.9051 - val_accuracy: 0.7204
Epoch 5/110
 - 3s - loss: 0.5277 - accuracy: 0.8658 - val_loss: 0.8498 - val_accuracy: 0.7321
Epoch 6/110
 - 3s - loss: 0.5082 - accuracy: 0.8645 - val_loss: 0.7903 - val_accuracy: 0.7599
Epoch 7/110
 - 3s - loss: 0.4790 - accuracy: 0.8786 - val_loss: 0.7658 - val_accuracy: 0.7876
Epoch 8/110
 - 3s - loss: 0.4598 - accuracy: 0.8879 - val_loss: 0.7392 - val_accuracy: 0.7949
Epoch 9/110
 - 3s - loss: 0.4507 - accuracy: 0.8835 - val_loss: 0.7601 - val_accuracy: 0.7803
Epoch 10/110
 - 3s - loss: 0.4314 - accuracy: 0.8956 - val_loss: 0.7880 - val_accuracy: 0.7752
Epoch 11/110
 - 3s - loss: 0.4226 - accuracy: 0.9005 - val_loss: 0.7865 - val_accuracy: 0.7781
Epoch 12/110
 - 3s - loss: 0.4064 - accuracy: 0.9014 - val_loss: 0.8958 - val_accuracy: 0.7759
Epoch 13/110
 - 3s - loss: 0.4307 - accuracy: 0.8939 - val_loss: 0.8326 - val_accuracy: 0.7891
Epoch 14/110
 - 3s - loss: 0.4201 - accuracy: 0.9023 - val_loss: 0.7969 - val_accuracy: 0.7861
Epoch 15/110
 - 3s - loss: 0.3961 - accuracy: 0.9084 - val_loss: 0.8207 - val_accuracy: 0.7891
Epoch 16/110
 - 3s - loss: 0.3922 - accuracy: 0.9151 - val_loss: 0.8001 - val_accuracy: 0.7964
Epoch 17/110
 - 3s - loss: 0.3942 - accuracy: 0.9089 - val_loss: 0.8033 - val_accuracy: 0.7920
Epoch 18/110
 - 3s - loss: 0.3978 - accuracy: 0.9074 - val_loss: 0.8952 - val_accuracy: 0.7708
Epoch 19/110
 - 3s - loss: 0.4188 - accuracy: 0.9007 - val_loss: 0.9760 - val_accuracy: 0.7569
Epoch 20/110
 - 3s - loss: 0.4127 - accuracy: 0.9025 - val_loss: 0.8125 - val_accuracy: 0.8022
Epoch 21/110
 - 3s - loss: 0.3934 - accuracy: 0.9078 - val_loss: 0.7811 - val_accuracy: 0.8022
Epoch 22/110
 - 3s - loss: 0.3687 - accuracy: 0.9169 - val_loss: 0.8135 - val_accuracy: 0.8007
Epoch 23/110
 - 3s - loss: 0.3644 - accuracy: 0.9213 - val_loss: 0.8000 - val_accuracy: 0.8124
Epoch 24/110
 - 3s - loss: 0.3758 - accuracy: 0.9126 - val_loss: 0.8941 - val_accuracy: 0.7861
Epoch 25/110
 - 3s - loss: 0.3740 - accuracy: 0.9162 - val_loss: 0.8542 - val_accuracy: 0.7766
Epoch 26/110
 - 3s - loss: 0.3758 - accuracy: 0.9184 - val_loss: 0.8706 - val_accuracy: 0.7766
Epoch 27/110
 - 3s - loss: 0.3594 - accuracy: 0.9217 - val_loss: 0.7808 - val_accuracy: 0.8066
Epoch 28/110
 - 3s - loss: 0.3483 - accuracy: 0.9297 - val_loss: 0.8449 - val_accuracy: 0.8022
Epoch 29/110
 - 3s - loss: 0.3497 - accuracy: 0.9266 - val_loss: 0.7977 - val_accuracy: 0.8175
Epoch 30/110
 - 3s - loss: 0.3367 - accuracy: 0.9294 - val_loss: 0.7208 - val_accuracy: 0.8328
Epoch 31/110
 - 3s - loss: 0.3236 - accuracy: 0.9341 - val_loss: 0.7548 - val_accuracy: 0.8270
Epoch 32/110
 - 3s - loss: 0.3253 - accuracy: 0.9357 - val_loss: 0.7824 - val_accuracy: 0.8219
Epoch 33/110
 - 3s - loss: 0.3279 - accuracy: 0.9332 - val_loss: 0.7708 - val_accuracy: 0.8226
Epoch 34/110
 - 3s - loss: 0.3283 - accuracy: 0.9334 - val_loss: 0.7753 - val_accuracy: 0.8226
Epoch 35/110
 - 3s - loss: 0.3171 - accuracy: 0.9356 - val_loss: 0.8147 - val_accuracy: 0.8131
Epoch 36/110
 - 3s - loss: 0.3166 - accuracy: 0.9412 - val_loss: 0.7639 - val_accuracy: 0.8117
Epoch 37/110
 - 3s - loss: 0.3048 - accuracy: 0.9443 - val_loss: 0.7801 - val_accuracy: 0.8358
Epoch 38/110
 - 3s - loss: 0.3162 - accuracy: 0.9436 - val_loss: 0.8080 - val_accuracy: 0.8182
Epoch 39/110
 - 3s - loss: 0.2946 - accuracy: 0.9461 - val_loss: 0.8002 - val_accuracy: 0.8358
Epoch 40/110
 - 3s - loss: 0.2932 - accuracy: 0.9478 - val_loss: 0.8003 - val_accuracy: 0.8285
Epoch 41/110
 - 3s - loss: 0.2898 - accuracy: 0.9487 - val_loss: 0.8202 - val_accuracy: 0.8219
Epoch 42/110
 - 3s - loss: 0.3178 - accuracy: 0.9388 - val_loss: 0.9544 - val_accuracy: 0.7942
Epoch 43/110
 - 3s - loss: 0.3003 - accuracy: 0.9440 - val_loss: 0.8047 - val_accuracy: 0.8445
Epoch 44/110
 - 3s - loss: 0.3024 - accuracy: 0.9463 - val_loss: 0.8167 - val_accuracy: 0.8234
Epoch 45/110
 - 3s - loss: 0.2917 - accuracy: 0.9498 - val_loss: 0.8836 - val_accuracy: 0.8277
Epoch 46/110
 - 3s - loss: 0.3045 - accuracy: 0.9445 - val_loss: 0.8922 - val_accuracy: 0.8241
Epoch 47/110
 - 3s - loss: 0.3112 - accuracy: 0.9440 - val_loss: 0.8323 - val_accuracy: 0.8328
Epoch 48/110
 - 3s - loss: 0.2785 - accuracy: 0.9514 - val_loss: 0.7993 - val_accuracy: 0.8380
Epoch 49/110
 - 3s - loss: 0.2792 - accuracy: 0.9562 - val_loss: 0.8330 - val_accuracy: 0.8248
Epoch 50/110
 - 3s - loss: 0.2838 - accuracy: 0.9558 - val_loss: 0.8334 - val_accuracy: 0.8263
Epoch 51/110
 - 3s - loss: 0.2648 - accuracy: 0.9564 - val_loss: 0.8284 - val_accuracy: 0.8321
Epoch 52/110
 - 3s - loss: 0.2792 - accuracy: 0.9533 - val_loss: 0.9165 - val_accuracy: 0.8051
Epoch 53/110
 - 3s - loss: 0.3093 - accuracy: 0.9409 - val_loss: 0.8923 - val_accuracy: 0.8139
Epoch 54/110
 - 3s - loss: 0.2915 - accuracy: 0.9467 - val_loss: 0.9008 - val_accuracy: 0.8197
Epoch 55/110
 - 3s - loss: 0.2909 - accuracy: 0.9476 - val_loss: 0.8470 - val_accuracy: 0.8343
Epoch 56/110
 - 3s - loss: 0.2750 - accuracy: 0.9558 - val_loss: 0.8032 - val_accuracy: 0.8292
Epoch 57/110
 - 3s - loss: 0.2700 - accuracy: 0.9564 - val_loss: 0.8616 - val_accuracy: 0.8175
Epoch 58/110
 - 3s - loss: 0.2751 - accuracy: 0.9540 - val_loss: 0.8460 - val_accuracy: 0.8168
Epoch 59/110
 - 3s - loss: 0.2645 - accuracy: 0.9575 - val_loss: 0.8005 - val_accuracy: 0.8350
Epoch 60/110
 - 3s - loss: 0.2777 - accuracy: 0.9560 - val_loss: 0.8456 - val_accuracy: 0.8219
Epoch 61/110
 - 3s - loss: 0.2662 - accuracy: 0.9576 - val_loss: 0.8310 - val_accuracy: 0.8307
Epoch 62/110
 - 3s - loss: 0.2440 - accuracy: 0.9682 - val_loss: 0.8414 - val_accuracy: 0.8248
Epoch 63/110
 - 3s - loss: 0.2493 - accuracy: 0.9640 - val_loss: 0.8731 - val_accuracy: 0.8431
Epoch 64/110
 - 3s - loss: 0.2716 - accuracy: 0.9587 - val_loss: 0.8719 - val_accuracy: 0.8307
Epoch 65/110
 - 3s - loss: 0.2620 - accuracy: 0.9598 - val_loss: 0.8243 - val_accuracy: 0.8438
Epoch 66/110
 - 3s - loss: 0.2738 - accuracy: 0.9538 - val_loss: 0.8610 - val_accuracy: 0.8336
Epoch 67/110
 - 3s - loss: 0.2640 - accuracy: 0.9597 - val_loss: 0.8760 - val_accuracy: 0.8409
Epoch 68/110
 - 3s - loss: 0.2663 - accuracy: 0.9606 - val_loss: 0.8097 - val_accuracy: 0.8416
Epoch 69/110
 - 3s - loss: 0.2548 - accuracy: 0.9602 - val_loss: 0.8604 - val_accuracy: 0.8387
Epoch 70/110
 - 3s - loss: 0.2687 - accuracy: 0.9587 - val_loss: 0.9001 - val_accuracy: 0.8241
Epoch 71/110
 - 3s - loss: 0.2616 - accuracy: 0.9602 - val_loss: 0.8343 - val_accuracy: 0.8504
Epoch 72/110
 - 3s - loss: 0.2535 - accuracy: 0.9671 - val_loss: 0.7783 - val_accuracy: 0.8453
Epoch 73/110
 - 3s - loss: 0.2515 - accuracy: 0.9635 - val_loss: 0.8317 - val_accuracy: 0.8489
Epoch 74/110
 - 3s - loss: 0.2442 - accuracy: 0.9668 - val_loss: 0.9151 - val_accuracy: 0.8328
Epoch 75/110
 - 3s - loss: 0.2633 - accuracy: 0.9586 - val_loss: 0.8055 - val_accuracy: 0.8482
Epoch 76/110
 - 3s - loss: 0.2741 - accuracy: 0.9522 - val_loss: 0.8479 - val_accuracy: 0.8496
Epoch 77/110
 - 3s - loss: 0.2354 - accuracy: 0.9702 - val_loss: 0.8808 - val_accuracy: 0.8467
Epoch 78/110
 - 3s - loss: 0.2204 - accuracy: 0.9763 - val_loss: 0.8171 - val_accuracy: 0.8526
Epoch 79/110
 - 3s - loss: 0.2328 - accuracy: 0.9730 - val_loss: 0.9106 - val_accuracy: 0.8350
Epoch 80/110
 - 3s - loss: 0.2190 - accuracy: 0.9785 - val_loss: 0.8670 - val_accuracy: 0.8380
Epoch 81/110
 - 3s - loss: 0.2306 - accuracy: 0.9724 - val_loss: 0.9262 - val_accuracy: 0.8387
Epoch 82/110
 - 3s - loss: 0.2893 - accuracy: 0.9503 - val_loss: 0.9088 - val_accuracy: 0.8387
Epoch 83/110
 - 3s - loss: 0.2752 - accuracy: 0.9547 - val_loss: 0.8856 - val_accuracy: 0.8248
Epoch 84/110
 - 3s - loss: 0.2539 - accuracy: 0.9622 - val_loss: 0.8562 - val_accuracy: 0.8314
Epoch 85/110
 - 3s - loss: 0.2377 - accuracy: 0.9690 - val_loss: 0.8717 - val_accuracy: 0.8453
Epoch 86/110
 - 3s - loss: 0.2344 - accuracy: 0.9682 - val_loss: 0.8467 - val_accuracy: 0.8526
Epoch 87/110
 - 3s - loss: 0.2568 - accuracy: 0.9642 - val_loss: 0.8904 - val_accuracy: 0.8314
Epoch 88/110
 - 3s - loss: 0.2329 - accuracy: 0.9723 - val_loss: 0.8128 - val_accuracy: 0.8562
Epoch 89/110
 - 3s - loss: 0.2180 - accuracy: 0.9763 - val_loss: 0.8616 - val_accuracy: 0.8423
Epoch 90/110
 - 3s - loss: 0.2534 - accuracy: 0.9677 - val_loss: 0.9057 - val_accuracy: 0.8423
Epoch 91/110
 - 3s - loss: 0.2628 - accuracy: 0.9608 - val_loss: 0.9189 - val_accuracy: 0.8255
Epoch 92/110
 - 3s - loss: 0.2369 - accuracy: 0.9695 - val_loss: 0.7918 - val_accuracy: 0.8679
Epoch 93/110
 - 3s - loss: 0.2172 - accuracy: 0.9761 - val_loss: 0.8004 - val_accuracy: 0.8511
Epoch 94/110
 - 3s - loss: 0.2124 - accuracy: 0.9797 - val_loss: 0.9090 - val_accuracy: 0.8511
Epoch 95/110
 - 3s - loss: 0.2302 - accuracy: 0.9721 - val_loss: 0.8674 - val_accuracy: 0.8336
Epoch 96/110
 - 3s - loss: 0.2193 - accuracy: 0.9772 - val_loss: 0.8721 - val_accuracy: 0.8423
Epoch 97/110
 - 3s - loss: 0.2495 - accuracy: 0.9653 - val_loss: 0.9700 - val_accuracy: 0.8212
Epoch 98/110
 - 3s - loss: 0.2387 - accuracy: 0.9664 - val_loss: 0.9001 - val_accuracy: 0.8343
Epoch 99/110
 - 3s - loss: 0.2248 - accuracy: 0.9743 - val_loss: 0.9009 - val_accuracy: 0.8555
Epoch 100/110
 - 3s - loss: 0.2334 - accuracy: 0.9702 - val_loss: 0.8902 - val_accuracy: 0.8511
Epoch 101/110
 - 3s - loss: 0.2096 - accuracy: 0.9779 - val_loss: 0.8720 - val_accuracy: 0.8511
Epoch 102/110
 - 3s - loss: 0.2105 - accuracy: 0.9806 - val_loss: 0.8594 - val_accuracy: 0.8635
Epoch 103/110
 - 3s - loss: 0.2150 - accuracy: 0.9779 - val_loss: 0.9203 - val_accuracy: 0.8489
Epoch 104/110
 - 3s - loss: 0.2130 - accuracy: 0.9774 - val_loss: 0.8774 - val_accuracy: 0.8460
Epoch 105/110
 - 3s - loss: 0.2261 - accuracy: 0.9715 - val_loss: 0.9071 - val_accuracy: 0.8321
Epoch 106/110
 - 3s - loss: 0.2168 - accuracy: 0.9761 - val_loss: 0.8560 - val_accuracy: 0.8569
Epoch 107/110
 - 3s - loss: 0.2065 - accuracy: 0.9808 - val_loss: 0.8564 - val_accuracy: 0.8555
Epoch 108/110
 - 3s - loss: 0.2354 - accuracy: 0.9712 - val_loss: 0.9590 - val_accuracy: 0.8328
Epoch 109/110
 - 3s - loss: 0.2589 - accuracy: 0.9597 - val_loss: 0.8865 - val_accuracy: 0.8380
Epoch 110/110
 - 3s - loss: 0.2823 - accuracy: 0.9547 - val_loss: 0.9203 - val_accuracy: 0.8277
------------------------------------------------------------------------
Score per fold
------------------------------------------------------------------------
Score for fold 1
Accuracy_Train: 89.53%
Accuracy_Test: 88.14%
Loss_Train: 0.61
Loss_Test: 0.66
------------------------------------------------------------------------
Score for fold 2
Accuracy_Train: 89.66%
Accuracy_Test: 89.89%
Loss_Train: 0.53
Loss_Test: 0.51
------------------------------------------------------------------------
Score for fold 3
Accuracy_Train: 87.24%
Accuracy_Test: 88.43%
Loss_Train: 0.62
Loss_Test: 0.57
------------------------------------------------------------------------
Score for fold 4
Accuracy_Train: 88.96%
Accuracy_Test: 90.42%
Loss_Train: 0.58
Loss_Test: 0.53
------------------------------------------------------------------------
Score for fold 5
Accuracy_Train: 86.74%
Accuracy_Test: 86.27%
Loss_Train: 0.63
Loss_Test: 0.63
------------------------------------------------------------------------
Average scores for all folds:
Average_Accuracy_Train: 88.43%
	-> (+- 1.2069230794323713 )
Average_Accuracy_Test: 88.63%
	-> (+- 1.4584566422673355 )
Average_Loss_Train: 0.59
	-> (+- 0.03604150929839481 )
Average_Loss_Test: 0.58
	-> (+- 0.05481610568727272 )
------------------------------------------------------------------------
