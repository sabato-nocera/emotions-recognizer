Dataset used: ../../datasets/full_dataset_without_humidity_augmented_balanced.csv 

      Temperature  Sound  Heartbeat   X1  ...  Y2  Z2  Classification  Feedback
9999           -1     -1         48   -1  ...  -1  -1             200     Angry
9998           35     -1         48  808  ...  -1  -1             150     Angry
9997           35     -1         48  860  ...  -1  -1             150     Angry
9996           -1     -1         48   -1  ...  -1  -1             150     Angry
9995           -1     -1         48   -1  ...  -1  -1             150     Angry

[5 rows x 11 columns]

Objservations: 20888

Layers:

{'name': 'dense_81', 'trainable': True, 'batch_input_shape': (None, 10), 'dtype': 'float32', 'units': 10, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_82', 'trainable': True, 'dtype': 'float32', 'units': 500, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_83', 'trainable': True, 'dtype': 'float32', 'units': 300, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_84', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_85', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_86', 'trainable': True, 'dtype': 'float32', 'units': 50, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_87', 'trainable': True, 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_88', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 13368 samples, validate on 3342 samples
Epoch 1/128
 - 2s - loss: 0.8260 - accuracy: 0.6896 - val_loss: 0.7062 - val_accuracy: 0.7528
Epoch 2/128
 - 2s - loss: 0.7089 - accuracy: 0.7492 - val_loss: 0.6572 - val_accuracy: 0.7711
Epoch 3/128
 - 2s - loss: 0.6705 - accuracy: 0.7626 - val_loss: 0.6246 - val_accuracy: 0.7759
Epoch 4/128
 - 2s - loss: 0.6436 - accuracy: 0.7696 - val_loss: 0.6010 - val_accuracy: 0.7873
Epoch 5/128
 - 2s - loss: 0.6192 - accuracy: 0.7782 - val_loss: 0.5776 - val_accuracy: 0.7956
Epoch 6/128
 - 2s - loss: 0.6006 - accuracy: 0.7831 - val_loss: 0.5596 - val_accuracy: 0.7980
Epoch 7/128
 - 2s - loss: 0.5793 - accuracy: 0.7906 - val_loss: 0.5415 - val_accuracy: 0.8016
Epoch 8/128
 - 2s - loss: 0.5633 - accuracy: 0.7944 - val_loss: 0.5245 - val_accuracy: 0.8109
Epoch 9/128
 - 2s - loss: 0.5470 - accuracy: 0.7976 - val_loss: 0.5067 - val_accuracy: 0.8112
Epoch 10/128
 - 2s - loss: 0.5335 - accuracy: 0.8023 - val_loss: 0.4967 - val_accuracy: 0.8127
Epoch 11/128
 - 2s - loss: 0.5192 - accuracy: 0.8060 - val_loss: 0.4932 - val_accuracy: 0.8145
Epoch 12/128
 - 2s - loss: 0.5051 - accuracy: 0.8092 - val_loss: 0.4764 - val_accuracy: 0.8262
Epoch 13/128
 - 2s - loss: 0.4891 - accuracy: 0.8149 - val_loss: 0.4705 - val_accuracy: 0.8259
Epoch 14/128
 - 2s - loss: 0.4813 - accuracy: 0.8184 - val_loss: 0.4550 - val_accuracy: 0.8306
Epoch 15/128
 - 2s - loss: 0.4655 - accuracy: 0.8234 - val_loss: 0.4513 - val_accuracy: 0.8306
Epoch 16/128
 - 2s - loss: 0.4564 - accuracy: 0.8274 - val_loss: 0.4366 - val_accuracy: 0.8375
Epoch 17/128
 - 2s - loss: 0.4445 - accuracy: 0.8308 - val_loss: 0.4337 - val_accuracy: 0.8411
Epoch 18/128
 - 2s - loss: 0.4344 - accuracy: 0.8327 - val_loss: 0.4206 - val_accuracy: 0.8444
Epoch 19/128
 - 2s - loss: 0.4269 - accuracy: 0.8345 - val_loss: 0.4265 - val_accuracy: 0.8354
Epoch 20/128
 - 2s - loss: 0.4223 - accuracy: 0.8358 - val_loss: 0.4149 - val_accuracy: 0.8351
Epoch 21/128
 - 2s - loss: 0.4142 - accuracy: 0.8349 - val_loss: 0.4076 - val_accuracy: 0.8453
Epoch 22/128
 - 2s - loss: 0.4043 - accuracy: 0.8398 - val_loss: 0.3963 - val_accuracy: 0.8501
Epoch 23/128
 - 2s - loss: 0.4000 - accuracy: 0.8409 - val_loss: 0.4049 - val_accuracy: 0.8513
Epoch 24/128
 - 2s - loss: 0.3923 - accuracy: 0.8422 - val_loss: 0.3956 - val_accuracy: 0.8534
Epoch 25/128
 - 2s - loss: 0.3923 - accuracy: 0.8428 - val_loss: 0.3982 - val_accuracy: 0.8537
Epoch 26/128
 - 2s - loss: 0.3828 - accuracy: 0.8446 - val_loss: 0.3994 - val_accuracy: 0.8501
Epoch 27/128
 - 2s - loss: 0.3817 - accuracy: 0.8455 - val_loss: 0.3967 - val_accuracy: 0.8465
Epoch 28/128
 - 2s - loss: 0.3723 - accuracy: 0.8509 - val_loss: 0.3848 - val_accuracy: 0.8534
Epoch 29/128
 - 2s - loss: 0.3681 - accuracy: 0.8509 - val_loss: 0.3926 - val_accuracy: 0.8504
Epoch 30/128
 - 2s - loss: 0.3651 - accuracy: 0.8509 - val_loss: 0.4038 - val_accuracy: 0.8531
Epoch 31/128
 - 2s - loss: 0.3649 - accuracy: 0.8529 - val_loss: 0.3945 - val_accuracy: 0.8591
Epoch 32/128
 - 2s - loss: 0.3518 - accuracy: 0.8569 - val_loss: 0.3844 - val_accuracy: 0.8600
Epoch 33/128
 - 2s - loss: 0.3505 - accuracy: 0.8565 - val_loss: 0.3675 - val_accuracy: 0.8656
Epoch 34/128
 - 2s - loss: 0.3424 - accuracy: 0.8609 - val_loss: 0.3696 - val_accuracy: 0.8659
Epoch 35/128
 - 2s - loss: 0.3397 - accuracy: 0.8615 - val_loss: 0.3770 - val_accuracy: 0.8561
Epoch 36/128
 - 2s - loss: 0.3337 - accuracy: 0.8628 - val_loss: 0.3729 - val_accuracy: 0.8624
Epoch 37/128
 - 2s - loss: 0.3398 - accuracy: 0.8581 - val_loss: 0.3647 - val_accuracy: 0.8600
Epoch 38/128
 - 2s - loss: 0.3398 - accuracy: 0.8611 - val_loss: 0.3733 - val_accuracy: 0.8659
Epoch 39/128
 - 2s - loss: 0.3332 - accuracy: 0.8621 - val_loss: 0.3557 - val_accuracy: 0.8710
Epoch 40/128
 - 2s - loss: 0.3330 - accuracy: 0.8648 - val_loss: 0.3640 - val_accuracy: 0.8615
Epoch 41/128
 - 2s - loss: 0.3312 - accuracy: 0.8625 - val_loss: 0.3721 - val_accuracy: 0.8615
Epoch 42/128
 - 2s - loss: 0.3204 - accuracy: 0.8652 - val_loss: 0.3682 - val_accuracy: 0.8588
Epoch 43/128
 - 2s - loss: 0.3203 - accuracy: 0.8651 - val_loss: 0.3752 - val_accuracy: 0.8624
Epoch 44/128
 - 2s - loss: 0.3249 - accuracy: 0.8634 - val_loss: 0.3635 - val_accuracy: 0.8537
Epoch 45/128
 - 2s - loss: 0.3229 - accuracy: 0.8651 - val_loss: 0.3541 - val_accuracy: 0.8683
Epoch 46/128
 - 2s - loss: 0.3108 - accuracy: 0.8701 - val_loss: 0.3623 - val_accuracy: 0.8615
Epoch 47/128
 - 2s - loss: 0.3130 - accuracy: 0.8686 - val_loss: 0.3552 - val_accuracy: 0.8636
Epoch 48/128
 - 2s - loss: 0.3154 - accuracy: 0.8680 - val_loss: 0.3647 - val_accuracy: 0.8600
Epoch 49/128
 - 2s - loss: 0.3080 - accuracy: 0.8710 - val_loss: 0.3441 - val_accuracy: 0.8674
Epoch 50/128
 - 2s - loss: 0.3058 - accuracy: 0.8730 - val_loss: 0.3438 - val_accuracy: 0.8665
Epoch 51/128
 - 2s - loss: 0.3090 - accuracy: 0.8705 - val_loss: 0.3387 - val_accuracy: 0.8722
Epoch 52/128
 - 2s - loss: 0.3006 - accuracy: 0.8725 - val_loss: 0.3332 - val_accuracy: 0.8674
Epoch 53/128
 - 2s - loss: 0.3110 - accuracy: 0.8685 - val_loss: 0.3680 - val_accuracy: 0.8594
Epoch 54/128
 - 2s - loss: 0.3009 - accuracy: 0.8729 - val_loss: 0.3390 - val_accuracy: 0.8656
Epoch 55/128
 - 2s - loss: 0.3006 - accuracy: 0.8723 - val_loss: 0.3388 - val_accuracy: 0.8743
Epoch 56/128
 - 2s - loss: 0.3022 - accuracy: 0.8731 - val_loss: 0.3639 - val_accuracy: 0.8591
Epoch 57/128
 - 2s - loss: 0.3003 - accuracy: 0.8730 - val_loss: 0.3299 - val_accuracy: 0.8719
Epoch 58/128
 - 2s - loss: 0.3008 - accuracy: 0.8722 - val_loss: 0.3440 - val_accuracy: 0.8654
Epoch 59/128
 - 2s - loss: 0.3010 - accuracy: 0.8734 - val_loss: 0.3390 - val_accuracy: 0.8695
Epoch 60/128
 - 2s - loss: 0.2928 - accuracy: 0.8762 - val_loss: 0.3249 - val_accuracy: 0.8734
Epoch 61/128
 - 2s - loss: 0.2934 - accuracy: 0.8756 - val_loss: 0.3379 - val_accuracy: 0.8746
Epoch 62/128
 - 2s - loss: 0.2943 - accuracy: 0.8763 - val_loss: 0.3382 - val_accuracy: 0.8737
Epoch 63/128
 - 2s - loss: 0.2876 - accuracy: 0.8793 - val_loss: 0.3262 - val_accuracy: 0.8734
Epoch 64/128
 - 2s - loss: 0.2879 - accuracy: 0.8778 - val_loss: 0.3358 - val_accuracy: 0.8722
Epoch 65/128
 - 2s - loss: 0.2919 - accuracy: 0.8754 - val_loss: 0.3429 - val_accuracy: 0.8689
Epoch 66/128
 - 2s - loss: 0.2988 - accuracy: 0.8757 - val_loss: 0.3410 - val_accuracy: 0.8648
Epoch 67/128
 - 2s - loss: 0.2914 - accuracy: 0.8769 - val_loss: 0.3255 - val_accuracy: 0.8773
Epoch 68/128
 - 2s - loss: 0.2794 - accuracy: 0.8795 - val_loss: 0.3410 - val_accuracy: 0.8707
Epoch 69/128
 - 2s - loss: 0.2869 - accuracy: 0.8801 - val_loss: 0.3319 - val_accuracy: 0.8809
Epoch 70/128
 - 2s - loss: 0.2891 - accuracy: 0.8787 - val_loss: 0.3770 - val_accuracy: 0.8603
Epoch 71/128
 - 2s - loss: 0.2953 - accuracy: 0.8765 - val_loss: 0.3233 - val_accuracy: 0.8728
Epoch 72/128
 - 2s - loss: 0.2867 - accuracy: 0.8794 - val_loss: 0.3312 - val_accuracy: 0.8770
Epoch 73/128
 - 2s - loss: 0.2838 - accuracy: 0.8796 - val_loss: 0.3479 - val_accuracy: 0.8686
Epoch 74/128
 - 2s - loss: 0.2851 - accuracy: 0.8783 - val_loss: 0.3227 - val_accuracy: 0.8683
Epoch 75/128
 - 2s - loss: 0.2807 - accuracy: 0.8813 - val_loss: 0.3238 - val_accuracy: 0.8698
Epoch 76/128
 - 2s - loss: 0.2890 - accuracy: 0.8757 - val_loss: 0.3263 - val_accuracy: 0.8728
Epoch 77/128
 - 2s - loss: 0.2876 - accuracy: 0.8777 - val_loss: 0.3092 - val_accuracy: 0.8794
Epoch 78/128
 - 2s - loss: 0.2798 - accuracy: 0.8803 - val_loss: 0.3153 - val_accuracy: 0.8812
Epoch 79/128
 - 2s - loss: 0.2872 - accuracy: 0.8782 - val_loss: 0.3254 - val_accuracy: 0.8785
Epoch 80/128
 - 2s - loss: 0.2835 - accuracy: 0.8802 - val_loss: 0.3344 - val_accuracy: 0.8737
Epoch 81/128
 - 2s - loss: 0.2798 - accuracy: 0.8816 - val_loss: 0.3083 - val_accuracy: 0.8803
Epoch 82/128
 - 2s - loss: 0.2751 - accuracy: 0.8799 - val_loss: 0.3231 - val_accuracy: 0.8791
Epoch 83/128
 - 2s - loss: 0.2871 - accuracy: 0.8779 - val_loss: 0.3250 - val_accuracy: 0.8773
Epoch 84/128
 - 2s - loss: 0.2859 - accuracy: 0.8779 - val_loss: 0.3408 - val_accuracy: 0.8683
Epoch 85/128
 - 2s - loss: 0.2773 - accuracy: 0.8806 - val_loss: 0.3409 - val_accuracy: 0.8642
Epoch 86/128
 - 2s - loss: 0.2794 - accuracy: 0.8805 - val_loss: 0.3234 - val_accuracy: 0.8728
Epoch 87/128
 - 2s - loss: 0.2738 - accuracy: 0.8829 - val_loss: 0.2983 - val_accuracy: 0.8860
Epoch 88/128
 - 2s - loss: 0.2806 - accuracy: 0.8802 - val_loss: 0.3149 - val_accuracy: 0.8746
Epoch 89/128
 - 2s - loss: 0.2774 - accuracy: 0.8817 - val_loss: 0.3132 - val_accuracy: 0.8779
Epoch 90/128
 - 2s - loss: 0.2726 - accuracy: 0.8832 - val_loss: 0.3346 - val_accuracy: 0.8737
Epoch 91/128
 - 2s - loss: 0.2702 - accuracy: 0.8846 - val_loss: 0.3066 - val_accuracy: 0.8842
Epoch 92/128
 - 2s - loss: 0.2694 - accuracy: 0.8829 - val_loss: 0.3631 - val_accuracy: 0.8671
Epoch 93/128
 - 2s - loss: 0.2812 - accuracy: 0.8802 - val_loss: 0.3281 - val_accuracy: 0.8782
Epoch 94/128
 - 2s - loss: 0.2660 - accuracy: 0.8860 - val_loss: 0.3270 - val_accuracy: 0.8788
Epoch 95/128
 - 2s - loss: 0.2836 - accuracy: 0.8780 - val_loss: 0.3162 - val_accuracy: 0.8737
Epoch 96/128
 - 2s - loss: 0.2680 - accuracy: 0.8831 - val_loss: 0.3188 - val_accuracy: 0.8776
Epoch 97/128
 - 2s - loss: 0.2711 - accuracy: 0.8808 - val_loss: 0.3420 - val_accuracy: 0.8755
Epoch 98/128
 - 2s - loss: 0.2729 - accuracy: 0.8823 - val_loss: 0.3263 - val_accuracy: 0.8764
Epoch 99/128
 - 2s - loss: 0.2730 - accuracy: 0.8833 - val_loss: 0.3210 - val_accuracy: 0.8875
Epoch 100/128
 - 2s - loss: 0.2680 - accuracy: 0.8857 - val_loss: 0.3106 - val_accuracy: 0.8866
Epoch 101/128
 - 2s - loss: 0.2649 - accuracy: 0.8861 - val_loss: 0.3103 - val_accuracy: 0.8872
Epoch 102/128
 - 2s - loss: 0.2719 - accuracy: 0.8837 - val_loss: 0.3549 - val_accuracy: 0.8686
Epoch 103/128
 - 2s - loss: 0.2734 - accuracy: 0.8840 - val_loss: 0.3261 - val_accuracy: 0.8785
Epoch 104/128
 - 2s - loss: 0.2707 - accuracy: 0.8821 - val_loss: 0.3159 - val_accuracy: 0.8788
Epoch 105/128
 - 2s - loss: 0.2594 - accuracy: 0.8850 - val_loss: 0.3176 - val_accuracy: 0.8869
Epoch 106/128
 - 2s - loss: 0.2659 - accuracy: 0.8852 - val_loss: 0.3399 - val_accuracy: 0.8776
Epoch 107/128
 - 2s - loss: 0.2651 - accuracy: 0.8860 - val_loss: 0.3122 - val_accuracy: 0.8857
Epoch 108/128
 - 2s - loss: 0.2765 - accuracy: 0.8819 - val_loss: 0.3160 - val_accuracy: 0.8773
Epoch 109/128
 - 2s - loss: 0.2631 - accuracy: 0.8854 - val_loss: 0.3220 - val_accuracy: 0.8803
Epoch 110/128
 - 2s - loss: 0.2714 - accuracy: 0.8837 - val_loss: 0.3259 - val_accuracy: 0.8770
Epoch 111/128
 - 2s - loss: 0.2703 - accuracy: 0.8832 - val_loss: 0.3058 - val_accuracy: 0.8788
Epoch 112/128
 - 2s - loss: 0.2622 - accuracy: 0.8873 - val_loss: 0.3046 - val_accuracy: 0.8836
Epoch 113/128
 - 2s - loss: 0.2669 - accuracy: 0.8846 - val_loss: 0.3049 - val_accuracy: 0.8767
Epoch 114/128
 - 2s - loss: 0.2692 - accuracy: 0.8834 - val_loss: 0.3095 - val_accuracy: 0.8863
Epoch 115/128
 - 2s - loss: 0.2569 - accuracy: 0.8864 - val_loss: 0.3026 - val_accuracy: 0.8791
Epoch 116/128
 - 2s - loss: 0.2732 - accuracy: 0.8835 - val_loss: 0.3134 - val_accuracy: 0.8839
Epoch 117/128
 - 2s - loss: 0.2678 - accuracy: 0.8843 - val_loss: 0.3082 - val_accuracy: 0.8857
Epoch 118/128
 - 2s - loss: 0.2660 - accuracy: 0.8851 - val_loss: 0.3062 - val_accuracy: 0.8791
Epoch 119/128
 - 2s - loss: 0.2691 - accuracy: 0.8843 - val_loss: 0.2971 - val_accuracy: 0.8878
Epoch 120/128
 - 2s - loss: 0.2593 - accuracy: 0.8860 - val_loss: 0.3031 - val_accuracy: 0.8860
Epoch 121/128
 - 2s - loss: 0.2586 - accuracy: 0.8878 - val_loss: 0.3059 - val_accuracy: 0.8893
Epoch 122/128
 - 2s - loss: 0.2616 - accuracy: 0.8859 - val_loss: 0.3119 - val_accuracy: 0.8887
Epoch 123/128
 - 2s - loss: 0.2719 - accuracy: 0.8835 - val_loss: 0.3151 - val_accuracy: 0.8872
Epoch 124/128
 - 2s - loss: 0.2731 - accuracy: 0.8835 - val_loss: 0.2971 - val_accuracy: 0.8884
Epoch 125/128
 - 2s - loss: 0.2605 - accuracy: 0.8881 - val_loss: 0.3087 - val_accuracy: 0.8863
Epoch 126/128
 - 2s - loss: 0.2520 - accuracy: 0.8897 - val_loss: 0.3092 - val_accuracy: 0.8893
Epoch 127/128
 - 2s - loss: 0.2611 - accuracy: 0.8862 - val_loss: 0.3075 - val_accuracy: 0.8884
Epoch 128/128
 - 2s - loss: 0.2761 - accuracy: 0.8829 - val_loss: 0.3031 - val_accuracy: 0.8890

Fit: epochs= 128 , batch_size= 32 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "sequential_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_81 (Dense)             (None, 10)                110       
_________________________________________________________________
dense_82 (Dense)             (None, 500)               5500      
_________________________________________________________________
dense_83 (Dense)             (None, 300)               150300    
_________________________________________________________________
dense_84 (Dense)             (None, 200)               60200     
_________________________________________________________________
dense_85 (Dense)             (None, 100)               20100     
_________________________________________________________________
dense_86 (Dense)             (None, 50)                5050      
_________________________________________________________________
dense_87 (Dense)             (None, 20)                1020      
_________________________________________________________________
dense_88 (Dense)             (None, 4)                 84        
=================================================================
Total params: 242,364
Trainable params: 242,364
Non-trainable params: 0
_________________________________________________________________
None

Accuracy Train: 88.83%
Accuracy Test: 87.84%
Loss Train: 0.27
Loss Test: 0.33
Numero dati esaminati: 4178
True Positive 3670
False Positive 508
