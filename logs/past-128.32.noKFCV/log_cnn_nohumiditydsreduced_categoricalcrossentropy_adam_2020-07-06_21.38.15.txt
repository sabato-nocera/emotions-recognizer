Dataset used: ../../datasets/full_dataset_without_humidity_reduced.csv 

   Temperature  Sound  Heartbeat   X1  ...    Y2     Z2  Classification  Feedback
0           32      1         60 -680  ... -7424 -15596             100     Happy
1           32      1         60 -780  ... -7408 -15628             100     Happy
2           -1      1         60   -1  ... -7276 -15612             100     Happy
3           -1     -1         60   -1  ...    -1     -1             100     Happy
4           32      1         60 -860  ... -7340 -15720             100     Happy

[5 rows x 11 columns]

Objservations: 3760
Reshaping:  ((3008, 10), (3008, 4), (752, 10), (752, 4))  -> ((3008, 10, 1), (3008, 4), (752, 10, 1), (752, 4))

Layers:

{'name': 'conv1d_8', 'trainable': True, 'batch_input_shape': (None, 10, 1), 'dtype': 'float32', 'filters': 500, 'kernel_size': (1,), 'strides': (1,), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'activation_15', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'} 

{'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.4, 'noise_shape': None, 'seed': None} 

{'name': 'dense_50', 'trainable': True, 'dtype': 'float32', 'units': 400, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_51', 'trainable': True, 'dtype': 'float32', 'units': 300, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_52', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_53', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_54', 'trainable': True, 'dtype': 'float32', 'units': 50, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_55', 'trainable': True, 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_56', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'activation_16', 'trainable': True, 'dtype': 'float32', 'activation': 'softmax'} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 2406 samples, validate on 602 samples
Epoch 1/128
 - 3s - loss: 0.8608 - accuracy: 0.6513 - val_loss: 0.6964 - val_accuracy: 0.7807
Epoch 2/128
 - 3s - loss: 0.6998 - accuracy: 0.7490 - val_loss: 0.6656 - val_accuracy: 0.7791
Epoch 3/128
 - 3s - loss: 0.6665 - accuracy: 0.7627 - val_loss: 0.6605 - val_accuracy: 0.7874
Epoch 4/128
 - 3s - loss: 0.6713 - accuracy: 0.7598 - val_loss: 0.6534 - val_accuracy: 0.7807
Epoch 5/128
 - 3s - loss: 0.6499 - accuracy: 0.7697 - val_loss: 0.6356 - val_accuracy: 0.7791
Epoch 6/128
 - 3s - loss: 0.6389 - accuracy: 0.7710 - val_loss: 0.6279 - val_accuracy: 0.7973
Epoch 7/128
 - 3s - loss: 0.6213 - accuracy: 0.7797 - val_loss: 0.6190 - val_accuracy: 0.7940
Epoch 8/128
 - 3s - loss: 0.6176 - accuracy: 0.7822 - val_loss: 0.6129 - val_accuracy: 0.7890
Epoch 9/128
 - 3s - loss: 0.6130 - accuracy: 0.7805 - val_loss: 0.6061 - val_accuracy: 0.8040
Epoch 10/128
 - 3s - loss: 0.5977 - accuracy: 0.7880 - val_loss: 0.6126 - val_accuracy: 0.7990
Epoch 11/128
 - 3s - loss: 0.5912 - accuracy: 0.7930 - val_loss: 0.6007 - val_accuracy: 0.8023
Epoch 12/128
 - 3s - loss: 0.5855 - accuracy: 0.7909 - val_loss: 0.5977 - val_accuracy: 0.8007
Epoch 13/128
 - 3s - loss: 0.5755 - accuracy: 0.7972 - val_loss: 0.5725 - val_accuracy: 0.8140
Epoch 14/128
 - 3s - loss: 0.5778 - accuracy: 0.7955 - val_loss: 0.5781 - val_accuracy: 0.8073
Epoch 15/128
 - 3s - loss: 0.5684 - accuracy: 0.8030 - val_loss: 0.5632 - val_accuracy: 0.8007
Epoch 16/128
 - 3s - loss: 0.5598 - accuracy: 0.8030 - val_loss: 0.5801 - val_accuracy: 0.8123
Epoch 17/128
 - 3s - loss: 0.5485 - accuracy: 0.8005 - val_loss: 0.7105 - val_accuracy: 0.7691
Epoch 18/128
 - 3s - loss: 0.5510 - accuracy: 0.8059 - val_loss: 0.5797 - val_accuracy: 0.8173
Epoch 19/128
 - 3s - loss: 0.5410 - accuracy: 0.8096 - val_loss: 0.5880 - val_accuracy: 0.8140
Epoch 20/128
 - 3s - loss: 0.5390 - accuracy: 0.8105 - val_loss: 0.5910 - val_accuracy: 0.8123
Epoch 21/128
 - 3s - loss: 0.5380 - accuracy: 0.8071 - val_loss: 0.5818 - val_accuracy: 0.8123
Epoch 22/128
 - 3s - loss: 0.5273 - accuracy: 0.8121 - val_loss: 0.5797 - val_accuracy: 0.8189
Epoch 23/128
 - 3s - loss: 0.5266 - accuracy: 0.8088 - val_loss: 0.5944 - val_accuracy: 0.8106
Epoch 24/128
 - 3s - loss: 0.5171 - accuracy: 0.8150 - val_loss: 0.6081 - val_accuracy: 0.8056
Epoch 25/128
 - 3s - loss: 0.5143 - accuracy: 0.8171 - val_loss: 0.5831 - val_accuracy: 0.8223
Epoch 26/128
 - 3s - loss: 0.5142 - accuracy: 0.8146 - val_loss: 0.5924 - val_accuracy: 0.8156
Epoch 27/128
 - 3s - loss: 0.5041 - accuracy: 0.8159 - val_loss: 0.5782 - val_accuracy: 0.8272
Epoch 28/128
 - 3s - loss: 0.5020 - accuracy: 0.8159 - val_loss: 0.5979 - val_accuracy: 0.8156
Epoch 29/128
 - 3s - loss: 0.4952 - accuracy: 0.8204 - val_loss: 0.6020 - val_accuracy: 0.8239
Epoch 30/128
 - 3s - loss: 0.4927 - accuracy: 0.8171 - val_loss: 0.5853 - val_accuracy: 0.8156
Epoch 31/128
 - 3s - loss: 0.4975 - accuracy: 0.8213 - val_loss: 0.6099 - val_accuracy: 0.8189
Epoch 32/128
 - 3s - loss: 0.5057 - accuracy: 0.8155 - val_loss: 0.5675 - val_accuracy: 0.8206
Epoch 33/128
 - 3s - loss: 0.4918 - accuracy: 0.8196 - val_loss: 0.5827 - val_accuracy: 0.8173
Epoch 34/128
 - 3s - loss: 0.4866 - accuracy: 0.8196 - val_loss: 0.5742 - val_accuracy: 0.8090
Epoch 35/128
 - 3s - loss: 0.4894 - accuracy: 0.8184 - val_loss: 0.5676 - val_accuracy: 0.8223
Epoch 36/128
 - 3s - loss: 0.4781 - accuracy: 0.8238 - val_loss: 0.5887 - val_accuracy: 0.8206
Epoch 37/128
 - 3s - loss: 0.4767 - accuracy: 0.8204 - val_loss: 0.5653 - val_accuracy: 0.8206
Epoch 38/128
 - 3s - loss: 0.4832 - accuracy: 0.8242 - val_loss: 0.5626 - val_accuracy: 0.8140
Epoch 39/128
 - 3s - loss: 0.4768 - accuracy: 0.8200 - val_loss: 0.5780 - val_accuracy: 0.8156
Epoch 40/128
 - 3s - loss: 0.4714 - accuracy: 0.8217 - val_loss: 0.5623 - val_accuracy: 0.8156
Epoch 41/128
 - 3s - loss: 0.4756 - accuracy: 0.8238 - val_loss: 0.5431 - val_accuracy: 0.8223
Epoch 42/128
 - 3s - loss: 0.4686 - accuracy: 0.8246 - val_loss: 0.5662 - val_accuracy: 0.8272
Epoch 43/128
 - 3s - loss: 0.4723 - accuracy: 0.8283 - val_loss: 0.5580 - val_accuracy: 0.8206
Epoch 44/128
 - 3s - loss: 0.4639 - accuracy: 0.8263 - val_loss: 0.5637 - val_accuracy: 0.8156
Epoch 45/128
 - 3s - loss: 0.4603 - accuracy: 0.8267 - val_loss: 0.5755 - val_accuracy: 0.8289
Epoch 46/128
 - 3s - loss: 0.4563 - accuracy: 0.8242 - val_loss: 0.5563 - val_accuracy: 0.8189
Epoch 47/128
 - 3s - loss: 0.4720 - accuracy: 0.8263 - val_loss: 0.5437 - val_accuracy: 0.8272
Epoch 48/128
 - 3s - loss: 0.4565 - accuracy: 0.8313 - val_loss: 0.5741 - val_accuracy: 0.8239
Epoch 49/128
 - 3s - loss: 0.4439 - accuracy: 0.8325 - val_loss: 0.5650 - val_accuracy: 0.8239
Epoch 50/128
 - 3s - loss: 0.4480 - accuracy: 0.8250 - val_loss: 0.5812 - val_accuracy: 0.8206
Epoch 51/128
 - 3s - loss: 0.4493 - accuracy: 0.8300 - val_loss: 0.5817 - val_accuracy: 0.8256
Epoch 52/128
 - 3s - loss: 0.4436 - accuracy: 0.8333 - val_loss: 0.5877 - val_accuracy: 0.8223
Epoch 53/128
 - 3s - loss: 0.4583 - accuracy: 0.8263 - val_loss: 0.5660 - val_accuracy: 0.8239
Epoch 54/128
 - 3s - loss: 0.4466 - accuracy: 0.8296 - val_loss: 0.5682 - val_accuracy: 0.8306
Epoch 55/128
 - 3s - loss: 0.4443 - accuracy: 0.8321 - val_loss: 0.5838 - val_accuracy: 0.8189
Epoch 56/128
 - 3s - loss: 0.4403 - accuracy: 0.8275 - val_loss: 0.6895 - val_accuracy: 0.8173
Epoch 57/128
 - 3s - loss: 0.4599 - accuracy: 0.8267 - val_loss: 0.5673 - val_accuracy: 0.8339
Epoch 58/128
 - 3s - loss: 0.4416 - accuracy: 0.8300 - val_loss: 0.5684 - val_accuracy: 0.8256
Epoch 59/128
 - 3s - loss: 0.4334 - accuracy: 0.8371 - val_loss: 0.5512 - val_accuracy: 0.8372
Epoch 60/128
 - 3s - loss: 0.4382 - accuracy: 0.8375 - val_loss: 0.5846 - val_accuracy: 0.8156
Epoch 61/128
 - 3s - loss: 0.4389 - accuracy: 0.8317 - val_loss: 0.5916 - val_accuracy: 0.8256
Epoch 62/128
 - 3s - loss: 0.4337 - accuracy: 0.8296 - val_loss: 0.6121 - val_accuracy: 0.8306
Epoch 63/128
 - 3s - loss: 0.4186 - accuracy: 0.8350 - val_loss: 0.6041 - val_accuracy: 0.8272
Epoch 64/128
 - 3s - loss: 0.4181 - accuracy: 0.8367 - val_loss: 0.6129 - val_accuracy: 0.8256
Epoch 65/128
 - 3s - loss: 0.4276 - accuracy: 0.8350 - val_loss: 0.6206 - val_accuracy: 0.8156
Epoch 66/128
 - 3s - loss: 0.4378 - accuracy: 0.8321 - val_loss: 0.5610 - val_accuracy: 0.8289
Epoch 67/128
 - 3s - loss: 0.4253 - accuracy: 0.8342 - val_loss: 0.5908 - val_accuracy: 0.8256
Epoch 68/128
 - 3s - loss: 0.4252 - accuracy: 0.8325 - val_loss: 0.6400 - val_accuracy: 0.8106
Epoch 69/128
 - 3s - loss: 0.4193 - accuracy: 0.8408 - val_loss: 0.6079 - val_accuracy: 0.8256
Epoch 70/128
 - 3s - loss: 0.4102 - accuracy: 0.8387 - val_loss: 0.6463 - val_accuracy: 0.8372
Epoch 71/128
 - 3s - loss: 0.4117 - accuracy: 0.8379 - val_loss: 0.6249 - val_accuracy: 0.8389
Epoch 72/128
 - 3s - loss: 0.4148 - accuracy: 0.8375 - val_loss: 0.5987 - val_accuracy: 0.8339
Epoch 73/128
 - 3s - loss: 0.4121 - accuracy: 0.8421 - val_loss: 0.6185 - val_accuracy: 0.8355
Epoch 74/128
 - 3s - loss: 0.4174 - accuracy: 0.8396 - val_loss: 0.6252 - val_accuracy: 0.8306
Epoch 75/128
 - 3s - loss: 0.4046 - accuracy: 0.8412 - val_loss: 0.6587 - val_accuracy: 0.8289
Epoch 76/128
 - 3s - loss: 0.4140 - accuracy: 0.8379 - val_loss: 0.6117 - val_accuracy: 0.8372
Epoch 77/128
 - 3s - loss: 0.4125 - accuracy: 0.8412 - val_loss: 0.6357 - val_accuracy: 0.8289
Epoch 78/128
 - 3s - loss: 0.4180 - accuracy: 0.8371 - val_loss: 0.6180 - val_accuracy: 0.8306
Epoch 79/128
 - 3s - loss: 0.4108 - accuracy: 0.8362 - val_loss: 0.6448 - val_accuracy: 0.8322
Epoch 80/128
 - 3s - loss: 0.4008 - accuracy: 0.8437 - val_loss: 0.6443 - val_accuracy: 0.8339
Epoch 81/128
 - 3s - loss: 0.4113 - accuracy: 0.8396 - val_loss: 0.6111 - val_accuracy: 0.8289
Epoch 82/128
 - 3s - loss: 0.4070 - accuracy: 0.8392 - val_loss: 0.6140 - val_accuracy: 0.8355
Epoch 83/128
 - 3s - loss: 0.4016 - accuracy: 0.8387 - val_loss: 0.6234 - val_accuracy: 0.8206
Epoch 84/128
 - 3s - loss: 0.3975 - accuracy: 0.8387 - val_loss: 0.6333 - val_accuracy: 0.8206
Epoch 85/128
 - 3s - loss: 0.3946 - accuracy: 0.8416 - val_loss: 0.6603 - val_accuracy: 0.8223
Epoch 86/128
 - 3s - loss: 0.4187 - accuracy: 0.8404 - val_loss: 0.5958 - val_accuracy: 0.8339
Epoch 87/128
 - 3s - loss: 0.4001 - accuracy: 0.8416 - val_loss: 0.6323 - val_accuracy: 0.8289
Epoch 88/128
 - 3s - loss: 0.3960 - accuracy: 0.8425 - val_loss: 0.5994 - val_accuracy: 0.8422
Epoch 89/128
 - 3s - loss: 0.4035 - accuracy: 0.8367 - val_loss: 0.6074 - val_accuracy: 0.8289
Epoch 90/128
 - 3s - loss: 0.3879 - accuracy: 0.8429 - val_loss: 0.6669 - val_accuracy: 0.8339
Epoch 91/128
 - 3s - loss: 0.4016 - accuracy: 0.8371 - val_loss: 0.6180 - val_accuracy: 0.8256
Epoch 92/128
 - 3s - loss: 0.3957 - accuracy: 0.8429 - val_loss: 0.6177 - val_accuracy: 0.8322
Epoch 93/128
 - 3s - loss: 0.3945 - accuracy: 0.8400 - val_loss: 0.6340 - val_accuracy: 0.8223
Epoch 94/128
 - 3s - loss: 0.3957 - accuracy: 0.8412 - val_loss: 0.6487 - val_accuracy: 0.8256
Epoch 95/128
 - 3s - loss: 0.3852 - accuracy: 0.8416 - val_loss: 0.6239 - val_accuracy: 0.8339
Epoch 96/128
 - 3s - loss: 0.3932 - accuracy: 0.8433 - val_loss: 0.6178 - val_accuracy: 0.8355
Epoch 97/128
 - 3s - loss: 0.3879 - accuracy: 0.8441 - val_loss: 0.5821 - val_accuracy: 0.8322
Epoch 98/128
 - 3s - loss: 0.3847 - accuracy: 0.8408 - val_loss: 0.5669 - val_accuracy: 0.8322
Epoch 99/128
 - 3s - loss: 0.3868 - accuracy: 0.8466 - val_loss: 0.6212 - val_accuracy: 0.8322
Epoch 100/128
 - 3s - loss: 0.3841 - accuracy: 0.8441 - val_loss: 0.5983 - val_accuracy: 0.8355
Epoch 101/128
 - 3s - loss: 0.3850 - accuracy: 0.8466 - val_loss: 0.6363 - val_accuracy: 0.8389
Epoch 102/128
 - 3s - loss: 0.3876 - accuracy: 0.8375 - val_loss: 0.5990 - val_accuracy: 0.8405
Epoch 103/128
 - 3s - loss: 0.3887 - accuracy: 0.8412 - val_loss: 0.5667 - val_accuracy: 0.8389
Epoch 104/128
 - 3s - loss: 0.3831 - accuracy: 0.8437 - val_loss: 0.6441 - val_accuracy: 0.8206
Epoch 105/128
 - 3s - loss: 0.3968 - accuracy: 0.8358 - val_loss: 0.6281 - val_accuracy: 0.8355
Epoch 106/128
 - 3s - loss: 0.3811 - accuracy: 0.8454 - val_loss: 0.5988 - val_accuracy: 0.8405
Epoch 107/128
 - 3s - loss: 0.3824 - accuracy: 0.8392 - val_loss: 0.5746 - val_accuracy: 0.8355
Epoch 108/128
 - 3s - loss: 0.3848 - accuracy: 0.8441 - val_loss: 0.5928 - val_accuracy: 0.8306
Epoch 109/128
 - 3s - loss: 0.3725 - accuracy: 0.8412 - val_loss: 0.6185 - val_accuracy: 0.8289
Epoch 110/128
 - 3s - loss: 0.3781 - accuracy: 0.8475 - val_loss: 0.6711 - val_accuracy: 0.8339
Epoch 111/128
 - 3s - loss: 0.3617 - accuracy: 0.8520 - val_loss: 0.6525 - val_accuracy: 0.8372
Epoch 112/128
 - 3s - loss: 0.3728 - accuracy: 0.8487 - val_loss: 0.6253 - val_accuracy: 0.8405
Epoch 113/128
 - 3s - loss: 0.3737 - accuracy: 0.8458 - val_loss: 0.5990 - val_accuracy: 0.8472
Epoch 114/128
 - 3s - loss: 0.3684 - accuracy: 0.8483 - val_loss: 0.6502 - val_accuracy: 0.8505
Epoch 115/128
 - 3s - loss: 0.3700 - accuracy: 0.8520 - val_loss: 0.6257 - val_accuracy: 0.8322
Epoch 116/128
 - 3s - loss: 0.3693 - accuracy: 0.8475 - val_loss: 0.6584 - val_accuracy: 0.8339
Epoch 117/128
 - 3s - loss: 0.3680 - accuracy: 0.8504 - val_loss: 0.6214 - val_accuracy: 0.8355
Epoch 118/128
 - 3s - loss: 0.3530 - accuracy: 0.8491 - val_loss: 0.6492 - val_accuracy: 0.8389
Epoch 119/128
 - 3s - loss: 0.3673 - accuracy: 0.8491 - val_loss: 0.6774 - val_accuracy: 0.8322
Epoch 120/128
 - 3s - loss: 0.3583 - accuracy: 0.8516 - val_loss: 0.6616 - val_accuracy: 0.8389
Epoch 121/128
 - 3s - loss: 0.3584 - accuracy: 0.8562 - val_loss: 0.7330 - val_accuracy: 0.8405
Epoch 122/128
 - 3s - loss: 0.3871 - accuracy: 0.8483 - val_loss: 0.6132 - val_accuracy: 0.8405
Epoch 123/128
 - 3s - loss: 0.3646 - accuracy: 0.8520 - val_loss: 0.6232 - val_accuracy: 0.8355
Epoch 124/128
 - 3s - loss: 0.3613 - accuracy: 0.8504 - val_loss: 0.6757 - val_accuracy: 0.8322
Epoch 125/128
 - 3s - loss: 0.3665 - accuracy: 0.8516 - val_loss: 0.6469 - val_accuracy: 0.8355
Epoch 126/128
 - 3s - loss: 0.3977 - accuracy: 0.8512 - val_loss: 0.5618 - val_accuracy: 0.8422
Epoch 127/128
 - 3s - loss: 0.3639 - accuracy: 0.8508 - val_loss: 0.5813 - val_accuracy: 0.8389
Epoch 128/128
 - 3s - loss: 0.3618 - accuracy: 0.8520 - val_loss: 0.5955 - val_accuracy: 0.8372

Fit: epochs= 128 , batch_size= 32 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "sequential_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_8 (Conv1D)            (None, 10, 500)           1000      
_________________________________________________________________
activation_15 (Activation)   (None, 10, 500)           0         
_________________________________________________________________
flatten_8 (Flatten)          (None, 5000)              0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 5000)              0         
_________________________________________________________________
dense_50 (Dense)             (None, 400)               2000400   
_________________________________________________________________
dense_51 (Dense)             (None, 300)               120300    
_________________________________________________________________
dense_52 (Dense)             (None, 200)               60200     
_________________________________________________________________
dense_53 (Dense)             (None, 100)               20100     
_________________________________________________________________
dense_54 (Dense)             (None, 50)                5050      
_________________________________________________________________
dense_55 (Dense)             (None, 20)                1020      
_________________________________________________________________
dense_56 (Dense)             (None, 4)                 84        
_________________________________________________________________
activation_16 (Activation)   (None, 4)                 0         
=================================================================
Total params: 2,208,154
Trainable params: 2,208,154
Non-trainable params: 0
_________________________________________________________________
None

Accuracy Train: 85.54%
Accuracy Test: 80.59%
Loss Train: 0.38
Loss Test: 0.65
Numero dati esaminati: 752
True Positive 606
False Positive 146
