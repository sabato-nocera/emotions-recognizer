Dataset used: ../../datasets/full_dataset.csv 

   Temperature  Humidity  Sound  ...     Z2  Classification  Feedback
0           32        95      1  ... -15596             100     Happy
1           32        86      1  ... -15628             100     Happy
2           -1        -1      1  ... -15612             100     Happy
3           -1        -1     -1  ...     -1             100     Happy
4           32        75      1  ... -15720             100     Happy

[5 rows x 12 columns]

Objservations: 8560
Reshaping:  ((6848, 11), (6848, 4), (1712, 11), (1712, 4))  -> ((6848, 11, 1), (6848, 4), (1712, 11, 1), (1712, 4))

Layers:

{'name': 'conv1d_9', 'trainable': True, 'batch_input_shape': (None, 11, 1), 'dtype': 'float32', 'filters': 500, 'kernel_size': (1,), 'strides': (1,), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'activation_17', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'} 

{'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.4, 'noise_shape': None, 'seed': None} 

{'name': 'dense_57', 'trainable': True, 'dtype': 'float32', 'units': 400, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_58', 'trainable': True, 'dtype': 'float32', 'units': 300, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_59', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_60', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_61', 'trainable': True, 'dtype': 'float32', 'units': 50, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_62', 'trainable': True, 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_63', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'activation_18', 'trainable': True, 'dtype': 'float32', 'activation': 'softmax'} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 5478 samples, validate on 1370 samples
Epoch 1/128
 - 8s - loss: 0.9355 - accuracy: 0.6154 - val_loss: 0.8511 - val_accuracy: 0.6832
Epoch 2/128
 - 7s - loss: 0.8078 - accuracy: 0.6909 - val_loss: 0.7788 - val_accuracy: 0.7234
Epoch 3/128
 - 7s - loss: 0.7737 - accuracy: 0.7061 - val_loss: 0.7469 - val_accuracy: 0.7328
Epoch 4/128
 - 7s - loss: 0.7363 - accuracy: 0.7256 - val_loss: 0.7261 - val_accuracy: 0.7350
Epoch 5/128
 - 7s - loss: 0.7103 - accuracy: 0.7373 - val_loss: 0.7090 - val_accuracy: 0.7438
Epoch 6/128
 - 8s - loss: 0.6882 - accuracy: 0.7450 - val_loss: 0.6670 - val_accuracy: 0.7555
Epoch 7/128
 - 8s - loss: 0.6676 - accuracy: 0.7503 - val_loss: 0.6532 - val_accuracy: 0.7657
Epoch 8/128
 - 8s - loss: 0.6450 - accuracy: 0.7623 - val_loss: 0.6975 - val_accuracy: 0.7438
Epoch 9/128
 - 7s - loss: 0.6258 - accuracy: 0.7671 - val_loss: 0.6368 - val_accuracy: 0.7723
Epoch 10/128
 - 7s - loss: 0.6070 - accuracy: 0.7751 - val_loss: 0.6272 - val_accuracy: 0.7752
Epoch 11/128
 - 7s - loss: 0.5977 - accuracy: 0.7733 - val_loss: 0.6155 - val_accuracy: 0.7745
Epoch 12/128
 - 7s - loss: 0.5821 - accuracy: 0.7775 - val_loss: 0.5957 - val_accuracy: 0.7752
Epoch 13/128
 - 7s - loss: 0.5774 - accuracy: 0.7831 - val_loss: 0.5673 - val_accuracy: 0.7891
Epoch 14/128
 - 7s - loss: 0.5558 - accuracy: 0.7881 - val_loss: 0.5942 - val_accuracy: 0.7847
Epoch 15/128
 - 7s - loss: 0.5483 - accuracy: 0.7899 - val_loss: 0.5754 - val_accuracy: 0.7942
Epoch 16/128
 - 7s - loss: 0.5383 - accuracy: 0.7945 - val_loss: 0.5729 - val_accuracy: 0.7912
Epoch 17/128
 - 7s - loss: 0.5308 - accuracy: 0.7974 - val_loss: 0.5462 - val_accuracy: 0.8102
Epoch 18/128
 - 8s - loss: 0.5147 - accuracy: 0.8021 - val_loss: 0.5631 - val_accuracy: 0.7978
Epoch 19/128
 - 8s - loss: 0.5171 - accuracy: 0.8023 - val_loss: 0.5402 - val_accuracy: 0.8044
Epoch 20/128
 - 7s - loss: 0.5048 - accuracy: 0.8043 - val_loss: 0.5267 - val_accuracy: 0.8051
Epoch 21/128
 - 7s - loss: 0.5027 - accuracy: 0.8081 - val_loss: 0.5374 - val_accuracy: 0.8139
Epoch 22/128
 - 7s - loss: 0.4891 - accuracy: 0.8074 - val_loss: 0.5224 - val_accuracy: 0.8088
Epoch 23/128
 - 8s - loss: 0.4855 - accuracy: 0.8083 - val_loss: 0.5155 - val_accuracy: 0.8080
Epoch 24/128
 - 8s - loss: 0.4813 - accuracy: 0.8103 - val_loss: 0.4944 - val_accuracy: 0.8124
Epoch 25/128
 - 7s - loss: 0.4735 - accuracy: 0.8145 - val_loss: 0.4966 - val_accuracy: 0.8168
Epoch 26/128
 - 7s - loss: 0.4790 - accuracy: 0.8138 - val_loss: 0.4939 - val_accuracy: 0.8139
Epoch 27/128
 - 7s - loss: 0.4759 - accuracy: 0.8118 - val_loss: 0.5045 - val_accuracy: 0.8117
Epoch 28/128
 - 7s - loss: 0.4570 - accuracy: 0.8195 - val_loss: 0.5040 - val_accuracy: 0.8131
Epoch 29/128
 - 7s - loss: 0.4622 - accuracy: 0.8182 - val_loss: 0.4894 - val_accuracy: 0.8109
Epoch 30/128
 - 7s - loss: 0.4479 - accuracy: 0.8220 - val_loss: 0.4851 - val_accuracy: 0.8241
Epoch 31/128
 - 7s - loss: 0.4474 - accuracy: 0.8242 - val_loss: 0.4764 - val_accuracy: 0.8241
Epoch 32/128
 - 7s - loss: 0.4438 - accuracy: 0.8253 - val_loss: 0.4847 - val_accuracy: 0.8234
Epoch 33/128
 - 7s - loss: 0.4466 - accuracy: 0.8227 - val_loss: 0.4794 - val_accuracy: 0.8292
Epoch 34/128
 - 7s - loss: 0.4486 - accuracy: 0.8260 - val_loss: 0.4743 - val_accuracy: 0.8307
Epoch 35/128
 - 7s - loss: 0.4308 - accuracy: 0.8288 - val_loss: 0.4656 - val_accuracy: 0.8321
Epoch 36/128
 - 7s - loss: 0.4295 - accuracy: 0.8288 - val_loss: 0.4784 - val_accuracy: 0.8380
Epoch 37/128
 - 7s - loss: 0.4359 - accuracy: 0.8258 - val_loss: 0.4721 - val_accuracy: 0.8226
Epoch 38/128
 - 7s - loss: 0.4407 - accuracy: 0.8237 - val_loss: 0.4580 - val_accuracy: 0.8343
Epoch 39/128
 - 7s - loss: 0.4254 - accuracy: 0.8288 - val_loss: 0.4633 - val_accuracy: 0.8307
Epoch 40/128
 - 7s - loss: 0.4215 - accuracy: 0.8326 - val_loss: 0.4886 - val_accuracy: 0.8117
Epoch 41/128
 - 7s - loss: 0.4182 - accuracy: 0.8313 - val_loss: 0.4672 - val_accuracy: 0.8380
Epoch 42/128
 - 7s - loss: 0.4153 - accuracy: 0.8346 - val_loss: 0.4659 - val_accuracy: 0.8387
Epoch 43/128
 - 7s - loss: 0.4164 - accuracy: 0.8352 - val_loss: 0.4604 - val_accuracy: 0.8248
Epoch 44/128
 - 7s - loss: 0.4172 - accuracy: 0.8299 - val_loss: 0.4790 - val_accuracy: 0.8277
Epoch 45/128
 - 7s - loss: 0.4088 - accuracy: 0.8364 - val_loss: 0.4474 - val_accuracy: 0.8460
Epoch 46/128
 - 7s - loss: 0.4067 - accuracy: 0.8364 - val_loss: 0.4646 - val_accuracy: 0.8401
Epoch 47/128
 - 7s - loss: 0.4040 - accuracy: 0.8352 - val_loss: 0.4651 - val_accuracy: 0.8336
Epoch 48/128
 - 7s - loss: 0.3961 - accuracy: 0.8399 - val_loss: 0.4455 - val_accuracy: 0.8511
Epoch 49/128
 - 7s - loss: 0.3944 - accuracy: 0.8408 - val_loss: 0.4621 - val_accuracy: 0.8474
Epoch 50/128
 - 7s - loss: 0.4025 - accuracy: 0.8377 - val_loss: 0.4653 - val_accuracy: 0.8365
Epoch 51/128
 - 8s - loss: 0.3929 - accuracy: 0.8423 - val_loss: 0.4716 - val_accuracy: 0.8460
Epoch 52/128
 - 8s - loss: 0.4065 - accuracy: 0.8379 - val_loss: 0.4749 - val_accuracy: 0.8474
Epoch 53/128
 - 8s - loss: 0.3886 - accuracy: 0.8395 - val_loss: 0.4801 - val_accuracy: 0.8431
Epoch 54/128
 - 8s - loss: 0.3949 - accuracy: 0.8436 - val_loss: 0.4761 - val_accuracy: 0.8372
Epoch 55/128
 - 7s - loss: 0.3876 - accuracy: 0.8392 - val_loss: 0.4545 - val_accuracy: 0.8453
Epoch 56/128
 - 7s - loss: 0.3874 - accuracy: 0.8430 - val_loss: 0.4762 - val_accuracy: 0.8372
Epoch 57/128
 - 7s - loss: 0.3827 - accuracy: 0.8415 - val_loss: 0.4520 - val_accuracy: 0.8489
Epoch 58/128
 - 7s - loss: 0.3885 - accuracy: 0.8406 - val_loss: 0.4418 - val_accuracy: 0.8489
Epoch 59/128
 - 7s - loss: 0.3863 - accuracy: 0.8443 - val_loss: 0.4655 - val_accuracy: 0.8453
Epoch 60/128
 - 7s - loss: 0.3832 - accuracy: 0.8437 - val_loss: 0.4389 - val_accuracy: 0.8540
Epoch 61/128
 - 7s - loss: 0.3786 - accuracy: 0.8434 - val_loss: 0.4631 - val_accuracy: 0.8445
Epoch 62/128
 - 7s - loss: 0.3885 - accuracy: 0.8425 - val_loss: 0.4639 - val_accuracy: 0.8474
Epoch 63/128
 - 7s - loss: 0.3708 - accuracy: 0.8478 - val_loss: 0.4801 - val_accuracy: 0.8453
Epoch 64/128
 - 7s - loss: 0.3914 - accuracy: 0.8421 - val_loss: 0.4775 - val_accuracy: 0.8328
Epoch 65/128
 - 7s - loss: 0.3864 - accuracy: 0.8414 - val_loss: 0.4404 - val_accuracy: 0.8511
Epoch 66/128
 - 7s - loss: 0.3795 - accuracy: 0.8459 - val_loss: 0.4472 - val_accuracy: 0.8518
Epoch 67/128
 - 7s - loss: 0.3710 - accuracy: 0.8476 - val_loss: 0.4401 - val_accuracy: 0.8496
Epoch 68/128
 - 8s - loss: 0.3699 - accuracy: 0.8485 - val_loss: 0.4518 - val_accuracy: 0.8526
Epoch 69/128
 - 8s - loss: 0.3708 - accuracy: 0.8470 - val_loss: 0.4512 - val_accuracy: 0.8489
Epoch 70/128
 - 8s - loss: 0.3653 - accuracy: 0.8498 - val_loss: 0.4537 - val_accuracy: 0.8555
Epoch 71/128
 - 7s - loss: 0.3702 - accuracy: 0.8461 - val_loss: 0.4671 - val_accuracy: 0.8445
Epoch 72/128
 - 7s - loss: 0.3650 - accuracy: 0.8523 - val_loss: 0.4703 - val_accuracy: 0.8496
Epoch 73/128
 - 7s - loss: 0.3712 - accuracy: 0.8468 - val_loss: 0.4578 - val_accuracy: 0.8460
Epoch 74/128
 - 7s - loss: 0.3697 - accuracy: 0.8465 - val_loss: 0.4490 - val_accuracy: 0.8489
Epoch 75/128
 - 7s - loss: 0.3698 - accuracy: 0.8470 - val_loss: 0.4661 - val_accuracy: 0.8518
Epoch 76/128
 - 7s - loss: 0.3644 - accuracy: 0.8516 - val_loss: 0.4589 - val_accuracy: 0.8526
Epoch 77/128
 - 7s - loss: 0.3759 - accuracy: 0.8436 - val_loss: 0.4578 - val_accuracy: 0.8467
Epoch 78/128
 - 7s - loss: 0.3624 - accuracy: 0.8496 - val_loss: 0.4661 - val_accuracy: 0.8474
Epoch 79/128
 - 7s - loss: 0.3657 - accuracy: 0.8457 - val_loss: 0.4752 - val_accuracy: 0.8380
Epoch 80/128
 - 7s - loss: 0.3614 - accuracy: 0.8468 - val_loss: 0.4649 - val_accuracy: 0.8496
Epoch 81/128
 - 7s - loss: 0.3687 - accuracy: 0.8503 - val_loss: 0.4601 - val_accuracy: 0.8562
Epoch 82/128
 - 7s - loss: 0.3650 - accuracy: 0.8457 - val_loss: 0.4715 - val_accuracy: 0.8474
Epoch 83/128
 - 7s - loss: 0.3549 - accuracy: 0.8527 - val_loss: 0.4760 - val_accuracy: 0.8526
Epoch 84/128
 - 7s - loss: 0.3569 - accuracy: 0.8521 - val_loss: 0.4721 - val_accuracy: 0.8474
Epoch 85/128
 - 7s - loss: 0.3625 - accuracy: 0.8490 - val_loss: 0.4611 - val_accuracy: 0.8555
Epoch 86/128
 - 7s - loss: 0.3612 - accuracy: 0.8503 - val_loss: 0.4658 - val_accuracy: 0.8504
Epoch 87/128
 - 7s - loss: 0.3560 - accuracy: 0.8512 - val_loss: 0.4435 - val_accuracy: 0.8511
Epoch 88/128
 - 7s - loss: 0.3633 - accuracy: 0.8534 - val_loss: 0.4514 - val_accuracy: 0.8445
Epoch 89/128
 - 7s - loss: 0.3501 - accuracy: 0.8560 - val_loss: 0.4886 - val_accuracy: 0.8496
Epoch 90/128
 - 7s - loss: 0.3536 - accuracy: 0.8521 - val_loss: 0.4649 - val_accuracy: 0.8547
Epoch 91/128
 - 7s - loss: 0.3466 - accuracy: 0.8530 - val_loss: 0.4645 - val_accuracy: 0.8489
Epoch 92/128
 - 7s - loss: 0.3421 - accuracy: 0.8551 - val_loss: 0.4797 - val_accuracy: 0.8533
Epoch 93/128
 - 7s - loss: 0.3561 - accuracy: 0.8530 - val_loss: 0.4783 - val_accuracy: 0.8474
Epoch 94/128
 - 7s - loss: 0.3498 - accuracy: 0.8540 - val_loss: 0.4779 - val_accuracy: 0.8438
Epoch 95/128
 - 7s - loss: 0.3592 - accuracy: 0.8505 - val_loss: 0.4614 - val_accuracy: 0.8533
Epoch 96/128
 - 7s - loss: 0.3593 - accuracy: 0.8503 - val_loss: 0.4791 - val_accuracy: 0.8496
Epoch 97/128
 - 7s - loss: 0.3410 - accuracy: 0.8585 - val_loss: 0.4824 - val_accuracy: 0.8526
Epoch 98/128
 - 7s - loss: 0.3383 - accuracy: 0.8589 - val_loss: 0.4854 - val_accuracy: 0.8533
Epoch 99/128
 - 7s - loss: 0.3496 - accuracy: 0.8509 - val_loss: 0.4894 - val_accuracy: 0.8445
Epoch 100/128
 - 8s - loss: 0.3522 - accuracy: 0.8538 - val_loss: 0.5088 - val_accuracy: 0.8489
Epoch 101/128
 - 8s - loss: 0.3562 - accuracy: 0.8503 - val_loss: 0.4965 - val_accuracy: 0.8533
Epoch 102/128
 - 7s - loss: 0.3465 - accuracy: 0.8569 - val_loss: 0.5037 - val_accuracy: 0.8504
Epoch 103/128
 - 7s - loss: 0.3415 - accuracy: 0.8594 - val_loss: 0.4920 - val_accuracy: 0.8540
Epoch 104/128
 - 7s - loss: 0.3432 - accuracy: 0.8543 - val_loss: 0.4806 - val_accuracy: 0.8511
Epoch 105/128
 - 7s - loss: 0.3449 - accuracy: 0.8547 - val_loss: 0.4852 - val_accuracy: 0.8518
Epoch 106/128
 - 7s - loss: 0.3494 - accuracy: 0.8549 - val_loss: 0.4870 - val_accuracy: 0.8453
Epoch 107/128
 - 7s - loss: 0.3486 - accuracy: 0.8525 - val_loss: 0.4872 - val_accuracy: 0.8496
Epoch 108/128
 - 7s - loss: 0.3414 - accuracy: 0.8562 - val_loss: 0.4635 - val_accuracy: 0.8460
Epoch 109/128
 - 7s - loss: 0.3457 - accuracy: 0.8530 - val_loss: 0.4600 - val_accuracy: 0.8489
Epoch 110/128
 - 7s - loss: 0.3551 - accuracy: 0.8483 - val_loss: 0.4702 - val_accuracy: 0.8562
Epoch 111/128
 - 7s - loss: 0.3490 - accuracy: 0.8501 - val_loss: 0.4515 - val_accuracy: 0.8518
Epoch 112/128
 - 7s - loss: 0.3396 - accuracy: 0.8552 - val_loss: 0.4581 - val_accuracy: 0.8526
Epoch 113/128
 - 7s - loss: 0.3385 - accuracy: 0.8563 - val_loss: 0.4540 - val_accuracy: 0.8460
Epoch 114/128
 - 7s - loss: 0.3467 - accuracy: 0.8536 - val_loss: 0.4579 - val_accuracy: 0.8489
Epoch 115/128
 - 8s - loss: 0.3390 - accuracy: 0.8560 - val_loss: 0.4625 - val_accuracy: 0.8504
Epoch 116/128
 - 7s - loss: 0.3439 - accuracy: 0.8538 - val_loss: 0.4558 - val_accuracy: 0.8496
Epoch 117/128
 - 8s - loss: 0.3299 - accuracy: 0.8563 - val_loss: 0.4785 - val_accuracy: 0.8504
Epoch 118/128
 - 7s - loss: 0.3396 - accuracy: 0.8552 - val_loss: 0.4665 - val_accuracy: 0.8453
Epoch 119/128
 - 7s - loss: 0.3407 - accuracy: 0.8543 - val_loss: 0.4600 - val_accuracy: 0.8562
Epoch 120/128
 - 7s - loss: 0.3391 - accuracy: 0.8556 - val_loss: 0.4706 - val_accuracy: 0.8409
Epoch 121/128
 - 7s - loss: 0.3374 - accuracy: 0.8541 - val_loss: 0.4574 - val_accuracy: 0.8562
Epoch 122/128
 - 7s - loss: 0.3394 - accuracy: 0.8574 - val_loss: 0.4652 - val_accuracy: 0.8518
Epoch 123/128
 - 7s - loss: 0.3390 - accuracy: 0.8565 - val_loss: 0.4835 - val_accuracy: 0.8453
Epoch 124/128
 - 7s - loss: 0.3524 - accuracy: 0.8521 - val_loss: 0.4797 - val_accuracy: 0.8445
Epoch 125/128
 - 7s - loss: 0.3340 - accuracy: 0.8549 - val_loss: 0.4703 - val_accuracy: 0.8504
Epoch 126/128
 - 7s - loss: 0.3361 - accuracy: 0.8576 - val_loss: 0.4789 - val_accuracy: 0.8504
Epoch 127/128
 - 7s - loss: 0.3283 - accuracy: 0.8618 - val_loss: 0.4907 - val_accuracy: 0.8533
Epoch 128/128
 - 7s - loss: 0.3271 - accuracy: 0.8607 - val_loss: 0.4837 - val_accuracy: 0.8526

Fit: epochs= 128 , batch_size= 32 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_9 (Conv1D)            (None, 11, 500)           1000      
_________________________________________________________________
activation_17 (Activation)   (None, 11, 500)           0         
_________________________________________________________________
flatten_9 (Flatten)          (None, 5500)              0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 5500)              0         
_________________________________________________________________
dense_57 (Dense)             (None, 400)               2200400   
_________________________________________________________________
dense_58 (Dense)             (None, 300)               120300    
_________________________________________________________________
dense_59 (Dense)             (None, 200)               60200     
_________________________________________________________________
dense_60 (Dense)             (None, 100)               20100     
_________________________________________________________________
dense_61 (Dense)             (None, 50)                5050      
_________________________________________________________________
dense_62 (Dense)             (None, 20)                1020      
_________________________________________________________________
dense_63 (Dense)             (None, 4)                 84        
_________________________________________________________________
activation_18 (Activation)   (None, 4)                 0         
=================================================================
Total params: 2,408,154
Trainable params: 2,408,154
Non-trainable params: 0
_________________________________________________________________
None

Accuracy Train: 86.32%
Accuracy Test: 84.81%
Loss Train: 0.34
Loss Test: 0.45
Numero dati esaminati: 1712
True Positive 1452
False Positive 260
