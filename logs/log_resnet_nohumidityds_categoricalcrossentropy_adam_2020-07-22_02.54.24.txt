Dataset used: ../../datasets/full_dataset_without_humidity.csv 

   Temperature  Sound  Heartbeat   X1  ...    Y2     Z2  Classification  Feedback
0           32      1         60 -680  ... -7424 -15596             100     Happy
1           32      1         60 -780  ... -7408 -15628             100     Happy
2           -1      1         60   -1  ... -7276 -15612             100     Happy
3           -1     -1         60   -1  ...    -1     -1             100     Happy
4           32      1         60 -860  ... -7340 -15720             100     Happy

[5 rows x 11 columns]

Objservations: 8560
Reshaping:  ((6848, 10), (6848, 4), (1712, 10), (1712, 4))  -> ((6848, 10, 1), (6848, 4), (1712, 10, 1), (1712, 4))

Layers:

{'batch_input_shape': (None, 10, 1), 'dtype': 'float32', 'sparse': False, 'name': 'input_7'} 

{'name': 'conv1d_127', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_115', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_115', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_128', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_116', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_116', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_129', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_117', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_55', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_117', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_130', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_118', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_118', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_131', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_119', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_56', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_119', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_132', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_120', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_120', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_133', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_121', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_57', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_121', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_134', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_122', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_122', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_135', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_136', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_123', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_58', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_123', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_137', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_124', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_124', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_138', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_125', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_59', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_125', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_139', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_126', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_126', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_140', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_127', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_60', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_127', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_141', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_128', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_128', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_142', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_143', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_129', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_61', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_129', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_144', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_130', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_130', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_145', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_131', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_62', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_131', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_146', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_132', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_132', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_147', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_133', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_63', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_133', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'average_pooling1d_7', 'trainable': True, 'dtype': 'float32', 'strides': (1,), 'pool_size': (1,), 'padding': 'valid', 'data_format': 'channels_last'} 

{'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'} 

{'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 6s - loss: 1.0456 - accuracy: 0.6763 - val_loss: 1.2818 - val_accuracy: 0.5350
Epoch 2/110
 - 3s - loss: 0.7182 - accuracy: 0.7904 - val_loss: 0.9523 - val_accuracy: 0.7066
Epoch 3/110
 - 3s - loss: 0.6628 - accuracy: 0.8067 - val_loss: 0.7905 - val_accuracy: 0.7664
Epoch 4/110
 - 3s - loss: 0.6358 - accuracy: 0.8147 - val_loss: 0.7623 - val_accuracy: 0.7854
Epoch 5/110
 - 2s - loss: 0.6108 - accuracy: 0.8271 - val_loss: 0.7079 - val_accuracy: 0.8000
Epoch 6/110
 - 3s - loss: 0.5967 - accuracy: 0.8311 - val_loss: 0.7129 - val_accuracy: 0.7971
Epoch 7/110
 - 2s - loss: 0.5741 - accuracy: 0.8373 - val_loss: 0.7048 - val_accuracy: 0.8007
Epoch 8/110
 - 2s - loss: 0.5470 - accuracy: 0.8474 - val_loss: 0.6829 - val_accuracy: 0.8139
Epoch 9/110
 - 2s - loss: 0.5382 - accuracy: 0.8459 - val_loss: 0.6985 - val_accuracy: 0.8058
Epoch 10/110
 - 2s - loss: 0.5362 - accuracy: 0.8487 - val_loss: 0.7135 - val_accuracy: 0.7861
Epoch 11/110
 - 2s - loss: 0.5309 - accuracy: 0.8483 - val_loss: 0.7125 - val_accuracy: 0.8000
Epoch 12/110
 - 3s - loss: 0.5313 - accuracy: 0.8501 - val_loss: 0.7882 - val_accuracy: 0.7803
Epoch 13/110
 - 3s - loss: 0.5218 - accuracy: 0.8520 - val_loss: 0.7245 - val_accuracy: 0.7993
Epoch 14/110
 - 3s - loss: 0.5157 - accuracy: 0.8527 - val_loss: 0.7165 - val_accuracy: 0.7956
Epoch 15/110
 - 2s - loss: 0.5250 - accuracy: 0.8479 - val_loss: 0.6856 - val_accuracy: 0.8051
Epoch 16/110
 - 2s - loss: 0.5144 - accuracy: 0.8556 - val_loss: 0.6902 - val_accuracy: 0.8175
Epoch 17/110
 - 3s - loss: 0.5012 - accuracy: 0.8571 - val_loss: 0.7005 - val_accuracy: 0.7993
Epoch 18/110
 - 3s - loss: 0.4803 - accuracy: 0.8686 - val_loss: 0.6952 - val_accuracy: 0.8212
Epoch 19/110
 - 2s - loss: 0.4793 - accuracy: 0.8708 - val_loss: 0.7446 - val_accuracy: 0.8000
Epoch 20/110
 - 3s - loss: 0.4750 - accuracy: 0.8666 - val_loss: 0.6964 - val_accuracy: 0.8139
Epoch 21/110
 - 3s - loss: 0.4592 - accuracy: 0.8755 - val_loss: 0.6544 - val_accuracy: 0.8380
Epoch 22/110
 - 3s - loss: 0.4478 - accuracy: 0.8810 - val_loss: 0.6949 - val_accuracy: 0.8182
Epoch 23/110
 - 3s - loss: 0.4574 - accuracy: 0.8757 - val_loss: 0.7016 - val_accuracy: 0.8175
Epoch 24/110
 - 3s - loss: 0.4560 - accuracy: 0.8748 - val_loss: 0.7558 - val_accuracy: 0.8117
Epoch 25/110
 - 3s - loss: 0.4493 - accuracy: 0.8810 - val_loss: 0.7586 - val_accuracy: 0.7905
Epoch 26/110
 - 3s - loss: 0.4407 - accuracy: 0.8806 - val_loss: 0.7547 - val_accuracy: 0.7964
Epoch 27/110
 - 3s - loss: 0.4456 - accuracy: 0.8812 - val_loss: 0.6968 - val_accuracy: 0.8234
Epoch 28/110
 - 3s - loss: 0.4478 - accuracy: 0.8810 - val_loss: 0.7101 - val_accuracy: 0.8234
Epoch 29/110
 - 3s - loss: 0.4402 - accuracy: 0.8839 - val_loss: 0.7409 - val_accuracy: 0.8182
Epoch 30/110
 - 3s - loss: 0.4335 - accuracy: 0.8844 - val_loss: 0.7039 - val_accuracy: 0.8007
Epoch 31/110
 - 3s - loss: 0.4302 - accuracy: 0.8857 - val_loss: 0.7428 - val_accuracy: 0.8153
Epoch 32/110
 - 3s - loss: 0.4209 - accuracy: 0.8872 - val_loss: 0.7223 - val_accuracy: 0.8015
Epoch 33/110
 - 3s - loss: 0.4297 - accuracy: 0.8854 - val_loss: 0.8670 - val_accuracy: 0.7861
Epoch 34/110
 - 3s - loss: 0.4336 - accuracy: 0.8881 - val_loss: 0.8445 - val_accuracy: 0.7803
Epoch 35/110
 - 3s - loss: 0.4378 - accuracy: 0.8841 - val_loss: 0.7680 - val_accuracy: 0.8044
Epoch 36/110
 - 3s - loss: 0.4393 - accuracy: 0.8854 - val_loss: 0.6384 - val_accuracy: 0.8263
Epoch 37/110
 - 3s - loss: 0.4396 - accuracy: 0.8839 - val_loss: 0.7367 - val_accuracy: 0.8219
Epoch 38/110
 - 3s - loss: 0.4296 - accuracy: 0.8852 - val_loss: 0.7802 - val_accuracy: 0.7949
Epoch 39/110
 - 3s - loss: 0.4135 - accuracy: 0.8870 - val_loss: 0.7548 - val_accuracy: 0.8073
Epoch 40/110
 - 2s - loss: 0.4064 - accuracy: 0.8928 - val_loss: 0.7454 - val_accuracy: 0.8234
Epoch 41/110
 - 2s - loss: 0.3971 - accuracy: 0.9001 - val_loss: 0.7245 - val_accuracy: 0.8146
Epoch 42/110
 - 2s - loss: 0.3994 - accuracy: 0.8987 - val_loss: 0.7438 - val_accuracy: 0.8234
Epoch 43/110
 - 2s - loss: 0.3907 - accuracy: 0.9016 - val_loss: 0.7563 - val_accuracy: 0.8036
Epoch 44/110
 - 2s - loss: 0.3809 - accuracy: 0.9029 - val_loss: 0.6729 - val_accuracy: 0.8394
Epoch 45/110
 - 2s - loss: 0.3849 - accuracy: 0.9040 - val_loss: 0.6994 - val_accuracy: 0.8328
Epoch 46/110
 - 2s - loss: 0.3891 - accuracy: 0.9025 - val_loss: 0.7572 - val_accuracy: 0.8226
Epoch 47/110
 - 2s - loss: 0.3868 - accuracy: 0.9058 - val_loss: 0.6735 - val_accuracy: 0.8372
Epoch 48/110
 - 2s - loss: 0.3941 - accuracy: 0.9003 - val_loss: 0.7085 - val_accuracy: 0.8299
Epoch 49/110
 - 2s - loss: 0.4115 - accuracy: 0.8932 - val_loss: 0.6692 - val_accuracy: 0.8226
Epoch 50/110
 - 2s - loss: 0.3898 - accuracy: 0.9000 - val_loss: 0.6698 - val_accuracy: 0.8270
Epoch 51/110
 - 2s - loss: 0.3695 - accuracy: 0.9056 - val_loss: 0.7459 - val_accuracy: 0.8182
Epoch 52/110
 - 3s - loss: 0.3709 - accuracy: 0.9107 - val_loss: 0.7318 - val_accuracy: 0.8270
Epoch 53/110
 - 3s - loss: 0.3758 - accuracy: 0.9054 - val_loss: 0.6897 - val_accuracy: 0.8350
Epoch 54/110
 - 3s - loss: 0.3551 - accuracy: 0.9147 - val_loss: 0.6726 - val_accuracy: 0.8314
Epoch 55/110
 - 3s - loss: 0.3630 - accuracy: 0.9115 - val_loss: 0.7028 - val_accuracy: 0.8401
Epoch 56/110
 - 3s - loss: 0.3558 - accuracy: 0.9144 - val_loss: 0.6925 - val_accuracy: 0.8285
Epoch 57/110
 - 3s - loss: 0.3611 - accuracy: 0.9133 - val_loss: 0.7227 - val_accuracy: 0.8197
Epoch 58/110
 - 3s - loss: 0.3401 - accuracy: 0.9215 - val_loss: 0.7478 - val_accuracy: 0.8182
Epoch 59/110
 - 2s - loss: 0.3769 - accuracy: 0.9073 - val_loss: 0.7292 - val_accuracy: 0.8328
Epoch 60/110
 - 2s - loss: 0.3676 - accuracy: 0.9113 - val_loss: 0.7484 - val_accuracy: 0.8255
Epoch 61/110
 - 2s - loss: 0.3618 - accuracy: 0.9115 - val_loss: 0.7188 - val_accuracy: 0.8255
Epoch 62/110
 - 2s - loss: 0.3347 - accuracy: 0.9237 - val_loss: 0.6935 - val_accuracy: 0.8380
Epoch 63/110
 - 2s - loss: 0.3367 - accuracy: 0.9257 - val_loss: 0.6852 - val_accuracy: 0.8299
Epoch 64/110
 - 3s - loss: 0.3563 - accuracy: 0.9140 - val_loss: 0.7711 - val_accuracy: 0.8226
Epoch 65/110
 - 3s - loss: 0.3392 - accuracy: 0.9197 - val_loss: 0.7173 - val_accuracy: 0.8255
Epoch 66/110
 - 2s - loss: 0.3490 - accuracy: 0.9200 - val_loss: 0.7538 - val_accuracy: 0.8270
Epoch 67/110
 - 2s - loss: 0.3619 - accuracy: 0.9126 - val_loss: 0.6993 - val_accuracy: 0.8219
Epoch 68/110
 - 2s - loss: 0.3391 - accuracy: 0.9204 - val_loss: 0.7250 - val_accuracy: 0.8175
Epoch 69/110
 - 2s - loss: 0.3307 - accuracy: 0.9294 - val_loss: 0.6998 - val_accuracy: 0.8292
Epoch 70/110
 - 3s - loss: 0.3325 - accuracy: 0.9235 - val_loss: 0.7095 - val_accuracy: 0.8285
Epoch 71/110
 - 3s - loss: 0.3451 - accuracy: 0.9224 - val_loss: 0.7314 - val_accuracy: 0.8182
Epoch 72/110
 - 3s - loss: 0.3368 - accuracy: 0.9252 - val_loss: 0.7365 - val_accuracy: 0.8299
Epoch 73/110
 - 3s - loss: 0.3238 - accuracy: 0.9304 - val_loss: 0.6999 - val_accuracy: 0.8343
Epoch 74/110
 - 3s - loss: 0.3204 - accuracy: 0.9295 - val_loss: 0.6976 - val_accuracy: 0.8277
Epoch 75/110
 - 3s - loss: 0.3312 - accuracy: 0.9277 - val_loss: 0.7381 - val_accuracy: 0.8255
Epoch 76/110
 - 2s - loss: 0.3194 - accuracy: 0.9345 - val_loss: 0.7197 - val_accuracy: 0.8175
Epoch 77/110
 - 2s - loss: 0.3352 - accuracy: 0.9246 - val_loss: 0.7329 - val_accuracy: 0.8358
Epoch 78/110
 - 3s - loss: 0.2996 - accuracy: 0.9352 - val_loss: 0.7097 - val_accuracy: 0.8277
Epoch 79/110
 - 3s - loss: 0.3225 - accuracy: 0.9308 - val_loss: 0.7337 - val_accuracy: 0.8299
Epoch 80/110
 - 3s - loss: 0.3088 - accuracy: 0.9352 - val_loss: 0.7666 - val_accuracy: 0.8139
Epoch 81/110
 - 3s - loss: 0.3125 - accuracy: 0.9330 - val_loss: 0.7665 - val_accuracy: 0.8350
Epoch 82/110
 - 3s - loss: 0.3249 - accuracy: 0.9303 - val_loss: 0.7627 - val_accuracy: 0.8248
Epoch 83/110
 - 3s - loss: 0.3124 - accuracy: 0.9328 - val_loss: 0.7355 - val_accuracy: 0.8263
Epoch 84/110
 - 3s - loss: 0.2949 - accuracy: 0.9403 - val_loss: 0.7211 - val_accuracy: 0.8358
Epoch 85/110
 - 3s - loss: 0.3174 - accuracy: 0.9321 - val_loss: 0.7177 - val_accuracy: 0.8387
Epoch 86/110
 - 3s - loss: 0.3014 - accuracy: 0.9396 - val_loss: 0.8107 - val_accuracy: 0.8321
Epoch 87/110
 - 3s - loss: 0.3233 - accuracy: 0.9294 - val_loss: 0.8118 - val_accuracy: 0.8161
Epoch 88/110
 - 3s - loss: 0.3132 - accuracy: 0.9319 - val_loss: 0.8240 - val_accuracy: 0.8307
Epoch 89/110
 - 3s - loss: 0.2921 - accuracy: 0.9441 - val_loss: 0.8276 - val_accuracy: 0.8336
Epoch 90/110
 - 3s - loss: 0.3057 - accuracy: 0.9379 - val_loss: 0.8301 - val_accuracy: 0.8161
Epoch 91/110
 - 3s - loss: 0.2982 - accuracy: 0.9401 - val_loss: 0.8493 - val_accuracy: 0.8277
Epoch 92/110
 - 3s - loss: 0.2869 - accuracy: 0.9461 - val_loss: 0.7694 - val_accuracy: 0.8299
Epoch 93/110
 - 3s - loss: 0.3046 - accuracy: 0.9336 - val_loss: 0.7831 - val_accuracy: 0.8241
Epoch 94/110
 - 3s - loss: 0.3017 - accuracy: 0.9427 - val_loss: 0.7919 - val_accuracy: 0.8190
Epoch 95/110
 - 3s - loss: 0.2912 - accuracy: 0.9398 - val_loss: 0.8022 - val_accuracy: 0.8153
Epoch 96/110
 - 3s - loss: 0.2908 - accuracy: 0.9409 - val_loss: 0.8065 - val_accuracy: 0.8212
Epoch 97/110
 - 3s - loss: 0.3051 - accuracy: 0.9409 - val_loss: 0.8975 - val_accuracy: 0.8044
Epoch 98/110
 - 3s - loss: 0.2963 - accuracy: 0.9405 - val_loss: 0.7459 - val_accuracy: 0.8226
Epoch 99/110
 - 3s - loss: 0.2753 - accuracy: 0.9496 - val_loss: 0.7866 - val_accuracy: 0.8212
Epoch 100/110
 - 2s - loss: 0.2851 - accuracy: 0.9438 - val_loss: 0.8628 - val_accuracy: 0.8168
Epoch 101/110
 - 2s - loss: 0.2848 - accuracy: 0.9421 - val_loss: 0.7697 - val_accuracy: 0.8314
Epoch 102/110
 - 2s - loss: 0.2813 - accuracy: 0.9493 - val_loss: 0.7661 - val_accuracy: 0.8161
Epoch 103/110
 - 2s - loss: 0.2999 - accuracy: 0.9405 - val_loss: 0.7803 - val_accuracy: 0.8248
Epoch 104/110
 - 2s - loss: 0.2825 - accuracy: 0.9449 - val_loss: 0.8225 - val_accuracy: 0.8277
Epoch 105/110
 - 3s - loss: 0.2699 - accuracy: 0.9542 - val_loss: 0.7692 - val_accuracy: 0.8277
Epoch 106/110
 - 2s - loss: 0.2963 - accuracy: 0.9419 - val_loss: 0.8491 - val_accuracy: 0.8044
Epoch 107/110
 - 2s - loss: 0.3284 - accuracy: 0.9346 - val_loss: 0.7877 - val_accuracy: 0.8095
Epoch 108/110
 - 2s - loss: 0.2812 - accuracy: 0.9465 - val_loss: 0.7432 - val_accuracy: 0.8365
Epoch 109/110
 - 2s - loss: 0.2717 - accuracy: 0.9522 - val_loss: 0.7763 - val_accuracy: 0.8350
Epoch 110/110
 - 3s - loss: 0.2751 - accuracy: 0.9498 - val_loss: 0.8533 - val_accuracy: 0.8248

Number of filters: 16 , Kernel Size: 3 , Strides: 1 Batch Normalization: True , Conv_First: True , Depth Value: 20

Fit: epochs= 110 , batch_size= 64 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "model_7"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 10, 1)        0                                            
__________________________________________________________________________________________________
conv1d_127 (Conv1D)             (None, 10, 16)       64          input_7[0][0]                    
__________________________________________________________________________________________________
batch_normalization_115 (BatchN (None, 10, 16)       64          conv1d_127[0][0]                 
__________________________________________________________________________________________________
activation_115 (Activation)     (None, 10, 16)       0           batch_normalization_115[0][0]    
__________________________________________________________________________________________________
conv1d_128 (Conv1D)             (None, 10, 16)       784         activation_115[0][0]             
__________________________________________________________________________________________________
batch_normalization_116 (BatchN (None, 10, 16)       64          conv1d_128[0][0]                 
__________________________________________________________________________________________________
activation_116 (Activation)     (None, 10, 16)       0           batch_normalization_116[0][0]    
__________________________________________________________________________________________________
conv1d_129 (Conv1D)             (None, 10, 16)       784         activation_116[0][0]             
__________________________________________________________________________________________________
batch_normalization_117 (BatchN (None, 10, 16)       64          conv1d_129[0][0]                 
__________________________________________________________________________________________________
add_55 (Add)                    (None, 10, 16)       0           activation_115[0][0]             
                                                                 batch_normalization_117[0][0]    
__________________________________________________________________________________________________
activation_117 (Activation)     (None, 10, 16)       0           add_55[0][0]                     
__________________________________________________________________________________________________
conv1d_130 (Conv1D)             (None, 10, 16)       784         activation_117[0][0]             
__________________________________________________________________________________________________
batch_normalization_118 (BatchN (None, 10, 16)       64          conv1d_130[0][0]                 
__________________________________________________________________________________________________
activation_118 (Activation)     (None, 10, 16)       0           batch_normalization_118[0][0]    
__________________________________________________________________________________________________
conv1d_131 (Conv1D)             (None, 10, 16)       784         activation_118[0][0]             
__________________________________________________________________________________________________
batch_normalization_119 (BatchN (None, 10, 16)       64          conv1d_131[0][0]                 
__________________________________________________________________________________________________
add_56 (Add)                    (None, 10, 16)       0           activation_117[0][0]             
                                                                 batch_normalization_119[0][0]    
__________________________________________________________________________________________________
activation_119 (Activation)     (None, 10, 16)       0           add_56[0][0]                     
__________________________________________________________________________________________________
conv1d_132 (Conv1D)             (None, 10, 16)       784         activation_119[0][0]             
__________________________________________________________________________________________________
batch_normalization_120 (BatchN (None, 10, 16)       64          conv1d_132[0][0]                 
__________________________________________________________________________________________________
activation_120 (Activation)     (None, 10, 16)       0           batch_normalization_120[0][0]    
__________________________________________________________________________________________________
conv1d_133 (Conv1D)             (None, 10, 16)       784         activation_120[0][0]             
__________________________________________________________________________________________________
batch_normalization_121 (BatchN (None, 10, 16)       64          conv1d_133[0][0]                 
__________________________________________________________________________________________________
add_57 (Add)                    (None, 10, 16)       0           activation_119[0][0]             
                                                                 batch_normalization_121[0][0]    
__________________________________________________________________________________________________
activation_121 (Activation)     (None, 10, 16)       0           add_57[0][0]                     
__________________________________________________________________________________________________
conv1d_134 (Conv1D)             (None, 5, 32)        1568        activation_121[0][0]             
__________________________________________________________________________________________________
batch_normalization_122 (BatchN (None, 5, 32)        128         conv1d_134[0][0]                 
__________________________________________________________________________________________________
activation_122 (Activation)     (None, 5, 32)        0           batch_normalization_122[0][0]    
__________________________________________________________________________________________________
conv1d_135 (Conv1D)             (None, 5, 32)        3104        activation_122[0][0]             
__________________________________________________________________________________________________
conv1d_136 (Conv1D)             (None, 5, 32)        544         activation_121[0][0]             
__________________________________________________________________________________________________
batch_normalization_123 (BatchN (None, 5, 32)        128         conv1d_135[0][0]                 
__________________________________________________________________________________________________
add_58 (Add)                    (None, 5, 32)        0           conv1d_136[0][0]                 
                                                                 batch_normalization_123[0][0]    
__________________________________________________________________________________________________
activation_123 (Activation)     (None, 5, 32)        0           add_58[0][0]                     
__________________________________________________________________________________________________
conv1d_137 (Conv1D)             (None, 5, 32)        3104        activation_123[0][0]             
__________________________________________________________________________________________________
batch_normalization_124 (BatchN (None, 5, 32)        128         conv1d_137[0][0]                 
__________________________________________________________________________________________________
activation_124 (Activation)     (None, 5, 32)        0           batch_normalization_124[0][0]    
__________________________________________________________________________________________________
conv1d_138 (Conv1D)             (None, 5, 32)        3104        activation_124[0][0]             
__________________________________________________________________________________________________
batch_normalization_125 (BatchN (None, 5, 32)        128         conv1d_138[0][0]                 
__________________________________________________________________________________________________
add_59 (Add)                    (None, 5, 32)        0           activation_123[0][0]             
                                                                 batch_normalization_125[0][0]    
__________________________________________________________________________________________________
activation_125 (Activation)     (None, 5, 32)        0           add_59[0][0]                     
__________________________________________________________________________________________________
conv1d_139 (Conv1D)             (None, 5, 32)        3104        activation_125[0][0]             
__________________________________________________________________________________________________
batch_normalization_126 (BatchN (None, 5, 32)        128         conv1d_139[0][0]                 
__________________________________________________________________________________________________
activation_126 (Activation)     (None, 5, 32)        0           batch_normalization_126[0][0]    
__________________________________________________________________________________________________
conv1d_140 (Conv1D)             (None, 5, 32)        3104        activation_126[0][0]             
__________________________________________________________________________________________________
batch_normalization_127 (BatchN (None, 5, 32)        128         conv1d_140[0][0]                 
__________________________________________________________________________________________________
add_60 (Add)                    (None, 5, 32)        0           activation_125[0][0]             
                                                                 batch_normalization_127[0][0]    
__________________________________________________________________________________________________
activation_127 (Activation)     (None, 5, 32)        0           add_60[0][0]                     
__________________________________________________________________________________________________
conv1d_141 (Conv1D)             (None, 3, 64)        6208        activation_127[0][0]             
__________________________________________________________________________________________________
batch_normalization_128 (BatchN (None, 3, 64)        256         conv1d_141[0][0]                 
__________________________________________________________________________________________________
activation_128 (Activation)     (None, 3, 64)        0           batch_normalization_128[0][0]    
__________________________________________________________________________________________________
conv1d_142 (Conv1D)             (None, 3, 64)        12352       activation_128[0][0]             
__________________________________________________________________________________________________
conv1d_143 (Conv1D)             (None, 3, 64)        2112        activation_127[0][0]             
__________________________________________________________________________________________________
batch_normalization_129 (BatchN (None, 3, 64)        256         conv1d_142[0][0]                 
__________________________________________________________________________________________________
add_61 (Add)                    (None, 3, 64)        0           conv1d_143[0][0]                 
                                                                 batch_normalization_129[0][0]    
__________________________________________________________________________________________________
activation_129 (Activation)     (None, 3, 64)        0           add_61[0][0]                     
__________________________________________________________________________________________________
conv1d_144 (Conv1D)             (None, 3, 64)        12352       activation_129[0][0]             
__________________________________________________________________________________________________
batch_normalization_130 (BatchN (None, 3, 64)        256         conv1d_144[0][0]                 
__________________________________________________________________________________________________
activation_130 (Activation)     (None, 3, 64)        0           batch_normalization_130[0][0]    
__________________________________________________________________________________________________
conv1d_145 (Conv1D)             (None, 3, 64)        12352       activation_130[0][0]             
__________________________________________________________________________________________________
batch_normalization_131 (BatchN (None, 3, 64)        256         conv1d_145[0][0]                 
__________________________________________________________________________________________________
add_62 (Add)                    (None, 3, 64)        0           activation_129[0][0]             
                                                                 batch_normalization_131[0][0]    
__________________________________________________________________________________________________
activation_131 (Activation)     (None, 3, 64)        0           add_62[0][0]                     
__________________________________________________________________________________________________
conv1d_146 (Conv1D)             (None, 3, 64)        12352       activation_131[0][0]             
__________________________________________________________________________________________________
batch_normalization_132 (BatchN (None, 3, 64)        256         conv1d_146[0][0]                 
__________________________________________________________________________________________________
activation_132 (Activation)     (None, 3, 64)        0           batch_normalization_132[0][0]    
__________________________________________________________________________________________________
conv1d_147 (Conv1D)             (None, 3, 64)        12352       activation_132[0][0]             
__________________________________________________________________________________________________
batch_normalization_133 (BatchN (None, 3, 64)        256         conv1d_147[0][0]                 
__________________________________________________________________________________________________
add_63 (Add)                    (None, 3, 64)        0           activation_131[0][0]             
                                                                 batch_normalization_133[0][0]    
__________________________________________________________________________________________________
activation_133 (Activation)     (None, 3, 64)        0           add_63[0][0]                     
__________________________________________________________________________________________________
average_pooling1d_7 (AveragePoo (None, 3, 64)        0           activation_133[0][0]             
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 192)          0           average_pooling1d_7[0][0]        
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 4)            772         flatten_7[0][0]                  
==================================================================================================
Total params: 96,004
Trainable params: 94,628
Non-trainable params: 1,376
__________________________________________________________________________________________________
None

Accuracy Train: 84.62%
Accuracy Test: 82.77%
Loss Train: 0.65
Loss Test: 0.77
Numero dati esaminati: 1712
True Positive 1417
False Positive 295


------------------------------------------------------------------------
K-fold Cross Validation
------------------------------------------------------------------------
Training for fold 1 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 6s - loss: 1.0888 - accuracy: 0.6754 - val_loss: 1.5203 - val_accuracy: 0.4518
Epoch 2/110
 - 3s - loss: 0.7451 - accuracy: 0.7846 - val_loss: 1.0237 - val_accuracy: 0.6540
Epoch 3/110
 - 3s - loss: 0.6810 - accuracy: 0.8038 - val_loss: 0.8026 - val_accuracy: 0.7533
Epoch 4/110
 - 3s - loss: 0.6496 - accuracy: 0.8133 - val_loss: 0.7443 - val_accuracy: 0.7956
Epoch 5/110
 - 3s - loss: 0.6235 - accuracy: 0.8209 - val_loss: 0.7010 - val_accuracy: 0.8051
Epoch 6/110
 - 3s - loss: 0.6048 - accuracy: 0.8257 - val_loss: 0.7148 - val_accuracy: 0.7985
Epoch 7/110
 - 3s - loss: 0.5890 - accuracy: 0.8350 - val_loss: 0.7395 - val_accuracy: 0.7942
Epoch 8/110
 - 3s - loss: 0.5648 - accuracy: 0.8425 - val_loss: 0.7004 - val_accuracy: 0.8197
Epoch 9/110
 - 3s - loss: 0.5557 - accuracy: 0.8401 - val_loss: 0.6921 - val_accuracy: 0.8109
Epoch 10/110
 - 3s - loss: 0.5389 - accuracy: 0.8510 - val_loss: 0.7043 - val_accuracy: 0.8109
Epoch 11/110
 - 3s - loss: 0.5489 - accuracy: 0.8436 - val_loss: 0.6896 - val_accuracy: 0.8146
Epoch 12/110
 - 3s - loss: 0.5165 - accuracy: 0.8582 - val_loss: 0.7084 - val_accuracy: 0.8036
Epoch 13/110
 - 3s - loss: 0.5074 - accuracy: 0.8587 - val_loss: 0.7350 - val_accuracy: 0.8066
Epoch 14/110
 - 3s - loss: 0.5171 - accuracy: 0.8536 - val_loss: 0.7207 - val_accuracy: 0.8109
Epoch 15/110
 - 3s - loss: 0.5292 - accuracy: 0.8501 - val_loss: 0.7197 - val_accuracy: 0.8088
Epoch 16/110
 - 3s - loss: 0.5113 - accuracy: 0.8593 - val_loss: 0.7383 - val_accuracy: 0.8080
Epoch 17/110
 - 3s - loss: 0.5075 - accuracy: 0.8558 - val_loss: 0.7545 - val_accuracy: 0.7985
Epoch 18/110
 - 3s - loss: 0.5128 - accuracy: 0.8567 - val_loss: 0.7131 - val_accuracy: 0.8182
Epoch 19/110
 - 3s - loss: 0.4991 - accuracy: 0.8591 - val_loss: 0.6971 - val_accuracy: 0.8109
Epoch 20/110
 - 3s - loss: 0.4990 - accuracy: 0.8600 - val_loss: 0.7210 - val_accuracy: 0.8058
Epoch 21/110
 - 3s - loss: 0.5086 - accuracy: 0.8613 - val_loss: 0.7287 - val_accuracy: 0.8015
Epoch 22/110
 - 3s - loss: 0.5085 - accuracy: 0.8618 - val_loss: 0.6791 - val_accuracy: 0.8190
Epoch 23/110
 - 3s - loss: 0.4904 - accuracy: 0.8660 - val_loss: 0.6725 - val_accuracy: 0.8197
Epoch 24/110
 - 2s - loss: 0.4727 - accuracy: 0.8717 - val_loss: 0.6626 - val_accuracy: 0.8277
Epoch 25/110
 - 3s - loss: 0.4736 - accuracy: 0.8706 - val_loss: 0.6802 - val_accuracy: 0.8263
Epoch 26/110
 - 3s - loss: 0.4668 - accuracy: 0.8779 - val_loss: 0.6594 - val_accuracy: 0.8394
Epoch 27/110
 - 3s - loss: 0.4489 - accuracy: 0.8823 - val_loss: 0.6819 - val_accuracy: 0.8226
Epoch 28/110
 - 3s - loss: 0.4481 - accuracy: 0.8804 - val_loss: 0.6891 - val_accuracy: 0.8197
Epoch 29/110
 - 3s - loss: 0.4582 - accuracy: 0.8750 - val_loss: 0.6854 - val_accuracy: 0.8234
Epoch 30/110
 - 3s - loss: 0.4507 - accuracy: 0.8779 - val_loss: 0.6810 - val_accuracy: 0.8263
Epoch 31/110
 - 3s - loss: 0.4342 - accuracy: 0.8857 - val_loss: 0.6711 - val_accuracy: 0.8292
Epoch 32/110
 - 3s - loss: 0.4270 - accuracy: 0.8890 - val_loss: 0.6949 - val_accuracy: 0.8241
Epoch 33/110
 - 3s - loss: 0.4304 - accuracy: 0.8852 - val_loss: 0.7506 - val_accuracy: 0.8146
Epoch 34/110
 - 3s - loss: 0.4402 - accuracy: 0.8841 - val_loss: 0.7193 - val_accuracy: 0.8175
Epoch 35/110
 - 3s - loss: 0.4351 - accuracy: 0.8865 - val_loss: 0.7355 - val_accuracy: 0.8139
Epoch 36/110
 - 3s - loss: 0.4132 - accuracy: 0.8932 - val_loss: 0.7003 - val_accuracy: 0.8277
Epoch 37/110
 - 3s - loss: 0.4025 - accuracy: 0.8972 - val_loss: 0.6804 - val_accuracy: 0.8423
Epoch 38/110
 - 3s - loss: 0.4000 - accuracy: 0.8983 - val_loss: 0.6655 - val_accuracy: 0.8307
Epoch 39/110
 - 2s - loss: 0.4000 - accuracy: 0.8970 - val_loss: 0.6965 - val_accuracy: 0.8182
Epoch 40/110
 - 2s - loss: 0.4189 - accuracy: 0.8830 - val_loss: 0.7494 - val_accuracy: 0.8117
Epoch 41/110
 - 3s - loss: 0.4285 - accuracy: 0.8890 - val_loss: 0.7347 - val_accuracy: 0.8131
Epoch 42/110
 - 3s - loss: 0.3950 - accuracy: 0.9012 - val_loss: 0.7098 - val_accuracy: 0.8365
Epoch 43/110
 - 3s - loss: 0.3822 - accuracy: 0.9056 - val_loss: 0.6783 - val_accuracy: 0.8336
Epoch 44/110
 - 3s - loss: 0.3835 - accuracy: 0.9060 - val_loss: 0.7365 - val_accuracy: 0.8219
Epoch 45/110
 - 3s - loss: 0.3811 - accuracy: 0.9032 - val_loss: 0.6809 - val_accuracy: 0.8401
Epoch 46/110
 - 2s - loss: 0.3926 - accuracy: 0.9032 - val_loss: 0.7101 - val_accuracy: 0.8153
Epoch 47/110
 - 2s - loss: 0.3977 - accuracy: 0.8994 - val_loss: 0.7054 - val_accuracy: 0.8328
Epoch 48/110
 - 2s - loss: 0.3818 - accuracy: 0.9053 - val_loss: 0.7343 - val_accuracy: 0.8292
Epoch 49/110
 - 2s - loss: 0.3849 - accuracy: 0.9036 - val_loss: 0.6692 - val_accuracy: 0.8292
Epoch 50/110
 - 2s - loss: 0.3867 - accuracy: 0.9007 - val_loss: 0.7645 - val_accuracy: 0.8146
Epoch 51/110
 - 2s - loss: 0.3849 - accuracy: 0.9029 - val_loss: 0.7122 - val_accuracy: 0.8234
Epoch 52/110
 - 3s - loss: 0.3784 - accuracy: 0.9020 - val_loss: 0.7426 - val_accuracy: 0.8131
Epoch 53/110
 - 3s - loss: 0.3844 - accuracy: 0.9042 - val_loss: 0.7277 - val_accuracy: 0.8168
Epoch 54/110
 - 3s - loss: 0.3663 - accuracy: 0.9104 - val_loss: 0.6910 - val_accuracy: 0.8175
Epoch 55/110
 - 3s - loss: 0.3482 - accuracy: 0.9179 - val_loss: 0.7152 - val_accuracy: 0.8336
Epoch 56/110
 - 3s - loss: 0.3524 - accuracy: 0.9144 - val_loss: 0.7431 - val_accuracy: 0.8212
Epoch 57/110
 - 3s - loss: 0.3454 - accuracy: 0.9186 - val_loss: 0.7231 - val_accuracy: 0.8277
Epoch 58/110
 - 2s - loss: 0.3549 - accuracy: 0.9189 - val_loss: 0.7150 - val_accuracy: 0.8314
Epoch 59/110
 - 3s - loss: 0.3419 - accuracy: 0.9208 - val_loss: 0.7460 - val_accuracy: 0.8401
Epoch 60/110
 - 3s - loss: 0.3516 - accuracy: 0.9155 - val_loss: 0.6994 - val_accuracy: 0.8416
Epoch 61/110
 - 3s - loss: 0.3473 - accuracy: 0.9168 - val_loss: 0.6853 - val_accuracy: 0.8423
Epoch 62/110
 - 3s - loss: 0.3484 - accuracy: 0.9199 - val_loss: 0.7201 - val_accuracy: 0.8336
Epoch 63/110
 - 3s - loss: 0.3453 - accuracy: 0.9213 - val_loss: 0.7444 - val_accuracy: 0.8248
Epoch 64/110
 - 3s - loss: 0.3350 - accuracy: 0.9237 - val_loss: 0.7632 - val_accuracy: 0.8365
Epoch 65/110
 - 2s - loss: 0.3753 - accuracy: 0.9056 - val_loss: 0.7044 - val_accuracy: 0.8321
Epoch 66/110
 - 3s - loss: 0.3401 - accuracy: 0.9231 - val_loss: 0.7448 - val_accuracy: 0.8358
Epoch 67/110
 - 3s - loss: 0.3356 - accuracy: 0.9193 - val_loss: 0.7970 - val_accuracy: 0.8372
Epoch 68/110
 - 2s - loss: 0.3211 - accuracy: 0.9348 - val_loss: 0.7434 - val_accuracy: 0.8387
Epoch 69/110
 - 3s - loss: 0.3163 - accuracy: 0.9325 - val_loss: 0.7737 - val_accuracy: 0.8204
Epoch 70/110
 - 3s - loss: 0.3191 - accuracy: 0.9295 - val_loss: 0.7341 - val_accuracy: 0.8277
Epoch 71/110
 - 3s - loss: 0.2947 - accuracy: 0.9403 - val_loss: 0.7029 - val_accuracy: 0.8438
Epoch 72/110
 - 2s - loss: 0.3094 - accuracy: 0.9336 - val_loss: 0.7353 - val_accuracy: 0.8328
Epoch 73/110
 - 3s - loss: 0.3003 - accuracy: 0.9401 - val_loss: 0.7457 - val_accuracy: 0.8241
Epoch 74/110
 - 3s - loss: 0.3123 - accuracy: 0.9343 - val_loss: 0.7682 - val_accuracy: 0.8139
Epoch 75/110
 - 3s - loss: 0.3376 - accuracy: 0.9268 - val_loss: 0.8021 - val_accuracy: 0.8241
Epoch 76/110
 - 3s - loss: 0.3383 - accuracy: 0.9241 - val_loss: 0.7818 - val_accuracy: 0.8241
Epoch 77/110
 - 3s - loss: 0.3349 - accuracy: 0.9268 - val_loss: 0.7302 - val_accuracy: 0.8350
Epoch 78/110
 - 3s - loss: 0.3052 - accuracy: 0.9396 - val_loss: 0.7197 - val_accuracy: 0.8263
Epoch 79/110
 - 3s - loss: 0.2996 - accuracy: 0.9427 - val_loss: 0.7423 - val_accuracy: 0.8182
Epoch 80/110
 - 3s - loss: 0.2811 - accuracy: 0.9500 - val_loss: 0.7033 - val_accuracy: 0.8350
Epoch 81/110
 - 3s - loss: 0.2955 - accuracy: 0.9407 - val_loss: 0.7463 - val_accuracy: 0.8328
Epoch 82/110
 - 3s - loss: 0.3087 - accuracy: 0.9376 - val_loss: 0.6926 - val_accuracy: 0.8358
Epoch 83/110
 - 3s - loss: 0.2808 - accuracy: 0.9482 - val_loss: 0.7352 - val_accuracy: 0.8277
Epoch 84/110
 - 3s - loss: 0.3117 - accuracy: 0.9345 - val_loss: 0.8054 - val_accuracy: 0.8117
Epoch 85/110
 - 3s - loss: 0.2992 - accuracy: 0.9414 - val_loss: 0.7889 - val_accuracy: 0.8190
Epoch 86/110
 - 3s - loss: 0.3015 - accuracy: 0.9418 - val_loss: 0.7734 - val_accuracy: 0.8358
Epoch 87/110
 - 3s - loss: 0.2889 - accuracy: 0.9438 - val_loss: 0.7717 - val_accuracy: 0.8139
Epoch 88/110
 - 3s - loss: 0.2735 - accuracy: 0.9509 - val_loss: 0.7564 - val_accuracy: 0.8328
Epoch 89/110
 - 3s - loss: 0.2992 - accuracy: 0.9368 - val_loss: 0.8495 - val_accuracy: 0.8109
Epoch 90/110
 - 3s - loss: 0.2914 - accuracy: 0.9419 - val_loss: 0.8176 - val_accuracy: 0.8321
Epoch 91/110
 - 3s - loss: 0.2818 - accuracy: 0.9461 - val_loss: 0.7187 - val_accuracy: 0.8336
Epoch 92/110
 - 3s - loss: 0.2757 - accuracy: 0.9505 - val_loss: 0.8031 - val_accuracy: 0.8270
Epoch 93/110
 - 3s - loss: 0.2834 - accuracy: 0.9476 - val_loss: 0.8278 - val_accuracy: 0.8365
Epoch 94/110
 - 3s - loss: 0.2923 - accuracy: 0.9425 - val_loss: 0.7651 - val_accuracy: 0.8212
Epoch 95/110
 - 3s - loss: 0.2900 - accuracy: 0.9441 - val_loss: 0.7157 - val_accuracy: 0.8263
Epoch 96/110
 - 3s - loss: 0.2887 - accuracy: 0.9465 - val_loss: 0.8104 - val_accuracy: 0.8255
Epoch 97/110
 - 3s - loss: 0.3053 - accuracy: 0.9348 - val_loss: 0.7855 - val_accuracy: 0.8234
Epoch 98/110
 - 3s - loss: 0.2955 - accuracy: 0.9432 - val_loss: 0.8536 - val_accuracy: 0.8095
Epoch 99/110
 - 3s - loss: 0.2998 - accuracy: 0.9410 - val_loss: 0.9411 - val_accuracy: 0.8095
Epoch 100/110
 - 3s - loss: 0.3175 - accuracy: 0.9330 - val_loss: 0.8230 - val_accuracy: 0.8029
Epoch 101/110
 - 3s - loss: 0.2757 - accuracy: 0.9483 - val_loss: 0.7653 - val_accuracy: 0.8372
Epoch 102/110
 - 2s - loss: 0.2767 - accuracy: 0.9505 - val_loss: 0.7966 - val_accuracy: 0.8314
Epoch 103/110
 - 2s - loss: 0.2663 - accuracy: 0.9558 - val_loss: 0.7904 - val_accuracy: 0.8234
Epoch 104/110
 - 3s - loss: 0.2834 - accuracy: 0.9513 - val_loss: 0.8067 - val_accuracy: 0.8321
Epoch 105/110
 - 2s - loss: 0.2578 - accuracy: 0.9578 - val_loss: 0.7300 - val_accuracy: 0.8343
Epoch 106/110
 - 2s - loss: 0.2623 - accuracy: 0.9544 - val_loss: 0.7276 - val_accuracy: 0.8496
Epoch 107/110
 - 2s - loss: 0.2616 - accuracy: 0.9555 - val_loss: 0.7385 - val_accuracy: 0.8431
Epoch 108/110
 - 2s - loss: 0.2627 - accuracy: 0.9536 - val_loss: 0.7362 - val_accuracy: 0.8423
Epoch 109/110
 - 2s - loss: 0.2663 - accuracy: 0.9538 - val_loss: 0.8071 - val_accuracy: 0.8343
Epoch 110/110
 - 3s - loss: 0.2707 - accuracy: 0.9507 - val_loss: 0.8725 - val_accuracy: 0.8190
------------------------------------------------------------------------
Training for fold 2 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 6s - loss: 1.0418 - accuracy: 0.6873 - val_loss: 1.2379 - val_accuracy: 0.5394
Epoch 2/110
 - 3s - loss: 0.7336 - accuracy: 0.7919 - val_loss: 0.8905 - val_accuracy: 0.7095
Epoch 3/110
 - 3s - loss: 0.6696 - accuracy: 0.8070 - val_loss: 0.7600 - val_accuracy: 0.7883
Epoch 4/110
 - 3s - loss: 0.6327 - accuracy: 0.8217 - val_loss: 0.7487 - val_accuracy: 0.7810
Epoch 5/110
 - 3s - loss: 0.6091 - accuracy: 0.8286 - val_loss: 0.7249 - val_accuracy: 0.8058
Epoch 6/110
 - 3s - loss: 0.5829 - accuracy: 0.8412 - val_loss: 0.7143 - val_accuracy: 0.8117
Epoch 7/110
 - 3s - loss: 0.5678 - accuracy: 0.8437 - val_loss: 0.6842 - val_accuracy: 0.8241
Epoch 8/110
 - 3s - loss: 0.5639 - accuracy: 0.8412 - val_loss: 0.6976 - val_accuracy: 0.8153
Epoch 9/110
 - 3s - loss: 0.5588 - accuracy: 0.8397 - val_loss: 0.7454 - val_accuracy: 0.7971
Epoch 10/110
 - 3s - loss: 0.5448 - accuracy: 0.8507 - val_loss: 0.7383 - val_accuracy: 0.7927
Epoch 11/110
 - 3s - loss: 0.5355 - accuracy: 0.8470 - val_loss: 0.6999 - val_accuracy: 0.8219
Epoch 12/110
 - 3s - loss: 0.5454 - accuracy: 0.8499 - val_loss: 0.7126 - val_accuracy: 0.8029
Epoch 13/110
 - 3s - loss: 0.5236 - accuracy: 0.8529 - val_loss: 0.6876 - val_accuracy: 0.8168
Epoch 14/110
 - 3s - loss: 0.5158 - accuracy: 0.8569 - val_loss: 0.6744 - val_accuracy: 0.8182
Epoch 15/110
 - 3s - loss: 0.4947 - accuracy: 0.8642 - val_loss: 0.7358 - val_accuracy: 0.8088
Epoch 16/110
 - 3s - loss: 0.5055 - accuracy: 0.8596 - val_loss: 0.7236 - val_accuracy: 0.8146
Epoch 17/110
 - 3s - loss: 0.5138 - accuracy: 0.8540 - val_loss: 0.7013 - val_accuracy: 0.8029
Epoch 18/110
 - 3s - loss: 0.5085 - accuracy: 0.8594 - val_loss: 0.7682 - val_accuracy: 0.7993
Epoch 19/110
 - 3s - loss: 0.5013 - accuracy: 0.8625 - val_loss: 0.7202 - val_accuracy: 0.8095
Epoch 20/110
 - 3s - loss: 0.4831 - accuracy: 0.8698 - val_loss: 0.6985 - val_accuracy: 0.8117
Epoch 21/110
 - 3s - loss: 0.4809 - accuracy: 0.8713 - val_loss: 0.6652 - val_accuracy: 0.8307
Epoch 22/110
 - 3s - loss: 0.4805 - accuracy: 0.8644 - val_loss: 0.7019 - val_accuracy: 0.8139
Epoch 23/110
 - 3s - loss: 0.4784 - accuracy: 0.8684 - val_loss: 0.6836 - val_accuracy: 0.8263
Epoch 24/110
 - 3s - loss: 0.4705 - accuracy: 0.8684 - val_loss: 0.6279 - val_accuracy: 0.8182
Epoch 25/110
 - 3s - loss: 0.4617 - accuracy: 0.8753 - val_loss: 0.6613 - val_accuracy: 0.8182
Epoch 26/110
 - 3s - loss: 0.4516 - accuracy: 0.8799 - val_loss: 0.6855 - val_accuracy: 0.8212
Epoch 27/110
 - 3s - loss: 0.4440 - accuracy: 0.8834 - val_loss: 0.7083 - val_accuracy: 0.7934
Epoch 28/110
 - 3s - loss: 0.4447 - accuracy: 0.8810 - val_loss: 0.6929 - val_accuracy: 0.8131
Epoch 29/110
 - 3s - loss: 0.4363 - accuracy: 0.8870 - val_loss: 0.6787 - val_accuracy: 0.8153
Epoch 30/110
 - 3s - loss: 0.4423 - accuracy: 0.8817 - val_loss: 0.6912 - val_accuracy: 0.8175
Epoch 31/110
 - 3s - loss: 0.4597 - accuracy: 0.8708 - val_loss: 0.7430 - val_accuracy: 0.8161
Epoch 32/110
 - 3s - loss: 0.4620 - accuracy: 0.8708 - val_loss: 0.7188 - val_accuracy: 0.8007
Epoch 33/110
 - 3s - loss: 0.4443 - accuracy: 0.8764 - val_loss: 0.7236 - val_accuracy: 0.8285
Epoch 34/110
 - 3s - loss: 0.4340 - accuracy: 0.8870 - val_loss: 0.7076 - val_accuracy: 0.8175
Epoch 35/110
 - 3s - loss: 0.4347 - accuracy: 0.8848 - val_loss: 0.7297 - val_accuracy: 0.8153
Epoch 36/110
 - 3s - loss: 0.4303 - accuracy: 0.8848 - val_loss: 0.7305 - val_accuracy: 0.8109
Epoch 37/110
 - 3s - loss: 0.4242 - accuracy: 0.8839 - val_loss: 0.6807 - val_accuracy: 0.8066
Epoch 38/110
 - 3s - loss: 0.4100 - accuracy: 0.8925 - val_loss: 0.6453 - val_accuracy: 0.8263
Epoch 39/110
 - 3s - loss: 0.4150 - accuracy: 0.8850 - val_loss: 0.7153 - val_accuracy: 0.8197
Epoch 40/110
 - 3s - loss: 0.3975 - accuracy: 0.8970 - val_loss: 0.7459 - val_accuracy: 0.8175
Epoch 41/110
 - 3s - loss: 0.4135 - accuracy: 0.8936 - val_loss: 0.7343 - val_accuracy: 0.8066
Epoch 42/110
 - 3s - loss: 0.4138 - accuracy: 0.8967 - val_loss: 0.7311 - val_accuracy: 0.8029
Epoch 43/110
 - 3s - loss: 0.4078 - accuracy: 0.8981 - val_loss: 0.6866 - val_accuracy: 0.8226
Epoch 44/110
 - 3s - loss: 0.4115 - accuracy: 0.8939 - val_loss: 0.7084 - val_accuracy: 0.8263
Epoch 45/110
 - 3s - loss: 0.4067 - accuracy: 0.8896 - val_loss: 0.6966 - val_accuracy: 0.8299
Epoch 46/110
 - 3s - loss: 0.3756 - accuracy: 0.9080 - val_loss: 0.6945 - val_accuracy: 0.8299
Epoch 47/110
 - 3s - loss: 0.3747 - accuracy: 0.9080 - val_loss: 0.7405 - val_accuracy: 0.8241
Epoch 48/110
 - 3s - loss: 0.3847 - accuracy: 0.9022 - val_loss: 0.7667 - val_accuracy: 0.8139
Epoch 49/110
 - 3s - loss: 0.4018 - accuracy: 0.8991 - val_loss: 0.7108 - val_accuracy: 0.8131
Epoch 50/110
 - 3s - loss: 0.3780 - accuracy: 0.9071 - val_loss: 0.6942 - val_accuracy: 0.8241
Epoch 51/110
 - 3s - loss: 0.3696 - accuracy: 0.9085 - val_loss: 0.7473 - val_accuracy: 0.8139
Epoch 52/110
 - 3s - loss: 0.3703 - accuracy: 0.9087 - val_loss: 0.6893 - val_accuracy: 0.8255
Epoch 53/110
 - 3s - loss: 0.3660 - accuracy: 0.9127 - val_loss: 0.6836 - val_accuracy: 0.8241
Epoch 54/110
 - 3s - loss: 0.3622 - accuracy: 0.9111 - val_loss: 0.7196 - val_accuracy: 0.8212
Epoch 55/110
 - 3s - loss: 0.3621 - accuracy: 0.9124 - val_loss: 0.6709 - val_accuracy: 0.8248
Epoch 56/110
 - 3s - loss: 0.3831 - accuracy: 0.9022 - val_loss: 0.7278 - val_accuracy: 0.8139
Epoch 57/110
 - 3s - loss: 0.4024 - accuracy: 0.9025 - val_loss: 0.6741 - val_accuracy: 0.8263
Epoch 58/110
 - 3s - loss: 0.3966 - accuracy: 0.8965 - val_loss: 0.6848 - val_accuracy: 0.8292
Epoch 59/110
 - 3s - loss: 0.3804 - accuracy: 0.9016 - val_loss: 0.7298 - val_accuracy: 0.8241
Epoch 60/110
 - 3s - loss: 0.3464 - accuracy: 0.9177 - val_loss: 0.7386 - val_accuracy: 0.8146
Epoch 61/110
 - 3s - loss: 0.3435 - accuracy: 0.9199 - val_loss: 0.6658 - val_accuracy: 0.8423
Epoch 62/110
 - 3s - loss: 0.3364 - accuracy: 0.9202 - val_loss: 0.7100 - val_accuracy: 0.8307
Epoch 63/110
 - 3s - loss: 0.3654 - accuracy: 0.9155 - val_loss: 0.8034 - val_accuracy: 0.8131
Epoch 64/110
 - 3s - loss: 0.3669 - accuracy: 0.9106 - val_loss: 0.7548 - val_accuracy: 0.8372
Epoch 65/110
 - 3s - loss: 0.3507 - accuracy: 0.9142 - val_loss: 0.7791 - val_accuracy: 0.8066
Epoch 66/110
 - 3s - loss: 0.3632 - accuracy: 0.9131 - val_loss: 0.7710 - val_accuracy: 0.8307
Epoch 67/110
 - 3s - loss: 0.3379 - accuracy: 0.9211 - val_loss: 0.6941 - val_accuracy: 0.8299
Epoch 68/110
 - 3s - loss: 0.3339 - accuracy: 0.9266 - val_loss: 0.7425 - val_accuracy: 0.8263
Epoch 69/110
 - 3s - loss: 0.3332 - accuracy: 0.9230 - val_loss: 0.7667 - val_accuracy: 0.8299
Epoch 70/110
 - 3s - loss: 0.3381 - accuracy: 0.9244 - val_loss: 0.7351 - val_accuracy: 0.8248
Epoch 71/110
 - 3s - loss: 0.3303 - accuracy: 0.9304 - val_loss: 0.7126 - val_accuracy: 0.8423
Epoch 72/110
 - 3s - loss: 0.3363 - accuracy: 0.9270 - val_loss: 0.7007 - val_accuracy: 0.8321
Epoch 73/110
 - 3s - loss: 0.3329 - accuracy: 0.9248 - val_loss: 0.6836 - val_accuracy: 0.8343
Epoch 74/110
 - 3s - loss: 0.3136 - accuracy: 0.9341 - val_loss: 0.6852 - val_accuracy: 0.8401
Epoch 75/110
 - 3s - loss: 0.3097 - accuracy: 0.9350 - val_loss: 0.7133 - val_accuracy: 0.8328
Epoch 76/110
 - 3s - loss: 0.3184 - accuracy: 0.9275 - val_loss: 0.8213 - val_accuracy: 0.8109
Epoch 77/110
 - 3s - loss: 0.3197 - accuracy: 0.9343 - val_loss: 0.7602 - val_accuracy: 0.8285
Epoch 78/110
 - 3s - loss: 0.3221 - accuracy: 0.9292 - val_loss: 0.7317 - val_accuracy: 0.8423
Epoch 79/110
 - 3s - loss: 0.3264 - accuracy: 0.9263 - val_loss: 0.7706 - val_accuracy: 0.8241
Epoch 80/110
 - 3s - loss: 0.3319 - accuracy: 0.9277 - val_loss: 0.7657 - val_accuracy: 0.8241
Epoch 81/110
 - 3s - loss: 0.3857 - accuracy: 0.9127 - val_loss: 0.7619 - val_accuracy: 0.8051
Epoch 82/110
 - 3s - loss: 0.3680 - accuracy: 0.9131 - val_loss: 0.8311 - val_accuracy: 0.8248
Epoch 83/110
 - 3s - loss: 0.3427 - accuracy: 0.9246 - val_loss: 0.6802 - val_accuracy: 0.8314
Epoch 84/110
 - 3s - loss: 0.2962 - accuracy: 0.9392 - val_loss: 0.7031 - val_accuracy: 0.8387
Epoch 85/110
 - 3s - loss: 0.2913 - accuracy: 0.9410 - val_loss: 0.7557 - val_accuracy: 0.8226
Epoch 86/110
 - 3s - loss: 0.2900 - accuracy: 0.9399 - val_loss: 0.7454 - val_accuracy: 0.8285
Epoch 87/110
 - 3s - loss: 0.2807 - accuracy: 0.9485 - val_loss: 0.7665 - val_accuracy: 0.8241
Epoch 88/110
 - 3s - loss: 0.2893 - accuracy: 0.9423 - val_loss: 0.7656 - val_accuracy: 0.8401
Epoch 89/110
 - 3s - loss: 0.2998 - accuracy: 0.9398 - val_loss: 0.7850 - val_accuracy: 0.8197
Epoch 90/110
 - 3s - loss: 0.3186 - accuracy: 0.9325 - val_loss: 0.7886 - val_accuracy: 0.8307
Epoch 91/110
 - 3s - loss: 0.2861 - accuracy: 0.9440 - val_loss: 0.7727 - val_accuracy: 0.8277
Epoch 92/110
 - 3s - loss: 0.3044 - accuracy: 0.9396 - val_loss: 0.7300 - val_accuracy: 0.8248
Epoch 93/110
 - 3s - loss: 0.3092 - accuracy: 0.9390 - val_loss: 0.7853 - val_accuracy: 0.8241
Epoch 94/110
 - 3s - loss: 0.2915 - accuracy: 0.9469 - val_loss: 0.7487 - val_accuracy: 0.8234
Epoch 95/110
 - 3s - loss: 0.2983 - accuracy: 0.9396 - val_loss: 0.7897 - val_accuracy: 0.8307
Epoch 96/110
 - 3s - loss: 0.3042 - accuracy: 0.9407 - val_loss: 0.7376 - val_accuracy: 0.8212
Epoch 97/110
 - 3s - loss: 0.2945 - accuracy: 0.9410 - val_loss: 0.7862 - val_accuracy: 0.8168
Epoch 98/110
 - 3s - loss: 0.2701 - accuracy: 0.9505 - val_loss: 0.7883 - val_accuracy: 0.8263
Epoch 99/110
 - 3s - loss: 0.2916 - accuracy: 0.9436 - val_loss: 0.7830 - val_accuracy: 0.8263
Epoch 100/110
 - 3s - loss: 0.3234 - accuracy: 0.9383 - val_loss: 0.8384 - val_accuracy: 0.7949
Epoch 101/110
 - 3s - loss: 0.3231 - accuracy: 0.9326 - val_loss: 0.7437 - val_accuracy: 0.8299
Epoch 102/110
 - 3s - loss: 0.2804 - accuracy: 0.9452 - val_loss: 0.6908 - val_accuracy: 0.8372
Epoch 103/110
 - 3s - loss: 0.2795 - accuracy: 0.9505 - val_loss: 0.7819 - val_accuracy: 0.8131
Epoch 104/110
 - 3s - loss: 0.2899 - accuracy: 0.9451 - val_loss: 0.7095 - val_accuracy: 0.8460
Epoch 105/110
 - 3s - loss: 0.2753 - accuracy: 0.9514 - val_loss: 0.7195 - val_accuracy: 0.8336
Epoch 106/110
 - 3s - loss: 0.2654 - accuracy: 0.9536 - val_loss: 0.6548 - val_accuracy: 0.8533
Epoch 107/110
 - 3s - loss: 0.2724 - accuracy: 0.9507 - val_loss: 0.7998 - val_accuracy: 0.8307
Epoch 108/110
 - 3s - loss: 0.2797 - accuracy: 0.9476 - val_loss: 0.7971 - val_accuracy: 0.8270
Epoch 109/110
 - 3s - loss: 0.2880 - accuracy: 0.9461 - val_loss: 0.7690 - val_accuracy: 0.8401
Epoch 110/110
 - 3s - loss: 0.2811 - accuracy: 0.9472 - val_loss: 0.6906 - val_accuracy: 0.8401
------------------------------------------------------------------------
Training for fold 3 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 7s - loss: 1.0066 - accuracy: 0.6902 - val_loss: 1.5103 - val_accuracy: 0.4321
Epoch 2/110
 - 3s - loss: 0.7508 - accuracy: 0.7773 - val_loss: 0.9081 - val_accuracy: 0.6883
Epoch 3/110
 - 3s - loss: 0.6899 - accuracy: 0.7999 - val_loss: 0.7817 - val_accuracy: 0.7657
Epoch 4/110
 - 3s - loss: 0.6451 - accuracy: 0.8116 - val_loss: 0.7149 - val_accuracy: 0.8066
Epoch 5/110
 - 3s - loss: 0.6112 - accuracy: 0.8306 - val_loss: 0.6971 - val_accuracy: 0.8139
Epoch 6/110
 - 3s - loss: 0.5973 - accuracy: 0.8370 - val_loss: 0.7038 - val_accuracy: 0.8109
Epoch 7/110
 - 3s - loss: 0.5944 - accuracy: 0.8273 - val_loss: 0.6922 - val_accuracy: 0.8102
Epoch 8/110
 - 3s - loss: 0.5886 - accuracy: 0.8304 - val_loss: 0.6773 - val_accuracy: 0.8161
Epoch 9/110
 - 3s - loss: 0.5617 - accuracy: 0.8405 - val_loss: 0.6482 - val_accuracy: 0.8409
Epoch 10/110
 - 3s - loss: 0.5443 - accuracy: 0.8481 - val_loss: 0.6725 - val_accuracy: 0.8219
Epoch 11/110
 - 3s - loss: 0.5411 - accuracy: 0.8472 - val_loss: 0.6942 - val_accuracy: 0.8197
Epoch 12/110
 - 3s - loss: 0.5315 - accuracy: 0.8467 - val_loss: 0.7349 - val_accuracy: 0.8022
Epoch 13/110
 - 3s - loss: 0.5302 - accuracy: 0.8520 - val_loss: 0.7116 - val_accuracy: 0.8066
Epoch 14/110
 - 3s - loss: 0.5249 - accuracy: 0.8521 - val_loss: 0.7179 - val_accuracy: 0.8036
Epoch 15/110
 - 3s - loss: 0.5098 - accuracy: 0.8602 - val_loss: 0.6694 - val_accuracy: 0.8285
Epoch 16/110
 - 3s - loss: 0.5099 - accuracy: 0.8565 - val_loss: 0.6980 - val_accuracy: 0.8102
Epoch 17/110
 - 3s - loss: 0.5082 - accuracy: 0.8549 - val_loss: 0.6788 - val_accuracy: 0.7978
Epoch 18/110
 - 3s - loss: 0.4879 - accuracy: 0.8629 - val_loss: 0.6880 - val_accuracy: 0.8175
Epoch 19/110
 - 3s - loss: 0.4913 - accuracy: 0.8614 - val_loss: 0.7052 - val_accuracy: 0.8175
Epoch 20/110
 - 3s - loss: 0.5035 - accuracy: 0.8567 - val_loss: 0.6985 - val_accuracy: 0.8292
Epoch 21/110
 - 3s - loss: 0.4974 - accuracy: 0.8594 - val_loss: 0.7061 - val_accuracy: 0.8204
Epoch 22/110
 - 3s - loss: 0.4835 - accuracy: 0.8651 - val_loss: 0.7332 - val_accuracy: 0.8131
Epoch 23/110
 - 3s - loss: 0.4910 - accuracy: 0.8594 - val_loss: 0.6947 - val_accuracy: 0.8248
Epoch 24/110
 - 3s - loss: 0.4813 - accuracy: 0.8666 - val_loss: 0.6598 - val_accuracy: 0.8336
Epoch 25/110
 - 3s - loss: 0.4767 - accuracy: 0.8715 - val_loss: 0.6162 - val_accuracy: 0.8358
Epoch 26/110
 - 3s - loss: 0.4550 - accuracy: 0.8760 - val_loss: 0.6732 - val_accuracy: 0.8328
Epoch 27/110
 - 3s - loss: 0.4400 - accuracy: 0.8768 - val_loss: 0.6718 - val_accuracy: 0.8285
Epoch 28/110
 - 3s - loss: 0.4287 - accuracy: 0.8883 - val_loss: 0.6560 - val_accuracy: 0.8380
Epoch 29/110
 - 3s - loss: 0.4227 - accuracy: 0.8834 - val_loss: 0.6835 - val_accuracy: 0.8168
Epoch 30/110
 - 3s - loss: 0.4318 - accuracy: 0.8844 - val_loss: 0.7516 - val_accuracy: 0.8314
Epoch 31/110
 - 3s - loss: 0.4418 - accuracy: 0.8801 - val_loss: 0.6631 - val_accuracy: 0.8380
Epoch 32/110
 - 3s - loss: 0.4290 - accuracy: 0.8879 - val_loss: 0.6856 - val_accuracy: 0.8263
Epoch 33/110
 - 3s - loss: 0.4140 - accuracy: 0.8910 - val_loss: 0.6800 - val_accuracy: 0.8307
Epoch 34/110
 - 3s - loss: 0.4070 - accuracy: 0.8932 - val_loss: 0.7139 - val_accuracy: 0.8212
Epoch 35/110
 - 3s - loss: 0.3950 - accuracy: 0.8994 - val_loss: 0.6738 - val_accuracy: 0.8321
Epoch 36/110
 - 3s - loss: 0.3949 - accuracy: 0.8989 - val_loss: 0.6956 - val_accuracy: 0.8285
Epoch 37/110
 - 3s - loss: 0.4140 - accuracy: 0.8928 - val_loss: 0.6865 - val_accuracy: 0.8168
Epoch 38/110
 - 3s - loss: 0.4063 - accuracy: 0.8949 - val_loss: 0.6479 - val_accuracy: 0.8328
Epoch 39/110
 - 3s - loss: 0.3952 - accuracy: 0.8985 - val_loss: 0.6452 - val_accuracy: 0.8518
Epoch 40/110
 - 3s - loss: 0.3964 - accuracy: 0.8989 - val_loss: 0.6920 - val_accuracy: 0.8350
Epoch 41/110
 - 3s - loss: 0.4017 - accuracy: 0.8972 - val_loss: 0.7192 - val_accuracy: 0.8328
Epoch 42/110
 - 3s - loss: 0.4065 - accuracy: 0.8967 - val_loss: 0.6994 - val_accuracy: 0.8292
Epoch 43/110
 - 3s - loss: 0.3924 - accuracy: 0.9000 - val_loss: 0.6618 - val_accuracy: 0.8161
Epoch 44/110
 - 3s - loss: 0.3744 - accuracy: 0.9056 - val_loss: 0.7183 - val_accuracy: 0.8255
Epoch 45/110
 - 3s - loss: 0.3693 - accuracy: 0.9064 - val_loss: 0.7023 - val_accuracy: 0.8365
Epoch 46/110
 - 2s - loss: 0.3641 - accuracy: 0.9126 - val_loss: 0.6895 - val_accuracy: 0.8314
Epoch 47/110
 - 2s - loss: 0.3767 - accuracy: 0.9093 - val_loss: 0.6916 - val_accuracy: 0.8219
Epoch 48/110
 - 2s - loss: 0.3669 - accuracy: 0.9087 - val_loss: 0.7496 - val_accuracy: 0.8241
Epoch 49/110
 - 3s - loss: 0.3951 - accuracy: 0.9022 - val_loss: 0.7660 - val_accuracy: 0.8270
Epoch 50/110
 - 2s - loss: 0.3991 - accuracy: 0.9012 - val_loss: 0.6982 - val_accuracy: 0.8212
Epoch 51/110
 - 3s - loss: 0.3639 - accuracy: 0.9106 - val_loss: 0.7038 - val_accuracy: 0.8387
Epoch 52/110
 - 3s - loss: 0.3533 - accuracy: 0.9144 - val_loss: 0.7017 - val_accuracy: 0.8270
Epoch 53/110
 - 3s - loss: 0.3522 - accuracy: 0.9140 - val_loss: 0.7166 - val_accuracy: 0.8270
Epoch 54/110
 - 3s - loss: 0.3472 - accuracy: 0.9182 - val_loss: 0.6669 - val_accuracy: 0.8409
Epoch 55/110
 - 3s - loss: 0.3520 - accuracy: 0.9153 - val_loss: 0.7211 - val_accuracy: 0.8248
Epoch 56/110
 - 3s - loss: 0.3552 - accuracy: 0.9171 - val_loss: 0.7613 - val_accuracy: 0.8197
Epoch 57/110
 - 3s - loss: 0.3533 - accuracy: 0.9160 - val_loss: 0.7434 - val_accuracy: 0.8204
Epoch 58/110
 - 3s - loss: 0.3459 - accuracy: 0.9206 - val_loss: 0.7419 - val_accuracy: 0.8168
Epoch 59/110
 - 3s - loss: 0.3415 - accuracy: 0.9200 - val_loss: 0.7027 - val_accuracy: 0.8328
Epoch 60/110
 - 3s - loss: 0.3332 - accuracy: 0.9246 - val_loss: 0.7258 - val_accuracy: 0.8270
Epoch 61/110
 - 3s - loss: 0.3311 - accuracy: 0.9255 - val_loss: 0.7451 - val_accuracy: 0.8263
Epoch 62/110
 - 3s - loss: 0.3437 - accuracy: 0.9188 - val_loss: 0.6847 - val_accuracy: 0.8343
Epoch 63/110
 - 3s - loss: 0.3427 - accuracy: 0.9188 - val_loss: 0.7069 - val_accuracy: 0.8190
Epoch 64/110
 - 3s - loss: 0.3523 - accuracy: 0.9186 - val_loss: 0.6944 - val_accuracy: 0.8453
Epoch 65/110
 - 3s - loss: 0.3452 - accuracy: 0.9226 - val_loss: 0.7632 - val_accuracy: 0.8102
Epoch 66/110
 - 3s - loss: 0.3547 - accuracy: 0.9164 - val_loss: 0.8423 - val_accuracy: 0.8102
Epoch 67/110
 - 3s - loss: 0.3296 - accuracy: 0.9288 - val_loss: 0.7054 - val_accuracy: 0.8277
Epoch 68/110
 - 3s - loss: 0.3330 - accuracy: 0.9241 - val_loss: 0.7028 - val_accuracy: 0.8365
Epoch 69/110
 - 3s - loss: 0.3142 - accuracy: 0.9310 - val_loss: 0.8066 - val_accuracy: 0.8190
Epoch 70/110
 - 3s - loss: 0.3268 - accuracy: 0.9273 - val_loss: 0.7143 - val_accuracy: 0.8204
Epoch 71/110
 - 3s - loss: 0.3098 - accuracy: 0.9356 - val_loss: 0.6706 - val_accuracy: 0.8358
Epoch 72/110
 - 3s - loss: 0.2931 - accuracy: 0.9410 - val_loss: 0.6690 - val_accuracy: 0.8234
Epoch 73/110
 - 3s - loss: 0.3033 - accuracy: 0.9374 - val_loss: 0.7532 - val_accuracy: 0.8314
Epoch 74/110
 - 3s - loss: 0.3095 - accuracy: 0.9352 - val_loss: 0.6699 - val_accuracy: 0.8394
Epoch 75/110
 - 3s - loss: 0.2936 - accuracy: 0.9432 - val_loss: 0.7605 - val_accuracy: 0.8372
Epoch 76/110
 - 3s - loss: 0.3126 - accuracy: 0.9359 - val_loss: 0.7616 - val_accuracy: 0.8109
Epoch 77/110
 - 2s - loss: 0.3076 - accuracy: 0.9352 - val_loss: 0.6768 - val_accuracy: 0.8321
Epoch 78/110
 - 2s - loss: 0.2851 - accuracy: 0.9430 - val_loss: 0.6759 - val_accuracy: 0.8496
Epoch 79/110
 - 3s - loss: 0.2867 - accuracy: 0.9449 - val_loss: 0.7352 - val_accuracy: 0.8387
Epoch 80/110
 - 3s - loss: 0.2929 - accuracy: 0.9427 - val_loss: 0.7669 - val_accuracy: 0.8394
Epoch 81/110
 - 2s - loss: 0.2980 - accuracy: 0.9423 - val_loss: 0.7175 - val_accuracy: 0.8416
Epoch 82/110
 - 2s - loss: 0.2856 - accuracy: 0.9458 - val_loss: 0.7070 - val_accuracy: 0.8372
Epoch 83/110
 - 3s - loss: 0.2787 - accuracy: 0.9500 - val_loss: 0.7914 - val_accuracy: 0.8212
Epoch 84/110
 - 3s - loss: 0.2810 - accuracy: 0.9507 - val_loss: 0.7144 - val_accuracy: 0.8401
Epoch 85/110
 - 3s - loss: 0.3000 - accuracy: 0.9407 - val_loss: 0.7338 - val_accuracy: 0.8212
Epoch 86/110
 - 3s - loss: 0.2900 - accuracy: 0.9396 - val_loss: 0.7102 - val_accuracy: 0.8445
Epoch 87/110
 - 3s - loss: 0.2824 - accuracy: 0.9436 - val_loss: 0.7189 - val_accuracy: 0.8350
Epoch 88/110
 - 3s - loss: 0.2705 - accuracy: 0.9513 - val_loss: 0.7674 - val_accuracy: 0.8336
Epoch 89/110
 - 3s - loss: 0.2846 - accuracy: 0.9496 - val_loss: 0.7788 - val_accuracy: 0.8328
Epoch 90/110
 - 3s - loss: 0.2729 - accuracy: 0.9496 - val_loss: 0.7741 - val_accuracy: 0.8343
Epoch 91/110
 - 3s - loss: 0.2601 - accuracy: 0.9564 - val_loss: 0.7630 - val_accuracy: 0.8526
Epoch 92/110
 - 2s - loss: 0.2787 - accuracy: 0.9454 - val_loss: 0.8008 - val_accuracy: 0.8204
Epoch 93/110
 - 2s - loss: 0.3386 - accuracy: 0.9310 - val_loss: 0.8900 - val_accuracy: 0.8314
Epoch 94/110
 - 3s - loss: 0.2972 - accuracy: 0.9449 - val_loss: 0.7407 - val_accuracy: 0.8409
Epoch 95/110
 - 3s - loss: 0.2894 - accuracy: 0.9440 - val_loss: 0.8417 - val_accuracy: 0.8277
Epoch 96/110
 - 3s - loss: 0.2822 - accuracy: 0.9496 - val_loss: 0.7634 - val_accuracy: 0.8350
Epoch 97/110
 - 3s - loss: 0.2805 - accuracy: 0.9500 - val_loss: 0.8163 - val_accuracy: 0.8299
Epoch 98/110
 - 3s - loss: 0.2516 - accuracy: 0.9613 - val_loss: 0.7296 - val_accuracy: 0.8511
Epoch 99/110
 - 3s - loss: 0.2505 - accuracy: 0.9602 - val_loss: 0.7628 - val_accuracy: 0.8496
Epoch 100/110
 - 3s - loss: 0.2780 - accuracy: 0.9511 - val_loss: 0.7558 - val_accuracy: 0.8474
Epoch 101/110
 - 3s - loss: 0.2699 - accuracy: 0.9511 - val_loss: 0.7689 - val_accuracy: 0.8453
Epoch 102/110
 - 3s - loss: 0.2656 - accuracy: 0.9535 - val_loss: 0.7572 - val_accuracy: 0.8445
Epoch 103/110
 - 3s - loss: 0.2618 - accuracy: 0.9540 - val_loss: 0.7497 - val_accuracy: 0.8394
Epoch 104/110
 - 3s - loss: 0.2534 - accuracy: 0.9584 - val_loss: 0.7518 - val_accuracy: 0.8445
Epoch 105/110
 - 3s - loss: 0.2717 - accuracy: 0.9513 - val_loss: 0.8693 - val_accuracy: 0.8285
Epoch 106/110
 - 3s - loss: 0.3038 - accuracy: 0.9394 - val_loss: 0.7731 - val_accuracy: 0.8540
Epoch 107/110
 - 3s - loss: 0.2510 - accuracy: 0.9602 - val_loss: 0.7494 - val_accuracy: 0.8438
Epoch 108/110
 - 3s - loss: 0.2344 - accuracy: 0.9660 - val_loss: 0.7818 - val_accuracy: 0.8496
Epoch 109/110
 - 3s - loss: 0.2564 - accuracy: 0.9604 - val_loss: 0.8062 - val_accuracy: 0.8387
Epoch 110/110
 - 3s - loss: 0.2688 - accuracy: 0.9518 - val_loss: 0.8203 - val_accuracy: 0.8299
------------------------------------------------------------------------
Training for fold 4 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 7s - loss: 1.0285 - accuracy: 0.6982 - val_loss: 1.4206 - val_accuracy: 0.4745
Epoch 2/110
 - 3s - loss: 0.7512 - accuracy: 0.7733 - val_loss: 0.8989 - val_accuracy: 0.7029
Epoch 3/110
 - 3s - loss: 0.6879 - accuracy: 0.8030 - val_loss: 0.7640 - val_accuracy: 0.7730
Epoch 4/110
 - 3s - loss: 0.6531 - accuracy: 0.8145 - val_loss: 0.7053 - val_accuracy: 0.8015
Epoch 5/110
 - 3s - loss: 0.6237 - accuracy: 0.8227 - val_loss: 0.7168 - val_accuracy: 0.8102
Epoch 6/110
 - 3s - loss: 0.6139 - accuracy: 0.8240 - val_loss: 0.6794 - val_accuracy: 0.8124
Epoch 7/110
 - 3s - loss: 0.5877 - accuracy: 0.8335 - val_loss: 0.7061 - val_accuracy: 0.8109
Epoch 8/110
 - 3s - loss: 0.5842 - accuracy: 0.8375 - val_loss: 0.7210 - val_accuracy: 0.8088
Epoch 9/110
 - 3s - loss: 0.5805 - accuracy: 0.8392 - val_loss: 0.7077 - val_accuracy: 0.8080
Epoch 10/110
 - 3s - loss: 0.5732 - accuracy: 0.8392 - val_loss: 0.7209 - val_accuracy: 0.7942
Epoch 11/110
 - 3s - loss: 0.5629 - accuracy: 0.8428 - val_loss: 0.7433 - val_accuracy: 0.8058
Epoch 12/110
 - 3s - loss: 0.5521 - accuracy: 0.8457 - val_loss: 0.7200 - val_accuracy: 0.8139
Epoch 13/110
 - 3s - loss: 0.5363 - accuracy: 0.8481 - val_loss: 0.7114 - val_accuracy: 0.8088
Epoch 14/110
 - 3s - loss: 0.5258 - accuracy: 0.8525 - val_loss: 0.6944 - val_accuracy: 0.8219
Epoch 15/110
 - 3s - loss: 0.5230 - accuracy: 0.8512 - val_loss: 0.7547 - val_accuracy: 0.7898
Epoch 16/110
 - 3s - loss: 0.5183 - accuracy: 0.8571 - val_loss: 0.7207 - val_accuracy: 0.8088
Epoch 17/110
 - 3s - loss: 0.5274 - accuracy: 0.8525 - val_loss: 0.6983 - val_accuracy: 0.8102
Epoch 18/110
 - 3s - loss: 0.5046 - accuracy: 0.8571 - val_loss: 0.7389 - val_accuracy: 0.7905
Epoch 19/110
 - 3s - loss: 0.4931 - accuracy: 0.8596 - val_loss: 0.7482 - val_accuracy: 0.7832
Epoch 20/110
 - 3s - loss: 0.5012 - accuracy: 0.8589 - val_loss: 0.7069 - val_accuracy: 0.8124
Epoch 21/110
 - 3s - loss: 0.4902 - accuracy: 0.8574 - val_loss: 0.6811 - val_accuracy: 0.8255
Epoch 22/110
 - 3s - loss: 0.4817 - accuracy: 0.8677 - val_loss: 0.6887 - val_accuracy: 0.8197
Epoch 23/110
 - 3s - loss: 0.4776 - accuracy: 0.8697 - val_loss: 0.6789 - val_accuracy: 0.8255
Epoch 24/110
 - 3s - loss: 0.4665 - accuracy: 0.8768 - val_loss: 0.6190 - val_accuracy: 0.8416
Epoch 25/110
 - 3s - loss: 0.4619 - accuracy: 0.8739 - val_loss: 0.6499 - val_accuracy: 0.8336
Epoch 26/110
 - 3s - loss: 0.4606 - accuracy: 0.8740 - val_loss: 0.6993 - val_accuracy: 0.8299
Epoch 27/110
 - 3s - loss: 0.4747 - accuracy: 0.8709 - val_loss: 0.7469 - val_accuracy: 0.8168
Epoch 28/110
 - 3s - loss: 0.4727 - accuracy: 0.8642 - val_loss: 0.6796 - val_accuracy: 0.8255
Epoch 29/110
 - 3s - loss: 0.4519 - accuracy: 0.8770 - val_loss: 0.6591 - val_accuracy: 0.8307
Epoch 30/110
 - 3s - loss: 0.4384 - accuracy: 0.8784 - val_loss: 0.7454 - val_accuracy: 0.8124
Epoch 31/110
 - 3s - loss: 0.4421 - accuracy: 0.8781 - val_loss: 0.7303 - val_accuracy: 0.8161
Epoch 32/110
 - 3s - loss: 0.4274 - accuracy: 0.8883 - val_loss: 0.6880 - val_accuracy: 0.8153
Epoch 33/110
 - 3s - loss: 0.4295 - accuracy: 0.8863 - val_loss: 0.7419 - val_accuracy: 0.8117
Epoch 34/110
 - 3s - loss: 0.4378 - accuracy: 0.8832 - val_loss: 0.6572 - val_accuracy: 0.8255
Epoch 35/110
 - 3s - loss: 0.4133 - accuracy: 0.8938 - val_loss: 0.6994 - val_accuracy: 0.8270
Epoch 36/110
 - 3s - loss: 0.4107 - accuracy: 0.8886 - val_loss: 0.6765 - val_accuracy: 0.8270
Epoch 37/110
 - 3s - loss: 0.4098 - accuracy: 0.8939 - val_loss: 0.7532 - val_accuracy: 0.8182
Epoch 38/110
 - 3s - loss: 0.4188 - accuracy: 0.8890 - val_loss: 0.7123 - val_accuracy: 0.8292
Epoch 39/110
 - 3s - loss: 0.4309 - accuracy: 0.8832 - val_loss: 0.6951 - val_accuracy: 0.8219
Epoch 40/110
 - 3s - loss: 0.4069 - accuracy: 0.8952 - val_loss: 0.7002 - val_accuracy: 0.8307
Epoch 41/110
 - 3s - loss: 0.4103 - accuracy: 0.8912 - val_loss: 0.6775 - val_accuracy: 0.8124
Epoch 42/110
 - 3s - loss: 0.4088 - accuracy: 0.8938 - val_loss: 0.7055 - val_accuracy: 0.8285
Epoch 43/110
 - 3s - loss: 0.4144 - accuracy: 0.8936 - val_loss: 0.6466 - val_accuracy: 0.8343
Epoch 44/110
 - 3s - loss: 0.4091 - accuracy: 0.8938 - val_loss: 0.6299 - val_accuracy: 0.8482
Epoch 45/110
 - 3s - loss: 0.3960 - accuracy: 0.8991 - val_loss: 0.6770 - val_accuracy: 0.8474
Epoch 46/110
 - 3s - loss: 0.3752 - accuracy: 0.9040 - val_loss: 0.6834 - val_accuracy: 0.8285
Epoch 47/110
 - 3s - loss: 0.3942 - accuracy: 0.9007 - val_loss: 0.6850 - val_accuracy: 0.8401
Epoch 48/110
 - 3s - loss: 0.3810 - accuracy: 0.9023 - val_loss: 0.6997 - val_accuracy: 0.8328
Epoch 49/110
 - 3s - loss: 0.3868 - accuracy: 0.8972 - val_loss: 0.7635 - val_accuracy: 0.8234
Epoch 50/110
 - 3s - loss: 0.3901 - accuracy: 0.9009 - val_loss: 0.7129 - val_accuracy: 0.8241
Epoch 51/110
 - 3s - loss: 0.3735 - accuracy: 0.9069 - val_loss: 0.6554 - val_accuracy: 0.8285
Epoch 52/110
 - 3s - loss: 0.3639 - accuracy: 0.9100 - val_loss: 0.6719 - val_accuracy: 0.8453
Epoch 53/110
 - 3s - loss: 0.3521 - accuracy: 0.9171 - val_loss: 0.6475 - val_accuracy: 0.8314
Epoch 54/110
 - 3s - loss: 0.3541 - accuracy: 0.9147 - val_loss: 0.7058 - val_accuracy: 0.8277
Epoch 55/110
 - 3s - loss: 0.3716 - accuracy: 0.9089 - val_loss: 0.7348 - val_accuracy: 0.8204
Epoch 56/110
 - 3s - loss: 0.3833 - accuracy: 0.8998 - val_loss: 0.7033 - val_accuracy: 0.8255
Epoch 57/110
 - 3s - loss: 0.3719 - accuracy: 0.9042 - val_loss: 0.7038 - val_accuracy: 0.8277
Epoch 58/110
 - 3s - loss: 0.3598 - accuracy: 0.9065 - val_loss: 0.6963 - val_accuracy: 0.8431
Epoch 59/110
 - 3s - loss: 0.3787 - accuracy: 0.9053 - val_loss: 0.6999 - val_accuracy: 0.8263
Epoch 60/110
 - 3s - loss: 0.3540 - accuracy: 0.9147 - val_loss: 0.7401 - val_accuracy: 0.8314
Epoch 61/110
 - 3s - loss: 0.3475 - accuracy: 0.9164 - val_loss: 0.7243 - val_accuracy: 0.8248
Epoch 62/110
 - 2s - loss: 0.3422 - accuracy: 0.9184 - val_loss: 0.6922 - val_accuracy: 0.8387
Epoch 63/110
 - 2s - loss: 0.3393 - accuracy: 0.9224 - val_loss: 0.6822 - val_accuracy: 0.8358
Epoch 64/110
 - 2s - loss: 0.3489 - accuracy: 0.9199 - val_loss: 0.7644 - val_accuracy: 0.8263
Epoch 65/110
 - 2s - loss: 0.3468 - accuracy: 0.9211 - val_loss: 0.7322 - val_accuracy: 0.8394
Epoch 66/110
 - 3s - loss: 0.3236 - accuracy: 0.9279 - val_loss: 0.7257 - val_accuracy: 0.8372
Epoch 67/110
 - 3s - loss: 0.3329 - accuracy: 0.9244 - val_loss: 0.7483 - val_accuracy: 0.8401
Epoch 68/110
 - 3s - loss: 0.3330 - accuracy: 0.9266 - val_loss: 0.6708 - val_accuracy: 0.8460
Epoch 69/110
 - 3s - loss: 0.3460 - accuracy: 0.9233 - val_loss: 0.6960 - val_accuracy: 0.8431
Epoch 70/110
 - 3s - loss: 0.3165 - accuracy: 0.9288 - val_loss: 0.7436 - val_accuracy: 0.8365
Epoch 71/110
 - 3s - loss: 0.3305 - accuracy: 0.9270 - val_loss: 0.6796 - val_accuracy: 0.8365
Epoch 72/110
 - 3s - loss: 0.3617 - accuracy: 0.9120 - val_loss: 0.7215 - val_accuracy: 0.8168
Epoch 73/110
 - 3s - loss: 0.3287 - accuracy: 0.9266 - val_loss: 0.7135 - val_accuracy: 0.8299
Epoch 74/110
 - 3s - loss: 0.3172 - accuracy: 0.9283 - val_loss: 0.6798 - val_accuracy: 0.8226
Epoch 75/110
 - 3s - loss: 0.3176 - accuracy: 0.9263 - val_loss: 0.7358 - val_accuracy: 0.8277
Epoch 76/110
 - 3s - loss: 0.3156 - accuracy: 0.9288 - val_loss: 0.7023 - val_accuracy: 0.8365
Epoch 77/110
 - 3s - loss: 0.3157 - accuracy: 0.9290 - val_loss: 0.8186 - val_accuracy: 0.8234
Epoch 78/110
 - 3s - loss: 0.3012 - accuracy: 0.9385 - val_loss: 0.7619 - val_accuracy: 0.8489
Epoch 79/110
 - 3s - loss: 0.3001 - accuracy: 0.9356 - val_loss: 0.8440 - val_accuracy: 0.8153
Epoch 80/110
 - 3s - loss: 0.3084 - accuracy: 0.9341 - val_loss: 0.8291 - val_accuracy: 0.8277
Epoch 81/110
 - 3s - loss: 0.3012 - accuracy: 0.9401 - val_loss: 0.8156 - val_accuracy: 0.8197
Epoch 82/110
 - 3s - loss: 0.2820 - accuracy: 0.9451 - val_loss: 0.7031 - val_accuracy: 0.8336
Epoch 83/110
 - 3s - loss: 0.2977 - accuracy: 0.9385 - val_loss: 0.9485 - val_accuracy: 0.7832
Epoch 84/110
 - 3s - loss: 0.3299 - accuracy: 0.9252 - val_loss: 0.8413 - val_accuracy: 0.8321
Epoch 85/110
 - 3s - loss: 0.3161 - accuracy: 0.9330 - val_loss: 0.8551 - val_accuracy: 0.8212
Epoch 86/110
 - 3s - loss: 0.2968 - accuracy: 0.9416 - val_loss: 0.9177 - val_accuracy: 0.8058
Epoch 87/110
 - 3s - loss: 0.3111 - accuracy: 0.9392 - val_loss: 0.7601 - val_accuracy: 0.8328
Epoch 88/110
 - 3s - loss: 0.3020 - accuracy: 0.9376 - val_loss: 0.7555 - val_accuracy: 0.8299
Epoch 89/110
 - 3s - loss: 0.2960 - accuracy: 0.9405 - val_loss: 0.7162 - val_accuracy: 0.8416
Epoch 90/110
 - 3s - loss: 0.2887 - accuracy: 0.9419 - val_loss: 0.7597 - val_accuracy: 0.8285
Epoch 91/110
 - 3s - loss: 0.2840 - accuracy: 0.9467 - val_loss: 0.8379 - val_accuracy: 0.8234
Epoch 92/110
 - 3s - loss: 0.3004 - accuracy: 0.9387 - val_loss: 0.8474 - val_accuracy: 0.8036
Epoch 93/110
 - 3s - loss: 0.3086 - accuracy: 0.9378 - val_loss: 0.8242 - val_accuracy: 0.8277
Epoch 94/110
 - 3s - loss: 0.3110 - accuracy: 0.9374 - val_loss: 0.7145 - val_accuracy: 0.8401
Epoch 95/110
 - 3s - loss: 0.2721 - accuracy: 0.9493 - val_loss: 0.7657 - val_accuracy: 0.8365
Epoch 96/110
 - 3s - loss: 0.2647 - accuracy: 0.9535 - val_loss: 0.9167 - val_accuracy: 0.8204
Epoch 97/110
 - 3s - loss: 0.2692 - accuracy: 0.9503 - val_loss: 0.8167 - val_accuracy: 0.8409
Epoch 98/110
 - 3s - loss: 0.2810 - accuracy: 0.9429 - val_loss: 0.7952 - val_accuracy: 0.8314
Epoch 99/110
 - 3s - loss: 0.3525 - accuracy: 0.9268 - val_loss: 0.9429 - val_accuracy: 0.8022
Epoch 100/110
 - 3s - loss: 0.3368 - accuracy: 0.9303 - val_loss: 0.7063 - val_accuracy: 0.8438
Epoch 101/110
 - 3s - loss: 0.2801 - accuracy: 0.9482 - val_loss: 0.7748 - val_accuracy: 0.8314
Epoch 102/110
 - 3s - loss: 0.2742 - accuracy: 0.9500 - val_loss: 0.8142 - val_accuracy: 0.8234
Epoch 103/110
 - 3s - loss: 0.2871 - accuracy: 0.9432 - val_loss: 0.7963 - val_accuracy: 0.8365
Epoch 104/110
 - 3s - loss: 0.2720 - accuracy: 0.9516 - val_loss: 0.8167 - val_accuracy: 0.8460
Epoch 105/110
 - 3s - loss: 0.2867 - accuracy: 0.9469 - val_loss: 0.7966 - val_accuracy: 0.8248
Epoch 106/110
 - 3s - loss: 0.2856 - accuracy: 0.9449 - val_loss: 0.7398 - val_accuracy: 0.8299
Epoch 107/110
 - 3s - loss: 0.2926 - accuracy: 0.9440 - val_loss: 0.7547 - val_accuracy: 0.8416
Epoch 108/110
 - 3s - loss: 0.2823 - accuracy: 0.9463 - val_loss: 0.7658 - val_accuracy: 0.8416
Epoch 109/110
 - 3s - loss: 0.2740 - accuracy: 0.9482 - val_loss: 0.7979 - val_accuracy: 0.8445
Epoch 110/110
 - 3s - loss: 0.2692 - accuracy: 0.9518 - val_loss: 0.8809 - val_accuracy: 0.8299
------------------------------------------------------------------------
Training for fold 5 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 6s - loss: 1.0281 - accuracy: 0.6882 - val_loss: 1.5031 - val_accuracy: 0.4635
Epoch 2/110
 - 3s - loss: 0.7518 - accuracy: 0.7788 - val_loss: 1.0547 - val_accuracy: 0.6584
Epoch 3/110
 - 3s - loss: 0.6863 - accuracy: 0.8052 - val_loss: 0.8079 - val_accuracy: 0.7577
Epoch 4/110
 - 3s - loss: 0.6494 - accuracy: 0.8151 - val_loss: 0.7635 - val_accuracy: 0.7796
Epoch 5/110
 - 3s - loss: 0.6408 - accuracy: 0.8196 - val_loss: 0.7411 - val_accuracy: 0.7905
Epoch 6/110
 - 3s - loss: 0.6261 - accuracy: 0.8217 - val_loss: 0.7092 - val_accuracy: 0.8015
Epoch 7/110
 - 3s - loss: 0.6079 - accuracy: 0.8308 - val_loss: 0.7001 - val_accuracy: 0.8095
Epoch 8/110
 - 3s - loss: 0.5898 - accuracy: 0.8337 - val_loss: 0.6944 - val_accuracy: 0.8029
Epoch 9/110
 - 3s - loss: 0.5738 - accuracy: 0.8421 - val_loss: 0.7891 - val_accuracy: 0.7898
Epoch 10/110
 - 3s - loss: 0.5590 - accuracy: 0.8454 - val_loss: 0.7460 - val_accuracy: 0.7956
Epoch 11/110
 - 3s - loss: 0.5614 - accuracy: 0.8397 - val_loss: 0.7025 - val_accuracy: 0.8066
Epoch 12/110
 - 3s - loss: 0.5451 - accuracy: 0.8430 - val_loss: 0.6921 - val_accuracy: 0.8117
Epoch 13/110
 - 3s - loss: 0.5379 - accuracy: 0.8530 - val_loss: 0.6996 - val_accuracy: 0.7942
Epoch 14/110
 - 3s - loss: 0.5279 - accuracy: 0.8503 - val_loss: 0.7519 - val_accuracy: 0.7905
Epoch 15/110
 - 3s - loss: 0.5163 - accuracy: 0.8560 - val_loss: 0.7384 - val_accuracy: 0.7891
Epoch 16/110
 - 3s - loss: 0.5227 - accuracy: 0.8516 - val_loss: 0.7185 - val_accuracy: 0.8095
Epoch 17/110
 - 3s - loss: 0.5292 - accuracy: 0.8483 - val_loss: 0.7021 - val_accuracy: 0.8080
Epoch 18/110
 - 3s - loss: 0.5132 - accuracy: 0.8609 - val_loss: 0.6725 - val_accuracy: 0.8131
Epoch 19/110
 - 3s - loss: 0.5103 - accuracy: 0.8605 - val_loss: 0.6779 - val_accuracy: 0.8219
Epoch 20/110
 - 3s - loss: 0.4938 - accuracy: 0.8671 - val_loss: 0.6937 - val_accuracy: 0.8080
Epoch 21/110
 - 3s - loss: 0.4950 - accuracy: 0.8602 - val_loss: 0.7617 - val_accuracy: 0.8036
Epoch 22/110
 - 3s - loss: 0.4971 - accuracy: 0.8600 - val_loss: 0.7380 - val_accuracy: 0.8029
Epoch 23/110
 - 3s - loss: 0.4835 - accuracy: 0.8684 - val_loss: 0.6976 - val_accuracy: 0.8263
Epoch 24/110
 - 3s - loss: 0.4876 - accuracy: 0.8680 - val_loss: 0.7101 - val_accuracy: 0.8066
Epoch 25/110
 - 3s - loss: 0.4870 - accuracy: 0.8633 - val_loss: 0.7184 - val_accuracy: 0.8088
Epoch 26/110
 - 3s - loss: 0.4796 - accuracy: 0.8697 - val_loss: 0.7035 - val_accuracy: 0.8124
Epoch 27/110
 - 3s - loss: 0.4658 - accuracy: 0.8753 - val_loss: 0.6590 - val_accuracy: 0.8248
Epoch 28/110
 - 3s - loss: 0.4612 - accuracy: 0.8753 - val_loss: 0.6770 - val_accuracy: 0.8285
Epoch 29/110
 - 3s - loss: 0.4597 - accuracy: 0.8713 - val_loss: 0.7055 - val_accuracy: 0.8102
Epoch 30/110
 - 3s - loss: 0.4518 - accuracy: 0.8779 - val_loss: 0.7102 - val_accuracy: 0.8080
Epoch 31/110
 - 3s - loss: 0.4489 - accuracy: 0.8839 - val_loss: 0.7038 - val_accuracy: 0.8146
Epoch 32/110
 - 3s - loss: 0.4487 - accuracy: 0.8799 - val_loss: 0.7502 - val_accuracy: 0.8051
Epoch 33/110
 - 3s - loss: 0.4446 - accuracy: 0.8792 - val_loss: 0.7309 - val_accuracy: 0.8102
Epoch 34/110
 - 3s - loss: 0.4475 - accuracy: 0.8775 - val_loss: 0.7203 - val_accuracy: 0.8051
Epoch 35/110
 - 3s - loss: 0.4426 - accuracy: 0.8810 - val_loss: 0.6454 - val_accuracy: 0.8241
Epoch 36/110
 - 3s - loss: 0.4344 - accuracy: 0.8839 - val_loss: 0.6931 - val_accuracy: 0.8219
Epoch 37/110
 - 3s - loss: 0.4220 - accuracy: 0.8892 - val_loss: 0.6692 - val_accuracy: 0.8307
Epoch 38/110
 - 3s - loss: 0.4098 - accuracy: 0.8967 - val_loss: 0.7539 - val_accuracy: 0.7912
Epoch 39/110
 - 3s - loss: 0.4334 - accuracy: 0.8857 - val_loss: 0.7895 - val_accuracy: 0.8073
Epoch 40/110
 - 3s - loss: 0.4310 - accuracy: 0.8841 - val_loss: 0.7024 - val_accuracy: 0.8219
Epoch 41/110
 - 3s - loss: 0.4216 - accuracy: 0.8897 - val_loss: 0.6970 - val_accuracy: 0.8285
Epoch 42/110
 - 3s - loss: 0.4222 - accuracy: 0.8872 - val_loss: 0.7071 - val_accuracy: 0.8212
Epoch 43/110
 - 3s - loss: 0.4138 - accuracy: 0.8894 - val_loss: 0.7036 - val_accuracy: 0.8241
Epoch 44/110
 - 3s - loss: 0.4036 - accuracy: 0.8958 - val_loss: 0.6877 - val_accuracy: 0.8307
Epoch 45/110
 - 3s - loss: 0.3951 - accuracy: 0.9014 - val_loss: 0.7163 - val_accuracy: 0.8277
Epoch 46/110
 - 3s - loss: 0.3901 - accuracy: 0.9007 - val_loss: 0.7450 - val_accuracy: 0.8255
Epoch 47/110
 - 3s - loss: 0.3953 - accuracy: 0.9011 - val_loss: 0.7103 - val_accuracy: 0.8248
Epoch 48/110
 - 3s - loss: 0.4067 - accuracy: 0.8943 - val_loss: 0.7762 - val_accuracy: 0.8139
Epoch 49/110
 - 3s - loss: 0.3944 - accuracy: 0.8961 - val_loss: 0.6954 - val_accuracy: 0.8358
Epoch 50/110
 - 3s - loss: 0.4047 - accuracy: 0.8939 - val_loss: 0.7105 - val_accuracy: 0.8255
Epoch 51/110
 - 3s - loss: 0.4032 - accuracy: 0.8954 - val_loss: 0.6981 - val_accuracy: 0.8321
Epoch 52/110
 - 3s - loss: 0.4249 - accuracy: 0.8883 - val_loss: 0.6822 - val_accuracy: 0.8263
Epoch 53/110
 - 3s - loss: 0.4028 - accuracy: 0.8970 - val_loss: 0.6902 - val_accuracy: 0.8365
Epoch 54/110
 - 3s - loss: 0.3954 - accuracy: 0.8996 - val_loss: 0.7011 - val_accuracy: 0.8124
Epoch 55/110
 - 3s - loss: 0.3879 - accuracy: 0.9027 - val_loss: 0.7054 - val_accuracy: 0.8285
Epoch 56/110
 - 3s - loss: 0.3895 - accuracy: 0.9060 - val_loss: 0.6467 - val_accuracy: 0.8343
Epoch 57/110
 - 3s - loss: 0.3778 - accuracy: 0.9082 - val_loss: 0.6700 - val_accuracy: 0.8387
Epoch 58/110
 - 3s - loss: 0.3816 - accuracy: 0.9054 - val_loss: 0.6652 - val_accuracy: 0.8343
Epoch 59/110
 - 3s - loss: 0.3929 - accuracy: 0.9018 - val_loss: 0.6397 - val_accuracy: 0.8453
Epoch 60/110
 - 3s - loss: 0.3641 - accuracy: 0.9142 - val_loss: 0.7328 - val_accuracy: 0.8263
Epoch 61/110
 - 3s - loss: 0.3590 - accuracy: 0.9111 - val_loss: 0.7050 - val_accuracy: 0.8401
Epoch 62/110
 - 3s - loss: 0.3511 - accuracy: 0.9140 - val_loss: 0.7260 - val_accuracy: 0.8263
Epoch 63/110
 - 3s - loss: 0.3510 - accuracy: 0.9186 - val_loss: 0.6759 - val_accuracy: 0.8416
Epoch 64/110
 - 3s - loss: 0.3540 - accuracy: 0.9175 - val_loss: 0.7017 - val_accuracy: 0.8328
Epoch 65/110
 - 3s - loss: 0.3600 - accuracy: 0.9129 - val_loss: 0.7923 - val_accuracy: 0.8197
Epoch 66/110
 - 3s - loss: 0.3568 - accuracy: 0.9144 - val_loss: 0.7602 - val_accuracy: 0.8321
Epoch 67/110
 - 3s - loss: 0.3521 - accuracy: 0.9179 - val_loss: 0.7256 - val_accuracy: 0.8277
Epoch 68/110
 - 3s - loss: 0.3459 - accuracy: 0.9202 - val_loss: 0.7572 - val_accuracy: 0.8197
Epoch 69/110
 - 3s - loss: 0.3353 - accuracy: 0.9222 - val_loss: 0.7020 - val_accuracy: 0.8372
Epoch 70/110
 - 3s - loss: 0.3461 - accuracy: 0.9182 - val_loss: 0.7003 - val_accuracy: 0.8263
Epoch 71/110
 - 3s - loss: 0.3381 - accuracy: 0.9191 - val_loss: 0.7226 - val_accuracy: 0.8445
Epoch 72/110
 - 3s - loss: 0.3256 - accuracy: 0.9259 - val_loss: 0.7064 - val_accuracy: 0.8365
Epoch 73/110
 - 3s - loss: 0.3268 - accuracy: 0.9259 - val_loss: 0.7183 - val_accuracy: 0.8460
Epoch 74/110
 - 3s - loss: 0.3243 - accuracy: 0.9295 - val_loss: 0.7379 - val_accuracy: 0.8350
Epoch 75/110
 - 3s - loss: 0.3445 - accuracy: 0.9191 - val_loss: 0.8143 - val_accuracy: 0.8255
Epoch 76/110
 - 3s - loss: 0.3467 - accuracy: 0.9184 - val_loss: 0.7470 - val_accuracy: 0.8336
Epoch 77/110
 - 3s - loss: 0.3419 - accuracy: 0.9211 - val_loss: 0.6986 - val_accuracy: 0.8328
Epoch 78/110
 - 3s - loss: 0.3264 - accuracy: 0.9303 - val_loss: 0.7215 - val_accuracy: 0.8226
Epoch 79/110
 - 3s - loss: 0.3182 - accuracy: 0.9312 - val_loss: 0.6740 - val_accuracy: 0.8423
Epoch 80/110
 - 3s - loss: 0.3166 - accuracy: 0.9312 - val_loss: 0.6807 - val_accuracy: 0.8372
Epoch 81/110
 - 3s - loss: 0.3125 - accuracy: 0.9290 - val_loss: 0.7049 - val_accuracy: 0.8336
Epoch 82/110
 - 3s - loss: 0.3206 - accuracy: 0.9273 - val_loss: 0.6984 - val_accuracy: 0.8394
Epoch 83/110
 - 3s - loss: 0.3411 - accuracy: 0.9226 - val_loss: 0.9164 - val_accuracy: 0.8022
Epoch 84/110
 - 3s - loss: 0.3616 - accuracy: 0.9116 - val_loss: 0.7621 - val_accuracy: 0.8088
Epoch 85/110
 - 3s - loss: 0.3348 - accuracy: 0.9241 - val_loss: 0.7416 - val_accuracy: 0.8307
Epoch 86/110
 - 3s - loss: 0.2920 - accuracy: 0.9398 - val_loss: 0.7307 - val_accuracy: 0.8423
Epoch 87/110
 - 3s - loss: 0.3006 - accuracy: 0.9387 - val_loss: 0.7948 - val_accuracy: 0.8190
Epoch 88/110
 - 3s - loss: 0.3077 - accuracy: 0.9332 - val_loss: 0.6915 - val_accuracy: 0.8401
Epoch 89/110
 - 3s - loss: 0.2979 - accuracy: 0.9392 - val_loss: 0.7067 - val_accuracy: 0.8372
Epoch 90/110
 - 3s - loss: 0.3233 - accuracy: 0.9310 - val_loss: 0.7445 - val_accuracy: 0.8263
Epoch 91/110
 - 3s - loss: 0.3059 - accuracy: 0.9343 - val_loss: 0.8331 - val_accuracy: 0.8161
Epoch 92/110
 - 3s - loss: 0.3072 - accuracy: 0.9388 - val_loss: 0.8272 - val_accuracy: 0.8182
Epoch 93/110
 - 3s - loss: 0.3100 - accuracy: 0.9341 - val_loss: 0.7843 - val_accuracy: 0.8168
Epoch 94/110
 - 3s - loss: 0.3201 - accuracy: 0.9304 - val_loss: 0.7693 - val_accuracy: 0.8299
Epoch 95/110
 - 3s - loss: 0.2941 - accuracy: 0.9405 - val_loss: 0.7574 - val_accuracy: 0.8241
Epoch 96/110
 - 3s - loss: 0.3145 - accuracy: 0.9303 - val_loss: 0.7033 - val_accuracy: 0.8409
Epoch 97/110
 - 3s - loss: 0.3170 - accuracy: 0.9308 - val_loss: 0.7653 - val_accuracy: 0.8365
Epoch 98/110
 - 3s - loss: 0.2991 - accuracy: 0.9409 - val_loss: 0.8224 - val_accuracy: 0.8241
Epoch 99/110
 - 3s - loss: 0.3124 - accuracy: 0.9319 - val_loss: 0.7768 - val_accuracy: 0.8358
Epoch 100/110
 - 3s - loss: 0.2984 - accuracy: 0.9388 - val_loss: 0.8024 - val_accuracy: 0.8175
Epoch 101/110
 - 3s - loss: 0.3008 - accuracy: 0.9410 - val_loss: 0.7491 - val_accuracy: 0.8372
Epoch 102/110
 - 3s - loss: 0.2974 - accuracy: 0.9409 - val_loss: 0.8185 - val_accuracy: 0.8292
Epoch 103/110
 - 3s - loss: 0.3316 - accuracy: 0.9283 - val_loss: 0.7751 - val_accuracy: 0.8299
Epoch 104/110
 - 3s - loss: 0.3254 - accuracy: 0.9294 - val_loss: 0.7938 - val_accuracy: 0.8204
Epoch 105/110
 - 3s - loss: 0.3006 - accuracy: 0.9399 - val_loss: 0.7786 - val_accuracy: 0.8088
Epoch 106/110
 - 3s - loss: 0.2962 - accuracy: 0.9403 - val_loss: 0.7550 - val_accuracy: 0.8314
Epoch 107/110
 - 3s - loss: 0.2967 - accuracy: 0.9401 - val_loss: 0.7647 - val_accuracy: 0.8387
Epoch 108/110
 - 3s - loss: 0.2819 - accuracy: 0.9452 - val_loss: 0.7736 - val_accuracy: 0.8248
Epoch 109/110
 - 3s - loss: 0.2903 - accuracy: 0.9419 - val_loss: 0.8245 - val_accuracy: 0.8314
Epoch 110/110
 - 3s - loss: 0.2736 - accuracy: 0.9496 - val_loss: 0.7575 - val_accuracy: 0.8387
------------------------------------------------------------------------
Score per fold
------------------------------------------------------------------------
Score for fold 1
Accuracy_Train: 83.81%
Accuracy_Test: 82.89%
Loss_Train: 0.73
Loss_Test: 0.76
------------------------------------------------------------------------
Score for fold 2
Accuracy_Train: 84.87%
Accuracy_Test: 85.81%
Loss_Train: 0.63
Loss_Test: 0.62
------------------------------------------------------------------------
Score for fold 3
Accuracy_Train: 85.27%
Accuracy_Test: 85.22%
Loss_Train: 0.68
Loss_Test: 0.66
------------------------------------------------------------------------
Score for fold 4
Accuracy_Train: 82.83%
Accuracy_Test: 83.29%
Loss_Train: 0.80
Loss_Test: 0.76
------------------------------------------------------------------------
Score for fold 5
Accuracy_Train: 85.27%
Accuracy_Test: 84.00%
Loss_Train: 0.66
Loss_Test: 0.67
------------------------------------------------------------------------
Average scores for all folds:
Average_Accuracy_Train: 84.41%
	-> (+- 0.9537953875923053 )
Average_Accuracy_Test: 84.24%
	-> (+- 1.1140484645497495 )
Average_Loss_Train: 0.70
	-> (+- 0.05866799339135897 )
Average_Loss_Test: 0.69
	-> (+- 0.05682372503063458 )
------------------------------------------------------------------------
