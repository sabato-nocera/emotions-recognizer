Dataset used: ../../datasets/full_dataset_without_humidity.csv 

   Temperature  Sound  Heartbeat   X1  ...    Y2     Z2  Classification  Feedback
0           32      1         60 -680  ... -7424 -15596             100     Happy
1           32      1         60 -780  ... -7408 -15628             100     Happy
2           -1      1         60   -1  ... -7276 -15612             100     Happy
3           -1     -1         60   -1  ...    -1     -1             100     Happy
4           32      1         60 -860  ... -7340 -15720             100     Happy

[5 rows x 11 columns]

Objservations: 8560
Reshaping:  ((6848, 10), (6848, 4), (1712, 10), (1712, 4))  -> ((6848, 10, 1), (6848, 4), (1712, 10, 1), (1712, 4))

Layers:

{'batch_input_shape': (None, 10, 1), 'dtype': 'float32', 'sparse': False, 'name': 'input_67'} 

{'name': 'conv1d_1464', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1255', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_1409', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_1465', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1256', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_1410', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_1466', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1257', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_595', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_1411', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_1467', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1258', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_1412', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_1468', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1259', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_596', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_1413', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_1469', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1260', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_1414', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_1470', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1261', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_597', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_1415', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_1471', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1262', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_1416', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_1472', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_1473', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1263', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_598', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_1417', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_1474', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1264', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_1418', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_1475', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1265', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_599', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_1419', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_1476', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1266', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_1420', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_1477', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1267', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_600', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_1421', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_1478', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1268', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_1422', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_1479', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_1480', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1269', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_601', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_1423', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_1481', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1270', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_1424', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_1482', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1271', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_602', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_1425', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_1483', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1272', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_1426', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_1484', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_1273', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_603', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_1427', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'average_pooling1d_67', 'trainable': True, 'dtype': 'float32', 'strides': (1,), 'pool_size': (1,), 'padding': 'valid', 'data_format': 'channels_last'} 

{'name': 'flatten_144', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'} 

{'name': 'dense_2212', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 6s - loss: 1.4831 - accuracy: 0.4631 - val_loss: 1.7290 - val_accuracy: 0.2818
Epoch 2/110
 - 2s - loss: 1.1967 - accuracy: 0.5646 - val_loss: 1.3414 - val_accuracy: 0.4803
Epoch 3/110
 - 2s - loss: 1.1082 - accuracy: 0.6028 - val_loss: 1.2325 - val_accuracy: 0.5445
Epoch 4/110
 - 2s - loss: 1.0403 - accuracy: 0.6314 - val_loss: 1.1768 - val_accuracy: 0.5547
Epoch 5/110
 - 2s - loss: 1.0072 - accuracy: 0.6533 - val_loss: 1.1981 - val_accuracy: 0.5664
Epoch 6/110
 - 2s - loss: 0.9669 - accuracy: 0.6637 - val_loss: 1.2545 - val_accuracy: 0.5431
Epoch 7/110
 - 2s - loss: 0.9410 - accuracy: 0.6740 - val_loss: 1.2470 - val_accuracy: 0.5460
Epoch 8/110
 - 2s - loss: 0.9118 - accuracy: 0.6877 - val_loss: 1.2976 - val_accuracy: 0.5547
Epoch 9/110
 - 2s - loss: 0.9141 - accuracy: 0.6862 - val_loss: 1.3186 - val_accuracy: 0.5394
Epoch 10/110
 - 2s - loss: 0.8890 - accuracy: 0.7001 - val_loss: 1.2796 - val_accuracy: 0.5533
Epoch 11/110
 - 2s - loss: 0.8724 - accuracy: 0.7072 - val_loss: 1.2696 - val_accuracy: 0.5445
Epoch 12/110
 - 2s - loss: 0.8657 - accuracy: 0.7129 - val_loss: 1.2787 - val_accuracy: 0.5533
Epoch 13/110
 - 2s - loss: 0.8450 - accuracy: 0.7174 - val_loss: 1.2304 - val_accuracy: 0.5540
Epoch 14/110
 - 2s - loss: 0.8215 - accuracy: 0.7273 - val_loss: 1.2736 - val_accuracy: 0.5401
Epoch 15/110
 - 2s - loss: 0.8283 - accuracy: 0.7276 - val_loss: 1.2583 - val_accuracy: 0.5533
Epoch 16/110
 - 2s - loss: 0.7985 - accuracy: 0.7373 - val_loss: 1.2566 - val_accuracy: 0.5723
Epoch 17/110
 - 2s - loss: 0.7912 - accuracy: 0.7401 - val_loss: 1.2167 - val_accuracy: 0.5978
Epoch 18/110
 - 2s - loss: 0.7787 - accuracy: 0.7464 - val_loss: 1.1948 - val_accuracy: 0.6219
Epoch 19/110
 - 2s - loss: 0.7370 - accuracy: 0.7667 - val_loss: 1.2153 - val_accuracy: 0.5964
Epoch 20/110
 - 2s - loss: 0.7455 - accuracy: 0.7634 - val_loss: 1.2409 - val_accuracy: 0.6073
Epoch 21/110
 - 2s - loss: 0.7252 - accuracy: 0.7609 - val_loss: 1.2508 - val_accuracy: 0.5964
Epoch 22/110
 - 2s - loss: 0.7630 - accuracy: 0.7512 - val_loss: 1.3018 - val_accuracy: 0.5883
Epoch 23/110
 - 2s - loss: 0.7233 - accuracy: 0.7683 - val_loss: 1.3188 - val_accuracy: 0.5737
Epoch 24/110
 - 2s - loss: 0.7573 - accuracy: 0.7526 - val_loss: 1.2975 - val_accuracy: 0.5956
Epoch 25/110
 - 2s - loss: 0.7456 - accuracy: 0.7671 - val_loss: 1.3493 - val_accuracy: 0.5788
Epoch 26/110
 - 2s - loss: 0.7225 - accuracy: 0.7698 - val_loss: 1.3304 - val_accuracy: 0.6007
Epoch 27/110
 - 2s - loss: 0.7065 - accuracy: 0.7764 - val_loss: 1.3376 - val_accuracy: 0.5847
Epoch 28/110
 - 2s - loss: 0.6855 - accuracy: 0.7831 - val_loss: 1.2660 - val_accuracy: 0.6088
Epoch 29/110
 - 2s - loss: 0.6966 - accuracy: 0.7862 - val_loss: 1.3037 - val_accuracy: 0.6109
Epoch 30/110
 - 2s - loss: 0.6894 - accuracy: 0.7864 - val_loss: 1.2868 - val_accuracy: 0.6058
Epoch 31/110
 - 2s - loss: 0.7162 - accuracy: 0.7685 - val_loss: 1.2539 - val_accuracy: 0.6197
Epoch 32/110
 - 2s - loss: 0.7099 - accuracy: 0.7782 - val_loss: 1.2743 - val_accuracy: 0.6088
Epoch 33/110
 - 2s - loss: 0.6875 - accuracy: 0.7866 - val_loss: 1.3024 - val_accuracy: 0.5956
Epoch 34/110
 - 2s - loss: 0.6809 - accuracy: 0.7851 - val_loss: 1.2596 - val_accuracy: 0.6044
Epoch 35/110
 - 2s - loss: 0.6635 - accuracy: 0.7939 - val_loss: 1.2136 - val_accuracy: 0.6153
Epoch 36/110
 - 2s - loss: 0.6552 - accuracy: 0.7983 - val_loss: 1.3177 - val_accuracy: 0.6073
Epoch 37/110
 - 2s - loss: 0.6464 - accuracy: 0.8080 - val_loss: 1.3438 - val_accuracy: 0.6153
Epoch 38/110
 - 2s - loss: 0.6307 - accuracy: 0.8092 - val_loss: 1.2973 - val_accuracy: 0.6029
Epoch 39/110
 - 2s - loss: 0.6174 - accuracy: 0.8158 - val_loss: 1.3072 - val_accuracy: 0.6241
Epoch 40/110
 - 2s - loss: 0.5912 - accuracy: 0.8224 - val_loss: 1.3821 - val_accuracy: 0.6168
Epoch 41/110
 - 2s - loss: 0.5887 - accuracy: 0.8240 - val_loss: 1.2942 - val_accuracy: 0.6358
Epoch 42/110
 - 2s - loss: 0.5824 - accuracy: 0.8339 - val_loss: 1.3741 - val_accuracy: 0.6095
Epoch 43/110
 - 2s - loss: 0.5882 - accuracy: 0.8277 - val_loss: 1.2815 - val_accuracy: 0.6460
Epoch 44/110
 - 2s - loss: 0.5813 - accuracy: 0.8364 - val_loss: 1.3719 - val_accuracy: 0.6168
Epoch 45/110
 - 2s - loss: 0.5987 - accuracy: 0.8262 - val_loss: 1.3480 - val_accuracy: 0.6496
Epoch 46/110
 - 2s - loss: 0.5614 - accuracy: 0.8383 - val_loss: 1.3714 - val_accuracy: 0.6372
Epoch 47/110
 - 2s - loss: 0.5523 - accuracy: 0.8443 - val_loss: 1.3755 - val_accuracy: 0.6445
Epoch 48/110
 - 2s - loss: 0.5578 - accuracy: 0.8432 - val_loss: 1.3993 - val_accuracy: 0.6431
Epoch 49/110
 - 2s - loss: 0.5659 - accuracy: 0.8379 - val_loss: 1.3264 - val_accuracy: 0.6307
Epoch 50/110
 - 2s - loss: 0.5332 - accuracy: 0.8510 - val_loss: 1.3460 - val_accuracy: 0.6299
Epoch 51/110
 - 2s - loss: 0.5401 - accuracy: 0.8492 - val_loss: 1.3614 - val_accuracy: 0.6350
Epoch 52/110
 - 2s - loss: 0.5145 - accuracy: 0.8640 - val_loss: 1.4374 - val_accuracy: 0.6307
Epoch 53/110
 - 2s - loss: 0.5240 - accuracy: 0.8569 - val_loss: 1.3218 - val_accuracy: 0.6248
Epoch 54/110
 - 2s - loss: 0.5360 - accuracy: 0.8496 - val_loss: 1.4694 - val_accuracy: 0.6482
Epoch 55/110
 - 2s - loss: 0.5284 - accuracy: 0.8538 - val_loss: 1.4368 - val_accuracy: 0.6343
Epoch 56/110
 - 2s - loss: 0.4999 - accuracy: 0.8677 - val_loss: 1.5094 - val_accuracy: 0.6117
Epoch 57/110
 - 2s - loss: 0.5095 - accuracy: 0.8633 - val_loss: 1.5395 - val_accuracy: 0.6219
Epoch 58/110
 - 2s - loss: 0.5290 - accuracy: 0.8602 - val_loss: 1.4219 - val_accuracy: 0.6474
Epoch 59/110
 - 2s - loss: 0.4992 - accuracy: 0.8680 - val_loss: 1.4597 - val_accuracy: 0.6438
Epoch 60/110
 - 2s - loss: 0.4856 - accuracy: 0.8719 - val_loss: 1.4905 - val_accuracy: 0.6146
Epoch 61/110
 - 2s - loss: 0.4881 - accuracy: 0.8757 - val_loss: 1.4567 - val_accuracy: 0.6358
Epoch 62/110
 - 2s - loss: 0.4809 - accuracy: 0.8726 - val_loss: 1.5368 - val_accuracy: 0.6277
Epoch 63/110
 - 2s - loss: 0.4904 - accuracy: 0.8715 - val_loss: 1.4152 - val_accuracy: 0.6387
Epoch 64/110
 - 2s - loss: 0.4769 - accuracy: 0.8777 - val_loss: 1.4586 - val_accuracy: 0.6365
Epoch 65/110
 - 2s - loss: 0.4624 - accuracy: 0.8808 - val_loss: 1.5001 - val_accuracy: 0.6482
Epoch 66/110
 - 2s - loss: 0.4854 - accuracy: 0.8755 - val_loss: 1.4279 - val_accuracy: 0.6336
Epoch 67/110
 - 2s - loss: 0.4797 - accuracy: 0.8817 - val_loss: 1.4007 - val_accuracy: 0.6569
Epoch 68/110
 - 2s - loss: 0.4697 - accuracy: 0.8795 - val_loss: 1.4403 - val_accuracy: 0.6489
Epoch 69/110
 - 2s - loss: 0.4468 - accuracy: 0.8949 - val_loss: 1.4738 - val_accuracy: 0.6584
Epoch 70/110
 - 2s - loss: 0.4605 - accuracy: 0.8870 - val_loss: 1.4470 - val_accuracy: 0.6387
Epoch 71/110
 - 2s - loss: 0.4334 - accuracy: 0.8949 - val_loss: 1.4961 - val_accuracy: 0.6555
Epoch 72/110
 - 2s - loss: 0.4169 - accuracy: 0.9009 - val_loss: 1.3937 - val_accuracy: 0.6453
Epoch 73/110
 - 2s - loss: 0.3899 - accuracy: 0.9120 - val_loss: 1.5704 - val_accuracy: 0.6460
Epoch 74/110
 - 2s - loss: 0.4335 - accuracy: 0.8980 - val_loss: 1.5851 - val_accuracy: 0.6336
Epoch 75/110
 - 2s - loss: 0.4404 - accuracy: 0.8959 - val_loss: 1.5195 - val_accuracy: 0.6358
Epoch 76/110
 - 2s - loss: 0.4256 - accuracy: 0.8991 - val_loss: 1.5509 - val_accuracy: 0.6358
Epoch 77/110
 - 2s - loss: 0.4180 - accuracy: 0.9034 - val_loss: 1.5451 - val_accuracy: 0.6467
Epoch 78/110
 - 2s - loss: 0.4368 - accuracy: 0.8980 - val_loss: 1.7678 - val_accuracy: 0.5993
Epoch 79/110
 - 2s - loss: 0.4280 - accuracy: 0.9018 - val_loss: 1.6416 - val_accuracy: 0.6401
Epoch 80/110
 - 2s - loss: 0.4308 - accuracy: 0.8987 - val_loss: 1.5713 - val_accuracy: 0.6336
Epoch 81/110
 - 2s - loss: 0.4332 - accuracy: 0.8996 - val_loss: 1.5456 - val_accuracy: 0.6569
Epoch 82/110
 - 2s - loss: 0.4134 - accuracy: 0.9020 - val_loss: 1.5563 - val_accuracy: 0.6562
Epoch 83/110
 - 2s - loss: 0.4384 - accuracy: 0.8950 - val_loss: 1.6370 - val_accuracy: 0.6394
Epoch 84/110
 - 2s - loss: 0.4130 - accuracy: 0.9053 - val_loss: 1.5297 - val_accuracy: 0.6650
Epoch 85/110
 - 2s - loss: 0.4002 - accuracy: 0.9127 - val_loss: 1.5259 - val_accuracy: 0.6453
Epoch 86/110
 - 2s - loss: 0.3970 - accuracy: 0.9146 - val_loss: 1.4634 - val_accuracy: 0.6577
Epoch 87/110
 - 2s - loss: 0.3960 - accuracy: 0.9091 - val_loss: 1.5965 - val_accuracy: 0.6387
Epoch 88/110
 - 2s - loss: 0.3992 - accuracy: 0.9179 - val_loss: 1.5895 - val_accuracy: 0.6460
Epoch 89/110
 - 2s - loss: 0.3977 - accuracy: 0.9137 - val_loss: 1.6419 - val_accuracy: 0.6511
Epoch 90/110
 - 2s - loss: 0.3794 - accuracy: 0.9211 - val_loss: 1.5817 - val_accuracy: 0.6540
Epoch 91/110
 - 2s - loss: 0.3773 - accuracy: 0.9253 - val_loss: 1.6947 - val_accuracy: 0.6336
Epoch 92/110
 - 2s - loss: 0.3703 - accuracy: 0.9241 - val_loss: 1.6778 - val_accuracy: 0.6467
Epoch 93/110
 - 2s - loss: 0.4215 - accuracy: 0.9100 - val_loss: 1.6038 - val_accuracy: 0.6387
Epoch 94/110
 - 2s - loss: 0.4125 - accuracy: 0.9104 - val_loss: 1.5180 - val_accuracy: 0.6555
Epoch 95/110
 - 2s - loss: 0.3668 - accuracy: 0.9303 - val_loss: 1.6858 - val_accuracy: 0.6569
Epoch 96/110
 - 2s - loss: 0.3768 - accuracy: 0.9241 - val_loss: 1.5760 - val_accuracy: 0.6606
Epoch 97/110
 - 2s - loss: 0.3590 - accuracy: 0.9317 - val_loss: 1.6348 - val_accuracy: 0.6891
Epoch 98/110
 - 2s - loss: 0.3818 - accuracy: 0.9242 - val_loss: 1.5766 - val_accuracy: 0.6460
Epoch 99/110
 - 2s - loss: 0.4104 - accuracy: 0.9142 - val_loss: 1.6974 - val_accuracy: 0.6241
Epoch 100/110
 - 2s - loss: 0.3951 - accuracy: 0.9155 - val_loss: 1.5821 - val_accuracy: 0.6504
Epoch 101/110
 - 2s - loss: 0.3459 - accuracy: 0.9419 - val_loss: 1.5025 - val_accuracy: 0.6920
Epoch 102/110
 - 2s - loss: 0.3777 - accuracy: 0.9246 - val_loss: 1.6834 - val_accuracy: 0.6409
Epoch 103/110
 - 2s - loss: 0.3505 - accuracy: 0.9315 - val_loss: 1.6035 - val_accuracy: 0.6679
Epoch 104/110
 - 2s - loss: 0.3640 - accuracy: 0.9281 - val_loss: 1.5839 - val_accuracy: 0.6723
Epoch 105/110
 - 2s - loss: 0.3776 - accuracy: 0.9284 - val_loss: 1.6587 - val_accuracy: 0.6496
Epoch 106/110
 - 2s - loss: 0.3943 - accuracy: 0.9188 - val_loss: 1.5703 - val_accuracy: 0.6584
Epoch 107/110
 - 2s - loss: 0.3850 - accuracy: 0.9231 - val_loss: 1.6860 - val_accuracy: 0.6555
Epoch 108/110
 - 2s - loss: 0.3775 - accuracy: 0.9239 - val_loss: 1.5734 - val_accuracy: 0.6796
Epoch 109/110
 - 2s - loss: 0.3570 - accuracy: 0.9317 - val_loss: 1.5175 - val_accuracy: 0.6949
Epoch 110/110
 - 2s - loss: 0.3410 - accuracy: 0.9392 - val_loss: 1.5557 - val_accuracy: 0.6825

Number of filters: 16 , Kernel Size: 3 , Strides: 1 Batch Normalization: True , Conv_First: True , Depth Value: 20

Fit: epochs= 110 , batch_size= 64 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "model_67"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_67 (InputLayer)           (None, 10, 1)        0                                            
__________________________________________________________________________________________________
conv1d_1464 (Conv1D)            (None, 10, 16)       64          input_67[0][0]                   
__________________________________________________________________________________________________
batch_normalization_1255 (Batch (None, 10, 16)       64          conv1d_1464[0][0]                
__________________________________________________________________________________________________
activation_1409 (Activation)    (None, 10, 16)       0           batch_normalization_1255[0][0]   
__________________________________________________________________________________________________
conv1d_1465 (Conv1D)            (None, 10, 16)       784         activation_1409[0][0]            
__________________________________________________________________________________________________
batch_normalization_1256 (Batch (None, 10, 16)       64          conv1d_1465[0][0]                
__________________________________________________________________________________________________
activation_1410 (Activation)    (None, 10, 16)       0           batch_normalization_1256[0][0]   
__________________________________________________________________________________________________
conv1d_1466 (Conv1D)            (None, 10, 16)       784         activation_1410[0][0]            
__________________________________________________________________________________________________
batch_normalization_1257 (Batch (None, 10, 16)       64          conv1d_1466[0][0]                
__________________________________________________________________________________________________
add_595 (Add)                   (None, 10, 16)       0           activation_1409[0][0]            
                                                                 batch_normalization_1257[0][0]   
__________________________________________________________________________________________________
activation_1411 (Activation)    (None, 10, 16)       0           add_595[0][0]                    
__________________________________________________________________________________________________
conv1d_1467 (Conv1D)            (None, 10, 16)       784         activation_1411[0][0]            
__________________________________________________________________________________________________
batch_normalization_1258 (Batch (None, 10, 16)       64          conv1d_1467[0][0]                
__________________________________________________________________________________________________
activation_1412 (Activation)    (None, 10, 16)       0           batch_normalization_1258[0][0]   
__________________________________________________________________________________________________
conv1d_1468 (Conv1D)            (None, 10, 16)       784         activation_1412[0][0]            
__________________________________________________________________________________________________
batch_normalization_1259 (Batch (None, 10, 16)       64          conv1d_1468[0][0]                
__________________________________________________________________________________________________
add_596 (Add)                   (None, 10, 16)       0           activation_1411[0][0]            
                                                                 batch_normalization_1259[0][0]   
__________________________________________________________________________________________________
activation_1413 (Activation)    (None, 10, 16)       0           add_596[0][0]                    
__________________________________________________________________________________________________
conv1d_1469 (Conv1D)            (None, 10, 16)       784         activation_1413[0][0]            
__________________________________________________________________________________________________
batch_normalization_1260 (Batch (None, 10, 16)       64          conv1d_1469[0][0]                
__________________________________________________________________________________________________
activation_1414 (Activation)    (None, 10, 16)       0           batch_normalization_1260[0][0]   
__________________________________________________________________________________________________
conv1d_1470 (Conv1D)            (None, 10, 16)       784         activation_1414[0][0]            
__________________________________________________________________________________________________
batch_normalization_1261 (Batch (None, 10, 16)       64          conv1d_1470[0][0]                
__________________________________________________________________________________________________
add_597 (Add)                   (None, 10, 16)       0           activation_1413[0][0]            
                                                                 batch_normalization_1261[0][0]   
__________________________________________________________________________________________________
activation_1415 (Activation)    (None, 10, 16)       0           add_597[0][0]                    
__________________________________________________________________________________________________
conv1d_1471 (Conv1D)            (None, 5, 32)        1568        activation_1415[0][0]            
__________________________________________________________________________________________________
batch_normalization_1262 (Batch (None, 5, 32)        128         conv1d_1471[0][0]                
__________________________________________________________________________________________________
activation_1416 (Activation)    (None, 5, 32)        0           batch_normalization_1262[0][0]   
__________________________________________________________________________________________________
conv1d_1472 (Conv1D)            (None, 5, 32)        3104        activation_1416[0][0]            
__________________________________________________________________________________________________
conv1d_1473 (Conv1D)            (None, 5, 32)        544         activation_1415[0][0]            
__________________________________________________________________________________________________
batch_normalization_1263 (Batch (None, 5, 32)        128         conv1d_1472[0][0]                
__________________________________________________________________________________________________
add_598 (Add)                   (None, 5, 32)        0           conv1d_1473[0][0]                
                                                                 batch_normalization_1263[0][0]   
__________________________________________________________________________________________________
activation_1417 (Activation)    (None, 5, 32)        0           add_598[0][0]                    
__________________________________________________________________________________________________
conv1d_1474 (Conv1D)            (None, 5, 32)        3104        activation_1417[0][0]            
__________________________________________________________________________________________________
batch_normalization_1264 (Batch (None, 5, 32)        128         conv1d_1474[0][0]                
__________________________________________________________________________________________________
activation_1418 (Activation)    (None, 5, 32)        0           batch_normalization_1264[0][0]   
__________________________________________________________________________________________________
conv1d_1475 (Conv1D)            (None, 5, 32)        3104        activation_1418[0][0]            
__________________________________________________________________________________________________
batch_normalization_1265 (Batch (None, 5, 32)        128         conv1d_1475[0][0]                
__________________________________________________________________________________________________
add_599 (Add)                   (None, 5, 32)        0           activation_1417[0][0]            
                                                                 batch_normalization_1265[0][0]   
__________________________________________________________________________________________________
activation_1419 (Activation)    (None, 5, 32)        0           add_599[0][0]                    
__________________________________________________________________________________________________
conv1d_1476 (Conv1D)            (None, 5, 32)        3104        activation_1419[0][0]            
__________________________________________________________________________________________________
batch_normalization_1266 (Batch (None, 5, 32)        128         conv1d_1476[0][0]                
__________________________________________________________________________________________________
activation_1420 (Activation)    (None, 5, 32)        0           batch_normalization_1266[0][0]   
__________________________________________________________________________________________________
conv1d_1477 (Conv1D)            (None, 5, 32)        3104        activation_1420[0][0]            
__________________________________________________________________________________________________
batch_normalization_1267 (Batch (None, 5, 32)        128         conv1d_1477[0][0]                
__________________________________________________________________________________________________
add_600 (Add)                   (None, 5, 32)        0           activation_1419[0][0]            
                                                                 batch_normalization_1267[0][0]   
__________________________________________________________________________________________________
activation_1421 (Activation)    (None, 5, 32)        0           add_600[0][0]                    
__________________________________________________________________________________________________
conv1d_1478 (Conv1D)            (None, 3, 64)        6208        activation_1421[0][0]            
__________________________________________________________________________________________________
batch_normalization_1268 (Batch (None, 3, 64)        256         conv1d_1478[0][0]                
__________________________________________________________________________________________________
activation_1422 (Activation)    (None, 3, 64)        0           batch_normalization_1268[0][0]   
__________________________________________________________________________________________________
conv1d_1479 (Conv1D)            (None, 3, 64)        12352       activation_1422[0][0]            
__________________________________________________________________________________________________
conv1d_1480 (Conv1D)            (None, 3, 64)        2112        activation_1421[0][0]            
__________________________________________________________________________________________________
batch_normalization_1269 (Batch (None, 3, 64)        256         conv1d_1479[0][0]                
__________________________________________________________________________________________________
add_601 (Add)                   (None, 3, 64)        0           conv1d_1480[0][0]                
                                                                 batch_normalization_1269[0][0]   
__________________________________________________________________________________________________
activation_1423 (Activation)    (None, 3, 64)        0           add_601[0][0]                    
__________________________________________________________________________________________________
conv1d_1481 (Conv1D)            (None, 3, 64)        12352       activation_1423[0][0]            
__________________________________________________________________________________________________
batch_normalization_1270 (Batch (None, 3, 64)        256         conv1d_1481[0][0]                
__________________________________________________________________________________________________
activation_1424 (Activation)    (None, 3, 64)        0           batch_normalization_1270[0][0]   
__________________________________________________________________________________________________
conv1d_1482 (Conv1D)            (None, 3, 64)        12352       activation_1424[0][0]            
__________________________________________________________________________________________________
batch_normalization_1271 (Batch (None, 3, 64)        256         conv1d_1482[0][0]                
__________________________________________________________________________________________________
add_602 (Add)                   (None, 3, 64)        0           activation_1423[0][0]            
                                                                 batch_normalization_1271[0][0]   
__________________________________________________________________________________________________
activation_1425 (Activation)    (None, 3, 64)        0           add_602[0][0]                    
__________________________________________________________________________________________________
conv1d_1483 (Conv1D)            (None, 3, 64)        12352       activation_1425[0][0]            
__________________________________________________________________________________________________
batch_normalization_1272 (Batch (None, 3, 64)        256         conv1d_1483[0][0]                
__________________________________________________________________________________________________
activation_1426 (Activation)    (None, 3, 64)        0           batch_normalization_1272[0][0]   
__________________________________________________________________________________________________
conv1d_1484 (Conv1D)            (None, 3, 64)        12352       activation_1426[0][0]            
__________________________________________________________________________________________________
batch_normalization_1273 (Batch (None, 3, 64)        256         conv1d_1484[0][0]                
__________________________________________________________________________________________________
add_603 (Add)                   (None, 3, 64)        0           activation_1425[0][0]            
                                                                 batch_normalization_1273[0][0]   
__________________________________________________________________________________________________
activation_1427 (Activation)    (None, 3, 64)        0           add_603[0][0]                    
__________________________________________________________________________________________________
average_pooling1d_67 (AveragePo (None, 3, 64)        0           activation_1427[0][0]            
__________________________________________________________________________________________________
flatten_144 (Flatten)           (None, 192)          0           average_pooling1d_67[0][0]       
__________________________________________________________________________________________________
dense_2212 (Dense)              (None, 4)            772         flatten_144[0][0]                
==================================================================================================
Total params: 96,004
Trainable params: 94,628
Non-trainable params: 1,376
__________________________________________________________________________________________________
None

Accuracy Train: 76.11%
Accuracy Test: 67.35%
Loss Train: 1.00
Loss Test: 1.63
Numero dati esaminati: 1712
True Positive 1153
False Positive 559


------------------------------------------------------------------------
K-fold Cross Validation
------------------------------------------------------------------------
Training for fold 1 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 2s - loss: 0.3247 - accuracy: 0.9463 - val_loss: 1.6614 - val_accuracy: 0.6555
Epoch 2/110
 - 2s - loss: 0.3403 - accuracy: 0.9383 - val_loss: 1.6321 - val_accuracy: 0.6584
Epoch 3/110
 - 2s - loss: 0.3695 - accuracy: 0.9290 - val_loss: 1.5162 - val_accuracy: 0.6956
Epoch 4/110
 - 2s - loss: 0.3578 - accuracy: 0.9339 - val_loss: 1.5902 - val_accuracy: 0.6832
Epoch 5/110
 - 2s - loss: 0.3496 - accuracy: 0.9357 - val_loss: 1.5562 - val_accuracy: 0.6606
Epoch 6/110
 - 2s - loss: 0.3288 - accuracy: 0.9451 - val_loss: 1.7651 - val_accuracy: 0.6642
Epoch 7/110
 - 2s - loss: 0.3349 - accuracy: 0.9458 - val_loss: 1.6217 - val_accuracy: 0.6810
Epoch 8/110
 - 2s - loss: 0.3292 - accuracy: 0.9489 - val_loss: 1.7014 - val_accuracy: 0.6540
Epoch 9/110
 - 2s - loss: 0.3185 - accuracy: 0.9485 - val_loss: 1.7179 - val_accuracy: 0.6642
Epoch 10/110
 - 2s - loss: 0.3671 - accuracy: 0.9348 - val_loss: 1.6292 - val_accuracy: 0.6584
Epoch 11/110
 - 2s - loss: 0.3816 - accuracy: 0.9259 - val_loss: 1.6430 - val_accuracy: 0.6620
Epoch 12/110
 - 2s - loss: 0.3563 - accuracy: 0.9359 - val_loss: 1.6124 - val_accuracy: 0.6642
Epoch 13/110
 - 2s - loss: 0.3405 - accuracy: 0.9403 - val_loss: 1.6818 - val_accuracy: 0.6635
Epoch 14/110
 - 2s - loss: 0.3200 - accuracy: 0.9491 - val_loss: 1.6054 - val_accuracy: 0.6672
Epoch 15/110
 - 2s - loss: 0.3596 - accuracy: 0.9330 - val_loss: 1.7860 - val_accuracy: 0.6401
Epoch 16/110
 - 2s - loss: 0.3385 - accuracy: 0.9414 - val_loss: 1.6744 - val_accuracy: 0.6555
Epoch 17/110
 - 2s - loss: 0.3532 - accuracy: 0.9341 - val_loss: 1.6360 - val_accuracy: 0.6891
Epoch 18/110
 - 2s - loss: 0.3712 - accuracy: 0.9317 - val_loss: 1.6841 - val_accuracy: 0.6613
Epoch 19/110
 - 2s - loss: 0.3543 - accuracy: 0.9346 - val_loss: 1.6247 - val_accuracy: 0.6701
Epoch 20/110
 - 2s - loss: 0.3404 - accuracy: 0.9425 - val_loss: 1.6606 - val_accuracy: 0.6650
Epoch 21/110
 - 2s - loss: 0.3169 - accuracy: 0.9476 - val_loss: 1.7101 - val_accuracy: 0.6730
Epoch 22/110
 - 2s - loss: 0.3075 - accuracy: 0.9533 - val_loss: 1.7230 - val_accuracy: 0.6708
Epoch 23/110
 - 2s - loss: 0.3235 - accuracy: 0.9487 - val_loss: 1.7051 - val_accuracy: 0.6796
Epoch 24/110
 - 2s - loss: 0.3287 - accuracy: 0.9483 - val_loss: 1.6322 - val_accuracy: 0.6803
Epoch 25/110
 - 2s - loss: 0.3299 - accuracy: 0.9447 - val_loss: 1.7347 - val_accuracy: 0.6876
Epoch 26/110
 - 2s - loss: 0.3220 - accuracy: 0.9478 - val_loss: 1.7968 - val_accuracy: 0.6686
Epoch 27/110
 - 2s - loss: 0.3844 - accuracy: 0.9330 - val_loss: 1.7820 - val_accuracy: 0.6518
Epoch 28/110
 - 2s - loss: 0.4100 - accuracy: 0.9208 - val_loss: 1.6102 - val_accuracy: 0.6876
Epoch 29/110
 - 2s - loss: 0.3274 - accuracy: 0.9480 - val_loss: 1.5765 - val_accuracy: 0.6686
Epoch 30/110
 - 2s - loss: 0.3150 - accuracy: 0.9493 - val_loss: 1.5611 - val_accuracy: 0.6832
Epoch 31/110
 - 2s - loss: 0.3009 - accuracy: 0.9560 - val_loss: 1.5925 - val_accuracy: 0.6759
Epoch 32/110
 - 2s - loss: 0.3050 - accuracy: 0.9566 - val_loss: 1.6013 - val_accuracy: 0.6861
Epoch 33/110
 - 2s - loss: 0.3076 - accuracy: 0.9518 - val_loss: 1.5963 - val_accuracy: 0.6898
Epoch 34/110
 - 2s - loss: 0.2935 - accuracy: 0.9595 - val_loss: 1.7274 - val_accuracy: 0.6810
Epoch 35/110
 - 2s - loss: 0.2963 - accuracy: 0.9600 - val_loss: 1.7378 - val_accuracy: 0.6832
Epoch 36/110
 - 2s - loss: 0.3306 - accuracy: 0.9449 - val_loss: 1.7477 - val_accuracy: 0.6796
Epoch 37/110
 - 2s - loss: 0.3503 - accuracy: 0.9378 - val_loss: 1.8142 - val_accuracy: 0.6693
Epoch 38/110
 - 2s - loss: 0.3882 - accuracy: 0.9246 - val_loss: 1.8642 - val_accuracy: 0.6474
Epoch 39/110
 - 2s - loss: 0.3568 - accuracy: 0.9379 - val_loss: 1.6821 - val_accuracy: 0.6657
Epoch 40/110
 - 2s - loss: 0.3194 - accuracy: 0.9480 - val_loss: 1.6761 - val_accuracy: 0.6832
Epoch 41/110
 - 2s - loss: 0.2967 - accuracy: 0.9578 - val_loss: 1.6089 - val_accuracy: 0.6978
Epoch 42/110
 - 2s - loss: 0.2882 - accuracy: 0.9613 - val_loss: 1.7105 - val_accuracy: 0.6861
Epoch 43/110
 - 2s - loss: 0.3276 - accuracy: 0.9471 - val_loss: 1.8121 - val_accuracy: 0.6620
Epoch 44/110
 - 2s - loss: 0.3741 - accuracy: 0.9328 - val_loss: 1.7291 - val_accuracy: 0.6620
Epoch 45/110
 - 2s - loss: 0.3378 - accuracy: 0.9443 - val_loss: 1.6410 - val_accuracy: 0.6796
Epoch 46/110
 - 2s - loss: 0.3094 - accuracy: 0.9555 - val_loss: 1.6876 - val_accuracy: 0.6810
Epoch 47/110
 - 2s - loss: 0.3083 - accuracy: 0.9520 - val_loss: 1.7086 - val_accuracy: 0.6708
Epoch 48/110
 - 1s - loss: 0.3179 - accuracy: 0.9567 - val_loss: 1.7095 - val_accuracy: 0.6766
Epoch 49/110
 - 2s - loss: 0.3159 - accuracy: 0.9529 - val_loss: 1.6905 - val_accuracy: 0.7022
Epoch 50/110
 - 2s - loss: 0.2904 - accuracy: 0.9628 - val_loss: 1.7634 - val_accuracy: 0.6825
Epoch 51/110
 - 2s - loss: 0.2871 - accuracy: 0.9618 - val_loss: 1.7837 - val_accuracy: 0.6766
Epoch 52/110
 - 2s - loss: 0.3208 - accuracy: 0.9500 - val_loss: 1.8288 - val_accuracy: 0.6686
Epoch 53/110
 - 2s - loss: 0.3159 - accuracy: 0.9520 - val_loss: 1.7814 - val_accuracy: 0.6635
Epoch 54/110
 - 2s - loss: 0.3064 - accuracy: 0.9560 - val_loss: 1.7373 - val_accuracy: 0.6847
Epoch 55/110
 - 2s - loss: 0.3031 - accuracy: 0.9564 - val_loss: 1.6380 - val_accuracy: 0.6861
Epoch 56/110
 - 2s - loss: 0.3177 - accuracy: 0.9542 - val_loss: 1.7887 - val_accuracy: 0.6613
Epoch 57/110
 - 2s - loss: 0.3137 - accuracy: 0.9551 - val_loss: 1.6821 - val_accuracy: 0.6825
Epoch 58/110
 - 2s - loss: 0.3005 - accuracy: 0.9608 - val_loss: 1.7752 - val_accuracy: 0.6730
Epoch 59/110
 - 2s - loss: 0.2903 - accuracy: 0.9629 - val_loss: 1.7186 - val_accuracy: 0.6628
Epoch 60/110
 - 2s - loss: 0.3096 - accuracy: 0.9549 - val_loss: 1.8830 - val_accuracy: 0.6606
Epoch 61/110
 - 2s - loss: 0.3276 - accuracy: 0.9487 - val_loss: 1.7712 - val_accuracy: 0.6891
Epoch 62/110
 - 2s - loss: 0.3053 - accuracy: 0.9567 - val_loss: 1.7332 - val_accuracy: 0.6920
Epoch 63/110
 - 2s - loss: 0.2792 - accuracy: 0.9684 - val_loss: 1.7475 - val_accuracy: 0.6818
Epoch 64/110
 - 2s - loss: 0.2787 - accuracy: 0.9659 - val_loss: 1.7518 - val_accuracy: 0.6883
Epoch 65/110
 - 2s - loss: 0.2940 - accuracy: 0.9595 - val_loss: 1.8796 - val_accuracy: 0.6672
Epoch 66/110
 - 2s - loss: 0.3129 - accuracy: 0.9511 - val_loss: 1.7738 - val_accuracy: 0.6723
Epoch 67/110
 - 2s - loss: 0.2990 - accuracy: 0.9617 - val_loss: 1.7333 - val_accuracy: 0.6803
Epoch 68/110
 - 2s - loss: 0.2958 - accuracy: 0.9633 - val_loss: 1.9341 - val_accuracy: 0.6672
Epoch 69/110
 - 2s - loss: 0.3475 - accuracy: 0.9449 - val_loss: 1.8898 - val_accuracy: 0.6686
Epoch 70/110
 - 2s - loss: 0.3545 - accuracy: 0.9383 - val_loss: 1.8127 - val_accuracy: 0.6445
Epoch 71/110
 - 2s - loss: 0.3636 - accuracy: 0.9348 - val_loss: 1.8212 - val_accuracy: 0.6650
Epoch 72/110
 - 2s - loss: 0.3163 - accuracy: 0.9533 - val_loss: 1.7638 - val_accuracy: 0.6810
Epoch 73/110
 - 2s - loss: 0.3019 - accuracy: 0.9576 - val_loss: 1.5947 - val_accuracy: 0.6774
Epoch 74/110
 - 2s - loss: 0.3017 - accuracy: 0.9571 - val_loss: 1.6876 - val_accuracy: 0.6964
Epoch 75/110
 - 2s - loss: 0.2897 - accuracy: 0.9651 - val_loss: 1.7681 - val_accuracy: 0.6927
Epoch 76/110
 - 2s - loss: 0.2764 - accuracy: 0.9653 - val_loss: 1.7468 - val_accuracy: 0.6810
Epoch 77/110
 - 2s - loss: 0.2863 - accuracy: 0.9618 - val_loss: 1.8524 - val_accuracy: 0.6854
Epoch 78/110
 - 2s - loss: 0.2954 - accuracy: 0.9624 - val_loss: 1.8484 - val_accuracy: 0.6905
Epoch 79/110
 - 2s - loss: 0.2888 - accuracy: 0.9633 - val_loss: 1.7111 - val_accuracy: 0.6927
Epoch 80/110
 - 2s - loss: 0.2693 - accuracy: 0.9704 - val_loss: 1.7070 - val_accuracy: 0.6956
Epoch 81/110
 - 2s - loss: 0.2828 - accuracy: 0.9644 - val_loss: 1.7665 - val_accuracy: 0.6752
Epoch 82/110
 - 2s - loss: 0.2893 - accuracy: 0.9637 - val_loss: 1.7891 - val_accuracy: 0.7007
Epoch 83/110
 - 2s - loss: 0.3246 - accuracy: 0.9533 - val_loss: 1.8162 - val_accuracy: 0.6701
Epoch 84/110
 - 2s - loss: 0.3212 - accuracy: 0.9520 - val_loss: 1.6267 - val_accuracy: 0.6920
Epoch 85/110
 - 2s - loss: 0.2936 - accuracy: 0.9618 - val_loss: 1.7583 - val_accuracy: 0.6664
Epoch 86/110
 - 2s - loss: 0.2783 - accuracy: 0.9673 - val_loss: 1.7190 - val_accuracy: 0.7029
Epoch 87/110
 - 2s - loss: 0.2892 - accuracy: 0.9650 - val_loss: 1.8413 - val_accuracy: 0.6796
Epoch 88/110
 - 2s - loss: 0.2949 - accuracy: 0.9606 - val_loss: 1.8162 - val_accuracy: 0.6810
Epoch 89/110
 - 2s - loss: 0.2922 - accuracy: 0.9609 - val_loss: 1.6811 - val_accuracy: 0.6861
Epoch 90/110
 - 2s - loss: 0.3104 - accuracy: 0.9566 - val_loss: 1.7760 - val_accuracy: 0.6861
Epoch 91/110
 - 2s - loss: 0.2801 - accuracy: 0.9626 - val_loss: 1.8260 - val_accuracy: 0.6869
Epoch 92/110
 - 2s - loss: 0.2760 - accuracy: 0.9664 - val_loss: 1.7244 - val_accuracy: 0.7095
Epoch 93/110
 - 2s - loss: 0.2688 - accuracy: 0.9701 - val_loss: 1.8485 - val_accuracy: 0.6672
Epoch 94/110
 - 2s - loss: 0.3429 - accuracy: 0.9491 - val_loss: 1.8009 - val_accuracy: 0.6745
Epoch 95/110
 - 2s - loss: 0.3342 - accuracy: 0.9447 - val_loss: 1.7108 - val_accuracy: 0.6635
Epoch 96/110
 - 2s - loss: 0.3080 - accuracy: 0.9571 - val_loss: 1.7144 - val_accuracy: 0.6752
Epoch 97/110
 - 2s - loss: 0.2749 - accuracy: 0.9660 - val_loss: 1.7075 - val_accuracy: 0.6978
Epoch 98/110
 - 2s - loss: 0.2874 - accuracy: 0.9673 - val_loss: 1.8853 - val_accuracy: 0.6869
Epoch 99/110
 - 2s - loss: 0.2704 - accuracy: 0.9721 - val_loss: 1.7928 - val_accuracy: 0.6847
Epoch 100/110
 - 2s - loss: 0.2751 - accuracy: 0.9691 - val_loss: 1.7767 - val_accuracy: 0.6810
Epoch 101/110
 - 2s - loss: 0.3021 - accuracy: 0.9609 - val_loss: 1.6881 - val_accuracy: 0.6927
Epoch 102/110
 - 2s - loss: 0.3386 - accuracy: 0.9471 - val_loss: 1.8613 - val_accuracy: 0.6730
Epoch 103/110
 - 2s - loss: 0.3504 - accuracy: 0.9425 - val_loss: 1.6878 - val_accuracy: 0.6912
Epoch 104/110
 - 2s - loss: 0.3177 - accuracy: 0.9571 - val_loss: 1.6760 - val_accuracy: 0.6971
Epoch 105/110
 - 2s - loss: 0.2710 - accuracy: 0.9706 - val_loss: 1.6073 - val_accuracy: 0.7058
Epoch 106/110
 - 2s - loss: 0.2616 - accuracy: 0.9728 - val_loss: 1.6429 - val_accuracy: 0.6985
Epoch 107/110
 - 2s - loss: 0.2432 - accuracy: 0.9808 - val_loss: 1.6209 - val_accuracy: 0.7153
Epoch 108/110
 - 2s - loss: 0.2494 - accuracy: 0.9799 - val_loss: 1.7580 - val_accuracy: 0.6876
Epoch 109/110
 - 2s - loss: 0.2702 - accuracy: 0.9719 - val_loss: 1.7332 - val_accuracy: 0.6971
Epoch 110/110
 - 2s - loss: 0.2849 - accuracy: 0.9637 - val_loss: 1.6652 - val_accuracy: 0.7036
------------------------------------------------------------------------
Training for fold 2 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 2s - loss: 0.3193 - accuracy: 0.9551 - val_loss: 1.8570 - val_accuracy: 0.6686
Epoch 2/110
 - 2s - loss: 0.3372 - accuracy: 0.9463 - val_loss: 1.6256 - val_accuracy: 0.6985
Epoch 3/110
 - 2s - loss: 0.3155 - accuracy: 0.9533 - val_loss: 1.6622 - val_accuracy: 0.6934
Epoch 4/110
 - 2s - loss: 0.2724 - accuracy: 0.9704 - val_loss: 1.6886 - val_accuracy: 0.6971
Epoch 5/110
 - 2s - loss: 0.2449 - accuracy: 0.9796 - val_loss: 1.5936 - val_accuracy: 0.7044
Epoch 6/110
 - 2s - loss: 0.2613 - accuracy: 0.9717 - val_loss: 1.6833 - val_accuracy: 0.7088
Epoch 7/110
 - 2s - loss: 0.2591 - accuracy: 0.9726 - val_loss: 1.6951 - val_accuracy: 0.7095
Epoch 8/110
 - 2s - loss: 0.2966 - accuracy: 0.9613 - val_loss: 1.7094 - val_accuracy: 0.6876
Epoch 9/110
 - 2s - loss: 0.2916 - accuracy: 0.9595 - val_loss: 1.8632 - val_accuracy: 0.6861
Epoch 10/110
 - 2s - loss: 0.3077 - accuracy: 0.9573 - val_loss: 1.7224 - val_accuracy: 0.6876
Epoch 11/110
 - 2s - loss: 0.3107 - accuracy: 0.9555 - val_loss: 1.8541 - val_accuracy: 0.6693
Epoch 12/110
 - 2s - loss: 0.2876 - accuracy: 0.9637 - val_loss: 1.7731 - val_accuracy: 0.6956
Epoch 13/110
 - 2s - loss: 0.3085 - accuracy: 0.9569 - val_loss: 1.8305 - val_accuracy: 0.6664
Epoch 14/110
 - 2s - loss: 0.3133 - accuracy: 0.9564 - val_loss: 1.6139 - val_accuracy: 0.7007
Epoch 15/110
 - 2s - loss: 0.3040 - accuracy: 0.9586 - val_loss: 1.6783 - val_accuracy: 0.6847
Epoch 16/110
 - 2s - loss: 0.2873 - accuracy: 0.9651 - val_loss: 1.5807 - val_accuracy: 0.6883
Epoch 17/110
 - 2s - loss: 0.2656 - accuracy: 0.9693 - val_loss: 1.7613 - val_accuracy: 0.6883
Epoch 18/110
 - 2s - loss: 0.2617 - accuracy: 0.9752 - val_loss: 1.7342 - val_accuracy: 0.7051
Epoch 19/110
 - 2s - loss: 0.2533 - accuracy: 0.9752 - val_loss: 1.7178 - val_accuracy: 0.7000
Epoch 20/110
 - 2s - loss: 0.2596 - accuracy: 0.9726 - val_loss: 1.7267 - val_accuracy: 0.7036
Epoch 21/110
 - 1s - loss: 0.3043 - accuracy: 0.9664 - val_loss: 1.8193 - val_accuracy: 0.6701
Epoch 22/110
 - 1s - loss: 0.3469 - accuracy: 0.9427 - val_loss: 1.7587 - val_accuracy: 0.6883
Epoch 23/110
 - 2s - loss: 0.3031 - accuracy: 0.9611 - val_loss: 1.5804 - val_accuracy: 0.6964
Epoch 24/110
 - 2s - loss: 0.2919 - accuracy: 0.9642 - val_loss: 1.7259 - val_accuracy: 0.6861
Epoch 25/110
 - 2s - loss: 0.2570 - accuracy: 0.9748 - val_loss: 1.6938 - val_accuracy: 0.7131
Epoch 26/110
 - 2s - loss: 0.2616 - accuracy: 0.9730 - val_loss: 1.7030 - val_accuracy: 0.7029
Epoch 27/110
 - 2s - loss: 0.2480 - accuracy: 0.9766 - val_loss: 1.6589 - val_accuracy: 0.7102
Epoch 28/110
 - 2s - loss: 0.2546 - accuracy: 0.9746 - val_loss: 1.6902 - val_accuracy: 0.7109
Epoch 29/110
 - 2s - loss: 0.2422 - accuracy: 0.9796 - val_loss: 1.7412 - val_accuracy: 0.7000
Epoch 30/110
 - 2s - loss: 0.2785 - accuracy: 0.9688 - val_loss: 1.7924 - val_accuracy: 0.6854
Epoch 31/110
 - 2s - loss: 0.3077 - accuracy: 0.9544 - val_loss: 1.6833 - val_accuracy: 0.7000
Epoch 32/110
 - 2s - loss: 0.2957 - accuracy: 0.9600 - val_loss: 1.8248 - val_accuracy: 0.6708
Epoch 33/110
 - 2s - loss: 0.3422 - accuracy: 0.9456 - val_loss: 1.6603 - val_accuracy: 0.6964
Epoch 34/110
 - 2s - loss: 0.3046 - accuracy: 0.9587 - val_loss: 1.6765 - val_accuracy: 0.6898
Epoch 35/110
 - 2s - loss: 0.2781 - accuracy: 0.9684 - val_loss: 1.6679 - val_accuracy: 0.6956
Epoch 36/110
 - 2s - loss: 0.2690 - accuracy: 0.9739 - val_loss: 1.7138 - val_accuracy: 0.7007
Epoch 37/110
 - 2s - loss: 0.2522 - accuracy: 0.9768 - val_loss: 1.7340 - val_accuracy: 0.6934
Epoch 38/110
 - 2s - loss: 0.2875 - accuracy: 0.9664 - val_loss: 1.7593 - val_accuracy: 0.6825
Epoch 39/110
 - 2s - loss: 0.3143 - accuracy: 0.9567 - val_loss: 1.6578 - val_accuracy: 0.6832
Epoch 40/110
 - 2s - loss: 0.2682 - accuracy: 0.9715 - val_loss: 1.7406 - val_accuracy: 0.6876
Epoch 41/110
 - 2s - loss: 0.2440 - accuracy: 0.9803 - val_loss: 1.7697 - val_accuracy: 0.7022
Epoch 42/110
 - 2s - loss: 0.2633 - accuracy: 0.9704 - val_loss: 1.7082 - val_accuracy: 0.7095
Epoch 43/110
 - 2s - loss: 0.2715 - accuracy: 0.9715 - val_loss: 1.6834 - val_accuracy: 0.6920
Epoch 44/110
 - 2s - loss: 0.2936 - accuracy: 0.9624 - val_loss: 1.7064 - val_accuracy: 0.6934
Epoch 45/110
 - 2s - loss: 0.2735 - accuracy: 0.9681 - val_loss: 1.5910 - val_accuracy: 0.7044
Epoch 46/110
 - 2s - loss: 0.2883 - accuracy: 0.9642 - val_loss: 1.8296 - val_accuracy: 0.7109
Epoch 47/110
 - 2s - loss: 0.2952 - accuracy: 0.9615 - val_loss: 1.6054 - val_accuracy: 0.7022
Epoch 48/110
 - 2s - loss: 0.3116 - accuracy: 0.9566 - val_loss: 1.7324 - val_accuracy: 0.6788
Epoch 49/110
 - 2s - loss: 0.2937 - accuracy: 0.9633 - val_loss: 1.6161 - val_accuracy: 0.7168
Epoch 50/110
 - 2s - loss: 0.2893 - accuracy: 0.9650 - val_loss: 1.7044 - val_accuracy: 0.6956
Epoch 51/110
 - 2s - loss: 0.2733 - accuracy: 0.9681 - val_loss: 1.7714 - val_accuracy: 0.6956
Epoch 52/110
 - 2s - loss: 0.2551 - accuracy: 0.9763 - val_loss: 1.7177 - val_accuracy: 0.7080
Epoch 53/110
 - 2s - loss: 0.2546 - accuracy: 0.9739 - val_loss: 1.8450 - val_accuracy: 0.6942
Epoch 54/110
 - 2s - loss: 0.2810 - accuracy: 0.9666 - val_loss: 1.7233 - val_accuracy: 0.6964
Epoch 55/110
 - 2s - loss: 0.2488 - accuracy: 0.9786 - val_loss: 1.7425 - val_accuracy: 0.7153
Epoch 56/110
 - 2s - loss: 0.2388 - accuracy: 0.9796 - val_loss: 1.6352 - val_accuracy: 0.7073
Epoch 57/110
 - 2s - loss: 0.2464 - accuracy: 0.9765 - val_loss: 1.7380 - val_accuracy: 0.7182
Epoch 58/110
 - 2s - loss: 0.2544 - accuracy: 0.9739 - val_loss: 2.0151 - val_accuracy: 0.6956
Epoch 59/110
 - 2s - loss: 0.3209 - accuracy: 0.9505 - val_loss: 2.2486 - val_accuracy: 0.6642
Epoch 60/110
 - 2s - loss: 0.3917 - accuracy: 0.9330 - val_loss: 1.8831 - val_accuracy: 0.6766
Epoch 61/110
 - 2s - loss: 0.3404 - accuracy: 0.9410 - val_loss: 1.7307 - val_accuracy: 0.6781
Epoch 62/110
 - 2s - loss: 0.2827 - accuracy: 0.9644 - val_loss: 1.8123 - val_accuracy: 0.6730
Epoch 63/110
 - 2s - loss: 0.2451 - accuracy: 0.9777 - val_loss: 1.7012 - val_accuracy: 0.6891
Epoch 64/110
 - 2s - loss: 0.2423 - accuracy: 0.9794 - val_loss: 1.6520 - val_accuracy: 0.7051
Epoch 65/110
 - 2s - loss: 0.2497 - accuracy: 0.9785 - val_loss: 1.8390 - val_accuracy: 0.7022
Epoch 66/110
 - 2s - loss: 0.2635 - accuracy: 0.9741 - val_loss: 1.7552 - val_accuracy: 0.7044
Epoch 67/110
 - 2s - loss: 0.2573 - accuracy: 0.9759 - val_loss: 1.7166 - val_accuracy: 0.6964
Epoch 68/110
 - 2s - loss: 0.2715 - accuracy: 0.9699 - val_loss: 1.7523 - val_accuracy: 0.7095
Epoch 69/110
 - 2s - loss: 0.2425 - accuracy: 0.9790 - val_loss: 1.7426 - val_accuracy: 0.6956
Epoch 70/110
 - 2s - loss: 0.2330 - accuracy: 0.9839 - val_loss: 1.6753 - val_accuracy: 0.7102
Epoch 71/110
 - 2s - loss: 0.2328 - accuracy: 0.9823 - val_loss: 1.6639 - val_accuracy: 0.7139
Epoch 72/110
 - 2s - loss: 0.2321 - accuracy: 0.9814 - val_loss: 1.7139 - val_accuracy: 0.7036
Epoch 73/110
 - 2s - loss: 0.2363 - accuracy: 0.9803 - val_loss: 1.6719 - val_accuracy: 0.7146
Epoch 74/110
 - 2s - loss: 0.2487 - accuracy: 0.9781 - val_loss: 1.8694 - val_accuracy: 0.7080
Epoch 75/110
 - 2s - loss: 0.3167 - accuracy: 0.9525 - val_loss: 1.9421 - val_accuracy: 0.6445
Epoch 76/110
 - 2s - loss: 0.3973 - accuracy: 0.9306 - val_loss: 1.6795 - val_accuracy: 0.6876
Epoch 77/110
 - 2s - loss: 0.3424 - accuracy: 0.9452 - val_loss: 1.8345 - val_accuracy: 0.6883
Epoch 78/110
 - 2s - loss: 0.3096 - accuracy: 0.9571 - val_loss: 1.6657 - val_accuracy: 0.6985
Epoch 79/110
 - 2s - loss: 0.2888 - accuracy: 0.9635 - val_loss: 1.7175 - val_accuracy: 0.6847
Epoch 80/110
 - 2s - loss: 0.2661 - accuracy: 0.9704 - val_loss: 1.6952 - val_accuracy: 0.7102
Epoch 81/110
 - 2s - loss: 0.2322 - accuracy: 0.9825 - val_loss: 1.5700 - val_accuracy: 0.7285
Epoch 82/110
 - 2s - loss: 0.2206 - accuracy: 0.9865 - val_loss: 1.8129 - val_accuracy: 0.7124
Epoch 83/110
 - 2s - loss: 0.2384 - accuracy: 0.9801 - val_loss: 1.9540 - val_accuracy: 0.6876
Epoch 84/110
 - 2s - loss: 0.2483 - accuracy: 0.9781 - val_loss: 1.7632 - val_accuracy: 0.6920
Epoch 85/110
 - 2s - loss: 0.2388 - accuracy: 0.9799 - val_loss: 1.6903 - val_accuracy: 0.7109
Epoch 86/110
 - 2s - loss: 0.2395 - accuracy: 0.9799 - val_loss: 1.7777 - val_accuracy: 0.6985
Epoch 87/110
 - 2s - loss: 0.2873 - accuracy: 0.9642 - val_loss: 2.2096 - val_accuracy: 0.6693
Epoch 88/110
 - 2s - loss: 0.4197 - accuracy: 0.9208 - val_loss: 1.9738 - val_accuracy: 0.6131
Epoch 89/110
 - 2s - loss: 0.4304 - accuracy: 0.9164 - val_loss: 1.6035 - val_accuracy: 0.6774
Epoch 90/110
 - 2s - loss: 0.2870 - accuracy: 0.9660 - val_loss: 1.5846 - val_accuracy: 0.7146
Epoch 91/110
 - 1s - loss: 0.2541 - accuracy: 0.9765 - val_loss: 1.5233 - val_accuracy: 0.7197
Epoch 92/110
 - 2s - loss: 0.2221 - accuracy: 0.9859 - val_loss: 1.5351 - val_accuracy: 0.7350
Epoch 93/110
 - 2s - loss: 0.2148 - accuracy: 0.9870 - val_loss: 1.5545 - val_accuracy: 0.7248
Epoch 94/110
 - 2s - loss: 0.2171 - accuracy: 0.9863 - val_loss: 1.6101 - val_accuracy: 0.7161
Epoch 95/110
 - 2s - loss: 0.2290 - accuracy: 0.9854 - val_loss: 1.5749 - val_accuracy: 0.7248
Epoch 96/110
 - 2s - loss: 0.2219 - accuracy: 0.9845 - val_loss: 1.6778 - val_accuracy: 0.7124
Epoch 97/110
 - 2s - loss: 0.2455 - accuracy: 0.9755 - val_loss: 1.6590 - val_accuracy: 0.6978
Epoch 98/110
 - 2s - loss: 0.2714 - accuracy: 0.9673 - val_loss: 1.7726 - val_accuracy: 0.6752
Epoch 99/110
 - 1s - loss: 0.2717 - accuracy: 0.9670 - val_loss: 1.8817 - val_accuracy: 0.6818
Epoch 100/110
 - 2s - loss: 0.2921 - accuracy: 0.9600 - val_loss: 1.7958 - val_accuracy: 0.6693
Epoch 101/110
 - 2s - loss: 0.3122 - accuracy: 0.9562 - val_loss: 1.5908 - val_accuracy: 0.6803
Epoch 102/110
 - 2s - loss: 0.2893 - accuracy: 0.9622 - val_loss: 1.6631 - val_accuracy: 0.6978
Epoch 103/110
 - 2s - loss: 0.2746 - accuracy: 0.9644 - val_loss: 1.8596 - val_accuracy: 0.6664
Epoch 104/110
 - 2s - loss: 0.2701 - accuracy: 0.9690 - val_loss: 1.7919 - val_accuracy: 0.6891
Epoch 105/110
 - 2s - loss: 0.2791 - accuracy: 0.9664 - val_loss: 1.6520 - val_accuracy: 0.7051
Epoch 106/110
 - 2s - loss: 0.2532 - accuracy: 0.9739 - val_loss: 1.7122 - val_accuracy: 0.6752
Epoch 107/110
 - 2s - loss: 0.2568 - accuracy: 0.9737 - val_loss: 1.6825 - val_accuracy: 0.7153
Epoch 108/110
 - 2s - loss: 0.2475 - accuracy: 0.9739 - val_loss: 1.7198 - val_accuracy: 0.7036
Epoch 109/110
 - 2s - loss: 0.2838 - accuracy: 0.9655 - val_loss: 1.8119 - val_accuracy: 0.6752
Epoch 110/110
 - 2s - loss: 0.2686 - accuracy: 0.9690 - val_loss: 1.8931 - val_accuracy: 0.6715
------------------------------------------------------------------------
Training for fold 3 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 2s - loss: 0.2434 - accuracy: 0.9774 - val_loss: 1.7019 - val_accuracy: 0.7000
Epoch 2/110
 - 2s - loss: 0.2567 - accuracy: 0.9728 - val_loss: 1.7126 - val_accuracy: 0.7102
Epoch 3/110
 - 2s - loss: 0.2385 - accuracy: 0.9768 - val_loss: 1.6914 - val_accuracy: 0.7197
Epoch 4/110
 - 2s - loss: 0.2249 - accuracy: 0.9834 - val_loss: 1.7258 - val_accuracy: 0.7044
Epoch 5/110
 - 2s - loss: 0.2294 - accuracy: 0.9814 - val_loss: 1.7751 - val_accuracy: 0.7161
Epoch 6/110
 - 2s - loss: 0.2316 - accuracy: 0.9810 - val_loss: 1.7295 - val_accuracy: 0.7212
Epoch 7/110
 - 2s - loss: 0.2659 - accuracy: 0.9693 - val_loss: 1.7489 - val_accuracy: 0.6985
Epoch 8/110
 - 2s - loss: 0.3317 - accuracy: 0.9507 - val_loss: 1.8769 - val_accuracy: 0.6737
Epoch 9/110
 - 2s - loss: 0.3506 - accuracy: 0.9418 - val_loss: 1.7297 - val_accuracy: 0.6883
Epoch 10/110
 - 2s - loss: 0.3065 - accuracy: 0.9566 - val_loss: 1.6810 - val_accuracy: 0.6642
Epoch 11/110
 - 2s - loss: 0.2825 - accuracy: 0.9648 - val_loss: 1.5508 - val_accuracy: 0.6942
Epoch 12/110
 - 2s - loss: 0.2396 - accuracy: 0.9808 - val_loss: 1.6429 - val_accuracy: 0.7058
Epoch 13/110
 - 2s - loss: 0.2345 - accuracy: 0.9794 - val_loss: 1.6307 - val_accuracy: 0.7124
Epoch 14/110
 - 2s - loss: 0.2230 - accuracy: 0.9845 - val_loss: 1.6114 - val_accuracy: 0.7219
Epoch 15/110
 - 2s - loss: 0.2621 - accuracy: 0.9710 - val_loss: 1.6922 - val_accuracy: 0.6898
Epoch 16/110
 - 2s - loss: 0.2630 - accuracy: 0.9699 - val_loss: 1.7305 - val_accuracy: 0.7058
Epoch 17/110
 - 1s - loss: 0.2413 - accuracy: 0.9770 - val_loss: 1.5695 - val_accuracy: 0.7146
Epoch 18/110
 - 2s - loss: 0.2247 - accuracy: 0.9832 - val_loss: 1.6110 - val_accuracy: 0.7204
Epoch 19/110
 - 2s - loss: 0.2422 - accuracy: 0.9775 - val_loss: 1.6539 - val_accuracy: 0.7241
Epoch 20/110
 - 2s - loss: 0.2635 - accuracy: 0.9739 - val_loss: 1.6905 - val_accuracy: 0.7051
Epoch 21/110
 - 2s - loss: 0.3313 - accuracy: 0.9503 - val_loss: 1.7605 - val_accuracy: 0.6803
Epoch 22/110
 - 2s - loss: 0.3814 - accuracy: 0.9317 - val_loss: 1.9280 - val_accuracy: 0.6591
Epoch 23/110
 - 2s - loss: 0.3339 - accuracy: 0.9440 - val_loss: 1.6574 - val_accuracy: 0.6796
Epoch 24/110
 - 2s - loss: 0.2631 - accuracy: 0.9706 - val_loss: 1.6010 - val_accuracy: 0.7073
Epoch 25/110
 - 2s - loss: 0.2500 - accuracy: 0.9748 - val_loss: 1.6099 - val_accuracy: 0.6964
Epoch 26/110
 - 2s - loss: 0.2320 - accuracy: 0.9821 - val_loss: 1.6090 - val_accuracy: 0.7241
Epoch 27/110
 - 2s - loss: 0.2170 - accuracy: 0.9858 - val_loss: 1.6492 - val_accuracy: 0.7161
Epoch 28/110
 - 2s - loss: 0.2186 - accuracy: 0.9856 - val_loss: 1.6099 - val_accuracy: 0.7073
Epoch 29/110
 - 2s - loss: 0.2203 - accuracy: 0.9848 - val_loss: 1.7147 - val_accuracy: 0.7036
Epoch 30/110
 - 2s - loss: 0.2354 - accuracy: 0.9781 - val_loss: 1.7342 - val_accuracy: 0.7314
Epoch 31/110
 - 2s - loss: 0.2406 - accuracy: 0.9794 - val_loss: 1.6565 - val_accuracy: 0.7146
Epoch 32/110
 - 2s - loss: 0.2321 - accuracy: 0.9823 - val_loss: 1.6623 - val_accuracy: 0.7175
Epoch 33/110
 - 2s - loss: 0.2224 - accuracy: 0.9814 - val_loss: 1.6500 - val_accuracy: 0.7204
Epoch 34/110
 - 2s - loss: 0.2341 - accuracy: 0.9803 - val_loss: 1.6591 - val_accuracy: 0.7161
Epoch 35/110
 - 2s - loss: 0.2293 - accuracy: 0.9817 - val_loss: 1.6326 - val_accuracy: 0.7263
Epoch 36/110
 - 2s - loss: 0.2477 - accuracy: 0.9779 - val_loss: 1.6650 - val_accuracy: 0.6956
Epoch 37/110
 - 2s - loss: 0.2739 - accuracy: 0.9673 - val_loss: 1.7468 - val_accuracy: 0.6701
Epoch 38/110
 - 2s - loss: 0.4570 - accuracy: 0.9120 - val_loss: 1.6665 - val_accuracy: 0.6679
Epoch 39/110
 - 2s - loss: 0.3712 - accuracy: 0.9346 - val_loss: 1.6682 - val_accuracy: 0.6540
Epoch 40/110
 - 2s - loss: 0.2963 - accuracy: 0.9576 - val_loss: 1.5724 - val_accuracy: 0.7102
Epoch 41/110
 - 2s - loss: 0.2554 - accuracy: 0.9732 - val_loss: 1.6262 - val_accuracy: 0.6971
Epoch 42/110
 - 2s - loss: 0.2392 - accuracy: 0.9783 - val_loss: 1.6285 - val_accuracy: 0.7073
Epoch 43/110
 - 2s - loss: 0.2382 - accuracy: 0.9790 - val_loss: 1.6310 - val_accuracy: 0.7161
Epoch 44/110
 - 2s - loss: 0.2203 - accuracy: 0.9841 - val_loss: 1.6144 - val_accuracy: 0.7146
Epoch 45/110
 - 2s - loss: 0.2183 - accuracy: 0.9847 - val_loss: 1.6421 - val_accuracy: 0.7058
Epoch 46/110
 - 2s - loss: 0.2405 - accuracy: 0.9765 - val_loss: 1.6810 - val_accuracy: 0.7007
Epoch 47/110
 - 2s - loss: 0.2626 - accuracy: 0.9706 - val_loss: 1.7312 - val_accuracy: 0.6912
Epoch 48/110
 - 2s - loss: 0.2482 - accuracy: 0.9755 - val_loss: 1.6004 - val_accuracy: 0.7102
Epoch 49/110
 - 2s - loss: 0.2342 - accuracy: 0.9796 - val_loss: 1.5681 - val_accuracy: 0.7263
Epoch 50/110
 - 2s - loss: 0.2299 - accuracy: 0.9803 - val_loss: 1.6657 - val_accuracy: 0.7117
Epoch 51/110
 - 2s - loss: 0.2348 - accuracy: 0.9779 - val_loss: 1.6464 - val_accuracy: 0.7182
Epoch 52/110
 - 2s - loss: 0.2581 - accuracy: 0.9712 - val_loss: 1.6026 - val_accuracy: 0.7153
Epoch 53/110
 - 2s - loss: 0.2279 - accuracy: 0.9816 - val_loss: 1.7111 - val_accuracy: 0.7197
Epoch 54/110
 - 2s - loss: 0.2310 - accuracy: 0.9803 - val_loss: 1.7546 - val_accuracy: 0.6818
Epoch 55/110
 - 2s - loss: 0.3030 - accuracy: 0.9580 - val_loss: 1.6476 - val_accuracy: 0.6803
Epoch 56/110
 - 2s - loss: 0.2959 - accuracy: 0.9635 - val_loss: 1.5874 - val_accuracy: 0.6993
Epoch 57/110
 - 1s - loss: 0.2839 - accuracy: 0.9650 - val_loss: 1.7780 - val_accuracy: 0.6861
Epoch 58/110
 - 2s - loss: 0.2698 - accuracy: 0.9695 - val_loss: 1.8285 - val_accuracy: 0.6825
Epoch 59/110
 - 2s - loss: 0.2689 - accuracy: 0.9686 - val_loss: 1.6854 - val_accuracy: 0.7044
Epoch 60/110
 - 2s - loss: 0.2595 - accuracy: 0.9741 - val_loss: 1.6508 - val_accuracy: 0.7109
Epoch 61/110
 - 2s - loss: 0.2247 - accuracy: 0.9808 - val_loss: 1.6190 - val_accuracy: 0.7146
Epoch 62/110
 - 2s - loss: 0.2261 - accuracy: 0.9825 - val_loss: 1.6592 - val_accuracy: 0.7168
Epoch 63/110
 - 2s - loss: 0.2153 - accuracy: 0.9856 - val_loss: 1.6752 - val_accuracy: 0.7146
Epoch 64/110
 - 2s - loss: 0.2423 - accuracy: 0.9775 - val_loss: 1.6534 - val_accuracy: 0.7066
Epoch 65/110
 - 2s - loss: 0.2354 - accuracy: 0.9792 - val_loss: 1.6293 - val_accuracy: 0.7088
Epoch 66/110
 - 2s - loss: 0.2728 - accuracy: 0.9679 - val_loss: 1.7263 - val_accuracy: 0.6723
Epoch 67/110
 - 2s - loss: 0.3299 - accuracy: 0.9503 - val_loss: 1.6483 - val_accuracy: 0.6861
Epoch 68/110
 - 2s - loss: 0.3066 - accuracy: 0.9549 - val_loss: 1.6148 - val_accuracy: 0.6905
Epoch 69/110
 - 1s - loss: 0.2796 - accuracy: 0.9600 - val_loss: 1.5535 - val_accuracy: 0.7161
Epoch 70/110
 - 2s - loss: 0.2367 - accuracy: 0.9777 - val_loss: 1.5369 - val_accuracy: 0.7117
Epoch 71/110
 - 2s - loss: 0.2227 - accuracy: 0.9823 - val_loss: 1.5425 - val_accuracy: 0.7117
Epoch 72/110
 - 1s - loss: 0.2396 - accuracy: 0.9786 - val_loss: 1.6205 - val_accuracy: 0.7263
Epoch 73/110
 - 2s - loss: 0.2450 - accuracy: 0.9763 - val_loss: 1.5981 - val_accuracy: 0.6949
Epoch 74/110
 - 2s - loss: 0.2616 - accuracy: 0.9704 - val_loss: 1.5775 - val_accuracy: 0.7146
Epoch 75/110
 - 2s - loss: 0.2415 - accuracy: 0.9774 - val_loss: 1.7012 - val_accuracy: 0.7044
Epoch 76/110
 - 2s - loss: 0.2320 - accuracy: 0.9794 - val_loss: 1.7432 - val_accuracy: 0.7095
Epoch 77/110
 - 2s - loss: 0.2742 - accuracy: 0.9637 - val_loss: 1.7753 - val_accuracy: 0.6971
Epoch 78/110
 - 2s - loss: 0.2735 - accuracy: 0.9691 - val_loss: 1.6889 - val_accuracy: 0.7124
Epoch 79/110
 - 2s - loss: 0.2589 - accuracy: 0.9712 - val_loss: 1.6047 - val_accuracy: 0.6905
Epoch 80/110
 - 2s - loss: 0.2707 - accuracy: 0.9695 - val_loss: 1.6214 - val_accuracy: 0.7088
Epoch 81/110
 - 2s - loss: 0.2424 - accuracy: 0.9763 - val_loss: 1.7426 - val_accuracy: 0.7007
Epoch 82/110
 - 2s - loss: 0.2443 - accuracy: 0.9783 - val_loss: 1.6662 - val_accuracy: 0.7029
Epoch 83/110
 - 2s - loss: 0.2337 - accuracy: 0.9781 - val_loss: 1.5863 - val_accuracy: 0.7204
Epoch 84/110
 - 2s - loss: 0.2614 - accuracy: 0.9706 - val_loss: 1.7020 - val_accuracy: 0.7095
Epoch 85/110
 - 2s - loss: 0.2585 - accuracy: 0.9708 - val_loss: 1.7217 - val_accuracy: 0.7139
Epoch 86/110
 - 2s - loss: 0.2382 - accuracy: 0.9785 - val_loss: 1.7781 - val_accuracy: 0.7029
Epoch 87/110
 - 2s - loss: 0.2597 - accuracy: 0.9719 - val_loss: 1.6883 - val_accuracy: 0.7234
Epoch 88/110
 - 2s - loss: 0.2462 - accuracy: 0.9746 - val_loss: 1.6096 - val_accuracy: 0.7416
Epoch 89/110
 - 2s - loss: 0.2506 - accuracy: 0.9766 - val_loss: 1.7664 - val_accuracy: 0.6861
Epoch 90/110
 - 2s - loss: 0.2680 - accuracy: 0.9679 - val_loss: 1.7198 - val_accuracy: 0.7029
Epoch 91/110
 - 2s - loss: 0.2645 - accuracy: 0.9702 - val_loss: 1.6627 - val_accuracy: 0.7109
Epoch 92/110
 - 2s - loss: 0.2480 - accuracy: 0.9741 - val_loss: 1.7024 - val_accuracy: 0.7095
Epoch 93/110
 - 2s - loss: 0.2414 - accuracy: 0.9754 - val_loss: 1.7619 - val_accuracy: 0.6876
Epoch 94/110
 - 2s - loss: 0.2485 - accuracy: 0.9737 - val_loss: 1.7625 - val_accuracy: 0.7022
Epoch 95/110
 - 2s - loss: 0.2515 - accuracy: 0.9743 - val_loss: 1.6213 - val_accuracy: 0.7263
Epoch 96/110
 - 2s - loss: 0.2437 - accuracy: 0.9775 - val_loss: 1.7014 - val_accuracy: 0.7015
Epoch 97/110
 - 2s - loss: 0.2670 - accuracy: 0.9675 - val_loss: 1.6452 - val_accuracy: 0.7044
Epoch 98/110
 - 2s - loss: 0.2264 - accuracy: 0.9803 - val_loss: 1.5481 - val_accuracy: 0.7270
Epoch 99/110
 - 2s - loss: 0.2185 - accuracy: 0.9847 - val_loss: 1.7527 - val_accuracy: 0.6993
Epoch 100/110
 - 2s - loss: 0.2257 - accuracy: 0.9803 - val_loss: 1.6378 - val_accuracy: 0.7131
Epoch 101/110
 - 2s - loss: 0.2286 - accuracy: 0.9812 - val_loss: 1.7065 - val_accuracy: 0.6934
Epoch 102/110
 - 2s - loss: 0.2397 - accuracy: 0.9759 - val_loss: 1.6635 - val_accuracy: 0.7139
Epoch 103/110
 - 2s - loss: 0.3179 - accuracy: 0.9569 - val_loss: 1.9266 - val_accuracy: 0.6328
Epoch 104/110
 - 2s - loss: 0.3451 - accuracy: 0.9416 - val_loss: 1.6585 - val_accuracy: 0.7139
Epoch 105/110
 - 2s - loss: 0.2788 - accuracy: 0.9655 - val_loss: 1.6312 - val_accuracy: 0.7036
Epoch 106/110
 - 2s - loss: 0.2464 - accuracy: 0.9750 - val_loss: 1.7050 - val_accuracy: 0.7161
Epoch 107/110
 - 2s - loss: 0.2417 - accuracy: 0.9770 - val_loss: 1.7389 - val_accuracy: 0.7095
Epoch 108/110
 - 2s - loss: 0.2266 - accuracy: 0.9825 - val_loss: 1.6195 - val_accuracy: 0.7255
Epoch 109/110
 - 2s - loss: 0.2157 - accuracy: 0.9850 - val_loss: 1.6704 - val_accuracy: 0.7212
Epoch 110/110
 - 2s - loss: 0.2211 - accuracy: 0.9827 - val_loss: 1.7435 - val_accuracy: 0.7212
------------------------------------------------------------------------
Training for fold 4 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 2s - loss: 0.2215 - accuracy: 0.9825 - val_loss: 1.7472 - val_accuracy: 0.7080
Epoch 2/110
 - 2s - loss: 0.2468 - accuracy: 0.9755 - val_loss: 1.7380 - val_accuracy: 0.7058
Epoch 3/110
 - 2s - loss: 0.2505 - accuracy: 0.9726 - val_loss: 1.6458 - val_accuracy: 0.7088
Epoch 4/110
 - 2s - loss: 0.2465 - accuracy: 0.9744 - val_loss: 1.6439 - val_accuracy: 0.7153
Epoch 5/110
 - 2s - loss: 0.2451 - accuracy: 0.9750 - val_loss: 1.7584 - val_accuracy: 0.6832
Epoch 6/110
 - 2s - loss: 0.2493 - accuracy: 0.9723 - val_loss: 1.7946 - val_accuracy: 0.7175
Epoch 7/110
 - 2s - loss: 0.2331 - accuracy: 0.9797 - val_loss: 1.6752 - val_accuracy: 0.7226
Epoch 8/110
 - 2s - loss: 0.2317 - accuracy: 0.9788 - val_loss: 1.8234 - val_accuracy: 0.6825
Epoch 9/110
 - 2s - loss: 0.2456 - accuracy: 0.9755 - val_loss: 1.6893 - val_accuracy: 0.6942
Epoch 10/110
 - 2s - loss: 0.2351 - accuracy: 0.9783 - val_loss: 1.6776 - val_accuracy: 0.7000
Epoch 11/110
 - 2s - loss: 0.2270 - accuracy: 0.9805 - val_loss: 1.6357 - val_accuracy: 0.7015
Epoch 12/110
 - 2s - loss: 0.2648 - accuracy: 0.9682 - val_loss: 2.0649 - val_accuracy: 0.6642
Epoch 13/110
 - 2s - loss: 0.2836 - accuracy: 0.9597 - val_loss: 1.7565 - val_accuracy: 0.6796
Epoch 14/110
 - 2s - loss: 0.2927 - accuracy: 0.9571 - val_loss: 1.6665 - val_accuracy: 0.7182
Epoch 15/110
 - 2s - loss: 0.2607 - accuracy: 0.9701 - val_loss: 1.7518 - val_accuracy: 0.6905
Epoch 16/110
 - 2s - loss: 0.2565 - accuracy: 0.9712 - val_loss: 1.6651 - val_accuracy: 0.7088
Epoch 17/110
 - 2s - loss: 0.2400 - accuracy: 0.9794 - val_loss: 1.7657 - val_accuracy: 0.7109
Epoch 18/110
 - 2s - loss: 0.2305 - accuracy: 0.9816 - val_loss: 1.6408 - val_accuracy: 0.7102
Epoch 19/110
 - 2s - loss: 0.2190 - accuracy: 0.9825 - val_loss: 1.7330 - val_accuracy: 0.7190
Epoch 20/110
 - 2s - loss: 0.2518 - accuracy: 0.9752 - val_loss: 1.7330 - val_accuracy: 0.6949
Epoch 21/110
 - 2s - loss: 0.2469 - accuracy: 0.9746 - val_loss: 1.7117 - val_accuracy: 0.7000
Epoch 22/110
 - 2s - loss: 0.2739 - accuracy: 0.9675 - val_loss: 1.6830 - val_accuracy: 0.6891
Epoch 23/110
 - 2s - loss: 0.2454 - accuracy: 0.9761 - val_loss: 1.6290 - val_accuracy: 0.7131
Epoch 24/110
 - 2s - loss: 0.2384 - accuracy: 0.9792 - val_loss: 1.6538 - val_accuracy: 0.7182
Epoch 25/110
 - 2s - loss: 0.2086 - accuracy: 0.9865 - val_loss: 1.6429 - val_accuracy: 0.7255
Epoch 26/110
 - 2s - loss: 0.2070 - accuracy: 0.9874 - val_loss: 1.7185 - val_accuracy: 0.7292
Epoch 27/110
 - 2s - loss: 0.2181 - accuracy: 0.9830 - val_loss: 1.7975 - val_accuracy: 0.7277
Epoch 28/110
 - 2s - loss: 0.2301 - accuracy: 0.9801 - val_loss: 1.8220 - val_accuracy: 0.7044
Epoch 29/110
 - 2s - loss: 0.2583 - accuracy: 0.9695 - val_loss: 1.8357 - val_accuracy: 0.6905
Epoch 30/110
 - 2s - loss: 0.3032 - accuracy: 0.9573 - val_loss: 1.6993 - val_accuracy: 0.7007
Epoch 31/110
 - 2s - loss: 0.2660 - accuracy: 0.9684 - val_loss: 1.6292 - val_accuracy: 0.7022
Epoch 32/110
 - 2s - loss: 0.2509 - accuracy: 0.9717 - val_loss: 1.6471 - val_accuracy: 0.7131
Epoch 33/110
 - 2s - loss: 0.2350 - accuracy: 0.9783 - val_loss: 1.6339 - val_accuracy: 0.7029
Epoch 34/110
 - 2s - loss: 0.2198 - accuracy: 0.9832 - val_loss: 1.6155 - val_accuracy: 0.7146
Epoch 35/110
 - 2s - loss: 0.2042 - accuracy: 0.9881 - val_loss: 1.5959 - val_accuracy: 0.7197
Epoch 36/110
 - 2s - loss: 0.2050 - accuracy: 0.9872 - val_loss: 1.7314 - val_accuracy: 0.7044
Epoch 37/110
 - 2s - loss: 0.2143 - accuracy: 0.9841 - val_loss: 1.7434 - val_accuracy: 0.7022
Epoch 38/110
 - 2s - loss: 0.2592 - accuracy: 0.9695 - val_loss: 1.8635 - val_accuracy: 0.6927
Epoch 39/110
 - 2s - loss: 0.2963 - accuracy: 0.9593 - val_loss: 1.8110 - val_accuracy: 0.6672
Epoch 40/110
 - 2s - loss: 0.3522 - accuracy: 0.9396 - val_loss: 1.7676 - val_accuracy: 0.6803
Epoch 41/110
 - 1s - loss: 0.2722 - accuracy: 0.9653 - val_loss: 1.6276 - val_accuracy: 0.7022
Epoch 42/110
 - 1s - loss: 0.2538 - accuracy: 0.9723 - val_loss: 1.6879 - val_accuracy: 0.7226
Epoch 43/110
 - 2s - loss: 0.2325 - accuracy: 0.9797 - val_loss: 1.5914 - val_accuracy: 0.7226
Epoch 44/110
 - 2s - loss: 0.2087 - accuracy: 0.9858 - val_loss: 1.6674 - val_accuracy: 0.7299
Epoch 45/110
 - 2s - loss: 0.2011 - accuracy: 0.9874 - val_loss: 1.6353 - val_accuracy: 0.7161
Epoch 46/110
 - 2s - loss: 0.1959 - accuracy: 0.9898 - val_loss: 1.6946 - val_accuracy: 0.7241
Epoch 47/110
 - 2s - loss: 0.1969 - accuracy: 0.9887 - val_loss: 1.6425 - val_accuracy: 0.7350
Epoch 48/110
 - 2s - loss: 0.2020 - accuracy: 0.9872 - val_loss: 1.6435 - val_accuracy: 0.7182
Epoch 49/110
 - 2s - loss: 0.1982 - accuracy: 0.9874 - val_loss: 1.7739 - val_accuracy: 0.7088
Epoch 50/110
 - 2s - loss: 0.2235 - accuracy: 0.9803 - val_loss: 1.7624 - val_accuracy: 0.7168
Epoch 51/110
 - 2s - loss: 0.2601 - accuracy: 0.9728 - val_loss: 1.6885 - val_accuracy: 0.6854
Epoch 52/110
 - 2s - loss: 0.2996 - accuracy: 0.9571 - val_loss: 1.7061 - val_accuracy: 0.6883
Epoch 53/110
 - 2s - loss: 0.2970 - accuracy: 0.9575 - val_loss: 1.8332 - val_accuracy: 0.6664
Epoch 54/110
 - 2s - loss: 0.3132 - accuracy: 0.9545 - val_loss: 1.6630 - val_accuracy: 0.6781
Epoch 55/110
 - 2s - loss: 0.2884 - accuracy: 0.9587 - val_loss: 1.7364 - val_accuracy: 0.6927
Epoch 56/110
 - 2s - loss: 0.2340 - accuracy: 0.9788 - val_loss: 1.5752 - val_accuracy: 0.7234
Epoch 57/110
 - 2s - loss: 0.2108 - accuracy: 0.9850 - val_loss: 1.6107 - val_accuracy: 0.7226
Epoch 58/110
 - 2s - loss: 0.2016 - accuracy: 0.9863 - val_loss: 1.5741 - val_accuracy: 0.7321
Epoch 59/110
 - 2s - loss: 0.2117 - accuracy: 0.9856 - val_loss: 1.7357 - val_accuracy: 0.7058
Epoch 60/110
 - 2s - loss: 0.2094 - accuracy: 0.9848 - val_loss: 1.7194 - val_accuracy: 0.7277
Epoch 61/110
 - 2s - loss: 0.2124 - accuracy: 0.9852 - val_loss: 1.6002 - val_accuracy: 0.7394
Epoch 62/110
 - 2s - loss: 0.2028 - accuracy: 0.9863 - val_loss: 1.6403 - val_accuracy: 0.7277
Epoch 63/110
 - 2s - loss: 0.2017 - accuracy: 0.9869 - val_loss: 1.7380 - val_accuracy: 0.7197
Epoch 64/110
 - 2s - loss: 0.2102 - accuracy: 0.9850 - val_loss: 1.6341 - val_accuracy: 0.7204
Epoch 65/110
 - 2s - loss: 0.2233 - accuracy: 0.9790 - val_loss: 1.7145 - val_accuracy: 0.7000
Epoch 66/110
 - 2s - loss: 0.2430 - accuracy: 0.9743 - val_loss: 1.9013 - val_accuracy: 0.6993
Epoch 67/110
 - 2s - loss: 0.2897 - accuracy: 0.9602 - val_loss: 1.7538 - val_accuracy: 0.6599
Epoch 68/110
 - 2s - loss: 0.2745 - accuracy: 0.9606 - val_loss: 1.8179 - val_accuracy: 0.6715
Epoch 69/110
 - 2s - loss: 0.3320 - accuracy: 0.9487 - val_loss: 1.7107 - val_accuracy: 0.6708
Epoch 70/110
 - 2s - loss: 0.2819 - accuracy: 0.9602 - val_loss: 1.6279 - val_accuracy: 0.7000
Epoch 71/110
 - 2s - loss: 0.2381 - accuracy: 0.9763 - val_loss: 1.6182 - val_accuracy: 0.7022
Epoch 72/110
 - 2s - loss: 0.2212 - accuracy: 0.9808 - val_loss: 1.5447 - val_accuracy: 0.7212
Epoch 73/110
 - 2s - loss: 0.2024 - accuracy: 0.9865 - val_loss: 1.5823 - val_accuracy: 0.7153
Epoch 74/110
 - 2s - loss: 0.1925 - accuracy: 0.9900 - val_loss: 1.5932 - val_accuracy: 0.7277
Epoch 75/110
 - 2s - loss: 0.1905 - accuracy: 0.9905 - val_loss: 1.6590 - val_accuracy: 0.7321
Epoch 76/110
 - 2s - loss: 0.1893 - accuracy: 0.9900 - val_loss: 1.6694 - val_accuracy: 0.7277
Epoch 77/110
 - 2s - loss: 0.1940 - accuracy: 0.9887 - val_loss: 1.6506 - val_accuracy: 0.7182
Epoch 78/110
 - 2s - loss: 0.1922 - accuracy: 0.9881 - val_loss: 1.7275 - val_accuracy: 0.7285
Epoch 79/110
 - 2s - loss: 0.1980 - accuracy: 0.9850 - val_loss: 1.6551 - val_accuracy: 0.7248
Epoch 80/110
 - 2s - loss: 0.2378 - accuracy: 0.9799 - val_loss: 1.7477 - val_accuracy: 0.7007
Epoch 81/110
 - 2s - loss: 0.3620 - accuracy: 0.9425 - val_loss: 1.8992 - val_accuracy: 0.6241
Epoch 82/110
 - 2s - loss: 0.4411 - accuracy: 0.9104 - val_loss: 1.6541 - val_accuracy: 0.6657
Epoch 83/110
 - 2s - loss: 0.2868 - accuracy: 0.9547 - val_loss: 1.5797 - val_accuracy: 0.7051
Epoch 84/110
 - 2s - loss: 0.2264 - accuracy: 0.9812 - val_loss: 1.5071 - val_accuracy: 0.7109
Epoch 85/110
 - 2s - loss: 0.2083 - accuracy: 0.9858 - val_loss: 1.5422 - val_accuracy: 0.7226
Epoch 86/110
 - 2s - loss: 0.1948 - accuracy: 0.9885 - val_loss: 1.5732 - val_accuracy: 0.7241
Epoch 87/110
 - 2s - loss: 0.1908 - accuracy: 0.9901 - val_loss: 1.5610 - val_accuracy: 0.7358
Epoch 88/110
 - 2s - loss: 0.1952 - accuracy: 0.9874 - val_loss: 1.6636 - val_accuracy: 0.7277
Epoch 89/110
 - 2s - loss: 0.1901 - accuracy: 0.9894 - val_loss: 1.6279 - val_accuracy: 0.7277
Epoch 90/110
 - 2s - loss: 0.2003 - accuracy: 0.9872 - val_loss: 1.6810 - val_accuracy: 0.7219
Epoch 91/110
 - 2s - loss: 0.2077 - accuracy: 0.9845 - val_loss: 1.6861 - val_accuracy: 0.7146
Epoch 92/110
 - 2s - loss: 0.2718 - accuracy: 0.9644 - val_loss: 1.8382 - val_accuracy: 0.6832
Epoch 93/110
 - 1s - loss: 0.3086 - accuracy: 0.9556 - val_loss: 1.7091 - val_accuracy: 0.6796
Epoch 94/110
 - 2s - loss: 0.3391 - accuracy: 0.9425 - val_loss: 1.6254 - val_accuracy: 0.6942
Epoch 95/110
 - 2s - loss: 0.2625 - accuracy: 0.9657 - val_loss: 1.5638 - val_accuracy: 0.7248
Epoch 96/110
 - 1s - loss: 0.2293 - accuracy: 0.9792 - val_loss: 1.5610 - val_accuracy: 0.7161
Epoch 97/110
 - 2s - loss: 0.2255 - accuracy: 0.9781 - val_loss: 1.6616 - val_accuracy: 0.6949
Epoch 98/110
 - 2s - loss: 0.2148 - accuracy: 0.9825 - val_loss: 1.6209 - val_accuracy: 0.7066
Epoch 99/110
 - 2s - loss: 0.2156 - accuracy: 0.9817 - val_loss: 1.6400 - val_accuracy: 0.6949
Epoch 100/110
 - 2s - loss: 0.2163 - accuracy: 0.9812 - val_loss: 1.6989 - val_accuracy: 0.7153
Epoch 101/110
 - 2s - loss: 0.2178 - accuracy: 0.9830 - val_loss: 1.6635 - val_accuracy: 0.7000
Epoch 102/110
 - 2s - loss: 0.1973 - accuracy: 0.9859 - val_loss: 1.6583 - val_accuracy: 0.7219
Epoch 103/110
 - 2s - loss: 0.2146 - accuracy: 0.9836 - val_loss: 1.7587 - val_accuracy: 0.7153
Epoch 104/110
 - 2s - loss: 0.2663 - accuracy: 0.9681 - val_loss: 1.7209 - val_accuracy: 0.7029
Epoch 105/110
 - 2s - loss: 0.2994 - accuracy: 0.9533 - val_loss: 1.7548 - val_accuracy: 0.6818
Epoch 106/110
 - 2s - loss: 0.2604 - accuracy: 0.9668 - val_loss: 1.7036 - val_accuracy: 0.7168
Epoch 107/110
 - 2s - loss: 0.2419 - accuracy: 0.9755 - val_loss: 1.6494 - val_accuracy: 0.7255
Epoch 108/110
 - 2s - loss: 0.2380 - accuracy: 0.9746 - val_loss: 1.7059 - val_accuracy: 0.7015
Epoch 109/110
 - 2s - loss: 0.2652 - accuracy: 0.9666 - val_loss: 1.8017 - val_accuracy: 0.6752
Epoch 110/110
 - 2s - loss: 0.2504 - accuracy: 0.9715 - val_loss: 1.6176 - val_accuracy: 0.7007
------------------------------------------------------------------------
Training for fold 5 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 2s - loss: 0.2300 - accuracy: 0.9768 - val_loss: 1.5965 - val_accuracy: 0.7197
Epoch 2/110
 - 2s - loss: 0.2154 - accuracy: 0.9823 - val_loss: 1.6902 - val_accuracy: 0.7153
Epoch 3/110
 - 2s - loss: 0.1957 - accuracy: 0.9878 - val_loss: 1.6761 - val_accuracy: 0.7190
Epoch 4/110
 - 2s - loss: 0.1928 - accuracy: 0.9874 - val_loss: 1.6648 - val_accuracy: 0.7102
Epoch 5/110
 - 2s - loss: 0.2126 - accuracy: 0.9832 - val_loss: 1.6654 - val_accuracy: 0.7088
Epoch 6/110
 - 2s - loss: 0.2100 - accuracy: 0.9850 - val_loss: 1.7138 - val_accuracy: 0.7073
Epoch 7/110
 - 2s - loss: 0.2075 - accuracy: 0.9841 - val_loss: 1.6652 - val_accuracy: 0.7314
Epoch 8/110
 - 2s - loss: 0.2172 - accuracy: 0.9810 - val_loss: 1.7410 - val_accuracy: 0.7102
Epoch 9/110
 - 2s - loss: 0.2236 - accuracy: 0.9801 - val_loss: 1.7434 - val_accuracy: 0.6934
Epoch 10/110
 - 2s - loss: 0.2125 - accuracy: 0.9819 - val_loss: 1.7263 - val_accuracy: 0.7073
Epoch 11/110
 - 2s - loss: 0.2046 - accuracy: 0.9854 - val_loss: 1.8049 - val_accuracy: 0.7051
Epoch 12/110
 - 2s - loss: 0.2214 - accuracy: 0.9816 - val_loss: 1.8350 - val_accuracy: 0.7124
Epoch 13/110
 - 2s - loss: 0.2556 - accuracy: 0.9741 - val_loss: 1.7769 - val_accuracy: 0.7058
Epoch 14/110
 - 2s - loss: 0.2425 - accuracy: 0.9741 - val_loss: 2.0569 - val_accuracy: 0.6577
Epoch 15/110
 - 2s - loss: 0.3493 - accuracy: 0.9407 - val_loss: 1.9382 - val_accuracy: 0.6650
Epoch 16/110
 - 2s - loss: 0.3467 - accuracy: 0.9405 - val_loss: 1.6418 - val_accuracy: 0.6752
Epoch 17/110
 - 2s - loss: 0.2684 - accuracy: 0.9650 - val_loss: 1.6478 - val_accuracy: 0.6934
Epoch 18/110
 - 2s - loss: 0.2592 - accuracy: 0.9688 - val_loss: 1.7553 - val_accuracy: 0.6854
Epoch 19/110
 - 2s - loss: 0.2267 - accuracy: 0.9792 - val_loss: 1.6175 - val_accuracy: 0.7182
Epoch 20/110
 - 2s - loss: 0.1971 - accuracy: 0.9876 - val_loss: 1.5884 - val_accuracy: 0.7358
Epoch 21/110
 - 2s - loss: 0.1934 - accuracy: 0.9889 - val_loss: 1.6309 - val_accuracy: 0.7285
Epoch 22/110
 - 2s - loss: 0.1878 - accuracy: 0.9905 - val_loss: 1.6357 - val_accuracy: 0.7394
Epoch 23/110
 - 2s - loss: 0.1919 - accuracy: 0.9896 - val_loss: 1.7184 - val_accuracy: 0.7190
Epoch 24/110
 - 2s - loss: 0.1882 - accuracy: 0.9898 - val_loss: 1.7174 - val_accuracy: 0.7175
Epoch 25/110
 - 2s - loss: 0.1894 - accuracy: 0.9894 - val_loss: 1.6785 - val_accuracy: 0.7197
Epoch 26/110
 - 2s - loss: 0.1870 - accuracy: 0.9883 - val_loss: 1.6581 - val_accuracy: 0.7321
Epoch 27/110
 - 2s - loss: 0.2060 - accuracy: 0.9838 - val_loss: 1.8200 - val_accuracy: 0.7029
Epoch 28/110
 - 2s - loss: 0.2010 - accuracy: 0.9847 - val_loss: 1.6922 - val_accuracy: 0.7248
Epoch 29/110
 - 2s - loss: 0.2184 - accuracy: 0.9823 - val_loss: 1.6547 - val_accuracy: 0.7226
Epoch 30/110
 - 2s - loss: 0.2260 - accuracy: 0.9783 - val_loss: 1.6786 - val_accuracy: 0.7168
Epoch 31/110
 - 2s - loss: 0.2739 - accuracy: 0.9646 - val_loss: 1.5871 - val_accuracy: 0.6985
Epoch 32/110
 - 2s - loss: 0.3292 - accuracy: 0.9438 - val_loss: 1.7530 - val_accuracy: 0.6818
Epoch 33/110
 - 2s - loss: 0.3286 - accuracy: 0.9460 - val_loss: 1.6296 - val_accuracy: 0.6949
Epoch 34/110
 - 2s - loss: 0.2477 - accuracy: 0.9721 - val_loss: 1.7073 - val_accuracy: 0.7066
Epoch 35/110
 - 2s - loss: 0.2041 - accuracy: 0.9850 - val_loss: 1.5413 - val_accuracy: 0.7234
Epoch 36/110
 - 2s - loss: 0.1981 - accuracy: 0.9872 - val_loss: 1.5545 - val_accuracy: 0.7168
Epoch 37/110
 - 2s - loss: 0.2016 - accuracy: 0.9848 - val_loss: 1.6641 - val_accuracy: 0.7095
Epoch 38/110
 - 2s - loss: 0.2172 - accuracy: 0.9838 - val_loss: 1.7399 - val_accuracy: 0.7241
Epoch 39/110
 - 2s - loss: 0.2004 - accuracy: 0.9852 - val_loss: 1.6129 - val_accuracy: 0.7234
Epoch 40/110
 - 2s - loss: 0.1982 - accuracy: 0.9859 - val_loss: 1.6540 - val_accuracy: 0.7234
Epoch 41/110
 - 2s - loss: 0.2017 - accuracy: 0.9870 - val_loss: 1.7370 - val_accuracy: 0.7000
Epoch 42/110
 - 2s - loss: 0.2212 - accuracy: 0.9785 - val_loss: 1.7965 - val_accuracy: 0.7022
Epoch 43/110
 - 2s - loss: 0.2561 - accuracy: 0.9686 - val_loss: 1.7304 - val_accuracy: 0.7000
Epoch 44/110
 - 2s - loss: 0.2600 - accuracy: 0.9675 - val_loss: 1.7900 - val_accuracy: 0.6876
Epoch 45/110
 - 1s - loss: 0.2800 - accuracy: 0.9597 - val_loss: 1.5587 - val_accuracy: 0.7066
Epoch 46/110
 - 1s - loss: 0.2578 - accuracy: 0.9664 - val_loss: 1.6659 - val_accuracy: 0.7058
Epoch 47/110
 - 1s - loss: 0.2386 - accuracy: 0.9765 - val_loss: 1.7079 - val_accuracy: 0.6796
Epoch 48/110
 - 1s - loss: 0.2506 - accuracy: 0.9733 - val_loss: 1.6031 - val_accuracy: 0.7095
Epoch 49/110
 - 2s - loss: 0.2291 - accuracy: 0.9781 - val_loss: 1.7167 - val_accuracy: 0.7175
Epoch 50/110
 - 1s - loss: 0.2208 - accuracy: 0.9816 - val_loss: 1.6330 - val_accuracy: 0.7314
Epoch 51/110
 - 1s - loss: 0.2022 - accuracy: 0.9845 - val_loss: 1.6619 - val_accuracy: 0.7234
Epoch 52/110
 - 2s - loss: 0.2113 - accuracy: 0.9830 - val_loss: 1.7532 - val_accuracy: 0.7080
Epoch 53/110
 - 2s - loss: 0.2235 - accuracy: 0.9768 - val_loss: 1.6530 - val_accuracy: 0.7109
Epoch 54/110
 - 2s - loss: 0.2338 - accuracy: 0.9755 - val_loss: 1.7393 - val_accuracy: 0.7029
Epoch 55/110
 - 2s - loss: 0.2251 - accuracy: 0.9788 - val_loss: 1.6802 - val_accuracy: 0.7146
Epoch 56/110
 - 1s - loss: 0.2101 - accuracy: 0.9830 - val_loss: 1.5824 - val_accuracy: 0.7234
Epoch 57/110
 - 2s - loss: 0.2012 - accuracy: 0.9856 - val_loss: 1.6866 - val_accuracy: 0.7299
Epoch 58/110
 - 2s - loss: 0.1924 - accuracy: 0.9890 - val_loss: 1.6332 - val_accuracy: 0.7168
Epoch 59/110
 - 2s - loss: 0.1944 - accuracy: 0.9876 - val_loss: 1.7275 - val_accuracy: 0.7117
Epoch 60/110
 - 2s - loss: 0.1931 - accuracy: 0.9872 - val_loss: 1.7157 - val_accuracy: 0.7226
Epoch 61/110
 - 1s - loss: 0.1921 - accuracy: 0.9867 - val_loss: 1.7029 - val_accuracy: 0.7285
Epoch 62/110
 - 2s - loss: 0.2473 - accuracy: 0.9728 - val_loss: 1.9908 - val_accuracy: 0.6730
Epoch 63/110
 - 2s - loss: 0.3312 - accuracy: 0.9434 - val_loss: 1.7409 - val_accuracy: 0.6934
Epoch 64/110
 - 2s - loss: 0.2989 - accuracy: 0.9533 - val_loss: 1.6490 - val_accuracy: 0.6788
Epoch 65/110
 - 1s - loss: 0.2640 - accuracy: 0.9650 - val_loss: 1.7196 - val_accuracy: 0.7000
Epoch 66/110
 - 2s - loss: 0.2311 - accuracy: 0.9759 - val_loss: 1.6734 - val_accuracy: 0.7117
Epoch 67/110
 - 2s - loss: 0.2136 - accuracy: 0.9852 - val_loss: 1.5854 - val_accuracy: 0.7139
Epoch 68/110
 - 2s - loss: 0.2091 - accuracy: 0.9836 - val_loss: 1.6565 - val_accuracy: 0.7044
Epoch 69/110
 - 2s - loss: 0.2088 - accuracy: 0.9848 - val_loss: 1.6828 - val_accuracy: 0.7044
Epoch 70/110
 - 2s - loss: 0.2389 - accuracy: 0.9750 - val_loss: 1.7875 - val_accuracy: 0.7022
Epoch 71/110
 - 2s - loss: 0.2566 - accuracy: 0.9682 - val_loss: 1.7465 - val_accuracy: 0.6920
Epoch 72/110
 - 2s - loss: 0.2137 - accuracy: 0.9799 - val_loss: 1.7365 - val_accuracy: 0.7161
Epoch 73/110
 - 2s - loss: 0.2125 - accuracy: 0.9814 - val_loss: 1.8158 - val_accuracy: 0.7036
Epoch 74/110
 - 1s - loss: 0.2238 - accuracy: 0.9790 - val_loss: 1.5840 - val_accuracy: 0.7088
Epoch 75/110
 - 1s - loss: 0.1987 - accuracy: 0.9872 - val_loss: 1.5918 - val_accuracy: 0.7102
Epoch 76/110
 - 2s - loss: 0.1878 - accuracy: 0.9883 - val_loss: 1.6791 - val_accuracy: 0.7066
Epoch 77/110
 - 2s - loss: 0.1843 - accuracy: 0.9890 - val_loss: 1.5998 - val_accuracy: 0.7292
Epoch 78/110
 - 2s - loss: 0.1822 - accuracy: 0.9894 - val_loss: 1.6159 - val_accuracy: 0.7255
Epoch 79/110
 - 1s - loss: 0.1889 - accuracy: 0.9885 - val_loss: 1.6852 - val_accuracy: 0.7080
Epoch 80/110
 - 2s - loss: 0.1956 - accuracy: 0.9859 - val_loss: 1.7247 - val_accuracy: 0.7153
Epoch 81/110
 - 1s - loss: 0.2070 - accuracy: 0.9827 - val_loss: 1.6150 - val_accuracy: 0.7263
Epoch 82/110
 - 1s - loss: 0.2069 - accuracy: 0.9838 - val_loss: 1.5942 - val_accuracy: 0.7212
Epoch 83/110
 - 1s - loss: 0.2386 - accuracy: 0.9746 - val_loss: 1.6519 - val_accuracy: 0.7051
Epoch 84/110
 - 2s - loss: 0.3061 - accuracy: 0.9527 - val_loss: 1.8623 - val_accuracy: 0.6547
Epoch 85/110
 - 1s - loss: 0.3289 - accuracy: 0.9447 - val_loss: 1.6659 - val_accuracy: 0.6847
Epoch 86/110
 - 2s - loss: 0.2744 - accuracy: 0.9624 - val_loss: 1.4919 - val_accuracy: 0.7109
Epoch 87/110
 - 2s - loss: 0.2103 - accuracy: 0.9830 - val_loss: 1.5552 - val_accuracy: 0.7241
Epoch 88/110
 - 2s - loss: 0.2227 - accuracy: 0.9788 - val_loss: 1.5798 - val_accuracy: 0.7153
Epoch 89/110
 - 2s - loss: 0.2014 - accuracy: 0.9834 - val_loss: 1.6197 - val_accuracy: 0.7131
Epoch 90/110
 - 2s - loss: 0.1834 - accuracy: 0.9892 - val_loss: 1.5948 - val_accuracy: 0.7212
Epoch 91/110
 - 2s - loss: 0.1781 - accuracy: 0.9916 - val_loss: 1.5865 - val_accuracy: 0.7321
Epoch 92/110
 - 2s - loss: 0.1786 - accuracy: 0.9905 - val_loss: 1.5902 - val_accuracy: 0.7255
Epoch 93/110
 - 2s - loss: 0.1879 - accuracy: 0.9870 - val_loss: 1.6487 - val_accuracy: 0.7372
Epoch 94/110
 - 2s - loss: 0.1966 - accuracy: 0.9845 - val_loss: 1.6118 - val_accuracy: 0.7168
Epoch 95/110
 - 1s - loss: 0.2045 - accuracy: 0.9825 - val_loss: 1.7588 - val_accuracy: 0.6971
Epoch 96/110
 - 2s - loss: 0.2335 - accuracy: 0.9768 - val_loss: 1.6479 - val_accuracy: 0.7066
Epoch 97/110
 - 2s - loss: 0.3061 - accuracy: 0.9542 - val_loss: 1.9501 - val_accuracy: 0.6547
Epoch 98/110
 - 2s - loss: 0.3836 - accuracy: 0.9235 - val_loss: 1.7155 - val_accuracy: 0.6664
Epoch 99/110
 - 2s - loss: 0.3024 - accuracy: 0.9487 - val_loss: 1.6705 - val_accuracy: 0.6891
Epoch 100/110
 - 2s - loss: 0.2715 - accuracy: 0.9642 - val_loss: 1.5567 - val_accuracy: 0.6942
Epoch 101/110
 - 2s - loss: 0.2171 - accuracy: 0.9794 - val_loss: 1.5951 - val_accuracy: 0.6905
Epoch 102/110
 - 2s - loss: 0.1975 - accuracy: 0.9869 - val_loss: 1.5650 - val_accuracy: 0.7124
Epoch 103/110
 - 2s - loss: 0.1833 - accuracy: 0.9905 - val_loss: 1.5770 - val_accuracy: 0.7255
Epoch 104/110
 - 2s - loss: 0.1863 - accuracy: 0.9887 - val_loss: 1.5746 - val_accuracy: 0.7314
Epoch 105/110
 - 2s - loss: 0.1826 - accuracy: 0.9890 - val_loss: 1.5543 - val_accuracy: 0.7423
Epoch 106/110
 - 2s - loss: 0.1781 - accuracy: 0.9903 - val_loss: 1.6388 - val_accuracy: 0.7212
Epoch 107/110
 - 2s - loss: 0.1758 - accuracy: 0.9914 - val_loss: 1.5919 - val_accuracy: 0.7314
Epoch 108/110
 - 2s - loss: 0.1750 - accuracy: 0.9907 - val_loss: 1.6672 - val_accuracy: 0.7168
Epoch 109/110
 - 2s - loss: 0.1781 - accuracy: 0.9900 - val_loss: 1.6204 - val_accuracy: 0.7343
Epoch 110/110
 - 2s - loss: 0.1799 - accuracy: 0.9901 - val_loss: 1.6355 - val_accuracy: 0.7197
------------------------------------------------------------------------
Training for fold 6 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 2s - loss: 0.1749 - accuracy: 0.9909 - val_loss: 1.6251 - val_accuracy: 0.7255
Epoch 2/110
 - 2s - loss: 0.1774 - accuracy: 0.9896 - val_loss: 1.6742 - val_accuracy: 0.7255
Epoch 3/110
 - 1s - loss: 0.1744 - accuracy: 0.9903 - val_loss: 1.6536 - val_accuracy: 0.7234
Epoch 4/110
 - 2s - loss: 0.1972 - accuracy: 0.9845 - val_loss: 1.6674 - val_accuracy: 0.7168
Epoch 5/110
 - 2s - loss: 0.2422 - accuracy: 0.9691 - val_loss: 1.8415 - val_accuracy: 0.6599
Epoch 6/110
 - 2s - loss: 0.4282 - accuracy: 0.9067 - val_loss: 1.7445 - val_accuracy: 0.6620
Epoch 7/110
 - 1s - loss: 0.3906 - accuracy: 0.9171 - val_loss: 1.5573 - val_accuracy: 0.6920
Epoch 8/110
 - 2s - loss: 0.3046 - accuracy: 0.9514 - val_loss: 1.5930 - val_accuracy: 0.6891
Epoch 9/110
 - 2s - loss: 0.2467 - accuracy: 0.9679 - val_loss: 1.5933 - val_accuracy: 0.7095
Epoch 10/110
 - 2s - loss: 0.2099 - accuracy: 0.9814 - val_loss: 1.5338 - val_accuracy: 0.7168
Epoch 11/110
 - 2s - loss: 0.1923 - accuracy: 0.9870 - val_loss: 1.5064 - val_accuracy: 0.7139
Epoch 12/110
 - 2s - loss: 0.1843 - accuracy: 0.9892 - val_loss: 1.5696 - val_accuracy: 0.7102
Epoch 13/110
 - 1s - loss: 0.1794 - accuracy: 0.9903 - val_loss: 1.5894 - val_accuracy: 0.7263
Epoch 14/110
 - 2s - loss: 0.1792 - accuracy: 0.9905 - val_loss: 1.6139 - val_accuracy: 0.7088
Epoch 15/110
 - 2s - loss: 0.1741 - accuracy: 0.9907 - val_loss: 1.6327 - val_accuracy: 0.7204
Epoch 16/110
 - 2s - loss: 0.1747 - accuracy: 0.9912 - val_loss: 1.5847 - val_accuracy: 0.7255
Epoch 17/110
 - 2s - loss: 0.1711 - accuracy: 0.9918 - val_loss: 1.6219 - val_accuracy: 0.7263
Epoch 18/110
 - 2s - loss: 0.1729 - accuracy: 0.9903 - val_loss: 1.6501 - val_accuracy: 0.7255
Epoch 19/110
 - 2s - loss: 0.1734 - accuracy: 0.9905 - val_loss: 1.6510 - val_accuracy: 0.7292
Epoch 20/110
 - 2s - loss: 0.1748 - accuracy: 0.9907 - val_loss: 1.5893 - val_accuracy: 0.7285
Epoch 21/110
 - 2s - loss: 0.1769 - accuracy: 0.9892 - val_loss: 1.7131 - val_accuracy: 0.7095
Epoch 22/110
 - 2s - loss: 0.2929 - accuracy: 0.9573 - val_loss: 2.0365 - val_accuracy: 0.6679
Epoch 23/110
 - 2s - loss: 0.4314 - accuracy: 0.9027 - val_loss: 1.6125 - val_accuracy: 0.6555
Epoch 24/110
 - 2s - loss: 0.3257 - accuracy: 0.9398 - val_loss: 1.6531 - val_accuracy: 0.6942
Epoch 25/110
 - 2s - loss: 0.2442 - accuracy: 0.9666 - val_loss: 1.6128 - val_accuracy: 0.6920
Epoch 26/110
 - 2s - loss: 0.2092 - accuracy: 0.9816 - val_loss: 1.6937 - val_accuracy: 0.7175
Epoch 27/110
 - 2s - loss: 0.1860 - accuracy: 0.9887 - val_loss: 1.5475 - val_accuracy: 0.7299
Epoch 28/110
 - 2s - loss: 0.1764 - accuracy: 0.9907 - val_loss: 1.5933 - val_accuracy: 0.7270
Epoch 29/110
 - 2s - loss: 0.1803 - accuracy: 0.9900 - val_loss: 1.6258 - val_accuracy: 0.7263
Epoch 30/110
 - 2s - loss: 0.1779 - accuracy: 0.9903 - val_loss: 1.5877 - val_accuracy: 0.7277
Epoch 31/110
 - 2s - loss: 0.1727 - accuracy: 0.9911 - val_loss: 1.6201 - val_accuracy: 0.7255
Epoch 32/110
 - 2s - loss: 0.1704 - accuracy: 0.9912 - val_loss: 1.6488 - val_accuracy: 0.7212
Epoch 33/110
 - 2s - loss: 0.1807 - accuracy: 0.9885 - val_loss: 1.6469 - val_accuracy: 0.7292
Epoch 34/110
 - 2s - loss: 0.2117 - accuracy: 0.9777 - val_loss: 1.7569 - val_accuracy: 0.7015
Epoch 35/110
 - 1s - loss: 0.2762 - accuracy: 0.9564 - val_loss: 1.7299 - val_accuracy: 0.6723
Epoch 36/110
 - 2s - loss: 0.3475 - accuracy: 0.9348 - val_loss: 1.6721 - val_accuracy: 0.6781
Epoch 37/110
 - 1s - loss: 0.3205 - accuracy: 0.9425 - val_loss: 1.5794 - val_accuracy: 0.6839
Epoch 38/110
 - 2s - loss: 0.2694 - accuracy: 0.9606 - val_loss: 1.5980 - val_accuracy: 0.7146
Epoch 39/110
 - 2s - loss: 0.2137 - accuracy: 0.9808 - val_loss: 1.5219 - val_accuracy: 0.7095
Epoch 40/110
 - 2s - loss: 0.1939 - accuracy: 0.9865 - val_loss: 1.5609 - val_accuracy: 0.7226
Epoch 41/110
 - 2s - loss: 0.1837 - accuracy: 0.9887 - val_loss: 1.6082 - val_accuracy: 0.7350
Epoch 42/110
 - 2s - loss: 0.1755 - accuracy: 0.9911 - val_loss: 1.5558 - val_accuracy: 0.7336
Epoch 43/110
 - 2s - loss: 0.1775 - accuracy: 0.9894 - val_loss: 1.6358 - val_accuracy: 0.7270
Epoch 44/110
 - 2s - loss: 0.1841 - accuracy: 0.9890 - val_loss: 1.5312 - val_accuracy: 0.7307
Epoch 45/110
 - 1s - loss: 0.1701 - accuracy: 0.9922 - val_loss: 1.5708 - val_accuracy: 0.7328
Epoch 46/110
 - 1s - loss: 0.1675 - accuracy: 0.9923 - val_loss: 1.5487 - val_accuracy: 0.7365
Epoch 47/110
 - 1s - loss: 0.1675 - accuracy: 0.9923 - val_loss: 1.5813 - val_accuracy: 0.7372
Epoch 48/110
 - 2s - loss: 0.1660 - accuracy: 0.9916 - val_loss: 1.6332 - val_accuracy: 0.7358
Epoch 49/110
 - 2s - loss: 0.1661 - accuracy: 0.9914 - val_loss: 1.6370 - val_accuracy: 0.7409
Epoch 50/110
 - 2s - loss: 0.1692 - accuracy: 0.9909 - val_loss: 1.6744 - val_accuracy: 0.7365
Epoch 51/110
 - 2s - loss: 0.1876 - accuracy: 0.9859 - val_loss: 1.7038 - val_accuracy: 0.7168
Epoch 52/110
 - 2s - loss: 0.1876 - accuracy: 0.9839 - val_loss: 1.7696 - val_accuracy: 0.7080
Epoch 53/110
 - 2s - loss: 0.2919 - accuracy: 0.9555 - val_loss: 1.6487 - val_accuracy: 0.6715
Epoch 54/110
 - 2s - loss: 0.4445 - accuracy: 0.9005 - val_loss: 1.6334 - val_accuracy: 0.6796
Epoch 55/110
 - 2s - loss: 0.3351 - accuracy: 0.9372 - val_loss: 1.4499 - val_accuracy: 0.6920
Epoch 56/110
 - 2s - loss: 0.2305 - accuracy: 0.9748 - val_loss: 1.4312 - val_accuracy: 0.7109
Epoch 57/110
 - 2s - loss: 0.2125 - accuracy: 0.9812 - val_loss: 1.5038 - val_accuracy: 0.7153
Epoch 58/110
 - 2s - loss: 0.1890 - accuracy: 0.9865 - val_loss: 1.5745 - val_accuracy: 0.7197
Epoch 59/110
 - 2s - loss: 0.1849 - accuracy: 0.9881 - val_loss: 1.6595 - val_accuracy: 0.7109
Epoch 60/110
 - 2s - loss: 0.2372 - accuracy: 0.9750 - val_loss: 1.6552 - val_accuracy: 0.7058
Epoch 61/110
 - 2s - loss: 0.2080 - accuracy: 0.9794 - val_loss: 1.5816 - val_accuracy: 0.7234
Epoch 62/110
 - 2s - loss: 0.2058 - accuracy: 0.9808 - val_loss: 1.6275 - val_accuracy: 0.7153
Epoch 63/110
 - 2s - loss: 0.1947 - accuracy: 0.9832 - val_loss: 1.6239 - val_accuracy: 0.7073
Epoch 64/110
 - 2s - loss: 0.1958 - accuracy: 0.9834 - val_loss: 1.6367 - val_accuracy: 0.7219
Epoch 65/110
 - 2s - loss: 0.1978 - accuracy: 0.9808 - val_loss: 1.5953 - val_accuracy: 0.7124
Epoch 66/110
 - 2s - loss: 0.1968 - accuracy: 0.9852 - val_loss: 1.5855 - val_accuracy: 0.7175
Epoch 67/110
 - 2s - loss: 0.2008 - accuracy: 0.9812 - val_loss: 1.7440 - val_accuracy: 0.7146
Epoch 68/110
 - 2s - loss: 0.1931 - accuracy: 0.9852 - val_loss: 1.6211 - val_accuracy: 0.7044
Epoch 69/110
 - 2s - loss: 0.1988 - accuracy: 0.9821 - val_loss: 1.6684 - val_accuracy: 0.7073
Epoch 70/110
 - 1s - loss: 0.2370 - accuracy: 0.9704 - val_loss: 1.6727 - val_accuracy: 0.7000
Epoch 71/110
 - 2s - loss: 0.2587 - accuracy: 0.9642 - val_loss: 1.7803 - val_accuracy: 0.6723
Epoch 72/110
 - 2s - loss: 0.2301 - accuracy: 0.9728 - val_loss: 1.6924 - val_accuracy: 0.7255
Epoch 73/110
 - 1s - loss: 0.2064 - accuracy: 0.9810 - val_loss: 1.7311 - val_accuracy: 0.7095
Epoch 74/110
 - 2s - loss: 0.2382 - accuracy: 0.9702 - val_loss: 1.6807 - val_accuracy: 0.6679
Epoch 75/110
 - 2s - loss: 0.2296 - accuracy: 0.9723 - val_loss: 1.6190 - val_accuracy: 0.7066
Epoch 76/110
 - 2s - loss: 0.1909 - accuracy: 0.9854 - val_loss: 1.6262 - val_accuracy: 0.7109
Epoch 77/110
 - 2s - loss: 0.2062 - accuracy: 0.9816 - val_loss: 1.6651 - val_accuracy: 0.7095
Epoch 78/110
 - 2s - loss: 0.2046 - accuracy: 0.9821 - val_loss: 1.5231 - val_accuracy: 0.7131
Epoch 79/110
 - 2s - loss: 0.1985 - accuracy: 0.9828 - val_loss: 1.5406 - val_accuracy: 0.7080
Epoch 80/110
 - 2s - loss: 0.1838 - accuracy: 0.9865 - val_loss: 1.5891 - val_accuracy: 0.7175
Epoch 81/110
 - 2s - loss: 0.2019 - accuracy: 0.9810 - val_loss: 1.6507 - val_accuracy: 0.6993
Epoch 82/110
 - 2s - loss: 0.2032 - accuracy: 0.9821 - val_loss: 1.6331 - val_accuracy: 0.6964
Epoch 83/110
 - 2s - loss: 0.2004 - accuracy: 0.9816 - val_loss: 1.6715 - val_accuracy: 0.7007
Epoch 84/110
 - 2s - loss: 0.1975 - accuracy: 0.9825 - val_loss: 1.6766 - val_accuracy: 0.7161
Epoch 85/110
 - 2s - loss: 0.3213 - accuracy: 0.9527 - val_loss: 1.7956 - val_accuracy: 0.6562
Epoch 86/110
 - 2s - loss: 0.3518 - accuracy: 0.9379 - val_loss: 1.5913 - val_accuracy: 0.6752
Epoch 87/110
 - 2s - loss: 0.2491 - accuracy: 0.9679 - val_loss: 1.4890 - val_accuracy: 0.7080
Epoch 88/110
 - 2s - loss: 0.2123 - accuracy: 0.9806 - val_loss: 1.5065 - val_accuracy: 0.7365
Epoch 89/110
 - 2s - loss: 0.1907 - accuracy: 0.9867 - val_loss: 1.5276 - val_accuracy: 0.7263
Epoch 90/110
 - 2s - loss: 0.1846 - accuracy: 0.9887 - val_loss: 1.5676 - val_accuracy: 0.7204
Epoch 91/110
 - 2s - loss: 0.1763 - accuracy: 0.9898 - val_loss: 1.5506 - val_accuracy: 0.7234
Epoch 92/110
 - 2s - loss: 0.1756 - accuracy: 0.9894 - val_loss: 1.5565 - val_accuracy: 0.7234
Epoch 93/110
 - 2s - loss: 0.1723 - accuracy: 0.9912 - val_loss: 1.5448 - val_accuracy: 0.7277
Epoch 94/110
 - 2s - loss: 0.1701 - accuracy: 0.9907 - val_loss: 1.5841 - val_accuracy: 0.7234
Epoch 95/110
 - 2s - loss: 0.1688 - accuracy: 0.9911 - val_loss: 1.6028 - val_accuracy: 0.7409
Epoch 96/110
 - 2s - loss: 0.1731 - accuracy: 0.9894 - val_loss: 1.5831 - val_accuracy: 0.7161
Epoch 97/110
 - 2s - loss: 0.1844 - accuracy: 0.9872 - val_loss: 1.6784 - val_accuracy: 0.7007
Epoch 98/110
 - 2s - loss: 0.2278 - accuracy: 0.9733 - val_loss: 1.7005 - val_accuracy: 0.6920
Epoch 99/110
 - 2s - loss: 0.2687 - accuracy: 0.9591 - val_loss: 1.6160 - val_accuracy: 0.6956
Epoch 100/110
 - 1s - loss: 0.3119 - accuracy: 0.9494 - val_loss: 1.5683 - val_accuracy: 0.6839
Epoch 101/110
 - 2s - loss: 0.2544 - accuracy: 0.9611 - val_loss: 1.5891 - val_accuracy: 0.6861
Epoch 102/110
 - 2s - loss: 0.2471 - accuracy: 0.9691 - val_loss: 1.5831 - val_accuracy: 0.6971
Epoch 103/110
 - 2s - loss: 0.2093 - accuracy: 0.9796 - val_loss: 1.5832 - val_accuracy: 0.7139
Epoch 104/110
 - 2s - loss: 0.1870 - accuracy: 0.9870 - val_loss: 1.6159 - val_accuracy: 0.7270
Epoch 105/110
 - 2s - loss: 0.1693 - accuracy: 0.9916 - val_loss: 1.6090 - val_accuracy: 0.7292
Epoch 106/110
 - 2s - loss: 0.1677 - accuracy: 0.9914 - val_loss: 1.5579 - val_accuracy: 0.7380
Epoch 107/110
 - 2s - loss: 0.1709 - accuracy: 0.9907 - val_loss: 1.6558 - val_accuracy: 0.7263
Epoch 108/110
 - 2s - loss: 0.1829 - accuracy: 0.9870 - val_loss: 1.7375 - val_accuracy: 0.7124
Epoch 109/110
 - 2s - loss: 0.1878 - accuracy: 0.9852 - val_loss: 1.6800 - val_accuracy: 0.7182
Epoch 110/110
 - 2s - loss: 0.2190 - accuracy: 0.9775 - val_loss: 1.7049 - val_accuracy: 0.7036
------------------------------------------------------------------------
Training for fold 7 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 2s - loss: 0.1999 - accuracy: 0.9803 - val_loss: 1.6619 - val_accuracy: 0.6978
Epoch 2/110
 - 2s - loss: 0.2942 - accuracy: 0.9547 - val_loss: 1.7983 - val_accuracy: 0.6723
Epoch 3/110
 - 2s - loss: 0.3152 - accuracy: 0.9432 - val_loss: 1.7305 - val_accuracy: 0.6861
Epoch 4/110
 - 2s - loss: 0.2474 - accuracy: 0.9650 - val_loss: 1.6005 - val_accuracy: 0.7139
Epoch 5/110
 - 2s - loss: 0.2293 - accuracy: 0.9746 - val_loss: 1.5306 - val_accuracy: 0.7036
Epoch 6/110
 - 2s - loss: 0.2226 - accuracy: 0.9763 - val_loss: 1.6111 - val_accuracy: 0.7131
Epoch 7/110
 - 2s - loss: 0.2021 - accuracy: 0.9830 - val_loss: 1.5731 - val_accuracy: 0.7255
Epoch 8/110
 - 2s - loss: 0.1812 - accuracy: 0.9889 - val_loss: 1.5398 - val_accuracy: 0.7314
Epoch 9/110
 - 2s - loss: 0.1762 - accuracy: 0.9885 - val_loss: 1.5942 - val_accuracy: 0.7248
Epoch 10/110
 - 2s - loss: 0.1767 - accuracy: 0.9896 - val_loss: 1.6150 - val_accuracy: 0.7285
Epoch 11/110
 - 2s - loss: 0.1790 - accuracy: 0.9880 - val_loss: 1.6555 - val_accuracy: 0.7241
Epoch 12/110
 - 2s - loss: 0.1726 - accuracy: 0.9907 - val_loss: 1.6052 - val_accuracy: 0.7131
Epoch 13/110
 - 2s - loss: 0.1762 - accuracy: 0.9872 - val_loss: 1.6270 - val_accuracy: 0.7299
Epoch 14/110
 - 2s - loss: 0.1748 - accuracy: 0.9887 - val_loss: 1.5560 - val_accuracy: 0.7314
Epoch 15/110
 - 2s - loss: 0.1800 - accuracy: 0.9874 - val_loss: 1.6753 - val_accuracy: 0.7175
Epoch 16/110
 - 2s - loss: 0.2361 - accuracy: 0.9717 - val_loss: 1.9269 - val_accuracy: 0.6737
Epoch 17/110
 - 2s - loss: 0.2900 - accuracy: 0.9500 - val_loss: 1.7684 - val_accuracy: 0.6861
Epoch 18/110
 - 2s - loss: 0.2952 - accuracy: 0.9533 - val_loss: 1.6291 - val_accuracy: 0.6971
Epoch 19/110
 - 2s - loss: 0.2295 - accuracy: 0.9735 - val_loss: 1.5559 - val_accuracy: 0.7197
Epoch 20/110
 - 2s - loss: 0.1882 - accuracy: 0.9863 - val_loss: 1.5689 - val_accuracy: 0.7190
Epoch 21/110
 - 2s - loss: 0.1762 - accuracy: 0.9894 - val_loss: 1.5659 - val_accuracy: 0.7255
Epoch 22/110
 - 2s - loss: 0.1710 - accuracy: 0.9905 - val_loss: 1.6320 - val_accuracy: 0.7161
Epoch 23/110
 - 2s - loss: 0.1686 - accuracy: 0.9909 - val_loss: 1.5581 - val_accuracy: 0.7263
Epoch 24/110
 - 2s - loss: 0.1684 - accuracy: 0.9903 - val_loss: 1.5443 - val_accuracy: 0.7307
Epoch 25/110
 - 2s - loss: 0.1687 - accuracy: 0.9898 - val_loss: 1.7001 - val_accuracy: 0.7219
Epoch 26/110
 - 2s - loss: 0.1727 - accuracy: 0.9892 - val_loss: 1.6067 - val_accuracy: 0.7350
Epoch 27/110
 - 1s - loss: 0.1649 - accuracy: 0.9903 - val_loss: 1.5767 - val_accuracy: 0.7314
Epoch 28/110
 - 2s - loss: 0.1674 - accuracy: 0.9900 - val_loss: 1.6806 - val_accuracy: 0.7263
Epoch 29/110
 - 2s - loss: 0.1626 - accuracy: 0.9909 - val_loss: 1.5986 - val_accuracy: 0.7248
Epoch 30/110
 - 2s - loss: 0.1695 - accuracy: 0.9887 - val_loss: 1.7241 - val_accuracy: 0.7058
Epoch 31/110
 - 2s - loss: 0.2614 - accuracy: 0.9613 - val_loss: 1.9414 - val_accuracy: 0.6766
Epoch 32/110
 - 2s - loss: 0.5438 - accuracy: 0.8744 - val_loss: 1.4096 - val_accuracy: 0.6737
Epoch 33/110
 - 2s - loss: 0.3486 - accuracy: 0.9310 - val_loss: 1.3675 - val_accuracy: 0.7007
Epoch 34/110
 - 2s - loss: 0.2344 - accuracy: 0.9704 - val_loss: 1.4220 - val_accuracy: 0.7088
Epoch 35/110
 - 2s - loss: 0.1914 - accuracy: 0.9843 - val_loss: 1.4529 - val_accuracy: 0.7153
Epoch 36/110
 - 2s - loss: 0.1735 - accuracy: 0.9907 - val_loss: 1.4136 - val_accuracy: 0.7226
Epoch 37/110
 - 2s - loss: 0.1654 - accuracy: 0.9922 - val_loss: 1.4599 - val_accuracy: 0.7336
Epoch 38/110
 - 2s - loss: 0.1652 - accuracy: 0.9911 - val_loss: 1.4718 - val_accuracy: 0.7336
Epoch 39/110
 - 2s - loss: 0.1653 - accuracy: 0.9916 - val_loss: 1.5065 - val_accuracy: 0.7343
Epoch 40/110
 - 2s - loss: 0.1685 - accuracy: 0.9903 - val_loss: 1.5707 - val_accuracy: 0.7270
Epoch 41/110
 - 2s - loss: 0.1654 - accuracy: 0.9903 - val_loss: 1.5330 - val_accuracy: 0.7277
Epoch 42/110
 - 2s - loss: 0.1649 - accuracy: 0.9896 - val_loss: 1.5883 - val_accuracy: 0.7277
Epoch 43/110
 - 2s - loss: 0.1776 - accuracy: 0.9870 - val_loss: 1.5921 - val_accuracy: 0.7131
Epoch 44/110
 - 2s - loss: 0.1967 - accuracy: 0.9814 - val_loss: 1.7347 - val_accuracy: 0.7073
Epoch 45/110
 - 2s - loss: 0.2205 - accuracy: 0.9748 - val_loss: 1.7392 - val_accuracy: 0.7036
Epoch 46/110
 - 2s - loss: 0.2659 - accuracy: 0.9580 - val_loss: 1.6119 - val_accuracy: 0.6745
Epoch 47/110
 - 2s - loss: 0.3208 - accuracy: 0.9414 - val_loss: 1.6561 - val_accuracy: 0.6620
Epoch 48/110
 - 2s - loss: 0.2735 - accuracy: 0.9582 - val_loss: 1.3970 - val_accuracy: 0.7175
Epoch 49/110
 - 1s - loss: 0.2360 - accuracy: 0.9693 - val_loss: 1.6021 - val_accuracy: 0.7051
Epoch 50/110
 - 2s - loss: 0.2144 - accuracy: 0.9772 - val_loss: 1.4929 - val_accuracy: 0.6985
Epoch 51/110
 - 2s - loss: 0.1922 - accuracy: 0.9843 - val_loss: 1.5283 - val_accuracy: 0.7328
Epoch 52/110
 - 2s - loss: 0.1795 - accuracy: 0.9872 - val_loss: 1.5153 - val_accuracy: 0.7234
Epoch 53/110
 - 2s - loss: 0.1749 - accuracy: 0.9889 - val_loss: 1.5769 - val_accuracy: 0.7190
Epoch 54/110
 - 2s - loss: 0.1677 - accuracy: 0.9911 - val_loss: 1.5627 - val_accuracy: 0.7226
Epoch 55/110
 - 2s - loss: 0.1719 - accuracy: 0.9892 - val_loss: 1.5864 - val_accuracy: 0.7168
Epoch 56/110
 - 2s - loss: 0.1655 - accuracy: 0.9911 - val_loss: 1.5886 - val_accuracy: 0.7314
Epoch 57/110
 - 2s - loss: 0.1622 - accuracy: 0.9912 - val_loss: 1.5784 - val_accuracy: 0.7270
Epoch 58/110
 - 2s - loss: 0.1618 - accuracy: 0.9912 - val_loss: 1.6329 - val_accuracy: 0.7307
Epoch 59/110
 - 2s - loss: 0.1643 - accuracy: 0.9905 - val_loss: 1.6993 - val_accuracy: 0.7153
Epoch 60/110
 - 2s - loss: 0.1992 - accuracy: 0.9797 - val_loss: 1.8002 - val_accuracy: 0.6898
Epoch 61/110
 - 1s - loss: 0.3029 - accuracy: 0.9478 - val_loss: 1.7842 - val_accuracy: 0.6759
Epoch 62/110
 - 2s - loss: 0.3551 - accuracy: 0.9295 - val_loss: 1.5135 - val_accuracy: 0.6788
Epoch 63/110
 - 2s - loss: 0.2760 - accuracy: 0.9571 - val_loss: 1.6361 - val_accuracy: 0.6701
Epoch 64/110
 - 2s - loss: 0.2027 - accuracy: 0.9805 - val_loss: 1.4890 - val_accuracy: 0.7190
Epoch 65/110
 - 2s - loss: 0.1831 - accuracy: 0.9854 - val_loss: 1.5612 - val_accuracy: 0.7080
Epoch 66/110
 - 2s - loss: 0.1798 - accuracy: 0.9883 - val_loss: 1.5571 - val_accuracy: 0.7036
Epoch 67/110
 - 2s - loss: 0.1714 - accuracy: 0.9898 - val_loss: 1.5467 - val_accuracy: 0.7146
Epoch 68/110
 - 2s - loss: 0.1680 - accuracy: 0.9900 - val_loss: 1.5497 - val_accuracy: 0.7117
Epoch 69/110
 - 2s - loss: 0.1740 - accuracy: 0.9878 - val_loss: 1.5671 - val_accuracy: 0.7131
Epoch 70/110
 - 2s - loss: 0.1842 - accuracy: 0.9861 - val_loss: 1.5632 - val_accuracy: 0.7190
Epoch 71/110
 - 2s - loss: 0.1718 - accuracy: 0.9870 - val_loss: 1.5944 - val_accuracy: 0.7204
Epoch 72/110
 - 2s - loss: 0.2817 - accuracy: 0.9600 - val_loss: 1.6986 - val_accuracy: 0.6803
Epoch 73/110
 - 1s - loss: 0.2680 - accuracy: 0.9608 - val_loss: 1.5694 - val_accuracy: 0.6993
Epoch 74/110
 - 2s - loss: 0.2393 - accuracy: 0.9653 - val_loss: 1.6328 - val_accuracy: 0.7139
Epoch 75/110
 - 1s - loss: 0.2046 - accuracy: 0.9794 - val_loss: 1.5370 - val_accuracy: 0.7124
Epoch 76/110
 - 2s - loss: 0.1906 - accuracy: 0.9859 - val_loss: 1.5851 - val_accuracy: 0.7153
Epoch 77/110
 - 2s - loss: 0.1802 - accuracy: 0.9872 - val_loss: 1.5876 - val_accuracy: 0.7234
Epoch 78/110
 - 2s - loss: 0.1818 - accuracy: 0.9889 - val_loss: 1.6244 - val_accuracy: 0.7226
Epoch 79/110
 - 2s - loss: 0.1714 - accuracy: 0.9903 - val_loss: 1.6728 - val_accuracy: 0.7190
Epoch 80/110
 - 2s - loss: 0.1899 - accuracy: 0.9838 - val_loss: 1.7723 - val_accuracy: 0.7226
Epoch 81/110
 - 2s - loss: 0.1877 - accuracy: 0.9858 - val_loss: 1.6450 - val_accuracy: 0.7182
Epoch 82/110
 - 2s - loss: 0.1845 - accuracy: 0.9838 - val_loss: 1.7009 - val_accuracy: 0.7015
Epoch 83/110
 - 2s - loss: 0.2222 - accuracy: 0.9723 - val_loss: 1.7930 - val_accuracy: 0.6912
Epoch 84/110
 - 2s - loss: 0.2356 - accuracy: 0.9695 - val_loss: 1.6687 - val_accuracy: 0.7088
Epoch 85/110
 - 2s - loss: 0.2317 - accuracy: 0.9719 - val_loss: 1.6142 - val_accuracy: 0.7175
Epoch 86/110
 - 1s - loss: 0.2121 - accuracy: 0.9779 - val_loss: 1.5961 - val_accuracy: 0.7095
Epoch 87/110
 - 1s - loss: 0.1971 - accuracy: 0.9797 - val_loss: 1.6654 - val_accuracy: 0.7015
Epoch 88/110
 - 2s - loss: 0.1839 - accuracy: 0.9843 - val_loss: 1.6162 - val_accuracy: 0.7153
Epoch 89/110
 - 2s - loss: 0.1801 - accuracy: 0.9867 - val_loss: 1.5104 - val_accuracy: 0.7241
Epoch 90/110
 - 2s - loss: 0.1766 - accuracy: 0.9880 - val_loss: 1.6161 - val_accuracy: 0.7292
Epoch 91/110
 - 2s - loss: 0.1745 - accuracy: 0.9883 - val_loss: 1.6347 - val_accuracy: 0.7044
Epoch 92/110
 - 2s - loss: 0.1882 - accuracy: 0.9843 - val_loss: 1.7660 - val_accuracy: 0.6898
Epoch 93/110
 - 2s - loss: 0.2263 - accuracy: 0.9737 - val_loss: 1.5636 - val_accuracy: 0.7241
Epoch 94/110
 - 2s - loss: 0.2289 - accuracy: 0.9744 - val_loss: 1.5031 - val_accuracy: 0.7080
Epoch 95/110
 - 2s - loss: 0.2134 - accuracy: 0.9772 - val_loss: 1.7137 - val_accuracy: 0.6934
Epoch 96/110
 - 2s - loss: 0.2365 - accuracy: 0.9681 - val_loss: 1.5252 - val_accuracy: 0.7109
Epoch 97/110
 - 2s - loss: 0.1935 - accuracy: 0.9819 - val_loss: 1.6485 - val_accuracy: 0.7161
Epoch 98/110
 - 2s - loss: 0.2185 - accuracy: 0.9750 - val_loss: 1.6486 - val_accuracy: 0.6971
Epoch 99/110
 - 2s - loss: 0.2843 - accuracy: 0.9595 - val_loss: 1.7428 - val_accuracy: 0.7080
Epoch 100/110
 - 1s - loss: 0.2604 - accuracy: 0.9642 - val_loss: 1.6350 - val_accuracy: 0.7095
Epoch 101/110
 - 2s - loss: 0.2083 - accuracy: 0.9808 - val_loss: 1.5913 - val_accuracy: 0.7146
Epoch 102/110
 - 2s - loss: 0.1854 - accuracy: 0.9867 - val_loss: 1.6167 - val_accuracy: 0.7226
Epoch 103/110
 - 2s - loss: 0.1705 - accuracy: 0.9896 - val_loss: 1.6489 - val_accuracy: 0.7219
Epoch 104/110
 - 2s - loss: 0.1687 - accuracy: 0.9903 - val_loss: 1.6055 - val_accuracy: 0.7263
Epoch 105/110
 - 2s - loss: 0.1859 - accuracy: 0.9858 - val_loss: 1.6318 - val_accuracy: 0.7153
Epoch 106/110
 - 2s - loss: 0.1714 - accuracy: 0.9890 - val_loss: 1.6104 - val_accuracy: 0.7307
Epoch 107/110
 - 2s - loss: 0.1756 - accuracy: 0.9874 - val_loss: 1.7122 - val_accuracy: 0.7131
Epoch 108/110
 - 2s - loss: 0.1642 - accuracy: 0.9911 - val_loss: 1.7387 - val_accuracy: 0.7299
Epoch 109/110
 - 2s - loss: 0.1663 - accuracy: 0.9905 - val_loss: 1.6565 - val_accuracy: 0.7241
Epoch 110/110
 - 2s - loss: 0.1982 - accuracy: 0.9801 - val_loss: 1.8433 - val_accuracy: 0.7212
------------------------------------------------------------------------
Training for fold 8 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 2s - loss: 0.2186 - accuracy: 0.9741 - val_loss: 1.7153 - val_accuracy: 0.6971
Epoch 2/110
 - 2s - loss: 0.2064 - accuracy: 0.9779 - val_loss: 1.5899 - val_accuracy: 0.7182
Epoch 3/110
 - 2s - loss: 0.2385 - accuracy: 0.9693 - val_loss: 1.7003 - val_accuracy: 0.6854
Epoch 4/110
 - 2s - loss: 0.2306 - accuracy: 0.9704 - val_loss: 1.7661 - val_accuracy: 0.7058
Epoch 5/110
 - 2s - loss: 0.2352 - accuracy: 0.9690 - val_loss: 1.7691 - val_accuracy: 0.6847
Epoch 6/110
 - 2s - loss: 0.2660 - accuracy: 0.9620 - val_loss: 1.5743 - val_accuracy: 0.6905
Epoch 7/110
 - 2s - loss: 0.2115 - accuracy: 0.9737 - val_loss: 1.6425 - val_accuracy: 0.7058
Epoch 8/110
 - 2s - loss: 0.1839 - accuracy: 0.9861 - val_loss: 1.6648 - val_accuracy: 0.7270
Epoch 9/110
 - 2s - loss: 0.1711 - accuracy: 0.9896 - val_loss: 1.6420 - val_accuracy: 0.7277
Epoch 10/110
 - 2s - loss: 0.1681 - accuracy: 0.9894 - val_loss: 1.6805 - val_accuracy: 0.7263
Epoch 11/110
 - 2s - loss: 0.1600 - accuracy: 0.9920 - val_loss: 1.6933 - val_accuracy: 0.7234
Epoch 12/110
 - 2s - loss: 0.1581 - accuracy: 0.9923 - val_loss: 1.6664 - val_accuracy: 0.7365
Epoch 13/110
 - 2s - loss: 0.1573 - accuracy: 0.9920 - val_loss: 1.7125 - val_accuracy: 0.7292
Epoch 14/110
 - 2s - loss: 0.1565 - accuracy: 0.9923 - val_loss: 1.6701 - val_accuracy: 0.7307
Epoch 15/110
 - 2s - loss: 0.1564 - accuracy: 0.9918 - val_loss: 1.7674 - val_accuracy: 0.7263
Epoch 16/110
 - 2s - loss: 0.1556 - accuracy: 0.9922 - val_loss: 1.6642 - val_accuracy: 0.7248
Epoch 17/110
 - 2s - loss: 0.1534 - accuracy: 0.9923 - val_loss: 1.6880 - val_accuracy: 0.7277
Epoch 18/110
 - 2s - loss: 0.1525 - accuracy: 0.9925 - val_loss: 1.6848 - val_accuracy: 0.7270
Epoch 19/110
 - 2s - loss: 0.1516 - accuracy: 0.9918 - val_loss: 1.6880 - val_accuracy: 0.7350
Epoch 20/110
 - 2s - loss: 0.1498 - accuracy: 0.9922 - val_loss: 1.7273 - val_accuracy: 0.7350
Epoch 21/110
 - 2s - loss: 0.1491 - accuracy: 0.9922 - val_loss: 1.7020 - val_accuracy: 0.7358
Epoch 22/110
 - 2s - loss: 0.1532 - accuracy: 0.9911 - val_loss: 1.7541 - val_accuracy: 0.7307
Epoch 23/110
 - 2s - loss: 0.2020 - accuracy: 0.9796 - val_loss: 1.8789 - val_accuracy: 0.6693
Epoch 24/110
 - 2s - loss: 0.5652 - accuracy: 0.8678 - val_loss: 1.5832 - val_accuracy: 0.6409
Epoch 25/110
 - 2s - loss: 0.4220 - accuracy: 0.9049 - val_loss: 1.4815 - val_accuracy: 0.6985
Epoch 26/110
 - 2s - loss: 0.2491 - accuracy: 0.9613 - val_loss: 1.4159 - val_accuracy: 0.7088
Epoch 27/110
 - 2s - loss: 0.1897 - accuracy: 0.9825 - val_loss: 1.5383 - val_accuracy: 0.7204
Epoch 28/110
 - 2s - loss: 0.1708 - accuracy: 0.9887 - val_loss: 1.5573 - val_accuracy: 0.7219
Epoch 29/110
 - 2s - loss: 0.1628 - accuracy: 0.9920 - val_loss: 1.6269 - val_accuracy: 0.7241
Epoch 30/110
 - 2s - loss: 0.1591 - accuracy: 0.9916 - val_loss: 1.5648 - val_accuracy: 0.7299
Epoch 31/110
 - 2s - loss: 0.1578 - accuracy: 0.9922 - val_loss: 1.6602 - val_accuracy: 0.7248
Epoch 32/110
 - 2s - loss: 0.1626 - accuracy: 0.9892 - val_loss: 1.6124 - val_accuracy: 0.7212
Epoch 33/110
 - 2s - loss: 0.1595 - accuracy: 0.9901 - val_loss: 1.6093 - val_accuracy: 0.7270
Epoch 34/110
 - 2s - loss: 0.1539 - accuracy: 0.9920 - val_loss: 1.7132 - val_accuracy: 0.7234
Epoch 35/110
 - 2s - loss: 0.1668 - accuracy: 0.9874 - val_loss: 1.7581 - val_accuracy: 0.7161
Epoch 36/110
 - 2s - loss: 0.2276 - accuracy: 0.9712 - val_loss: 1.8307 - val_accuracy: 0.6796
Epoch 37/110
 - 2s - loss: 0.3512 - accuracy: 0.9348 - val_loss: 1.7290 - val_accuracy: 0.6358
Epoch 38/110
 - 2s - loss: 0.2815 - accuracy: 0.9483 - val_loss: 1.5129 - val_accuracy: 0.7117
Epoch 39/110
 - 2s - loss: 0.1984 - accuracy: 0.9810 - val_loss: 1.4385 - val_accuracy: 0.7234
Epoch 40/110
 - 2s - loss: 0.1847 - accuracy: 0.9839 - val_loss: 1.6038 - val_accuracy: 0.7044
Epoch 41/110
 - 2s - loss: 0.1779 - accuracy: 0.9881 - val_loss: 1.5338 - val_accuracy: 0.7066
Epoch 42/110
 - 2s - loss: 0.1663 - accuracy: 0.9900 - val_loss: 1.5188 - val_accuracy: 0.7234
Epoch 43/110
 - 2s - loss: 0.1651 - accuracy: 0.9892 - val_loss: 1.5589 - val_accuracy: 0.7197
Epoch 44/110
 - 2s - loss: 0.1620 - accuracy: 0.9901 - val_loss: 1.5935 - val_accuracy: 0.7285
Epoch 45/110
 - 2s - loss: 0.1635 - accuracy: 0.9890 - val_loss: 1.6153 - val_accuracy: 0.7314
Epoch 46/110
 - 2s - loss: 0.1649 - accuracy: 0.9901 - val_loss: 1.7134 - val_accuracy: 0.7168
Epoch 47/110
 - 2s - loss: 0.1923 - accuracy: 0.9821 - val_loss: 1.6382 - val_accuracy: 0.6949
Epoch 48/110
 - 2s - loss: 0.2317 - accuracy: 0.9688 - val_loss: 1.7080 - val_accuracy: 0.6891
Epoch 49/110
 - 2s - loss: 0.2562 - accuracy: 0.9615 - val_loss: 1.5823 - val_accuracy: 0.6781
Epoch 50/110
 - 2s - loss: 0.2503 - accuracy: 0.9618 - val_loss: 1.5610 - val_accuracy: 0.7168
Epoch 51/110
 - 1s - loss: 0.2304 - accuracy: 0.9688 - val_loss: 1.6100 - val_accuracy: 0.7007
Epoch 52/110
 - 2s - loss: 0.2019 - accuracy: 0.9781 - val_loss: 1.5229 - val_accuracy: 0.7182
Epoch 53/110
 - 1s - loss: 0.1868 - accuracy: 0.9825 - val_loss: 1.5175 - val_accuracy: 0.7131
Epoch 54/110
 - 2s - loss: 0.1723 - accuracy: 0.9885 - val_loss: 1.5516 - val_accuracy: 0.7248
Epoch 55/110
 - 2s - loss: 0.1623 - accuracy: 0.9905 - val_loss: 1.5734 - val_accuracy: 0.7234
Epoch 56/110
 - 2s - loss: 0.1591 - accuracy: 0.9905 - val_loss: 1.6426 - val_accuracy: 0.7197
Epoch 57/110
 - 2s - loss: 0.1567 - accuracy: 0.9920 - val_loss: 1.5547 - val_accuracy: 0.7255
Epoch 58/110
 - 2s - loss: 0.1540 - accuracy: 0.9918 - val_loss: 1.6114 - val_accuracy: 0.7234
Epoch 59/110
 - 2s - loss: 0.1537 - accuracy: 0.9911 - val_loss: 1.6076 - val_accuracy: 0.7270
Epoch 60/110
 - 2s - loss: 0.1560 - accuracy: 0.9911 - val_loss: 1.7591 - val_accuracy: 0.7234
Epoch 61/110
 - 2s - loss: 0.1578 - accuracy: 0.9900 - val_loss: 1.6880 - val_accuracy: 0.7248
Epoch 62/110
 - 2s - loss: 0.1711 - accuracy: 0.9856 - val_loss: 1.7005 - val_accuracy: 0.6985
Epoch 63/110
 - 2s - loss: 0.2772 - accuracy: 0.9524 - val_loss: 1.7377 - val_accuracy: 0.6701
Epoch 64/110
 - 2s - loss: 0.3968 - accuracy: 0.9142 - val_loss: 1.6986 - val_accuracy: 0.6409
Epoch 65/110
 - 2s - loss: 0.3510 - accuracy: 0.9288 - val_loss: 1.3387 - val_accuracy: 0.7022
Epoch 66/110
 - 2s - loss: 0.2247 - accuracy: 0.9697 - val_loss: 1.4468 - val_accuracy: 0.7124
Epoch 67/110
 - 2s - loss: 0.1756 - accuracy: 0.9869 - val_loss: 1.5525 - val_accuracy: 0.7153
Epoch 68/110
 - 2s - loss: 0.1670 - accuracy: 0.9894 - val_loss: 1.5484 - val_accuracy: 0.7139
Epoch 69/110
 - 2s - loss: 0.1591 - accuracy: 0.9918 - val_loss: 1.5494 - val_accuracy: 0.7380
Epoch 70/110
 - 2s - loss: 0.1567 - accuracy: 0.9914 - val_loss: 1.5367 - val_accuracy: 0.7292
Epoch 71/110
 - 2s - loss: 0.1568 - accuracy: 0.9907 - val_loss: 1.5861 - val_accuracy: 0.7285
Epoch 72/110
 - 2s - loss: 0.1577 - accuracy: 0.9907 - val_loss: 1.5859 - val_accuracy: 0.7255
Epoch 73/110
 - 2s - loss: 0.1559 - accuracy: 0.9907 - val_loss: 1.5869 - val_accuracy: 0.7241
Epoch 74/110
 - 2s - loss: 0.1578 - accuracy: 0.9898 - val_loss: 1.6109 - val_accuracy: 0.7285
Epoch 75/110
 - 2s - loss: 0.1565 - accuracy: 0.9905 - val_loss: 1.5813 - val_accuracy: 0.7343
Epoch 76/110
 - 2s - loss: 0.1551 - accuracy: 0.9909 - val_loss: 1.6125 - val_accuracy: 0.7248
Epoch 77/110
 - 2s - loss: 0.1658 - accuracy: 0.9883 - val_loss: 1.6164 - val_accuracy: 0.7175
Epoch 78/110
 - 2s - loss: 0.1661 - accuracy: 0.9861 - val_loss: 1.7794 - val_accuracy: 0.7109
Epoch 79/110
 - 2s - loss: 0.1972 - accuracy: 0.9790 - val_loss: 1.8170 - val_accuracy: 0.6876
Epoch 80/110
 - 2s - loss: 0.2882 - accuracy: 0.9494 - val_loss: 1.7435 - val_accuracy: 0.6737
Epoch 81/110
 - 2s - loss: 0.3618 - accuracy: 0.9303 - val_loss: 1.7455 - val_accuracy: 0.6818
Epoch 82/110
 - 1s - loss: 0.2506 - accuracy: 0.9620 - val_loss: 1.5186 - val_accuracy: 0.7073
Epoch 83/110
 - 2s - loss: 0.2018 - accuracy: 0.9785 - val_loss: 1.5270 - val_accuracy: 0.7139
Epoch 84/110
 - 2s - loss: 0.1714 - accuracy: 0.9878 - val_loss: 1.5188 - val_accuracy: 0.7248
Epoch 85/110
 - 2s - loss: 0.1555 - accuracy: 0.9911 - val_loss: 1.5458 - val_accuracy: 0.7153
Epoch 86/110
 - 2s - loss: 0.1548 - accuracy: 0.9907 - val_loss: 1.5671 - val_accuracy: 0.7292
Epoch 87/110
 - 2s - loss: 0.1741 - accuracy: 0.9848 - val_loss: 1.6250 - val_accuracy: 0.7263
Epoch 88/110
 - 2s - loss: 0.1805 - accuracy: 0.9854 - val_loss: 1.6291 - val_accuracy: 0.7088
Epoch 89/110
 - 2s - loss: 0.1647 - accuracy: 0.9883 - val_loss: 1.5693 - val_accuracy: 0.7255
Epoch 90/110
 - 2s - loss: 0.1604 - accuracy: 0.9900 - val_loss: 1.6123 - val_accuracy: 0.7277
Epoch 91/110
 - 2s - loss: 0.1572 - accuracy: 0.9900 - val_loss: 1.5593 - val_accuracy: 0.7343
Epoch 92/110
 - 2s - loss: 0.1644 - accuracy: 0.9887 - val_loss: 1.5566 - val_accuracy: 0.7226
Epoch 93/110
 - 2s - loss: 0.2269 - accuracy: 0.9677 - val_loss: 1.6866 - val_accuracy: 0.6891
Epoch 94/110
 - 2s - loss: 0.3142 - accuracy: 0.9401 - val_loss: 1.7257 - val_accuracy: 0.6708
Epoch 95/110
 - 2s - loss: 0.2870 - accuracy: 0.9461 - val_loss: 1.4835 - val_accuracy: 0.6898
Epoch 96/110
 - 2s - loss: 0.2195 - accuracy: 0.9701 - val_loss: 1.4861 - val_accuracy: 0.7212
Epoch 97/110
 - 2s - loss: 0.1908 - accuracy: 0.9810 - val_loss: 1.6596 - val_accuracy: 0.7146
Epoch 98/110
 - 2s - loss: 0.1952 - accuracy: 0.9821 - val_loss: 1.6100 - val_accuracy: 0.7036
Epoch 99/110
 - 2s - loss: 0.1965 - accuracy: 0.9801 - val_loss: 1.6202 - val_accuracy: 0.7080
Epoch 100/110
 - 1s - loss: 0.1896 - accuracy: 0.9812 - val_loss: 1.5752 - val_accuracy: 0.7212
Epoch 101/110
 - 2s - loss: 0.1764 - accuracy: 0.9870 - val_loss: 1.6345 - val_accuracy: 0.7190
Epoch 102/110
 - 2s - loss: 0.1613 - accuracy: 0.9898 - val_loss: 1.6071 - val_accuracy: 0.7277
Epoch 103/110
 - 2s - loss: 0.1579 - accuracy: 0.9909 - val_loss: 1.6303 - val_accuracy: 0.7102
Epoch 104/110
 - 2s - loss: 0.1779 - accuracy: 0.9869 - val_loss: 1.6239 - val_accuracy: 0.7124
Epoch 105/110
 - 2s - loss: 0.1649 - accuracy: 0.9870 - val_loss: 1.6290 - val_accuracy: 0.7248
Epoch 106/110
 - 2s - loss: 0.1724 - accuracy: 0.9856 - val_loss: 1.6879 - val_accuracy: 0.7044
Epoch 107/110
 - 2s - loss: 0.1671 - accuracy: 0.9881 - val_loss: 1.6120 - val_accuracy: 0.7212
Epoch 108/110
 - 2s - loss: 0.1610 - accuracy: 0.9903 - val_loss: 1.6574 - val_accuracy: 0.7234
Epoch 109/110
 - 2s - loss: 0.1628 - accuracy: 0.9885 - val_loss: 1.6987 - val_accuracy: 0.7139
Epoch 110/110
 - 2s - loss: 0.1636 - accuracy: 0.9887 - val_loss: 1.6982 - val_accuracy: 0.7131
------------------------------------------------------------------------
Training for fold 9 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 2s - loss: 0.2017 - accuracy: 0.9797 - val_loss: 1.7182 - val_accuracy: 0.7080
Epoch 2/110
 - 2s - loss: 0.2805 - accuracy: 0.9558 - val_loss: 1.7777 - val_accuracy: 0.6715
Epoch 3/110
 - 2s - loss: 0.3104 - accuracy: 0.9427 - val_loss: 1.5788 - val_accuracy: 0.6861
Epoch 4/110
 - 2s - loss: 0.2311 - accuracy: 0.9668 - val_loss: 1.6323 - val_accuracy: 0.6891
Epoch 5/110
 - 2s - loss: 0.2042 - accuracy: 0.9752 - val_loss: 1.6263 - val_accuracy: 0.7248
Epoch 6/110
 - 2s - loss: 0.1839 - accuracy: 0.9847 - val_loss: 1.6217 - val_accuracy: 0.7109
Epoch 7/110
 - 2s - loss: 0.1754 - accuracy: 0.9850 - val_loss: 1.5485 - val_accuracy: 0.7336
Epoch 8/110
 - 2s - loss: 0.1636 - accuracy: 0.9889 - val_loss: 1.6405 - val_accuracy: 0.7307
Epoch 9/110
 - 2s - loss: 0.1589 - accuracy: 0.9901 - val_loss: 1.6630 - val_accuracy: 0.7234
Epoch 10/110
 - 2s - loss: 0.1604 - accuracy: 0.9900 - val_loss: 1.6910 - val_accuracy: 0.7190
Epoch 11/110
 - 2s - loss: 0.1573 - accuracy: 0.9903 - val_loss: 1.5809 - val_accuracy: 0.7460
Epoch 12/110
 - 2s - loss: 0.1526 - accuracy: 0.9911 - val_loss: 1.6085 - val_accuracy: 0.7511
Epoch 13/110
 - 2s - loss: 0.1497 - accuracy: 0.9920 - val_loss: 1.6352 - val_accuracy: 0.7372
Epoch 14/110
 - 2s - loss: 0.1536 - accuracy: 0.9909 - val_loss: 1.6585 - val_accuracy: 0.7336
Epoch 15/110
 - 2s - loss: 0.1694 - accuracy: 0.9865 - val_loss: 1.6656 - val_accuracy: 0.7248
Epoch 16/110
 - 2s - loss: 0.1667 - accuracy: 0.9874 - val_loss: 1.6082 - val_accuracy: 0.7248
Epoch 17/110
 - 2s - loss: 0.1601 - accuracy: 0.9880 - val_loss: 1.7020 - val_accuracy: 0.7139
Epoch 18/110
 - 2s - loss: 0.1724 - accuracy: 0.9859 - val_loss: 1.7698 - val_accuracy: 0.7095
Epoch 19/110
 - 2s - loss: 0.1923 - accuracy: 0.9783 - val_loss: 1.7080 - val_accuracy: 0.7161
Epoch 20/110
 - 2s - loss: 0.3086 - accuracy: 0.9443 - val_loss: 1.8589 - val_accuracy: 0.6635
Epoch 21/110
 - 2s - loss: 0.3033 - accuracy: 0.9372 - val_loss: 1.8058 - val_accuracy: 0.6832
Epoch 22/110
 - 2s - loss: 0.2705 - accuracy: 0.9533 - val_loss: 1.6092 - val_accuracy: 0.7015
Epoch 23/110
 - 1s - loss: 0.2154 - accuracy: 0.9712 - val_loss: 1.5156 - val_accuracy: 0.7175
Epoch 24/110
 - 2s - loss: 0.1885 - accuracy: 0.9805 - val_loss: 1.6211 - val_accuracy: 0.7190
Epoch 25/110
 - 2s - loss: 0.1753 - accuracy: 0.9856 - val_loss: 1.6414 - val_accuracy: 0.7102
Epoch 26/110
 - 1s - loss: 0.1717 - accuracy: 0.9863 - val_loss: 1.6078 - val_accuracy: 0.7102
Epoch 27/110
 - 1s - loss: 0.1677 - accuracy: 0.9878 - val_loss: 1.5354 - val_accuracy: 0.7255
Epoch 28/110
 - 2s - loss: 0.1585 - accuracy: 0.9900 - val_loss: 1.5488 - val_accuracy: 0.7241
Epoch 29/110
 - 2s - loss: 0.1565 - accuracy: 0.9903 - val_loss: 1.5461 - val_accuracy: 0.7226
Epoch 30/110
 - 2s - loss: 0.1523 - accuracy: 0.9912 - val_loss: 1.5534 - val_accuracy: 0.7321
Epoch 31/110
 - 1s - loss: 0.1505 - accuracy: 0.9918 - val_loss: 1.5968 - val_accuracy: 0.7255
Epoch 32/110
 - 2s - loss: 0.1484 - accuracy: 0.9918 - val_loss: 1.6000 - val_accuracy: 0.7226
Epoch 33/110
 - 2s - loss: 0.1498 - accuracy: 0.9914 - val_loss: 1.6060 - val_accuracy: 0.7270
Epoch 34/110
 - 2s - loss: 0.1502 - accuracy: 0.9903 - val_loss: 1.7138 - val_accuracy: 0.7234
Epoch 35/110
 - 2s - loss: 0.1527 - accuracy: 0.9898 - val_loss: 1.6058 - val_accuracy: 0.7263
Epoch 36/110
 - 2s - loss: 0.1966 - accuracy: 0.9808 - val_loss: 1.8107 - val_accuracy: 0.6745
Epoch 37/110
 - 2s - loss: 0.2760 - accuracy: 0.9549 - val_loss: 1.7305 - val_accuracy: 0.6708
Epoch 38/110
 - 2s - loss: 0.3485 - accuracy: 0.9325 - val_loss: 1.5171 - val_accuracy: 0.6781
Epoch 39/110
 - 2s - loss: 0.2337 - accuracy: 0.9688 - val_loss: 1.7023 - val_accuracy: 0.7029
Epoch 40/110
 - 2s - loss: 0.1975 - accuracy: 0.9799 - val_loss: 1.5418 - val_accuracy: 0.7102
Epoch 41/110
 - 1s - loss: 0.1667 - accuracy: 0.9880 - val_loss: 1.5136 - val_accuracy: 0.7124
Epoch 42/110
 - 2s - loss: 0.1623 - accuracy: 0.9889 - val_loss: 1.5056 - val_accuracy: 0.7197
Epoch 43/110
 - 2s - loss: 0.1600 - accuracy: 0.9889 - val_loss: 1.5716 - val_accuracy: 0.7248
Epoch 44/110
 - 2s - loss: 0.1567 - accuracy: 0.9901 - val_loss: 1.5819 - val_accuracy: 0.7168
Epoch 45/110
 - 2s - loss: 0.1510 - accuracy: 0.9918 - val_loss: 1.5535 - val_accuracy: 0.7204
Epoch 46/110
 - 2s - loss: 0.1534 - accuracy: 0.9901 - val_loss: 1.5216 - val_accuracy: 0.7175
Epoch 47/110
 - 2s - loss: 0.1788 - accuracy: 0.9848 - val_loss: 1.6933 - val_accuracy: 0.6920
Epoch 48/110
 - 2s - loss: 0.2087 - accuracy: 0.9754 - val_loss: 1.8151 - val_accuracy: 0.6518
Epoch 49/110
 - 2s - loss: 0.2747 - accuracy: 0.9511 - val_loss: 1.6070 - val_accuracy: 0.6978
Epoch 50/110
 - 2s - loss: 0.2748 - accuracy: 0.9507 - val_loss: 1.8474 - val_accuracy: 0.6657
Epoch 51/110
 - 2s - loss: 0.2370 - accuracy: 0.9657 - val_loss: 1.5126 - val_accuracy: 0.7015
Epoch 52/110
 - 2s - loss: 0.1933 - accuracy: 0.9801 - val_loss: 1.6377 - val_accuracy: 0.7095
Epoch 53/110
 - 2s - loss: 0.1700 - accuracy: 0.9861 - val_loss: 1.5456 - val_accuracy: 0.7197
Epoch 54/110
 - 2s - loss: 0.1647 - accuracy: 0.9881 - val_loss: 1.5750 - val_accuracy: 0.7234
Epoch 55/110
 - 2s - loss: 0.1673 - accuracy: 0.9876 - val_loss: 1.5718 - val_accuracy: 0.7153
Epoch 56/110
 - 2s - loss: 0.1575 - accuracy: 0.9894 - val_loss: 1.5683 - val_accuracy: 0.7365
Epoch 57/110
 - 2s - loss: 0.1570 - accuracy: 0.9900 - val_loss: 1.5871 - val_accuracy: 0.7182
Epoch 58/110
 - 2s - loss: 0.1485 - accuracy: 0.9922 - val_loss: 1.5525 - val_accuracy: 0.7365
Epoch 59/110
 - 2s - loss: 0.1478 - accuracy: 0.9916 - val_loss: 1.5758 - val_accuracy: 0.7365
Epoch 60/110
 - 2s - loss: 0.1493 - accuracy: 0.9916 - val_loss: 1.6465 - val_accuracy: 0.7277
Epoch 61/110
 - 2s - loss: 0.1456 - accuracy: 0.9918 - val_loss: 1.5598 - val_accuracy: 0.7321
Epoch 62/110
 - 2s - loss: 0.1449 - accuracy: 0.9916 - val_loss: 1.6066 - val_accuracy: 0.7336
Epoch 63/110
 - 2s - loss: 0.1426 - accuracy: 0.9925 - val_loss: 1.5927 - val_accuracy: 0.7358
Epoch 64/110
 - 2s - loss: 0.1472 - accuracy: 0.9905 - val_loss: 1.6740 - val_accuracy: 0.7263
Epoch 65/110
 - 2s - loss: 0.1587 - accuracy: 0.9880 - val_loss: 1.7545 - val_accuracy: 0.7212
Epoch 66/110
 - 2s - loss: 0.2213 - accuracy: 0.9699 - val_loss: 1.8410 - val_accuracy: 0.6562
Epoch 67/110
 - 2s - loss: 0.4522 - accuracy: 0.9036 - val_loss: 1.6500 - val_accuracy: 0.6569
Epoch 68/110
 - 2s - loss: 0.3434 - accuracy: 0.9273 - val_loss: 1.4007 - val_accuracy: 0.7007
Epoch 69/110
 - 2s - loss: 0.2246 - accuracy: 0.9691 - val_loss: 1.4845 - val_accuracy: 0.7124
Epoch 70/110
 - 2s - loss: 0.1837 - accuracy: 0.9834 - val_loss: 1.4804 - val_accuracy: 0.7153
Epoch 71/110
 - 2s - loss: 0.1742 - accuracy: 0.9861 - val_loss: 1.6333 - val_accuracy: 0.7044
Epoch 72/110
 - 2s - loss: 0.1743 - accuracy: 0.9848 - val_loss: 1.5407 - val_accuracy: 0.7197
Epoch 73/110
 - 2s - loss: 0.1587 - accuracy: 0.9894 - val_loss: 1.5862 - val_accuracy: 0.7241
Epoch 74/110
 - 1s - loss: 0.1531 - accuracy: 0.9909 - val_loss: 1.5673 - val_accuracy: 0.7358
Epoch 75/110
 - 2s - loss: 0.1486 - accuracy: 0.9922 - val_loss: 1.5832 - val_accuracy: 0.7350
Epoch 76/110
 - 1s - loss: 0.1467 - accuracy: 0.9925 - val_loss: 1.5848 - val_accuracy: 0.7380
Epoch 77/110
 - 2s - loss: 0.1460 - accuracy: 0.9916 - val_loss: 1.5967 - val_accuracy: 0.7372
Epoch 78/110
 - 2s - loss: 0.1486 - accuracy: 0.9905 - val_loss: 1.5964 - val_accuracy: 0.7292
Epoch 79/110
 - 2s - loss: 0.1439 - accuracy: 0.9923 - val_loss: 1.6312 - val_accuracy: 0.7380
Epoch 80/110
 - 2s - loss: 0.1427 - accuracy: 0.9923 - val_loss: 1.6326 - val_accuracy: 0.7474
Epoch 81/110
 - 2s - loss: 0.1424 - accuracy: 0.9925 - val_loss: 1.6278 - val_accuracy: 0.7365
Epoch 82/110
 - 2s - loss: 0.1421 - accuracy: 0.9918 - val_loss: 1.6426 - val_accuracy: 0.7321
Epoch 83/110
 - 2s - loss: 0.1457 - accuracy: 0.9909 - val_loss: 1.7076 - val_accuracy: 0.7307
Epoch 84/110
 - 2s - loss: 0.1695 - accuracy: 0.9830 - val_loss: 1.7781 - val_accuracy: 0.6993
Epoch 85/110
 - 2s - loss: 0.3037 - accuracy: 0.9429 - val_loss: 1.7253 - val_accuracy: 0.6613
Epoch 86/110
 - 2s - loss: 0.3960 - accuracy: 0.9155 - val_loss: 1.5963 - val_accuracy: 0.6672
Epoch 87/110
 - 2s - loss: 0.2663 - accuracy: 0.9509 - val_loss: 1.4810 - val_accuracy: 0.6869
Epoch 88/110
 - 2s - loss: 0.2100 - accuracy: 0.9735 - val_loss: 1.6353 - val_accuracy: 0.6854
Epoch 89/110
 - 1s - loss: 0.1983 - accuracy: 0.9792 - val_loss: 1.5770 - val_accuracy: 0.7109
Epoch 90/110
 - 2s - loss: 0.1883 - accuracy: 0.9814 - val_loss: 1.5840 - val_accuracy: 0.7044
Epoch 91/110
 - 1s - loss: 0.2049 - accuracy: 0.9788 - val_loss: 1.6116 - val_accuracy: 0.7124
Epoch 92/110
 - 2s - loss: 0.1805 - accuracy: 0.9823 - val_loss: 1.5389 - val_accuracy: 0.7255
Epoch 93/110
 - 2s - loss: 0.1707 - accuracy: 0.9856 - val_loss: 1.5894 - val_accuracy: 0.7255
Epoch 94/110
 - 1s - loss: 0.1594 - accuracy: 0.9907 - val_loss: 1.6203 - val_accuracy: 0.7182
Epoch 95/110
 - 2s - loss: 0.1497 - accuracy: 0.9912 - val_loss: 1.6549 - val_accuracy: 0.7285
Epoch 96/110
 - 2s - loss: 0.1540 - accuracy: 0.9912 - val_loss: 1.7241 - val_accuracy: 0.7299
Epoch 97/110
 - 2s - loss: 0.1525 - accuracy: 0.9905 - val_loss: 1.7184 - val_accuracy: 0.7241
Epoch 98/110
 - 2s - loss: 0.1537 - accuracy: 0.9903 - val_loss: 1.7034 - val_accuracy: 0.7212
Epoch 99/110
 - 2s - loss: 0.1563 - accuracy: 0.9883 - val_loss: 1.6846 - val_accuracy: 0.7372
Epoch 100/110
 - 2s - loss: 0.1769 - accuracy: 0.9836 - val_loss: 1.7684 - val_accuracy: 0.7022
Epoch 101/110
 - 2s - loss: 0.1825 - accuracy: 0.9801 - val_loss: 1.8548 - val_accuracy: 0.7095
Epoch 102/110
 - 2s - loss: 0.1880 - accuracy: 0.9806 - val_loss: 1.7446 - val_accuracy: 0.7036
Epoch 103/110
 - 2s - loss: 0.2077 - accuracy: 0.9726 - val_loss: 1.7215 - val_accuracy: 0.7058
Epoch 104/110
 - 2s - loss: 0.2382 - accuracy: 0.9644 - val_loss: 1.7295 - val_accuracy: 0.6847
Epoch 105/110
 - 2s - loss: 0.2439 - accuracy: 0.9609 - val_loss: 1.7054 - val_accuracy: 0.6788
Epoch 106/110
 - 2s - loss: 0.2333 - accuracy: 0.9657 - val_loss: 1.6168 - val_accuracy: 0.7044
Epoch 107/110
 - 2s - loss: 0.1845 - accuracy: 0.9783 - val_loss: 1.7472 - val_accuracy: 0.7073
Epoch 108/110
 - 1s - loss: 0.1781 - accuracy: 0.9852 - val_loss: 1.6092 - val_accuracy: 0.7204
Epoch 109/110
 - 2s - loss: 0.1618 - accuracy: 0.9878 - val_loss: 1.5523 - val_accuracy: 0.7168
Epoch 110/110
 - 2s - loss: 0.1554 - accuracy: 0.9896 - val_loss: 1.6356 - val_accuracy: 0.7292
------------------------------------------------------------------------
Training for fold 10 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 2s - loss: 0.1550 - accuracy: 0.9898 - val_loss: 1.6216 - val_accuracy: 0.7124
Epoch 2/110
 - 2s - loss: 0.1655 - accuracy: 0.9872 - val_loss: 1.7080 - val_accuracy: 0.6942
Epoch 3/110
 - 2s - loss: 0.1617 - accuracy: 0.9876 - val_loss: 1.6291 - val_accuracy: 0.7161
Epoch 4/110
 - 2s - loss: 0.1730 - accuracy: 0.9850 - val_loss: 1.6814 - val_accuracy: 0.7131
Epoch 5/110
 - 2s - loss: 0.1647 - accuracy: 0.9865 - val_loss: 1.6417 - val_accuracy: 0.7226
Epoch 6/110
 - 2s - loss: 0.1557 - accuracy: 0.9890 - val_loss: 1.6720 - val_accuracy: 0.7277
Epoch 7/110
 - 2s - loss: 0.1833 - accuracy: 0.9827 - val_loss: 1.8585 - val_accuracy: 0.6993
Epoch 8/110
 - 2s - loss: 0.2179 - accuracy: 0.9719 - val_loss: 1.8522 - val_accuracy: 0.7029
Epoch 9/110
 - 2s - loss: 0.2219 - accuracy: 0.9679 - val_loss: 1.8037 - val_accuracy: 0.6905
Epoch 10/110
 - 2s - loss: 0.2516 - accuracy: 0.9602 - val_loss: 1.6894 - val_accuracy: 0.7029
Epoch 11/110
 - 2s - loss: 0.2278 - accuracy: 0.9693 - val_loss: 1.5270 - val_accuracy: 0.7168
Epoch 12/110
 - 2s - loss: 0.1997 - accuracy: 0.9761 - val_loss: 1.6087 - val_accuracy: 0.7117
Epoch 13/110
 - 2s - loss: 0.1921 - accuracy: 0.9814 - val_loss: 1.6685 - val_accuracy: 0.7153
Epoch 14/110
 - 2s - loss: 0.1697 - accuracy: 0.9854 - val_loss: 1.5677 - val_accuracy: 0.7182
Epoch 15/110
 - 2s - loss: 0.1623 - accuracy: 0.9869 - val_loss: 1.6160 - val_accuracy: 0.7190
Epoch 16/110
 - 2s - loss: 0.1580 - accuracy: 0.9894 - val_loss: 1.6497 - val_accuracy: 0.7088
Epoch 17/110
 - 2s - loss: 0.1554 - accuracy: 0.9898 - val_loss: 1.6569 - val_accuracy: 0.7190
Epoch 18/110
 - 2s - loss: 0.1734 - accuracy: 0.9867 - val_loss: 1.6980 - val_accuracy: 0.7051
Epoch 19/110
 - 2s - loss: 0.1731 - accuracy: 0.9841 - val_loss: 1.6192 - val_accuracy: 0.7168
Epoch 20/110
 - 2s - loss: 0.1657 - accuracy: 0.9870 - val_loss: 1.6801 - val_accuracy: 0.7088
Epoch 21/110
 - 2s - loss: 0.1634 - accuracy: 0.9870 - val_loss: 1.6394 - val_accuracy: 0.7146
Epoch 22/110
 - 2s - loss: 0.1699 - accuracy: 0.9858 - val_loss: 1.6739 - val_accuracy: 0.7066
Epoch 23/110
 - 2s - loss: 0.1802 - accuracy: 0.9821 - val_loss: 1.8305 - val_accuracy: 0.6978
Epoch 24/110
 - 2s - loss: 0.2000 - accuracy: 0.9792 - val_loss: 1.9348 - val_accuracy: 0.7007
Epoch 25/110
 - 2s - loss: 0.1868 - accuracy: 0.9806 - val_loss: 1.7208 - val_accuracy: 0.7153
Epoch 26/110
 - 2s - loss: 0.1856 - accuracy: 0.9797 - val_loss: 1.7288 - val_accuracy: 0.7168
Epoch 27/110
 - 2s - loss: 0.1729 - accuracy: 0.9838 - val_loss: 1.6956 - val_accuracy: 0.7212
Epoch 28/110
 - 2s - loss: 0.1739 - accuracy: 0.9839 - val_loss: 1.6463 - val_accuracy: 0.7139
Epoch 29/110
 - 2s - loss: 0.1714 - accuracy: 0.9861 - val_loss: 1.7723 - val_accuracy: 0.7088
Epoch 30/110
 - 2s - loss: 0.2047 - accuracy: 0.9766 - val_loss: 1.6714 - val_accuracy: 0.7088
Epoch 31/110
 - 2s - loss: 0.2116 - accuracy: 0.9706 - val_loss: 1.7350 - val_accuracy: 0.7190
Epoch 32/110
 - 2s - loss: 0.2192 - accuracy: 0.9699 - val_loss: 1.5498 - val_accuracy: 0.6978
Epoch 33/110
 - 2s - loss: 0.1979 - accuracy: 0.9761 - val_loss: 1.6748 - val_accuracy: 0.7044
Epoch 34/110
 - 2s - loss: 0.1726 - accuracy: 0.9861 - val_loss: 1.5616 - val_accuracy: 0.7234
Epoch 35/110
 - 2s - loss: 0.1518 - accuracy: 0.9903 - val_loss: 1.6154 - val_accuracy: 0.7190
Epoch 36/110
 - 2s - loss: 0.1577 - accuracy: 0.9887 - val_loss: 1.6399 - val_accuracy: 0.7292
Epoch 37/110
 - 2s - loss: 0.1508 - accuracy: 0.9912 - val_loss: 1.6846 - val_accuracy: 0.7292
Epoch 38/110
 - 2s - loss: 0.1503 - accuracy: 0.9907 - val_loss: 1.7397 - val_accuracy: 0.7212
Epoch 39/110
 - 2s - loss: 0.1500 - accuracy: 0.9903 - val_loss: 1.7207 - val_accuracy: 0.7117
Epoch 40/110
 - 2s - loss: 0.1594 - accuracy: 0.9880 - val_loss: 1.6783 - val_accuracy: 0.7131
Epoch 41/110
 - 2s - loss: 0.1588 - accuracy: 0.9880 - val_loss: 1.8235 - val_accuracy: 0.7131
Epoch 42/110
 - 2s - loss: 0.1912 - accuracy: 0.9785 - val_loss: 1.8148 - val_accuracy: 0.7000
Epoch 43/110
 - 2s - loss: 0.3006 - accuracy: 0.9496 - val_loss: 1.7362 - val_accuracy: 0.6825
Epoch 44/110
 - 2s - loss: 0.3222 - accuracy: 0.9336 - val_loss: 1.5712 - val_accuracy: 0.6869
Epoch 45/110
 - 2s - loss: 0.2176 - accuracy: 0.9691 - val_loss: 1.5486 - val_accuracy: 0.6942
Epoch 46/110
 - 2s - loss: 0.1792 - accuracy: 0.9836 - val_loss: 1.6011 - val_accuracy: 0.7109
Epoch 47/110
 - 2s - loss: 0.1584 - accuracy: 0.9901 - val_loss: 1.5683 - val_accuracy: 0.7234
Epoch 48/110
 - 2s - loss: 0.1488 - accuracy: 0.9922 - val_loss: 1.5788 - val_accuracy: 0.7182
Epoch 49/110
 - 2s - loss: 0.1465 - accuracy: 0.9920 - val_loss: 1.6072 - val_accuracy: 0.7226
Epoch 50/110
 - 2s - loss: 0.1465 - accuracy: 0.9916 - val_loss: 1.5686 - val_accuracy: 0.7263
Epoch 51/110
 - 2s - loss: 0.1478 - accuracy: 0.9916 - val_loss: 1.5948 - val_accuracy: 0.7131
Epoch 52/110
 - 2s - loss: 0.1452 - accuracy: 0.9918 - val_loss: 1.5507 - val_accuracy: 0.7336
Epoch 53/110
 - 2s - loss: 0.1427 - accuracy: 0.9923 - val_loss: 1.6323 - val_accuracy: 0.7241
Epoch 54/110
 - 2s - loss: 0.1452 - accuracy: 0.9912 - val_loss: 1.5795 - val_accuracy: 0.7314
Epoch 55/110
 - 2s - loss: 0.1408 - accuracy: 0.9923 - val_loss: 1.5843 - val_accuracy: 0.7263
Epoch 56/110
 - 2s - loss: 0.1417 - accuracy: 0.9916 - val_loss: 1.5672 - val_accuracy: 0.7212
Epoch 57/110
 - 2s - loss: 0.1571 - accuracy: 0.9876 - val_loss: 1.6611 - val_accuracy: 0.7212
Epoch 58/110
 - 2s - loss: 0.2085 - accuracy: 0.9759 - val_loss: 1.6621 - val_accuracy: 0.6993
Epoch 59/110
 - 2s - loss: 0.3201 - accuracy: 0.9374 - val_loss: 1.6719 - val_accuracy: 0.6650
Epoch 60/110
 - 2s - loss: 0.3077 - accuracy: 0.9403 - val_loss: 1.5652 - val_accuracy: 0.6752
Epoch 61/110
 - 2s - loss: 0.2191 - accuracy: 0.9670 - val_loss: 1.5937 - val_accuracy: 0.6942
Epoch 62/110
 - 2s - loss: 0.1953 - accuracy: 0.9770 - val_loss: 1.6330 - val_accuracy: 0.7153
Epoch 63/110
 - 2s - loss: 0.1842 - accuracy: 0.9839 - val_loss: 1.6960 - val_accuracy: 0.7000
Epoch 64/110
 - 2s - loss: 0.1881 - accuracy: 0.9788 - val_loss: 1.8139 - val_accuracy: 0.6912
Epoch 65/110
 - 2s - loss: 0.1798 - accuracy: 0.9861 - val_loss: 1.5689 - val_accuracy: 0.7153
Epoch 66/110
 - 2s - loss: 0.1606 - accuracy: 0.9880 - val_loss: 1.5962 - val_accuracy: 0.7139
Epoch 67/110
 - 2s - loss: 0.1653 - accuracy: 0.9859 - val_loss: 1.6418 - val_accuracy: 0.7080
Epoch 68/110
 - 2s - loss: 0.1623 - accuracy: 0.9880 - val_loss: 1.6298 - val_accuracy: 0.7131
Epoch 69/110
 - 2s - loss: 0.1630 - accuracy: 0.9887 - val_loss: 1.6379 - val_accuracy: 0.7248
Epoch 70/110
 - 2s - loss: 0.1586 - accuracy: 0.9889 - val_loss: 1.5780 - val_accuracy: 0.7248
Epoch 71/110
 - 2s - loss: 0.1583 - accuracy: 0.9874 - val_loss: 1.6252 - val_accuracy: 0.7007
Epoch 72/110
 - 2s - loss: 0.1715 - accuracy: 0.9838 - val_loss: 1.6893 - val_accuracy: 0.7080
Epoch 73/110
 - 2s - loss: 0.1963 - accuracy: 0.9785 - val_loss: 1.8205 - val_accuracy: 0.6956
Epoch 74/110
 - 2s - loss: 0.2507 - accuracy: 0.9597 - val_loss: 1.6804 - val_accuracy: 0.6752
Epoch 75/110
 - 2s - loss: 0.2203 - accuracy: 0.9675 - val_loss: 1.4892 - val_accuracy: 0.7175
Epoch 76/110
 - 2s - loss: 0.1982 - accuracy: 0.9772 - val_loss: 1.5379 - val_accuracy: 0.6985
Epoch 77/110
 - 2s - loss: 0.1994 - accuracy: 0.9768 - val_loss: 1.9950 - val_accuracy: 0.6620
Epoch 78/110
 - 2s - loss: 0.2261 - accuracy: 0.9719 - val_loss: 1.6442 - val_accuracy: 0.7212
Epoch 79/110
 - 2s - loss: 0.1750 - accuracy: 0.9852 - val_loss: 1.7411 - val_accuracy: 0.7022
Epoch 80/110
 - 2s - loss: 0.1706 - accuracy: 0.9852 - val_loss: 1.6162 - val_accuracy: 0.7190
Epoch 81/110
 - 2s - loss: 0.1616 - accuracy: 0.9870 - val_loss: 1.6832 - val_accuracy: 0.7029
Epoch 82/110
 - 2s - loss: 0.1626 - accuracy: 0.9878 - val_loss: 1.6841 - val_accuracy: 0.7292
Epoch 83/110
 - 2s - loss: 0.1533 - accuracy: 0.9898 - val_loss: 1.6364 - val_accuracy: 0.7175
Epoch 84/110
 - 2s - loss: 0.1511 - accuracy: 0.9911 - val_loss: 1.5789 - val_accuracy: 0.7307
Epoch 85/110
 - 2s - loss: 0.1521 - accuracy: 0.9898 - val_loss: 1.6706 - val_accuracy: 0.7168
Epoch 86/110
 - 2s - loss: 0.1598 - accuracy: 0.9887 - val_loss: 1.6999 - val_accuracy: 0.7066
Epoch 87/110
 - 2s - loss: 0.1602 - accuracy: 0.9867 - val_loss: 1.7149 - val_accuracy: 0.7095
Epoch 88/110
 - 2s - loss: 0.1624 - accuracy: 0.9872 - val_loss: 1.7141 - val_accuracy: 0.7182
Epoch 89/110
 - 2s - loss: 0.1554 - accuracy: 0.9887 - val_loss: 1.7261 - val_accuracy: 0.7190
Epoch 90/110
 - 2s - loss: 0.1538 - accuracy: 0.9890 - val_loss: 1.7280 - val_accuracy: 0.7212
Epoch 91/110
 - 2s - loss: 0.1562 - accuracy: 0.9887 - val_loss: 1.8345 - val_accuracy: 0.7007
Epoch 92/110
 - 2s - loss: 0.1857 - accuracy: 0.9783 - val_loss: 1.8155 - val_accuracy: 0.7109
Epoch 93/110
 - 2s - loss: 0.1925 - accuracy: 0.9766 - val_loss: 1.6575 - val_accuracy: 0.7131
Epoch 94/110
 - 2s - loss: 0.1884 - accuracy: 0.9790 - val_loss: 1.7163 - val_accuracy: 0.7015
Epoch 95/110
 - 2s - loss: 0.2068 - accuracy: 0.9752 - val_loss: 1.6949 - val_accuracy: 0.6985
Epoch 96/110
 - 2s - loss: 0.2188 - accuracy: 0.9708 - val_loss: 1.6588 - val_accuracy: 0.7007
Epoch 97/110
 - 2s - loss: 0.1988 - accuracy: 0.9743 - val_loss: 1.7031 - val_accuracy: 0.6956
Epoch 98/110
 - 2s - loss: 0.2033 - accuracy: 0.9724 - val_loss: 1.7045 - val_accuracy: 0.7066
Epoch 99/110
 - 2s - loss: 0.1814 - accuracy: 0.9799 - val_loss: 1.6860 - val_accuracy: 0.7124
Epoch 100/110
 - 2s - loss: 0.1633 - accuracy: 0.9867 - val_loss: 1.6651 - val_accuracy: 0.7109
Epoch 101/110
 - 2s - loss: 0.1625 - accuracy: 0.9872 - val_loss: 1.6927 - val_accuracy: 0.7234
Epoch 102/110
 - 2s - loss: 0.1534 - accuracy: 0.9892 - val_loss: 1.7127 - val_accuracy: 0.7175
Epoch 103/110
 - 2s - loss: 0.1540 - accuracy: 0.9894 - val_loss: 1.6689 - val_accuracy: 0.7197
Epoch 104/110
 - 2s - loss: 0.1883 - accuracy: 0.9808 - val_loss: 1.6845 - val_accuracy: 0.7197
Epoch 105/110
 - 2s - loss: 0.1829 - accuracy: 0.9816 - val_loss: 1.6796 - val_accuracy: 0.7197
Epoch 106/110
 - 2s - loss: 0.2008 - accuracy: 0.9775 - val_loss: 1.6725 - val_accuracy: 0.7146
Epoch 107/110
 - 2s - loss: 0.2767 - accuracy: 0.9606 - val_loss: 1.6855 - val_accuracy: 0.6584
Epoch 108/110
 - 2s - loss: 0.3075 - accuracy: 0.9443 - val_loss: 1.4269 - val_accuracy: 0.7088
Epoch 109/110
 - 2s - loss: 0.2105 - accuracy: 0.9730 - val_loss: 1.4980 - val_accuracy: 0.7153
Epoch 110/110
 - 2s - loss: 0.1685 - accuracy: 0.9876 - val_loss: 1.4834 - val_accuracy: 0.7328
------------------------------------------------------------------------
Score per fold
------------------------------------------------------------------------
Score for fold 1
Accuracy_Train: 21.12%
Accuracy_Test: 20.44%
Loss_Train: 18.05
Loss_Test: 18.31
------------------------------------------------------------------------
Score for fold 2
Accuracy_Train: 23.64%
Accuracy_Test: 22.66%
Loss_Train: 15.88
Loss_Test: 16.42
------------------------------------------------------------------------
Score for fold 3
Accuracy_Train: 28.25%
Accuracy_Test: 29.56%
Loss_Train: 53.41
Loss_Test: 52.88
------------------------------------------------------------------------
Score for fold 4
Accuracy_Train: 21.38%
Accuracy_Test: 20.33%
Loss_Train: 33.26
Loss_Test: 34.26
------------------------------------------------------------------------
Score for fold 5
Accuracy_Train: 21.31%
Accuracy_Test: 20.56%
Loss_Train: 18.35
Loss_Test: 17.94
------------------------------------------------------------------------
Score for fold 6
Accuracy_Train: 23.26%
Accuracy_Test: 23.95%
Loss_Train: 31.03
Loss_Test: 31.10
------------------------------------------------------------------------
Score for fold 7
Accuracy_Train: 22.21%
Accuracy_Test: 24.77%
Loss_Train: 19.68
Loss_Test: 18.96
------------------------------------------------------------------------
Score for fold 8
Accuracy_Train: 23.33%
Accuracy_Test: 25.35%
Loss_Train: 54.87
Loss_Test: 53.26
------------------------------------------------------------------------
Score for fold 9
Accuracy_Train: 21.37%
Accuracy_Test: 22.66%
Loss_Train: 13.51
Loss_Test: 12.96
------------------------------------------------------------------------
Score for fold 10
Accuracy_Train: 28.19%
Accuracy_Test: 29.91%
Loss_Train: 46.00
Loss_Test: 45.48
------------------------------------------------------------------------
Average scores for all folds:
Average_Accuracy_Train: 23.40%
	-> (+- 2.5637819993707827 )
Average_Accuracy_Test: 24.02%
	-> (+- 3.3121577508340567 )
Average_Loss_Train: 30.41
	-> (+- 15.130802872939404 )
Average_Loss_Test: 30.16
	-> (+- 14.838816728213834 )
------------------------------------------------------------------------
