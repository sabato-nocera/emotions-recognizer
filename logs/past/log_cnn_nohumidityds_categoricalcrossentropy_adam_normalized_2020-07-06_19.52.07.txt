Dataset used: ../../datasets/full_dataset_without_humidity.csv 

   Temperature  Sound  Heartbeat   X1  ...    Y2     Z2  Classification  Feedback
0           32      1         60 -680  ... -7424 -15596             100     Happy
1           32      1         60 -780  ... -7408 -15628             100     Happy
2           -1      1         60   -1  ... -7276 -15612             100     Happy
3           -1     -1         60   -1  ...    -1     -1             100     Happy
4           32      1         60 -860  ... -7340 -15720             100     Happy

[5 rows x 11 columns]

Objservations: 8560
Reshaping:  ((6848, 10), (6848, 4), (1712, 10), (1712, 4))  -> ((6848, 10, 1), (6848, 4), (1712, 10, 1), (1712, 4))

Layers:

{'name': 'conv1d_4', 'trainable': True, 'batch_input_shape': (None, 10, 1), 'dtype': 'float32', 'filters': 500, 'kernel_size': (1,), 'strides': (1,), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'activation_7', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'} 

{'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.4, 'noise_shape': None, 'seed': None} 

{'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 400, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 300, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 50, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'activation_8', 'trainable': True, 'dtype': 'float32', 'activation': 'softmax'} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 5478 samples, validate on 1370 samples
Epoch 1/128
 - 7s - loss: 0.9798 - accuracy: 0.6124 - val_loss: 0.8674 - val_accuracy: 0.6672
Epoch 2/128
 - 7s - loss: 0.8204 - accuracy: 0.6767 - val_loss: 0.7821 - val_accuracy: 0.6905
Epoch 3/128
 - 7s - loss: 0.7699 - accuracy: 0.6984 - val_loss: 0.7044 - val_accuracy: 0.7292
Epoch 4/128
 - 7s - loss: 0.7263 - accuracy: 0.7161 - val_loss: 0.6925 - val_accuracy: 0.7241
Epoch 5/128
 - 7s - loss: 0.6979 - accuracy: 0.7273 - val_loss: 0.6919 - val_accuracy: 0.7343
Epoch 6/128
 - 7s - loss: 0.6660 - accuracy: 0.7357 - val_loss: 0.6481 - val_accuracy: 0.7482
Epoch 7/128
 - 7s - loss: 0.6345 - accuracy: 0.7470 - val_loss: 0.6397 - val_accuracy: 0.7438
Epoch 8/128
 - 7s - loss: 0.6096 - accuracy: 0.7578 - val_loss: 0.6043 - val_accuracy: 0.7620
Epoch 9/128
 - 7s - loss: 0.5810 - accuracy: 0.7665 - val_loss: 0.6012 - val_accuracy: 0.7737
Epoch 10/128
 - 7s - loss: 0.5566 - accuracy: 0.7782 - val_loss: 0.6019 - val_accuracy: 0.7628
Epoch 11/128
 - 7s - loss: 0.5406 - accuracy: 0.7877 - val_loss: 0.5705 - val_accuracy: 0.7708
Epoch 12/128
 - 7s - loss: 0.5211 - accuracy: 0.7924 - val_loss: 0.5686 - val_accuracy: 0.7686
Epoch 13/128
 - 7s - loss: 0.5007 - accuracy: 0.7963 - val_loss: 0.5592 - val_accuracy: 0.7803
Epoch 14/128
 - 7s - loss: 0.4783 - accuracy: 0.8092 - val_loss: 0.5576 - val_accuracy: 0.7883
Epoch 15/128
 - 7s - loss: 0.4810 - accuracy: 0.8063 - val_loss: 0.5504 - val_accuracy: 0.7964
Epoch 16/128
 - 7s - loss: 0.4571 - accuracy: 0.8133 - val_loss: 0.5491 - val_accuracy: 0.7810
Epoch 17/128
 - 7s - loss: 0.4495 - accuracy: 0.8175 - val_loss: 0.5597 - val_accuracy: 0.7891
Epoch 18/128
 - 7s - loss: 0.4377 - accuracy: 0.8231 - val_loss: 0.5598 - val_accuracy: 0.7854
Epoch 19/128
 - 7s - loss: 0.4312 - accuracy: 0.8218 - val_loss: 0.5492 - val_accuracy: 0.7912
Epoch 20/128
 - 7s - loss: 0.4219 - accuracy: 0.8260 - val_loss: 0.5468 - val_accuracy: 0.7869
Epoch 21/128
 - 7s - loss: 0.4092 - accuracy: 0.8282 - val_loss: 0.5570 - val_accuracy: 0.7898
Epoch 22/128
 - 7s - loss: 0.4059 - accuracy: 0.8300 - val_loss: 0.5153 - val_accuracy: 0.8066
Epoch 23/128
 - 7s - loss: 0.3980 - accuracy: 0.8333 - val_loss: 0.5431 - val_accuracy: 0.7985
Epoch 24/128
 - 7s - loss: 0.3928 - accuracy: 0.8357 - val_loss: 0.5417 - val_accuracy: 0.8007
Epoch 25/128
 - 7s - loss: 0.3813 - accuracy: 0.8368 - val_loss: 0.5597 - val_accuracy: 0.7876
Epoch 26/128
 - 7s - loss: 0.3706 - accuracy: 0.8437 - val_loss: 0.5568 - val_accuracy: 0.8036
Epoch 27/128
 - 7s - loss: 0.3732 - accuracy: 0.8457 - val_loss: 0.5277 - val_accuracy: 0.8036
Epoch 28/128
 - 7s - loss: 0.3613 - accuracy: 0.8461 - val_loss: 0.5122 - val_accuracy: 0.8102
Epoch 29/128
 - 7s - loss: 0.3569 - accuracy: 0.8456 - val_loss: 0.5229 - val_accuracy: 0.8066
Epoch 30/128
 - 7s - loss: 0.3510 - accuracy: 0.8463 - val_loss: 0.5626 - val_accuracy: 0.7942
Epoch 31/128
 - 7s - loss: 0.3420 - accuracy: 0.8552 - val_loss: 0.5298 - val_accuracy: 0.8212
Epoch 32/128
 - 7s - loss: 0.3553 - accuracy: 0.8520 - val_loss: 0.5423 - val_accuracy: 0.8190
Epoch 33/128
 - 7s - loss: 0.3354 - accuracy: 0.8560 - val_loss: 0.5150 - val_accuracy: 0.8102
Epoch 34/128
 - 7s - loss: 0.3413 - accuracy: 0.8529 - val_loss: 0.5363 - val_accuracy: 0.8139
Epoch 35/128
 - 7s - loss: 0.3297 - accuracy: 0.8572 - val_loss: 0.5279 - val_accuracy: 0.8234
Epoch 36/128
 - 7s - loss: 0.3328 - accuracy: 0.8556 - val_loss: 0.4948 - val_accuracy: 0.8321
Epoch 37/128
 - 7s - loss: 0.3244 - accuracy: 0.8625 - val_loss: 0.5154 - val_accuracy: 0.8365
Epoch 38/128
 - 7s - loss: 0.3212 - accuracy: 0.8620 - val_loss: 0.5350 - val_accuracy: 0.8197
Epoch 39/128
 - 7s - loss: 0.3065 - accuracy: 0.8686 - val_loss: 0.5092 - val_accuracy: 0.8197
Epoch 40/128
 - 7s - loss: 0.3103 - accuracy: 0.8666 - val_loss: 0.5252 - val_accuracy: 0.8350
Epoch 41/128
 - 7s - loss: 0.3041 - accuracy: 0.8731 - val_loss: 0.5106 - val_accuracy: 0.8270
Epoch 42/128
 - 8s - loss: 0.3059 - accuracy: 0.8667 - val_loss: 0.5216 - val_accuracy: 0.8124
Epoch 43/128
 - 7s - loss: 0.3015 - accuracy: 0.8729 - val_loss: 0.5365 - val_accuracy: 0.8285
Epoch 44/128
 - 7s - loss: 0.2885 - accuracy: 0.8739 - val_loss: 0.4899 - val_accuracy: 0.8438
Epoch 45/128
 - 9s - loss: 0.3003 - accuracy: 0.8678 - val_loss: 0.5359 - val_accuracy: 0.8234
Epoch 46/128
 - 9s - loss: 0.2921 - accuracy: 0.8742 - val_loss: 0.5143 - val_accuracy: 0.8365
Epoch 47/128
 - 11s - loss: 0.2947 - accuracy: 0.8735 - val_loss: 0.5252 - val_accuracy: 0.8343
Epoch 48/128
 - 9s - loss: 0.2908 - accuracy: 0.8797 - val_loss: 0.5111 - val_accuracy: 0.8365
Epoch 49/128
 - 9s - loss: 0.2858 - accuracy: 0.8751 - val_loss: 0.5262 - val_accuracy: 0.8270
Epoch 50/128
 - 9s - loss: 0.2784 - accuracy: 0.8766 - val_loss: 0.5222 - val_accuracy: 0.8380
Epoch 51/128
 - 9s - loss: 0.2855 - accuracy: 0.8817 - val_loss: 0.4912 - val_accuracy: 0.8445
Epoch 52/128
 - 10s - loss: 0.2803 - accuracy: 0.8786 - val_loss: 0.5130 - val_accuracy: 0.8336
Epoch 53/128
 - 11s - loss: 0.2733 - accuracy: 0.8832 - val_loss: 0.5018 - val_accuracy: 0.8489
Epoch 54/128
 - 11s - loss: 0.2603 - accuracy: 0.8885 - val_loss: 0.4858 - val_accuracy: 0.8467
Epoch 55/128
 - 12s - loss: 0.2636 - accuracy: 0.8886 - val_loss: 0.5088 - val_accuracy: 0.8401
Epoch 56/128
 - 11s - loss: 0.2544 - accuracy: 0.8863 - val_loss: 0.4979 - val_accuracy: 0.8460
Epoch 57/128
 - 10s - loss: 0.2564 - accuracy: 0.8932 - val_loss: 0.5063 - val_accuracy: 0.8482
Epoch 58/128
 - 10s - loss: 0.2611 - accuracy: 0.8876 - val_loss: 0.5412 - val_accuracy: 0.8336
Epoch 59/128
 - 9s - loss: 0.2556 - accuracy: 0.8876 - val_loss: 0.4820 - val_accuracy: 0.8584
Epoch 60/128
 - 9s - loss: 0.2486 - accuracy: 0.8936 - val_loss: 0.5117 - val_accuracy: 0.8409
Epoch 61/128
 - 11s - loss: 0.2579 - accuracy: 0.8919 - val_loss: 0.4908 - val_accuracy: 0.8599
Epoch 62/128
 - 11s - loss: 0.2461 - accuracy: 0.8963 - val_loss: 0.5248 - val_accuracy: 0.8533
Epoch 63/128
 - 10s - loss: 0.2404 - accuracy: 0.8965 - val_loss: 0.5093 - val_accuracy: 0.8438
Epoch 64/128
 - 9s - loss: 0.2817 - accuracy: 0.8835 - val_loss: 0.4805 - val_accuracy: 0.8628
Epoch 65/128
 - 11s - loss: 0.2565 - accuracy: 0.8899 - val_loss: 0.4836 - val_accuracy: 0.8547
Epoch 66/128
 - 10s - loss: 0.2488 - accuracy: 0.8970 - val_loss: 0.5247 - val_accuracy: 0.8482
Epoch 67/128
 - 12s - loss: 0.2465 - accuracy: 0.8934 - val_loss: 0.5309 - val_accuracy: 0.8526
Epoch 68/128
 - 10s - loss: 0.2465 - accuracy: 0.8967 - val_loss: 0.5824 - val_accuracy: 0.8555
Epoch 69/128
 - 8s - loss: 0.2489 - accuracy: 0.8928 - val_loss: 0.5196 - val_accuracy: 0.8628
Epoch 70/128
 - 10s - loss: 0.2355 - accuracy: 0.9007 - val_loss: 0.5173 - val_accuracy: 0.8540
Epoch 71/128
 - 7s - loss: 0.2233 - accuracy: 0.9014 - val_loss: 0.5500 - val_accuracy: 0.8540
Epoch 72/128
 - 7s - loss: 0.2335 - accuracy: 0.8992 - val_loss: 0.5350 - val_accuracy: 0.8540
Epoch 73/128
 - 9s - loss: 0.2342 - accuracy: 0.8998 - val_loss: 0.5444 - val_accuracy: 0.8453
Epoch 74/128
 - 7s - loss: 0.2294 - accuracy: 0.9027 - val_loss: 0.5276 - val_accuracy: 0.8533
Epoch 75/128
 - 7s - loss: 0.2359 - accuracy: 0.8978 - val_loss: 0.5321 - val_accuracy: 0.8650
Epoch 76/128
 - 8s - loss: 0.2388 - accuracy: 0.8991 - val_loss: 0.5586 - val_accuracy: 0.8599
Epoch 77/128
 - 7s - loss: 0.2270 - accuracy: 0.9047 - val_loss: 0.5507 - val_accuracy: 0.8613
Epoch 78/128
 - 7s - loss: 0.2141 - accuracy: 0.9074 - val_loss: 0.5320 - val_accuracy: 0.8701
Epoch 79/128
 - 7s - loss: 0.2219 - accuracy: 0.9040 - val_loss: 0.5644 - val_accuracy: 0.8599
Epoch 80/128
 - 7s - loss: 0.2155 - accuracy: 0.9064 - val_loss: 0.5622 - val_accuracy: 0.8599
Epoch 81/128
 - 7s - loss: 0.2159 - accuracy: 0.9076 - val_loss: 0.5795 - val_accuracy: 0.8533
Epoch 82/128
 - 7s - loss: 0.2148 - accuracy: 0.9085 - val_loss: 0.5131 - val_accuracy: 0.8628
Epoch 83/128
 - 7s - loss: 0.2236 - accuracy: 0.9020 - val_loss: 0.5305 - val_accuracy: 0.8628
Epoch 84/128
 - 7s - loss: 0.2156 - accuracy: 0.9087 - val_loss: 0.5401 - val_accuracy: 0.8555
Epoch 85/128
 - 7s - loss: 0.2127 - accuracy: 0.9089 - val_loss: 0.5061 - val_accuracy: 0.8752
Epoch 86/128
 - 7s - loss: 0.2135 - accuracy: 0.9098 - val_loss: 0.5448 - val_accuracy: 0.8620
Epoch 87/128
 - 7s - loss: 0.2092 - accuracy: 0.9137 - val_loss: 0.5494 - val_accuracy: 0.8715
Epoch 88/128
 - 7s - loss: 0.2163 - accuracy: 0.9076 - val_loss: 0.5295 - val_accuracy: 0.8679
Epoch 89/128
 - 7s - loss: 0.2175 - accuracy: 0.9069 - val_loss: 0.5286 - val_accuracy: 0.8672
Epoch 90/128
 - 7s - loss: 0.2118 - accuracy: 0.9084 - val_loss: 0.5965 - val_accuracy: 0.8650
Epoch 91/128
 - 7s - loss: 0.1997 - accuracy: 0.9153 - val_loss: 0.5585 - val_accuracy: 0.8657
Epoch 92/128
 - 7s - loss: 0.2177 - accuracy: 0.9074 - val_loss: 0.5306 - val_accuracy: 0.8657
Epoch 93/128
 - 7s - loss: 0.2076 - accuracy: 0.9102 - val_loss: 0.5211 - val_accuracy: 0.8774
Epoch 94/128
 - 7s - loss: 0.2060 - accuracy: 0.9131 - val_loss: 0.5401 - val_accuracy: 0.8664
Epoch 95/128
 - 7s - loss: 0.1970 - accuracy: 0.9160 - val_loss: 0.5913 - val_accuracy: 0.8708
Epoch 96/128
 - 7s - loss: 0.2056 - accuracy: 0.9084 - val_loss: 0.5405 - val_accuracy: 0.8781
Epoch 97/128
 - 7s - loss: 0.1964 - accuracy: 0.9177 - val_loss: 0.5026 - val_accuracy: 0.8796
Epoch 98/128
 - 7s - loss: 0.2038 - accuracy: 0.9131 - val_loss: 0.5558 - val_accuracy: 0.8635
Epoch 99/128
 - 7s - loss: 0.2034 - accuracy: 0.9147 - val_loss: 0.5780 - val_accuracy: 0.8752
Epoch 100/128
 - 7s - loss: 0.1959 - accuracy: 0.9140 - val_loss: 0.5783 - val_accuracy: 0.8657
Epoch 101/128
 - 7s - loss: 0.1910 - accuracy: 0.9160 - val_loss: 0.5347 - val_accuracy: 0.8701
Epoch 102/128
 - 7s - loss: 0.1969 - accuracy: 0.9155 - val_loss: 0.5321 - val_accuracy: 0.8613
Epoch 103/128
 - 7s - loss: 0.1901 - accuracy: 0.9193 - val_loss: 0.5520 - val_accuracy: 0.8635
Epoch 104/128
 - 7s - loss: 0.1921 - accuracy: 0.9188 - val_loss: 0.5403 - val_accuracy: 0.8745
Epoch 105/128
 - 7s - loss: 0.1954 - accuracy: 0.9186 - val_loss: 0.5371 - val_accuracy: 0.8672
Epoch 106/128
 - 7s - loss: 0.1932 - accuracy: 0.9182 - val_loss: 0.5562 - val_accuracy: 0.8533
Epoch 107/128
 - 7s - loss: 0.1910 - accuracy: 0.9169 - val_loss: 0.5668 - val_accuracy: 0.8745
Epoch 108/128
 - 7s - loss: 0.1934 - accuracy: 0.9202 - val_loss: 0.5580 - val_accuracy: 0.8686
Epoch 109/128
 - 7s - loss: 0.1921 - accuracy: 0.9168 - val_loss: 0.5366 - val_accuracy: 0.8745
Epoch 110/128
 - 7s - loss: 0.1946 - accuracy: 0.9182 - val_loss: 0.5578 - val_accuracy: 0.8672
Epoch 111/128
 - 7s - loss: 0.1898 - accuracy: 0.9166 - val_loss: 0.5569 - val_accuracy: 0.8737
Epoch 112/128
 - 7s - loss: 0.1781 - accuracy: 0.9246 - val_loss: 0.5667 - val_accuracy: 0.8672
Epoch 113/128
 - 7s - loss: 0.1835 - accuracy: 0.9206 - val_loss: 0.6293 - val_accuracy: 0.8606
Epoch 114/128
 - 7s - loss: 0.1883 - accuracy: 0.9217 - val_loss: 0.5582 - val_accuracy: 0.8796
Epoch 115/128
 - 7s - loss: 0.1911 - accuracy: 0.9208 - val_loss: 0.5505 - val_accuracy: 0.8679
Epoch 116/128
 - 7s - loss: 0.1918 - accuracy: 0.9193 - val_loss: 0.5487 - val_accuracy: 0.8818
Epoch 117/128
 - 7s - loss: 0.1776 - accuracy: 0.9239 - val_loss: 0.5695 - val_accuracy: 0.8781
Epoch 118/128
 - 7s - loss: 0.1827 - accuracy: 0.9244 - val_loss: 0.5754 - val_accuracy: 0.8686
Epoch 119/128
 - 7s - loss: 0.1789 - accuracy: 0.9221 - val_loss: 0.5588 - val_accuracy: 0.8715
Epoch 120/128
 - 7s - loss: 0.1884 - accuracy: 0.9199 - val_loss: 0.5535 - val_accuracy: 0.8693
Epoch 121/128
 - 7s - loss: 0.1760 - accuracy: 0.9253 - val_loss: 0.6257 - val_accuracy: 0.8664
Epoch 122/128
 - 7s - loss: 0.1803 - accuracy: 0.9231 - val_loss: 0.5262 - val_accuracy: 0.8664
Epoch 123/128
 - 7s - loss: 0.1828 - accuracy: 0.9206 - val_loss: 0.5343 - val_accuracy: 0.8839
Epoch 124/128
 - 7s - loss: 0.1828 - accuracy: 0.9219 - val_loss: 0.5470 - val_accuracy: 0.8752
Epoch 125/128
 - 7s - loss: 0.1813 - accuracy: 0.9226 - val_loss: 0.5588 - val_accuracy: 0.8810
Epoch 126/128
 - 7s - loss: 0.1800 - accuracy: 0.9215 - val_loss: 0.5698 - val_accuracy: 0.8737
Epoch 127/128
 - 7s - loss: 0.1570 - accuracy: 0.9323 - val_loss: 0.5753 - val_accuracy: 0.8788
Epoch 128/128
 - 7s - loss: 0.2014 - accuracy: 0.9186 - val_loss: 0.5253 - val_accuracy: 0.8672

Fit: epochs= 128 , batch_size= 32 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_4 (Conv1D)            (None, 10, 500)           1000      
_________________________________________________________________
activation_7 (Activation)    (None, 10, 500)           0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 5000)              0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 5000)              0         
_________________________________________________________________
dense_22 (Dense)             (None, 400)               2000400   
_________________________________________________________________
dense_23 (Dense)             (None, 300)               120300    
_________________________________________________________________
dense_24 (Dense)             (None, 200)               60200     
_________________________________________________________________
dense_25 (Dense)             (None, 100)               20100     
_________________________________________________________________
dense_26 (Dense)             (None, 50)                5050      
_________________________________________________________________
dense_27 (Dense)             (None, 20)                1020      
_________________________________________________________________
dense_28 (Dense)             (None, 4)                 84        
_________________________________________________________________
activation_8 (Activation)    (None, 4)                 0         
=================================================================
Total params: 2,208,154
Trainable params: 2,208,154
Non-trainable params: 0
_________________________________________________________________
None

Accuracy Train: 91.31%
Accuracy Test: 87.73%
Loss Train: 0.24
Loss Test: 0.48
Numero dati esaminati: 1712
True Positive 1502
False Positive 210
