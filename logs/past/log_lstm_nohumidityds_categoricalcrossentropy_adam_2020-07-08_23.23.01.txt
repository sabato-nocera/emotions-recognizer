Dataset used: ../../datasets/full_dataset_without_humidity.csv 

   Temperature  Sound  Heartbeat   X1  ...    Y2     Z2  Classification  Feedback
0           32      1         60 -680  ... -7424 -15596             100     Happy
1           32      1         60 -780  ... -7408 -15628             100     Happy
2           -1      1         60   -1  ... -7276 -15612             100     Happy
3           -1     -1         60   -1  ...    -1     -1             100     Happy
4           32      1         60 -860  ... -7340 -15720             100     Happy

[5 rows x 11 columns]

Objservations: 8560
Reshaping:  ((6848, 10), (6848, 4), (1712, 10), (1712, 4))  -> ((6848, 1, 10), (6848, 4), (1712, 1, 10), (1712, 4))

Layers:

{'name': 'lstm_1', 'trainable': True, 'batch_input_shape': (None, 1, 10), 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 500, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 2} 

{'name': 'activation_1', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None} 

{'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 400, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 300, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 50, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'activation_2', 'trainable': True, 'dtype': 'float32', 'activation': 'softmax'} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 5478 samples, validate on 1370 samples
Epoch 1/128
 - 9s - loss: 1.0062 - accuracy: 0.5865 - val_loss: 0.8843 - val_accuracy: 0.6584
Epoch 2/128
 - 7s - loss: 0.8392 - accuracy: 0.6822 - val_loss: 0.8259 - val_accuracy: 0.7051
Epoch 3/128
 - 7s - loss: 0.8023 - accuracy: 0.6997 - val_loss: 0.7992 - val_accuracy: 0.7117
Epoch 4/128
 - 7s - loss: 0.7741 - accuracy: 0.7118 - val_loss: 0.7655 - val_accuracy: 0.7336
Epoch 5/128
 - 7s - loss: 0.7442 - accuracy: 0.7231 - val_loss: 0.7450 - val_accuracy: 0.7445
Epoch 6/128
 - 7s - loss: 0.7237 - accuracy: 0.7337 - val_loss: 0.7406 - val_accuracy: 0.7445
Epoch 7/128
 - 8s - loss: 0.7148 - accuracy: 0.7320 - val_loss: 0.7234 - val_accuracy: 0.7467
Epoch 8/128
 - 7s - loss: 0.6880 - accuracy: 0.7410 - val_loss: 0.7088 - val_accuracy: 0.7504
Epoch 9/128
 - 7s - loss: 0.6775 - accuracy: 0.7484 - val_loss: 0.7103 - val_accuracy: 0.7394
Epoch 10/128
 - 7s - loss: 0.6618 - accuracy: 0.7558 - val_loss: 0.6665 - val_accuracy: 0.7460
Epoch 11/128
 - 7s - loss: 0.6470 - accuracy: 0.7579 - val_loss: 0.6555 - val_accuracy: 0.7737
Epoch 12/128
 - 7s - loss: 0.6246 - accuracy: 0.7694 - val_loss: 0.6549 - val_accuracy: 0.7628
Epoch 13/128
 - 7s - loss: 0.6197 - accuracy: 0.7725 - val_loss: 0.6298 - val_accuracy: 0.7686
Epoch 14/128
 - 7s - loss: 0.6055 - accuracy: 0.7777 - val_loss: 0.6337 - val_accuracy: 0.7752
Epoch 15/128
 - 7s - loss: 0.6003 - accuracy: 0.7778 - val_loss: 0.6335 - val_accuracy: 0.7708
Epoch 16/128
 - 7s - loss: 0.5927 - accuracy: 0.7808 - val_loss: 0.5955 - val_accuracy: 0.7825
Epoch 17/128
 - 7s - loss: 0.5785 - accuracy: 0.7829 - val_loss: 0.6305 - val_accuracy: 0.7745
Epoch 18/128
 - 7s - loss: 0.5801 - accuracy: 0.7822 - val_loss: 0.6117 - val_accuracy: 0.7832
Epoch 19/128
 - 7s - loss: 0.5708 - accuracy: 0.7890 - val_loss: 0.5905 - val_accuracy: 0.7854
Epoch 20/128
 - 7s - loss: 0.5649 - accuracy: 0.7899 - val_loss: 0.5763 - val_accuracy: 0.7927
Epoch 21/128
 - 7s - loss: 0.5458 - accuracy: 0.7965 - val_loss: 0.5800 - val_accuracy: 0.7920
Epoch 22/128
 - 7s - loss: 0.5392 - accuracy: 0.7965 - val_loss: 0.5851 - val_accuracy: 0.7920
Epoch 23/128
 - 7s - loss: 0.5377 - accuracy: 0.7976 - val_loss: 0.5728 - val_accuracy: 0.7905
Epoch 24/128
 - 7s - loss: 0.5328 - accuracy: 0.8001 - val_loss: 0.5674 - val_accuracy: 0.7971
Epoch 25/128
 - 7s - loss: 0.5243 - accuracy: 0.7999 - val_loss: 0.5716 - val_accuracy: 0.7927
Epoch 26/128
 - 7s - loss: 0.5245 - accuracy: 0.7999 - val_loss: 0.5543 - val_accuracy: 0.7978
Epoch 27/128
 - 7s - loss: 0.5138 - accuracy: 0.8038 - val_loss: 0.5546 - val_accuracy: 0.7971
Epoch 28/128
 - 7s - loss: 0.5061 - accuracy: 0.8072 - val_loss: 0.5791 - val_accuracy: 0.7942
Epoch 29/128
 - 7s - loss: 0.5081 - accuracy: 0.8054 - val_loss: 0.5443 - val_accuracy: 0.8058
Epoch 30/128
 - 5s - loss: 0.4992 - accuracy: 0.8069 - val_loss: 0.5509 - val_accuracy: 0.8044
Epoch 31/128
 - 4s - loss: 0.4934 - accuracy: 0.8158 - val_loss: 0.5370 - val_accuracy: 0.8182
Epoch 32/128
 - 4s - loss: 0.4801 - accuracy: 0.8105 - val_loss: 0.5497 - val_accuracy: 0.8051
Epoch 33/128
 - 4s - loss: 0.4772 - accuracy: 0.8176 - val_loss: 0.5542 - val_accuracy: 0.8102
Epoch 34/128
 - 4s - loss: 0.4858 - accuracy: 0.8153 - val_loss: 0.5224 - val_accuracy: 0.8182
Epoch 35/128
 - 4s - loss: 0.4704 - accuracy: 0.8193 - val_loss: 0.5309 - val_accuracy: 0.8197
Epoch 36/128
 - 4s - loss: 0.4644 - accuracy: 0.8198 - val_loss: 0.5172 - val_accuracy: 0.8336
Epoch 37/128
 - 4s - loss: 0.4615 - accuracy: 0.8238 - val_loss: 0.5239 - val_accuracy: 0.8219
Epoch 38/128
 - 4s - loss: 0.4638 - accuracy: 0.8257 - val_loss: 0.5163 - val_accuracy: 0.8117
Epoch 39/128
 - 4s - loss: 0.4584 - accuracy: 0.8206 - val_loss: 0.4948 - val_accuracy: 0.8336
Epoch 40/128
 - 4s - loss: 0.4427 - accuracy: 0.8311 - val_loss: 0.4911 - val_accuracy: 0.8175
Epoch 41/128
 - 4s - loss: 0.4402 - accuracy: 0.8299 - val_loss: 0.4984 - val_accuracy: 0.8182
Epoch 42/128
 - 4s - loss: 0.4423 - accuracy: 0.8293 - val_loss: 0.4917 - val_accuracy: 0.8314
Epoch 43/128
 - 4s - loss: 0.4314 - accuracy: 0.8332 - val_loss: 0.4857 - val_accuracy: 0.8336
Epoch 44/128
 - 4s - loss: 0.4161 - accuracy: 0.8403 - val_loss: 0.4909 - val_accuracy: 0.8255
Epoch 45/128
 - 4s - loss: 0.4264 - accuracy: 0.8341 - val_loss: 0.4867 - val_accuracy: 0.8263
Epoch 46/128
 - 4s - loss: 0.4263 - accuracy: 0.8348 - val_loss: 0.4749 - val_accuracy: 0.8350
Epoch 47/128
 - 4s - loss: 0.4167 - accuracy: 0.8366 - val_loss: 0.4739 - val_accuracy: 0.8387
Epoch 48/128
 - 4s - loss: 0.4114 - accuracy: 0.8381 - val_loss: 0.4829 - val_accuracy: 0.8336
Epoch 49/128
 - 4s - loss: 0.4078 - accuracy: 0.8375 - val_loss: 0.4808 - val_accuracy: 0.8343
Epoch 50/128
 - 4s - loss: 0.4181 - accuracy: 0.8352 - val_loss: 0.4843 - val_accuracy: 0.8270
Epoch 51/128
 - 4s - loss: 0.4110 - accuracy: 0.8377 - val_loss: 0.4719 - val_accuracy: 0.8321
Epoch 52/128
 - 4s - loss: 0.4119 - accuracy: 0.8346 - val_loss: 0.4934 - val_accuracy: 0.8226
Epoch 53/128
 - 4s - loss: 0.4058 - accuracy: 0.8410 - val_loss: 0.4870 - val_accuracy: 0.8292
Epoch 54/128
 - 4s - loss: 0.3986 - accuracy: 0.8414 - val_loss: 0.4947 - val_accuracy: 0.8307
Epoch 55/128
 - 4s - loss: 0.4005 - accuracy: 0.8379 - val_loss: 0.4926 - val_accuracy: 0.8241
Epoch 56/128
 - 4s - loss: 0.3931 - accuracy: 0.8425 - val_loss: 0.4701 - val_accuracy: 0.8314
Epoch 57/128
 - 5s - loss: 0.3927 - accuracy: 0.8448 - val_loss: 0.4769 - val_accuracy: 0.8350
Epoch 58/128
 - 5s - loss: 0.3907 - accuracy: 0.8452 - val_loss: 0.4697 - val_accuracy: 0.8431
Epoch 59/128
 - 5s - loss: 0.3825 - accuracy: 0.8445 - val_loss: 0.4735 - val_accuracy: 0.8453
Epoch 60/128
 - 5s - loss: 0.3932 - accuracy: 0.8437 - val_loss: 0.4842 - val_accuracy: 0.8445
Epoch 61/128
 - 5s - loss: 0.3817 - accuracy: 0.8481 - val_loss: 0.4497 - val_accuracy: 0.8445
Epoch 62/128
 - 5s - loss: 0.3859 - accuracy: 0.8426 - val_loss: 0.4626 - val_accuracy: 0.8511
Epoch 63/128
 - 5s - loss: 0.3822 - accuracy: 0.8452 - val_loss: 0.4762 - val_accuracy: 0.8387
Epoch 64/128
 - 5s - loss: 0.3766 - accuracy: 0.8468 - val_loss: 0.4637 - val_accuracy: 0.8445
Epoch 65/128
 - 5s - loss: 0.3769 - accuracy: 0.8436 - val_loss: 0.4654 - val_accuracy: 0.8489
Epoch 66/128
 - 5s - loss: 0.3775 - accuracy: 0.8447 - val_loss: 0.4775 - val_accuracy: 0.8453
Epoch 67/128
 - 5s - loss: 0.3705 - accuracy: 0.8488 - val_loss: 0.4925 - val_accuracy: 0.8358
Epoch 68/128
 - 5s - loss: 0.3832 - accuracy: 0.8463 - val_loss: 0.4569 - val_accuracy: 0.8467
Epoch 69/128
 - 5s - loss: 0.3718 - accuracy: 0.8479 - val_loss: 0.4651 - val_accuracy: 0.8445
Epoch 70/128
 - 5s - loss: 0.3671 - accuracy: 0.8509 - val_loss: 0.4592 - val_accuracy: 0.8526
Epoch 71/128
 - 5s - loss: 0.3718 - accuracy: 0.8463 - val_loss: 0.4798 - val_accuracy: 0.8489
Epoch 72/128
 - 5s - loss: 0.3583 - accuracy: 0.8468 - val_loss: 0.4580 - val_accuracy: 0.8540
Epoch 73/128
 - 5s - loss: 0.3643 - accuracy: 0.8481 - val_loss: 0.4619 - val_accuracy: 0.8482
Epoch 74/128
 - 5s - loss: 0.3602 - accuracy: 0.8496 - val_loss: 0.4785 - val_accuracy: 0.8482
Epoch 75/128
 - 5s - loss: 0.3698 - accuracy: 0.8516 - val_loss: 0.5021 - val_accuracy: 0.8460
Epoch 76/128
 - 5s - loss: 0.3630 - accuracy: 0.8492 - val_loss: 0.4996 - val_accuracy: 0.8460
Epoch 77/128
 - 5s - loss: 0.3636 - accuracy: 0.8463 - val_loss: 0.4924 - val_accuracy: 0.8518
Epoch 78/128
 - 5s - loss: 0.3715 - accuracy: 0.8483 - val_loss: 0.4961 - val_accuracy: 0.8489
Epoch 79/128
 - 5s - loss: 0.3504 - accuracy: 0.8496 - val_loss: 0.4701 - val_accuracy: 0.8599
Epoch 80/128
 - 5s - loss: 0.3552 - accuracy: 0.8501 - val_loss: 0.4791 - val_accuracy: 0.8547
Epoch 81/128
 - 6s - loss: 0.3572 - accuracy: 0.8529 - val_loss: 0.4795 - val_accuracy: 0.8569
Epoch 82/128
 - 5s - loss: 0.3536 - accuracy: 0.8499 - val_loss: 0.4919 - val_accuracy: 0.8540
Epoch 83/128
 - 5s - loss: 0.3604 - accuracy: 0.8507 - val_loss: 0.5030 - val_accuracy: 0.8474
Epoch 84/128
 - 5s - loss: 0.3571 - accuracy: 0.8525 - val_loss: 0.4748 - val_accuracy: 0.8474
Epoch 85/128
 - 5s - loss: 0.3504 - accuracy: 0.8532 - val_loss: 0.4671 - val_accuracy: 0.8533
Epoch 86/128
 - 5s - loss: 0.3486 - accuracy: 0.8525 - val_loss: 0.4895 - val_accuracy: 0.8474
Epoch 87/128
 - 5s - loss: 0.3458 - accuracy: 0.8554 - val_loss: 0.4682 - val_accuracy: 0.8496
Epoch 88/128
 - 5s - loss: 0.3479 - accuracy: 0.8551 - val_loss: 0.4917 - val_accuracy: 0.8540
Epoch 89/128
 - 5s - loss: 0.3473 - accuracy: 0.8558 - val_loss: 0.5010 - val_accuracy: 0.8533
Epoch 90/128
 - 5s - loss: 0.3457 - accuracy: 0.8582 - val_loss: 0.4983 - val_accuracy: 0.8584
Epoch 91/128
 - 5s - loss: 0.3436 - accuracy: 0.8571 - val_loss: 0.5022 - val_accuracy: 0.8511
Epoch 92/128
 - 5s - loss: 0.3575 - accuracy: 0.8547 - val_loss: 0.5107 - val_accuracy: 0.8526
Epoch 93/128
 - 5s - loss: 0.3461 - accuracy: 0.8552 - val_loss: 0.4820 - val_accuracy: 0.8577
Epoch 94/128
 - 5s - loss: 0.3396 - accuracy: 0.8633 - val_loss: 0.5436 - val_accuracy: 0.8394
Epoch 95/128
 - 5s - loss: 0.3503 - accuracy: 0.8536 - val_loss: 0.5044 - val_accuracy: 0.8540
Epoch 96/128
 - 5s - loss: 0.3523 - accuracy: 0.8530 - val_loss: 0.4991 - val_accuracy: 0.8504
Epoch 97/128
 - 5s - loss: 0.3371 - accuracy: 0.8596 - val_loss: 0.5105 - val_accuracy: 0.8606
Epoch 98/128
 - 5s - loss: 0.3381 - accuracy: 0.8593 - val_loss: 0.5243 - val_accuracy: 0.8518
Epoch 99/128
 - 5s - loss: 0.3480 - accuracy: 0.8547 - val_loss: 0.5249 - val_accuracy: 0.8584
Epoch 100/128
 - 5s - loss: 0.3394 - accuracy: 0.8587 - val_loss: 0.4842 - val_accuracy: 0.8547
Epoch 101/128
 - 5s - loss: 0.3320 - accuracy: 0.8636 - val_loss: 0.4970 - val_accuracy: 0.8606
Epoch 102/128
 - 5s - loss: 0.3364 - accuracy: 0.8587 - val_loss: 0.4878 - val_accuracy: 0.8518
Epoch 103/128
 - 5s - loss: 0.3415 - accuracy: 0.8598 - val_loss: 0.4818 - val_accuracy: 0.8540
Epoch 104/128
 - 5s - loss: 0.3346 - accuracy: 0.8589 - val_loss: 0.4900 - val_accuracy: 0.8569
Epoch 105/128
 - 5s - loss: 0.3342 - accuracy: 0.8627 - val_loss: 0.4930 - val_accuracy: 0.8555
Epoch 106/128
 - 5s - loss: 0.3510 - accuracy: 0.8558 - val_loss: 0.4840 - val_accuracy: 0.8526
Epoch 107/128
 - 5s - loss: 0.3429 - accuracy: 0.8642 - val_loss: 0.4816 - val_accuracy: 0.8518
Epoch 108/128
 - 5s - loss: 0.3318 - accuracy: 0.8598 - val_loss: 0.5155 - val_accuracy: 0.8511
Epoch 109/128
 - 5s - loss: 0.3335 - accuracy: 0.8616 - val_loss: 0.4951 - val_accuracy: 0.8504
Epoch 110/128
 - 5s - loss: 0.3389 - accuracy: 0.8611 - val_loss: 0.4894 - val_accuracy: 0.8555
Epoch 111/128
 - 5s - loss: 0.3289 - accuracy: 0.8618 - val_loss: 0.5164 - val_accuracy: 0.8511
Epoch 112/128
 - 5s - loss: 0.3342 - accuracy: 0.8580 - val_loss: 0.4929 - val_accuracy: 0.8489
Epoch 113/128
 - 5s - loss: 0.3370 - accuracy: 0.8638 - val_loss: 0.4863 - val_accuracy: 0.8504
Epoch 114/128
 - 5s - loss: 0.3416 - accuracy: 0.8591 - val_loss: 0.5012 - val_accuracy: 0.8453
Epoch 115/128
 - 5s - loss: 0.3303 - accuracy: 0.8604 - val_loss: 0.4889 - val_accuracy: 0.8555
Epoch 116/128
 - 5s - loss: 0.3308 - accuracy: 0.8629 - val_loss: 0.4801 - val_accuracy: 0.8569
Epoch 117/128
 - 5s - loss: 0.3222 - accuracy: 0.8656 - val_loss: 0.4885 - val_accuracy: 0.8584
Epoch 118/128
 - 5s - loss: 0.3174 - accuracy: 0.8655 - val_loss: 0.5192 - val_accuracy: 0.8526
Epoch 119/128
 - 5s - loss: 0.3281 - accuracy: 0.8640 - val_loss: 0.4907 - val_accuracy: 0.8569
Epoch 120/128
 - 5s - loss: 0.3275 - accuracy: 0.8656 - val_loss: 0.5089 - val_accuracy: 0.8467
Epoch 121/128
 - 5s - loss: 0.3299 - accuracy: 0.8647 - val_loss: 0.5109 - val_accuracy: 0.8511
Epoch 122/128
 - 5s - loss: 0.3239 - accuracy: 0.8664 - val_loss: 0.5016 - val_accuracy: 0.8467
Epoch 123/128
 - 5s - loss: 0.3443 - accuracy: 0.8567 - val_loss: 0.5020 - val_accuracy: 0.8460
Epoch 124/128
 - 5s - loss: 0.3433 - accuracy: 0.8549 - val_loss: 0.5019 - val_accuracy: 0.8504
Epoch 125/128
 - 5s - loss: 0.3260 - accuracy: 0.8651 - val_loss: 0.5127 - val_accuracy: 0.8511
Epoch 126/128
 - 5s - loss: 0.3201 - accuracy: 0.8656 - val_loss: 0.5375 - val_accuracy: 0.8547
Epoch 127/128
 - 5s - loss: 0.3230 - accuracy: 0.8651 - val_loss: 0.5191 - val_accuracy: 0.8533
Epoch 128/128
 - 5s - loss: 0.3212 - accuracy: 0.8660 - val_loss: 0.4941 - val_accuracy: 0.8613

Fit: epochs= 128 , batch_size= 32 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 500)               1022000   
_________________________________________________________________
activation_1 (Activation)    (None, 500)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 500)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 400)               200400    
_________________________________________________________________
dense_2 (Dense)              (None, 300)               120300    
_________________________________________________________________
dense_3 (Dense)              (None, 200)               60200     
_________________________________________________________________
dense_4 (Dense)              (None, 100)               20100     
_________________________________________________________________
dense_5 (Dense)              (None, 50)                5050      
_________________________________________________________________
dense_6 (Dense)              (None, 20)                1020      
_________________________________________________________________
dense_7 (Dense)              (None, 4)                 84        
_________________________________________________________________
activation_2 (Activation)    (None, 4)                 0         
=================================================================
Total params: 1,429,154
Trainable params: 1,429,154
Non-trainable params: 0
_________________________________________________________________
None

Accuracy Train: 87.22%
Accuracy Test: 84.81%
Loss Train: 0.33
Loss Test: 0.43
Numero dati esaminati: 1712
True Positive 1452
False Positive 260
