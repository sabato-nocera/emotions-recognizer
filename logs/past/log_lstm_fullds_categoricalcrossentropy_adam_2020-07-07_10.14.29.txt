Dataset used: ../../datasets/full_dataset.csv 

   Temperature  Humidity  Sound  ...     Z2  Classification  Feedback
0           32        95      1  ... -15596             100     Happy
1           32        86      1  ... -15628             100     Happy
2           -1        -1      1  ... -15612             100     Happy
3           -1        -1     -1  ...     -1             100     Happy
4           32        75      1  ... -15720             100     Happy

[5 rows x 12 columns]

Objservations: 8560
Reshaping:  ((6848, 11), (6848, 4), (1712, 11), (1712, 4))  -> ((6848, 1, 11), (6848, 4), (1712, 1, 11), (1712, 4))

Layers:

{'name': 'lstm_2', 'trainable': True, 'batch_input_shape': (None, 1, 11), 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 500, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 2} 

{'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None} 

{'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 300, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 50, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 5478 samples, validate on 1370 samples
Epoch 1/128
 - 5s - loss: 1.0053 - accuracy: 0.6031 - val_loss: 0.9036 - val_accuracy: 0.6730
Epoch 2/128
 - 4s - loss: 0.8447 - accuracy: 0.6840 - val_loss: 0.8570 - val_accuracy: 0.6745
Epoch 3/128
 - 4s - loss: 0.7978 - accuracy: 0.6970 - val_loss: 0.8117 - val_accuracy: 0.6905
Epoch 4/128
 - 4s - loss: 0.7593 - accuracy: 0.7143 - val_loss: 0.7900 - val_accuracy: 0.7153
Epoch 5/128
 - 4s - loss: 0.7337 - accuracy: 0.7191 - val_loss: 0.7457 - val_accuracy: 0.7212
Epoch 6/128
 - 4s - loss: 0.7139 - accuracy: 0.7304 - val_loss: 0.7353 - val_accuracy: 0.7248
Epoch 7/128
 - 4s - loss: 0.6932 - accuracy: 0.7369 - val_loss: 0.7239 - val_accuracy: 0.7321
Epoch 8/128
 - 4s - loss: 0.6815 - accuracy: 0.7424 - val_loss: 0.6961 - val_accuracy: 0.7409
Epoch 9/128
 - 4s - loss: 0.6593 - accuracy: 0.7490 - val_loss: 0.6604 - val_accuracy: 0.7482
Epoch 10/128
 - 4s - loss: 0.6449 - accuracy: 0.7574 - val_loss: 0.6431 - val_accuracy: 0.7467
Epoch 11/128
 - 4s - loss: 0.6281 - accuracy: 0.7636 - val_loss: 0.6204 - val_accuracy: 0.7620
Epoch 12/128
 - 4s - loss: 0.6137 - accuracy: 0.7707 - val_loss: 0.6025 - val_accuracy: 0.7752
Epoch 13/128
 - 4s - loss: 0.5955 - accuracy: 0.7733 - val_loss: 0.6081 - val_accuracy: 0.7650
Epoch 14/128
 - 4s - loss: 0.5875 - accuracy: 0.7769 - val_loss: 0.5960 - val_accuracy: 0.7693
Epoch 15/128
 - 4s - loss: 0.5728 - accuracy: 0.7831 - val_loss: 0.5973 - val_accuracy: 0.7796
Epoch 16/128
 - 4s - loss: 0.5647 - accuracy: 0.7866 - val_loss: 0.5701 - val_accuracy: 0.7854
Epoch 17/128
 - 4s - loss: 0.5510 - accuracy: 0.7879 - val_loss: 0.5676 - val_accuracy: 0.7920
Epoch 18/128
 - 4s - loss: 0.5435 - accuracy: 0.7888 - val_loss: 0.5630 - val_accuracy: 0.7942
Epoch 19/128
 - 4s - loss: 0.5276 - accuracy: 0.7959 - val_loss: 0.5850 - val_accuracy: 0.7847
Epoch 20/128
 - 4s - loss: 0.5197 - accuracy: 0.8005 - val_loss: 0.5693 - val_accuracy: 0.7912
Epoch 21/128
 - 4s - loss: 0.5143 - accuracy: 0.8023 - val_loss: 0.5449 - val_accuracy: 0.7993
Epoch 22/128
 - 4s - loss: 0.5089 - accuracy: 0.8001 - val_loss: 0.5382 - val_accuracy: 0.7971
Epoch 23/128
 - 4s - loss: 0.4989 - accuracy: 0.8038 - val_loss: 0.5400 - val_accuracy: 0.7934
Epoch 24/128
 - 4s - loss: 0.4987 - accuracy: 0.8041 - val_loss: 0.5403 - val_accuracy: 0.7934
Epoch 25/128
 - 4s - loss: 0.4972 - accuracy: 0.8078 - val_loss: 0.5508 - val_accuracy: 0.7949
Epoch 26/128
 - 4s - loss: 0.4833 - accuracy: 0.8116 - val_loss: 0.5261 - val_accuracy: 0.8058
Epoch 27/128
 - 4s - loss: 0.4820 - accuracy: 0.8143 - val_loss: 0.5284 - val_accuracy: 0.7971
Epoch 28/128
 - 4s - loss: 0.4714 - accuracy: 0.8114 - val_loss: 0.5101 - val_accuracy: 0.8073
Epoch 29/128
 - 4s - loss: 0.4702 - accuracy: 0.8105 - val_loss: 0.5061 - val_accuracy: 0.8102
Epoch 30/128
 - 4s - loss: 0.4648 - accuracy: 0.8142 - val_loss: 0.5138 - val_accuracy: 0.8080
Epoch 31/128
 - 4s - loss: 0.4533 - accuracy: 0.8207 - val_loss: 0.4959 - val_accuracy: 0.8190
Epoch 32/128
 - 4s - loss: 0.4514 - accuracy: 0.8202 - val_loss: 0.5250 - val_accuracy: 0.8000
Epoch 33/128
 - 4s - loss: 0.4484 - accuracy: 0.8209 - val_loss: 0.4846 - val_accuracy: 0.8175
Epoch 34/128
 - 4s - loss: 0.4416 - accuracy: 0.8213 - val_loss: 0.4937 - val_accuracy: 0.8182
Epoch 35/128
 - 4s - loss: 0.4584 - accuracy: 0.8178 - val_loss: 0.4986 - val_accuracy: 0.8175
Epoch 36/128
 - 4s - loss: 0.4356 - accuracy: 0.8237 - val_loss: 0.4790 - val_accuracy: 0.8219
Epoch 37/128
 - 5s - loss: 0.4279 - accuracy: 0.8295 - val_loss: 0.4872 - val_accuracy: 0.8241
Epoch 38/128
 - 5s - loss: 0.4258 - accuracy: 0.8280 - val_loss: 0.4875 - val_accuracy: 0.8299
Epoch 39/128
 - 5s - loss: 0.4306 - accuracy: 0.8246 - val_loss: 0.4824 - val_accuracy: 0.8285
Epoch 40/128
 - 5s - loss: 0.4288 - accuracy: 0.8237 - val_loss: 0.4666 - val_accuracy: 0.8285
Epoch 41/128
 - 5s - loss: 0.4231 - accuracy: 0.8306 - val_loss: 0.4677 - val_accuracy: 0.8321
Epoch 42/128
 - 5s - loss: 0.4156 - accuracy: 0.8346 - val_loss: 0.4651 - val_accuracy: 0.8336
Epoch 43/128
 - 5s - loss: 0.4136 - accuracy: 0.8295 - val_loss: 0.4687 - val_accuracy: 0.8321
Epoch 44/128
 - 5s - loss: 0.4085 - accuracy: 0.8335 - val_loss: 0.4660 - val_accuracy: 0.8292
Epoch 45/128
 - 5s - loss: 0.4071 - accuracy: 0.8337 - val_loss: 0.4786 - val_accuracy: 0.8234
Epoch 46/128
 - 4s - loss: 0.4053 - accuracy: 0.8379 - val_loss: 0.4626 - val_accuracy: 0.8248
Epoch 47/128
 - 4s - loss: 0.4006 - accuracy: 0.8388 - val_loss: 0.4628 - val_accuracy: 0.8234
Epoch 48/128
 - 4s - loss: 0.4026 - accuracy: 0.8322 - val_loss: 0.4798 - val_accuracy: 0.8190
Epoch 49/128
 - 4s - loss: 0.4068 - accuracy: 0.8324 - val_loss: 0.4670 - val_accuracy: 0.8285
Epoch 50/128
 - 4s - loss: 0.3957 - accuracy: 0.8363 - val_loss: 0.4665 - val_accuracy: 0.8226
Epoch 51/128
 - 4s - loss: 0.4046 - accuracy: 0.8353 - val_loss: 0.4558 - val_accuracy: 0.8358
Epoch 52/128
 - 4s - loss: 0.3945 - accuracy: 0.8386 - val_loss: 0.4477 - val_accuracy: 0.8401
Epoch 53/128
 - 4s - loss: 0.3890 - accuracy: 0.8373 - val_loss: 0.4669 - val_accuracy: 0.8336
Epoch 54/128
 - 4s - loss: 0.3873 - accuracy: 0.8405 - val_loss: 0.4542 - val_accuracy: 0.8372
Epoch 55/128
 - 4s - loss: 0.3827 - accuracy: 0.8403 - val_loss: 0.4433 - val_accuracy: 0.8453
Epoch 56/128
 - 4s - loss: 0.3864 - accuracy: 0.8392 - val_loss: 0.4643 - val_accuracy: 0.8343
Epoch 57/128
 - 4s - loss: 0.3803 - accuracy: 0.8428 - val_loss: 0.4478 - val_accuracy: 0.8423
Epoch 58/128
 - 4s - loss: 0.3834 - accuracy: 0.8439 - val_loss: 0.4688 - val_accuracy: 0.8277
Epoch 59/128
 - 4s - loss: 0.3771 - accuracy: 0.8445 - val_loss: 0.4444 - val_accuracy: 0.8358
Epoch 60/128
 - 4s - loss: 0.3721 - accuracy: 0.8437 - val_loss: 0.4726 - val_accuracy: 0.8299
Epoch 61/128
 - 4s - loss: 0.3699 - accuracy: 0.8447 - val_loss: 0.4400 - val_accuracy: 0.8314
Epoch 62/128
 - 4s - loss: 0.3779 - accuracy: 0.8441 - val_loss: 0.4599 - val_accuracy: 0.8321
Epoch 63/128
 - 4s - loss: 0.3755 - accuracy: 0.8450 - val_loss: 0.4509 - val_accuracy: 0.8394
Epoch 64/128
 - 4s - loss: 0.3709 - accuracy: 0.8474 - val_loss: 0.4478 - val_accuracy: 0.8380
Epoch 65/128
 - 4s - loss: 0.3783 - accuracy: 0.8410 - val_loss: 0.4780 - val_accuracy: 0.8248
Epoch 66/128
 - 4s - loss: 0.3696 - accuracy: 0.8448 - val_loss: 0.4528 - val_accuracy: 0.8372
Epoch 67/128
 - 4s - loss: 0.3727 - accuracy: 0.8447 - val_loss: 0.4551 - val_accuracy: 0.8380
Epoch 68/128
 - 4s - loss: 0.3579 - accuracy: 0.8514 - val_loss: 0.4546 - val_accuracy: 0.8489
Epoch 69/128
 - 4s - loss: 0.3597 - accuracy: 0.8505 - val_loss: 0.4635 - val_accuracy: 0.8336
Epoch 70/128
 - 4s - loss: 0.3716 - accuracy: 0.8478 - val_loss: 0.4480 - val_accuracy: 0.8423
Epoch 71/128
 - 4s - loss: 0.3717 - accuracy: 0.8465 - val_loss: 0.4645 - val_accuracy: 0.8321
Epoch 72/128
 - 4s - loss: 0.3634 - accuracy: 0.8496 - val_loss: 0.4807 - val_accuracy: 0.8255
Epoch 73/128
 - 4s - loss: 0.3576 - accuracy: 0.8481 - val_loss: 0.4575 - val_accuracy: 0.8365
Epoch 74/128
 - 4s - loss: 0.3546 - accuracy: 0.8509 - val_loss: 0.4536 - val_accuracy: 0.8445
Epoch 75/128
 - 4s - loss: 0.3586 - accuracy: 0.8523 - val_loss: 0.4318 - val_accuracy: 0.8460
Epoch 76/128
 - 4s - loss: 0.3587 - accuracy: 0.8488 - val_loss: 0.4526 - val_accuracy: 0.8438
Epoch 77/128
 - 4s - loss: 0.3584 - accuracy: 0.8498 - val_loss: 0.4327 - val_accuracy: 0.8423
Epoch 78/128
 - 4s - loss: 0.3512 - accuracy: 0.8476 - val_loss: 0.4505 - val_accuracy: 0.8365
Epoch 79/128
 - 4s - loss: 0.3594 - accuracy: 0.8481 - val_loss: 0.4602 - val_accuracy: 0.8321
Epoch 80/128
 - 4s - loss: 0.3472 - accuracy: 0.8582 - val_loss: 0.4505 - val_accuracy: 0.8445
Epoch 81/128
 - 4s - loss: 0.3504 - accuracy: 0.8523 - val_loss: 0.4402 - val_accuracy: 0.8482
Epoch 82/128
 - 4s - loss: 0.3521 - accuracy: 0.8527 - val_loss: 0.4754 - val_accuracy: 0.8336
Epoch 83/128
 - 4s - loss: 0.3571 - accuracy: 0.8494 - val_loss: 0.4698 - val_accuracy: 0.8299
Epoch 84/128
 - 4s - loss: 0.3493 - accuracy: 0.8505 - val_loss: 0.4685 - val_accuracy: 0.8321
Epoch 85/128
 - 4s - loss: 0.3465 - accuracy: 0.8562 - val_loss: 0.4645 - val_accuracy: 0.8314
Epoch 86/128
 - 4s - loss: 0.3629 - accuracy: 0.8478 - val_loss: 0.4416 - val_accuracy: 0.8416
Epoch 87/128
 - 4s - loss: 0.3417 - accuracy: 0.8580 - val_loss: 0.4661 - val_accuracy: 0.8431
Epoch 88/128
 - 4s - loss: 0.3492 - accuracy: 0.8516 - val_loss: 0.4620 - val_accuracy: 0.8358
Epoch 89/128
 - 4s - loss: 0.3386 - accuracy: 0.8580 - val_loss: 0.4520 - val_accuracy: 0.8496
Epoch 90/128
 - 4s - loss: 0.3359 - accuracy: 0.8540 - val_loss: 0.4618 - val_accuracy: 0.8460
Epoch 91/128
 - 4s - loss: 0.3485 - accuracy: 0.8523 - val_loss: 0.4495 - val_accuracy: 0.8467
Epoch 92/128
 - 4s - loss: 0.3321 - accuracy: 0.8591 - val_loss: 0.4884 - val_accuracy: 0.8343
Epoch 93/128
 - 4s - loss: 0.3526 - accuracy: 0.8556 - val_loss: 0.4824 - val_accuracy: 0.8277
Epoch 94/128
 - 4s - loss: 0.3416 - accuracy: 0.8536 - val_loss: 0.4621 - val_accuracy: 0.8489
Epoch 95/128
 - 4s - loss: 0.3454 - accuracy: 0.8530 - val_loss: 0.4586 - val_accuracy: 0.8453
Epoch 96/128
 - 4s - loss: 0.3392 - accuracy: 0.8563 - val_loss: 0.4722 - val_accuracy: 0.8416
Epoch 97/128
 - 4s - loss: 0.3454 - accuracy: 0.8552 - val_loss: 0.4596 - val_accuracy: 0.8453
Epoch 98/128
 - 4s - loss: 0.3343 - accuracy: 0.8600 - val_loss: 0.4769 - val_accuracy: 0.8460
Epoch 99/128
 - 4s - loss: 0.3362 - accuracy: 0.8547 - val_loss: 0.4786 - val_accuracy: 0.8299
Epoch 100/128
 - 4s - loss: 0.3327 - accuracy: 0.8565 - val_loss: 0.4622 - val_accuracy: 0.8445
Epoch 101/128
 - 4s - loss: 0.3395 - accuracy: 0.8540 - val_loss: 0.4655 - val_accuracy: 0.8423
Epoch 102/128
 - 4s - loss: 0.3398 - accuracy: 0.8540 - val_loss: 0.4542 - val_accuracy: 0.8372
Epoch 103/128
 - 4s - loss: 0.3452 - accuracy: 0.8514 - val_loss: 0.4434 - val_accuracy: 0.8504
Epoch 104/128
 - 4s - loss: 0.3462 - accuracy: 0.8514 - val_loss: 0.4970 - val_accuracy: 0.8423
Epoch 105/128
 - 4s - loss: 0.3392 - accuracy: 0.8551 - val_loss: 0.4517 - val_accuracy: 0.8431
Epoch 106/128
 - 4s - loss: 0.3281 - accuracy: 0.8609 - val_loss: 0.4589 - val_accuracy: 0.8416
Epoch 107/128
 - 4s - loss: 0.3256 - accuracy: 0.8604 - val_loss: 0.4602 - val_accuracy: 0.8431
Epoch 108/128
 - 4s - loss: 0.3291 - accuracy: 0.8611 - val_loss: 0.4499 - val_accuracy: 0.8540
Epoch 109/128
 - 4s - loss: 0.3294 - accuracy: 0.8572 - val_loss: 0.4418 - val_accuracy: 0.8460
Epoch 110/128
 - 5s - loss: 0.3361 - accuracy: 0.8558 - val_loss: 0.4642 - val_accuracy: 0.8423
Epoch 111/128
 - 4s - loss: 0.3251 - accuracy: 0.8662 - val_loss: 0.4374 - val_accuracy: 0.8482
Epoch 112/128
 - 4s - loss: 0.3258 - accuracy: 0.8574 - val_loss: 0.4347 - val_accuracy: 0.8423
Epoch 113/128
 - 4s - loss: 0.3354 - accuracy: 0.8534 - val_loss: 0.4753 - val_accuracy: 0.8336
Epoch 114/128
 - 4s - loss: 0.3398 - accuracy: 0.8576 - val_loss: 0.4633 - val_accuracy: 0.8372
Epoch 115/128
 - 4s - loss: 0.3380 - accuracy: 0.8547 - val_loss: 0.4463 - val_accuracy: 0.8431
Epoch 116/128
 - 4s - loss: 0.3309 - accuracy: 0.8572 - val_loss: 0.4596 - val_accuracy: 0.8453
Epoch 117/128
 - 4s - loss: 0.3283 - accuracy: 0.8598 - val_loss: 0.4399 - val_accuracy: 0.8474
Epoch 118/128
 - 4s - loss: 0.3217 - accuracy: 0.8609 - val_loss: 0.4338 - val_accuracy: 0.8474
Epoch 119/128
 - 4s - loss: 0.3230 - accuracy: 0.8620 - val_loss: 0.4452 - val_accuracy: 0.8496
Epoch 120/128
 - 4s - loss: 0.3143 - accuracy: 0.8622 - val_loss: 0.4379 - val_accuracy: 0.8540
Epoch 121/128
 - 4s - loss: 0.3185 - accuracy: 0.8613 - val_loss: 0.4289 - val_accuracy: 0.8482
Epoch 122/128
 - 4s - loss: 0.3157 - accuracy: 0.8627 - val_loss: 0.4513 - val_accuracy: 0.8482
Epoch 123/128
 - 4s - loss: 0.3176 - accuracy: 0.8644 - val_loss: 0.4459 - val_accuracy: 0.8518
Epoch 124/128
 - 4s - loss: 0.3247 - accuracy: 0.8655 - val_loss: 0.4680 - val_accuracy: 0.8526
Epoch 125/128
 - 4s - loss: 0.3230 - accuracy: 0.8596 - val_loss: 0.4461 - val_accuracy: 0.8489
Epoch 126/128
 - 4s - loss: 0.3290 - accuracy: 0.8600 - val_loss: 0.4891 - val_accuracy: 0.8380
Epoch 127/128
 - 4s - loss: 0.3293 - accuracy: 0.8618 - val_loss: 0.4255 - val_accuracy: 0.8547
Epoch 128/128
 - 4s - loss: 0.3195 - accuracy: 0.8631 - val_loss: 0.4715 - val_accuracy: 0.8518

Fit: epochs= 128 , batch_size= 32 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_2 (LSTM)                (None, 500)               1024000   
_________________________________________________________________
dropout_2 (Dropout)          (None, 500)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 300)               150300    
_________________________________________________________________
dense_8 (Dense)              (None, 200)               60200     
_________________________________________________________________
dense_9 (Dense)              (None, 100)               20100     
_________________________________________________________________
dense_10 (Dense)             (None, 50)                5050      
_________________________________________________________________
dense_11 (Dense)             (None, 20)                1020      
_________________________________________________________________
dense_12 (Dense)             (None, 4)                 84        
=================================================================
Total params: 1,260,754
Trainable params: 1,260,754
Non-trainable params: 0
_________________________________________________________________
None

Accuracy Train: 86.35%
Accuracy Test: 84.29%
Loss Train: 0.35
Loss Test: 0.45
Numero dati esaminati: 1712
True Positive 1443
False Positive 269
