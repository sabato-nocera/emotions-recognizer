Dataset used: ../../datasets/full_dataset_without_humidity.csv 

   Temperature  Sound  Heartbeat   X1  ...    Y2     Z2  Classification  Feedback
0           32      1         60 -680  ... -7424 -15596             100     Happy
1           32      1         60 -780  ... -7408 -15628             100     Happy
2           -1      1         60   -1  ... -7276 -15612             100     Happy
3           -1     -1         60   -1  ...    -1     -1             100     Happy
4           32      1         60 -860  ... -7340 -15720             100     Happy

[5 rows x 11 columns]

Objservations: 8560
Reshaping:  ((6848, 10), (6848, 4), (1712, 10), (1712, 4))  -> ((6848, 1, 10), (6848, 4), (1712, 1, 10), (1712, 4))

Layers:

{'name': 'lstm_13', 'trainable': True, 'batch_input_shape': (None, 1, 10), 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 500, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 2} 

{'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None} 

{'name': 'dense_73', 'trainable': True, 'dtype': 'float32', 'units': 300, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_74', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_75', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_76', 'trainable': True, 'dtype': 'float32', 'units': 50, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_77', 'trainable': True, 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_78', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 5478 samples, validate on 1370 samples
Epoch 1/128
 - 5s - loss: 1.0233 - accuracy: 0.5674 - val_loss: 0.8568 - val_accuracy: 0.6642
Epoch 2/128
 - 5s - loss: 0.8243 - accuracy: 0.6751 - val_loss: 0.7895 - val_accuracy: 0.6978
Epoch 3/128
 - 5s - loss: 0.7726 - accuracy: 0.6935 - val_loss: 0.7354 - val_accuracy: 0.7066
Epoch 4/128
 - 5s - loss: 0.7339 - accuracy: 0.7105 - val_loss: 0.7208 - val_accuracy: 0.7212
Epoch 5/128
 - 5s - loss: 0.7080 - accuracy: 0.7222 - val_loss: 0.6787 - val_accuracy: 0.7496
Epoch 6/128
 - 5s - loss: 0.6838 - accuracy: 0.7315 - val_loss: 0.6647 - val_accuracy: 0.7431
Epoch 7/128
 - 5s - loss: 0.6613 - accuracy: 0.7393 - val_loss: 0.6570 - val_accuracy: 0.7387
Epoch 8/128
 - 5s - loss: 0.6349 - accuracy: 0.7532 - val_loss: 0.6560 - val_accuracy: 0.7365
Epoch 9/128
 - 5s - loss: 0.6132 - accuracy: 0.7616 - val_loss: 0.6421 - val_accuracy: 0.7416
Epoch 10/128
 - 5s - loss: 0.5979 - accuracy: 0.7680 - val_loss: 0.6283 - val_accuracy: 0.7365
Epoch 11/128
 - 5s - loss: 0.5777 - accuracy: 0.7722 - val_loss: 0.6217 - val_accuracy: 0.7533
Epoch 12/128
 - 4s - loss: 0.5617 - accuracy: 0.7762 - val_loss: 0.5932 - val_accuracy: 0.7686
Epoch 13/128
 - 5s - loss: 0.5419 - accuracy: 0.7888 - val_loss: 0.5944 - val_accuracy: 0.7693
Epoch 14/128
 - 4s - loss: 0.5299 - accuracy: 0.7864 - val_loss: 0.5918 - val_accuracy: 0.7701
Epoch 15/128
 - 4s - loss: 0.5129 - accuracy: 0.7981 - val_loss: 0.5818 - val_accuracy: 0.7876
Epoch 16/128
 - 5s - loss: 0.5127 - accuracy: 0.7935 - val_loss: 0.5765 - val_accuracy: 0.7803
Epoch 17/128
 - 4s - loss: 0.4961 - accuracy: 0.7981 - val_loss: 0.5650 - val_accuracy: 0.7869
Epoch 18/128
 - 5s - loss: 0.4842 - accuracy: 0.8012 - val_loss: 0.5754 - val_accuracy: 0.7766
Epoch 19/128
 - 5s - loss: 0.4777 - accuracy: 0.8043 - val_loss: 0.5736 - val_accuracy: 0.7774
Epoch 20/128
 - 4s - loss: 0.4737 - accuracy: 0.8038 - val_loss: 0.5723 - val_accuracy: 0.7766
Epoch 21/128
 - 4s - loss: 0.4623 - accuracy: 0.8103 - val_loss: 0.5572 - val_accuracy: 0.7825
Epoch 22/128
 - 4s - loss: 0.4555 - accuracy: 0.8140 - val_loss: 0.5806 - val_accuracy: 0.7745
Epoch 23/128
 - 4s - loss: 0.4483 - accuracy: 0.8143 - val_loss: 0.5813 - val_accuracy: 0.7701
Epoch 24/128
 - 4s - loss: 0.4458 - accuracy: 0.8134 - val_loss: 0.5611 - val_accuracy: 0.7810
Epoch 25/128
 - 5s - loss: 0.4424 - accuracy: 0.8140 - val_loss: 0.5703 - val_accuracy: 0.7766
Epoch 26/128
 - 4s - loss: 0.4295 - accuracy: 0.8226 - val_loss: 0.5678 - val_accuracy: 0.7788
Epoch 27/128
 - 4s - loss: 0.4223 - accuracy: 0.8229 - val_loss: 0.5670 - val_accuracy: 0.7788
Epoch 28/128
 - 4s - loss: 0.4229 - accuracy: 0.8246 - val_loss: 0.5588 - val_accuracy: 0.7774
Epoch 29/128
 - 5s - loss: 0.4113 - accuracy: 0.8290 - val_loss: 0.5633 - val_accuracy: 0.7832
Epoch 30/128
 - 4s - loss: 0.4082 - accuracy: 0.8317 - val_loss: 0.5668 - val_accuracy: 0.7905
Epoch 31/128
 - 4s - loss: 0.4019 - accuracy: 0.8308 - val_loss: 0.5597 - val_accuracy: 0.7818
Epoch 32/128
 - 4s - loss: 0.3973 - accuracy: 0.8342 - val_loss: 0.5639 - val_accuracy: 0.7825
Epoch 33/128
 - 4s - loss: 0.3982 - accuracy: 0.8293 - val_loss: 0.5691 - val_accuracy: 0.7825
Epoch 34/128
 - 4s - loss: 0.3924 - accuracy: 0.8344 - val_loss: 0.5505 - val_accuracy: 0.7839
Epoch 35/128
 - 4s - loss: 0.3948 - accuracy: 0.8328 - val_loss: 0.5465 - val_accuracy: 0.7971
Epoch 36/128
 - 4s - loss: 0.3829 - accuracy: 0.8421 - val_loss: 0.5441 - val_accuracy: 0.7985
Epoch 37/128
 - 4s - loss: 0.3809 - accuracy: 0.8423 - val_loss: 0.5369 - val_accuracy: 0.8007
Epoch 38/128
 - 4s - loss: 0.3795 - accuracy: 0.8434 - val_loss: 0.5357 - val_accuracy: 0.7912
Epoch 39/128
 - 4s - loss: 0.3725 - accuracy: 0.8443 - val_loss: 0.5389 - val_accuracy: 0.8095
Epoch 40/128
 - 5s - loss: 0.3739 - accuracy: 0.8445 - val_loss: 0.5509 - val_accuracy: 0.8168
Epoch 41/128
 - 4s - loss: 0.3756 - accuracy: 0.8461 - val_loss: 0.5095 - val_accuracy: 0.8153
Epoch 42/128
 - 4s - loss: 0.3704 - accuracy: 0.8476 - val_loss: 0.5312 - val_accuracy: 0.8161
Epoch 43/128
 - 5s - loss: 0.3562 - accuracy: 0.8498 - val_loss: 0.5423 - val_accuracy: 0.8139
Epoch 44/128
 - 4s - loss: 0.3554 - accuracy: 0.8487 - val_loss: 0.5312 - val_accuracy: 0.8146
Epoch 45/128
 - 4s - loss: 0.3640 - accuracy: 0.8465 - val_loss: 0.5171 - val_accuracy: 0.8270
Epoch 46/128
 - 5s - loss: 0.3497 - accuracy: 0.8518 - val_loss: 0.5366 - val_accuracy: 0.8117
Epoch 47/128
 - 5s - loss: 0.3505 - accuracy: 0.8572 - val_loss: 0.5282 - val_accuracy: 0.8153
Epoch 48/128
 - 4s - loss: 0.3518 - accuracy: 0.8525 - val_loss: 0.5379 - val_accuracy: 0.8168
Epoch 49/128
 - 4s - loss: 0.3495 - accuracy: 0.8520 - val_loss: 0.5273 - val_accuracy: 0.8248
Epoch 50/128
 - 4s - loss: 0.3456 - accuracy: 0.8558 - val_loss: 0.5248 - val_accuracy: 0.8197
Epoch 51/128
 - 4s - loss: 0.3368 - accuracy: 0.8616 - val_loss: 0.5310 - val_accuracy: 0.8255
Epoch 52/128
 - 4s - loss: 0.3343 - accuracy: 0.8563 - val_loss: 0.5206 - val_accuracy: 0.8204
Epoch 53/128
 - 4s - loss: 0.3305 - accuracy: 0.8582 - val_loss: 0.5337 - val_accuracy: 0.8307
Epoch 54/128
 - 4s - loss: 0.3360 - accuracy: 0.8594 - val_loss: 0.5354 - val_accuracy: 0.8153
Epoch 55/128
 - 4s - loss: 0.3466 - accuracy: 0.8521 - val_loss: 0.5214 - val_accuracy: 0.8277
Epoch 56/128
 - 4s - loss: 0.3271 - accuracy: 0.8655 - val_loss: 0.5225 - val_accuracy: 0.8234
Epoch 57/128
 - 4s - loss: 0.3182 - accuracy: 0.8664 - val_loss: 0.5221 - val_accuracy: 0.8277
Epoch 58/128
 - 4s - loss: 0.3172 - accuracy: 0.8662 - val_loss: 0.5359 - val_accuracy: 0.8234
Epoch 59/128
 - 4s - loss: 0.3138 - accuracy: 0.8669 - val_loss: 0.5382 - val_accuracy: 0.8263
Epoch 60/128
 - 4s - loss: 0.3156 - accuracy: 0.8655 - val_loss: 0.5367 - val_accuracy: 0.8277
Epoch 61/128
 - 4s - loss: 0.3165 - accuracy: 0.8611 - val_loss: 0.5130 - val_accuracy: 0.8387
Epoch 62/128
 - 4s - loss: 0.3146 - accuracy: 0.8622 - val_loss: 0.5275 - val_accuracy: 0.8343
Epoch 63/128
 - 4s - loss: 0.3119 - accuracy: 0.8649 - val_loss: 0.5465 - val_accuracy: 0.8372
Epoch 64/128
 - 4s - loss: 0.3088 - accuracy: 0.8709 - val_loss: 0.5080 - val_accuracy: 0.8438
Epoch 65/128
 - 4s - loss: 0.3081 - accuracy: 0.8719 - val_loss: 0.5479 - val_accuracy: 0.8255
Epoch 66/128
 - 4s - loss: 0.3022 - accuracy: 0.8682 - val_loss: 0.5456 - val_accuracy: 0.8270
Epoch 67/128
 - 4s - loss: 0.3043 - accuracy: 0.8711 - val_loss: 0.5455 - val_accuracy: 0.8365
Epoch 68/128
 - 5s - loss: 0.2985 - accuracy: 0.8751 - val_loss: 0.5537 - val_accuracy: 0.8175
Epoch 69/128
 - 4s - loss: 0.2968 - accuracy: 0.8757 - val_loss: 0.5400 - val_accuracy: 0.8350
Epoch 70/128
 - 4s - loss: 0.3074 - accuracy: 0.8728 - val_loss: 0.5491 - val_accuracy: 0.8131
Epoch 71/128
 - 4s - loss: 0.2906 - accuracy: 0.8777 - val_loss: 0.5265 - val_accuracy: 0.8314
Epoch 72/128
 - 4s - loss: 0.2928 - accuracy: 0.8748 - val_loss: 0.5601 - val_accuracy: 0.8336
Epoch 73/128
 - 4s - loss: 0.2931 - accuracy: 0.8739 - val_loss: 0.5464 - val_accuracy: 0.8343
Epoch 74/128
 - 4s - loss: 0.2996 - accuracy: 0.8740 - val_loss: 0.5059 - val_accuracy: 0.8438
Epoch 75/128
 - 4s - loss: 0.2786 - accuracy: 0.8801 - val_loss: 0.5840 - val_accuracy: 0.8197
Epoch 76/128
 - 4s - loss: 0.2934 - accuracy: 0.8766 - val_loss: 0.5544 - val_accuracy: 0.8299
Epoch 77/128
 - 4s - loss: 0.2793 - accuracy: 0.8795 - val_loss: 0.5512 - val_accuracy: 0.8336
Epoch 78/128
 - 4s - loss: 0.2901 - accuracy: 0.8792 - val_loss: 0.5328 - val_accuracy: 0.8307
Epoch 79/128
 - 4s - loss: 0.2795 - accuracy: 0.8812 - val_loss: 0.5849 - val_accuracy: 0.8358
Epoch 80/128
 - 4s - loss: 0.2863 - accuracy: 0.8786 - val_loss: 0.5438 - val_accuracy: 0.8416
Epoch 81/128
 - 4s - loss: 0.2740 - accuracy: 0.8806 - val_loss: 0.5738 - val_accuracy: 0.8182
Epoch 82/128
 - 4s - loss: 0.2835 - accuracy: 0.8799 - val_loss: 0.5541 - val_accuracy: 0.8328
Epoch 83/128
 - 4s - loss: 0.2797 - accuracy: 0.8819 - val_loss: 0.5970 - val_accuracy: 0.8307
Epoch 84/128
 - 4s - loss: 0.2775 - accuracy: 0.8799 - val_loss: 0.5576 - val_accuracy: 0.8328
Epoch 85/128
 - 4s - loss: 0.2671 - accuracy: 0.8876 - val_loss: 0.5930 - val_accuracy: 0.8314
Epoch 86/128
 - 4s - loss: 0.2679 - accuracy: 0.8885 - val_loss: 0.5649 - val_accuracy: 0.8285
Epoch 87/128
 - 4s - loss: 0.2765 - accuracy: 0.8826 - val_loss: 0.5576 - val_accuracy: 0.8314
Epoch 88/128
 - 4s - loss: 0.2669 - accuracy: 0.8866 - val_loss: 0.5738 - val_accuracy: 0.8212
Epoch 89/128
 - 4s - loss: 0.2738 - accuracy: 0.8850 - val_loss: 0.5839 - val_accuracy: 0.8358
Epoch 90/128
 - 4s - loss: 0.2638 - accuracy: 0.8886 - val_loss: 0.5415 - val_accuracy: 0.8372
Epoch 91/128
 - 4s - loss: 0.2673 - accuracy: 0.8848 - val_loss: 0.5585 - val_accuracy: 0.8401
Epoch 92/128
 - 4s - loss: 0.2621 - accuracy: 0.8886 - val_loss: 0.5674 - val_accuracy: 0.8248
Epoch 93/128
 - 4s - loss: 0.2775 - accuracy: 0.8832 - val_loss: 0.5647 - val_accuracy: 0.8226
Epoch 94/128
 - 4s - loss: 0.2648 - accuracy: 0.8848 - val_loss: 0.5601 - val_accuracy: 0.8387
Epoch 95/128
 - 4s - loss: 0.2644 - accuracy: 0.8881 - val_loss: 0.5820 - val_accuracy: 0.8307
Epoch 96/128
 - 4s - loss: 0.2601 - accuracy: 0.8859 - val_loss: 0.5625 - val_accuracy: 0.8380
Epoch 97/128
 - 4s - loss: 0.2554 - accuracy: 0.8883 - val_loss: 0.5631 - val_accuracy: 0.8336
Epoch 98/128
 - 4s - loss: 0.2576 - accuracy: 0.8921 - val_loss: 0.5420 - val_accuracy: 0.8394
Epoch 99/128
 - 4s - loss: 0.2689 - accuracy: 0.8854 - val_loss: 0.5557 - val_accuracy: 0.8307
Epoch 100/128
 - 4s - loss: 0.2615 - accuracy: 0.8865 - val_loss: 0.5553 - val_accuracy: 0.8277
Epoch 101/128
 - 4s - loss: 0.2520 - accuracy: 0.8916 - val_loss: 0.5678 - val_accuracy: 0.8401
Epoch 102/128
 - 4s - loss: 0.2517 - accuracy: 0.8910 - val_loss: 0.5679 - val_accuracy: 0.8365
Epoch 103/128
 - 4s - loss: 0.2503 - accuracy: 0.8921 - val_loss: 0.5703 - val_accuracy: 0.8438
Epoch 104/128
 - 4s - loss: 0.2581 - accuracy: 0.8879 - val_loss: 0.6170 - val_accuracy: 0.8255
Epoch 105/128
 - 4s - loss: 0.2587 - accuracy: 0.8907 - val_loss: 0.5729 - val_accuracy: 0.8489
Epoch 106/128
 - 4s - loss: 0.2420 - accuracy: 0.8958 - val_loss: 0.5751 - val_accuracy: 0.8489
Epoch 107/128
 - 4s - loss: 0.2417 - accuracy: 0.8939 - val_loss: 0.5822 - val_accuracy: 0.8328
Epoch 108/128
 - 4s - loss: 0.2539 - accuracy: 0.8890 - val_loss: 0.6048 - val_accuracy: 0.8285
Epoch 109/128
 - 4s - loss: 0.2453 - accuracy: 0.8923 - val_loss: 0.5656 - val_accuracy: 0.8416
Epoch 110/128
 - 4s - loss: 0.2529 - accuracy: 0.8921 - val_loss: 0.5546 - val_accuracy: 0.8540
Epoch 111/128
 - 4s - loss: 0.2615 - accuracy: 0.8912 - val_loss: 0.5612 - val_accuracy: 0.8394
Epoch 112/128
 - 4s - loss: 0.2494 - accuracy: 0.8930 - val_loss: 0.5579 - val_accuracy: 0.8387
Epoch 113/128
 - 4s - loss: 0.2370 - accuracy: 0.9001 - val_loss: 0.5608 - val_accuracy: 0.8460
Epoch 114/128
 - 4s - loss: 0.2417 - accuracy: 0.8952 - val_loss: 0.5561 - val_accuracy: 0.8504
Epoch 115/128
 - 4s - loss: 0.2480 - accuracy: 0.8947 - val_loss: 0.5475 - val_accuracy: 0.8467
Epoch 116/128
 - 4s - loss: 0.2319 - accuracy: 0.8980 - val_loss: 0.5668 - val_accuracy: 0.8438
Epoch 117/128
 - 4s - loss: 0.2463 - accuracy: 0.8910 - val_loss: 0.5645 - val_accuracy: 0.8518
Epoch 118/128
 - 4s - loss: 0.2479 - accuracy: 0.8930 - val_loss: 0.5667 - val_accuracy: 0.8328
Epoch 119/128
 - 4s - loss: 0.2400 - accuracy: 0.8970 - val_loss: 0.5710 - val_accuracy: 0.8343
Epoch 120/128
 - 4s - loss: 0.2456 - accuracy: 0.8976 - val_loss: 0.5705 - val_accuracy: 0.8270
Epoch 121/128
 - 4s - loss: 0.2402 - accuracy: 0.8969 - val_loss: 0.5887 - val_accuracy: 0.8380
Epoch 122/128
 - 4s - loss: 0.2363 - accuracy: 0.8965 - val_loss: 0.5647 - val_accuracy: 0.8336
Epoch 123/128
 - 4s - loss: 0.2344 - accuracy: 0.8947 - val_loss: 0.5675 - val_accuracy: 0.8445
Epoch 124/128
 - 5s - loss: 0.2354 - accuracy: 0.9007 - val_loss: 0.5599 - val_accuracy: 0.8431
Epoch 125/128
 - 4s - loss: 0.2275 - accuracy: 0.9014 - val_loss: 0.5643 - val_accuracy: 0.8401
Epoch 126/128
 - 4s - loss: 0.2269 - accuracy: 0.9058 - val_loss: 0.5461 - val_accuracy: 0.8460
Epoch 127/128
 - 4s - loss: 0.2376 - accuracy: 0.8989 - val_loss: 0.5949 - val_accuracy: 0.8526
Epoch 128/128
 - 4s - loss: 0.2352 - accuracy: 0.9005 - val_loss: 0.5931 - val_accuracy: 0.8460

Fit: epochs= 128 , batch_size= 32 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "sequential_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_13 (LSTM)               (None, 500)               1022000   
_________________________________________________________________
dropout_13 (Dropout)         (None, 500)               0         
_________________________________________________________________
dense_73 (Dense)             (None, 300)               150300    
_________________________________________________________________
dense_74 (Dense)             (None, 200)               60200     
_________________________________________________________________
dense_75 (Dense)             (None, 100)               20100     
_________________________________________________________________
dense_76 (Dense)             (None, 50)                5050      
_________________________________________________________________
dense_77 (Dense)             (None, 20)                1020      
_________________________________________________________________
dense_78 (Dense)             (None, 4)                 84        
=================================================================
Total params: 1,258,754
Trainable params: 1,258,754
Non-trainable params: 0
_________________________________________________________________
None

Accuracy Train: 89.97%
Accuracy Test: 84.46%
Loss Train: 0.28
Loss Test: 0.54
Numero dati esaminati: 1712
True Positive 1446
False Positive 266
