Dataset used: ../../datasets/full_dataset.csv 

   Temperature  Humidity  Sound  ...     Z2  Classification  Feedback
0           32        95      1  ... -15596             100     Happy
1           32        86      1  ... -15628             100     Happy
2           -1        -1      1  ... -15612             100     Happy
3           -1        -1     -1  ...     -1             100     Happy
4           32        75      1  ... -15720             100     Happy

[5 rows x 12 columns]

Objservations: 8560
Reshaping:  ((6848, 11), (6848, 4), (1712, 11), (1712, 4))  -> ((6848, 11, 1), (6848, 4), (1712, 11, 1), (1712, 4))

Layers:

{'name': 'lstm_1', 'trainable': True, 'batch_input_shape': (None, 11, 1), 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 256, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 2} 

{'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 5478 samples, validate on 1370 samples
Epoch 1/500
 - 4s - loss: 1.1172 - accuracy: 0.5241 - val_loss: 0.9544 - val_accuracy: 0.6416
Epoch 2/500
 - 3s - loss: 0.9321 - accuracy: 0.6670 - val_loss: 0.8991 - val_accuracy: 0.6620
Epoch 3/500
 - 3s - loss: 0.9004 - accuracy: 0.6771 - val_loss: 0.8871 - val_accuracy: 0.6701
Epoch 4/500
 - 3s - loss: 0.8826 - accuracy: 0.6796 - val_loss: 0.8742 - val_accuracy: 0.6905
Epoch 5/500
 - 3s - loss: 0.8668 - accuracy: 0.6838 - val_loss: 0.8612 - val_accuracy: 0.6825
Epoch 6/500
 - 3s - loss: 0.8509 - accuracy: 0.6836 - val_loss: 0.8463 - val_accuracy: 0.6927
Epoch 7/500
 - 3s - loss: 0.8297 - accuracy: 0.6858 - val_loss: 0.8259 - val_accuracy: 0.6898
Epoch 8/500
 - 4s - loss: 0.8059 - accuracy: 0.6893 - val_loss: 0.8009 - val_accuracy: 0.6964
Epoch 9/500
 - 3s - loss: 0.7840 - accuracy: 0.6966 - val_loss: 0.7844 - val_accuracy: 0.7102
Epoch 10/500
 - 3s - loss: 0.7616 - accuracy: 0.7112 - val_loss: 0.7644 - val_accuracy: 0.7088
Epoch 11/500
 - 3s - loss: 0.7405 - accuracy: 0.7222 - val_loss: 0.7499 - val_accuracy: 0.7153
Epoch 12/500
 - 3s - loss: 0.7202 - accuracy: 0.7271 - val_loss: 0.7408 - val_accuracy: 0.7197
Epoch 13/500
 - 3s - loss: 0.7070 - accuracy: 0.7307 - val_loss: 0.7377 - val_accuracy: 0.7234
Epoch 14/500
 - 3s - loss: 0.6923 - accuracy: 0.7351 - val_loss: 0.7243 - val_accuracy: 0.7299
Epoch 15/500
 - 3s - loss: 0.6771 - accuracy: 0.7424 - val_loss: 0.7041 - val_accuracy: 0.7387
Epoch 16/500
 - 3s - loss: 0.6575 - accuracy: 0.7499 - val_loss: 0.6913 - val_accuracy: 0.7431
Epoch 17/500
 - 3s - loss: 0.6455 - accuracy: 0.7550 - val_loss: 0.6700 - val_accuracy: 0.7533
Epoch 18/500
 - 3s - loss: 0.6266 - accuracy: 0.7663 - val_loss: 0.6489 - val_accuracy: 0.7562
Epoch 19/500
 - 3s - loss: 0.6092 - accuracy: 0.7724 - val_loss: 0.6257 - val_accuracy: 0.7672
Epoch 20/500
 - 3s - loss: 0.5916 - accuracy: 0.7777 - val_loss: 0.6032 - val_accuracy: 0.7708
Epoch 21/500
 - 3s - loss: 0.5775 - accuracy: 0.7804 - val_loss: 0.5925 - val_accuracy: 0.7766
Epoch 22/500
 - 3s - loss: 0.5603 - accuracy: 0.7826 - val_loss: 0.5771 - val_accuracy: 0.7839
Epoch 23/500
 - 3s - loss: 0.5457 - accuracy: 0.7903 - val_loss: 0.5676 - val_accuracy: 0.7942
Epoch 24/500
 - 3s - loss: 0.5419 - accuracy: 0.7928 - val_loss: 0.5630 - val_accuracy: 0.7927
Epoch 25/500
 - 3s - loss: 0.5354 - accuracy: 0.7903 - val_loss: 0.5466 - val_accuracy: 0.7942
Epoch 26/500
 - 3s - loss: 0.5272 - accuracy: 0.7954 - val_loss: 0.5607 - val_accuracy: 0.7883
Epoch 27/500
 - 3s - loss: 0.5262 - accuracy: 0.7943 - val_loss: 0.5409 - val_accuracy: 0.7920
Epoch 28/500
 - 3s - loss: 0.5155 - accuracy: 0.7939 - val_loss: 0.5339 - val_accuracy: 0.7927
Epoch 29/500
 - 3s - loss: 0.5019 - accuracy: 0.8058 - val_loss: 0.5243 - val_accuracy: 0.7978
Epoch 30/500
 - 3s - loss: 0.4944 - accuracy: 0.8039 - val_loss: 0.5235 - val_accuracy: 0.8051
Epoch 31/500
 - 4s - loss: 0.4888 - accuracy: 0.8087 - val_loss: 0.5205 - val_accuracy: 0.8058
Epoch 32/500
 - 3s - loss: 0.4827 - accuracy: 0.8083 - val_loss: 0.5350 - val_accuracy: 0.7993
Epoch 33/500
 - 3s - loss: 0.4766 - accuracy: 0.8123 - val_loss: 0.5331 - val_accuracy: 0.7956
Epoch 34/500
 - 3s - loss: 0.4688 - accuracy: 0.8140 - val_loss: 0.5151 - val_accuracy: 0.8036
Epoch 35/500
 - 3s - loss: 0.4631 - accuracy: 0.8147 - val_loss: 0.5006 - val_accuracy: 0.8131
Epoch 36/500
 - 4s - loss: 0.4602 - accuracy: 0.8156 - val_loss: 0.4962 - val_accuracy: 0.8117
Epoch 37/500
 - 3s - loss: 0.4532 - accuracy: 0.8176 - val_loss: 0.4890 - val_accuracy: 0.8168
Epoch 38/500
 - 3s - loss: 0.4476 - accuracy: 0.8195 - val_loss: 0.4848 - val_accuracy: 0.8109
Epoch 39/500
 - 3s - loss: 0.4496 - accuracy: 0.8206 - val_loss: 0.4841 - val_accuracy: 0.8182
Epoch 40/500
 - 3s - loss: 0.4444 - accuracy: 0.8257 - val_loss: 0.4826 - val_accuracy: 0.8219
Epoch 41/500
 - 3s - loss: 0.4305 - accuracy: 0.8264 - val_loss: 0.4795 - val_accuracy: 0.8161
Epoch 42/500
 - 3s - loss: 0.4234 - accuracy: 0.8310 - val_loss: 0.4658 - val_accuracy: 0.8234
Epoch 43/500
 - 4s - loss: 0.4245 - accuracy: 0.8321 - val_loss: 0.4692 - val_accuracy: 0.8197
Epoch 44/500
 - 4s - loss: 0.4322 - accuracy: 0.8282 - val_loss: 0.4546 - val_accuracy: 0.8292
Epoch 45/500
 - 4s - loss: 0.4198 - accuracy: 0.8315 - val_loss: 0.4478 - val_accuracy: 0.8321
Epoch 46/500
 - 4s - loss: 0.4162 - accuracy: 0.8333 - val_loss: 0.4565 - val_accuracy: 0.8358
Epoch 47/500
 - 4s - loss: 0.4084 - accuracy: 0.8341 - val_loss: 0.4587 - val_accuracy: 0.8336
Epoch 48/500
 - 4s - loss: 0.4059 - accuracy: 0.8324 - val_loss: 0.4509 - val_accuracy: 0.8372
Epoch 49/500
 - 3s - loss: 0.4060 - accuracy: 0.8321 - val_loss: 0.4684 - val_accuracy: 0.8350
Epoch 50/500
 - 3s - loss: 0.4072 - accuracy: 0.8302 - val_loss: 0.4622 - val_accuracy: 0.8387
Epoch 51/500
 - 3s - loss: 0.3942 - accuracy: 0.8381 - val_loss: 0.4587 - val_accuracy: 0.8372
Epoch 52/500
 - 3s - loss: 0.3948 - accuracy: 0.8361 - val_loss: 0.4633 - val_accuracy: 0.8394

Fit: epochs = 500, batch_size = 80, verbose = 2, shuffle=False, validation_split = 0.20, callbacks=[EarlyStopping(monitor='val_loss',patience=7, min_delta=0.0001)]

Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 256)               264192    
_________________________________________________________________
dense_1 (Dense)              (None, 200)               51400     
_________________________________________________________________
dense_2 (Dense)              (None, 100)               20100     
_________________________________________________________________
dense_3 (Dense)              (None, 4)                 404       
=================================================================
Total params: 336,096
Trainable params: 336,096
Non-trainable params: 0
_________________________________________________________________
None

Accuracy Train: 84.62%
Accuracy Test: 83.18%
Numero dati esaminati: 1712
True Positive 1424
False Positive 288
