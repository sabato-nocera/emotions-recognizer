Dataset used: ../../datasets/full_dataset.csv 

   Temperature  Humidity  Sound  ...     Z2  Classification  Feedback
0           32        95      1  ... -15596             100     Happy
1           32        86      1  ... -15628             100     Happy
2           -1        -1      1  ... -15612             100     Happy
3           -1        -1     -1  ...     -1             100     Happy
4           32        75      1  ... -15720             100     Happy

[5 rows x 12 columns]

Objservations: 8560
Reshaping:  ((6848, 11), (6848, 4), (1712, 11), (1712, 4))  -> ((6848, 1, 11), (6848, 4), (1712, 1, 11), (1712, 4))

Layers:

{'name': 'bidirectional_1', 'trainable': True, 'dtype': 'float32', 'layer': {'class_name': 'LSTM', 'config': {'name': 'lstm_3', 'trainable': True, 'batch_input_shape': (None, 1, 11), 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 500, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 2}}, 'merge_mode': 'concat'} 

{'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None} 

{'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 300, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 50, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 5478 samples, validate on 1370 samples
Epoch 1/128
 - 9s - loss: 0.9523 - accuracy: 0.6135 - val_loss: 0.8421 - val_accuracy: 0.6869
Epoch 2/128
 - 8s - loss: 0.8058 - accuracy: 0.6981 - val_loss: 0.7929 - val_accuracy: 0.7124
Epoch 3/128
 - 8s - loss: 0.7674 - accuracy: 0.7085 - val_loss: 0.7722 - val_accuracy: 0.7219
Epoch 4/128
 - 8s - loss: 0.7407 - accuracy: 0.7187 - val_loss: 0.7466 - val_accuracy: 0.7401
Epoch 5/128
 - 8s - loss: 0.7139 - accuracy: 0.7337 - val_loss: 0.7126 - val_accuracy: 0.7343
Epoch 6/128
 - 8s - loss: 0.6940 - accuracy: 0.7413 - val_loss: 0.6899 - val_accuracy: 0.7423
Epoch 7/128
 - 8s - loss: 0.6753 - accuracy: 0.7477 - val_loss: 0.6767 - val_accuracy: 0.7489
Epoch 8/128
 - 8s - loss: 0.6515 - accuracy: 0.7610 - val_loss: 0.6460 - val_accuracy: 0.7613
Epoch 9/128
 - 8s - loss: 0.6331 - accuracy: 0.7685 - val_loss: 0.6384 - val_accuracy: 0.7518
Epoch 10/128
 - 8s - loss: 0.6188 - accuracy: 0.7705 - val_loss: 0.6277 - val_accuracy: 0.7620
Epoch 11/128
 - 8s - loss: 0.6008 - accuracy: 0.7755 - val_loss: 0.6150 - val_accuracy: 0.7737
Epoch 12/128
 - 8s - loss: 0.5873 - accuracy: 0.7795 - val_loss: 0.6005 - val_accuracy: 0.7796
Epoch 13/128
 - 8s - loss: 0.5755 - accuracy: 0.7824 - val_loss: 0.6055 - val_accuracy: 0.7825
Epoch 14/128
 - 8s - loss: 0.5624 - accuracy: 0.7848 - val_loss: 0.6194 - val_accuracy: 0.7540
Epoch 15/128
 - 8s - loss: 0.5552 - accuracy: 0.7873 - val_loss: 0.5765 - val_accuracy: 0.7839
Epoch 16/128
 - 8s - loss: 0.5416 - accuracy: 0.7923 - val_loss: 0.5822 - val_accuracy: 0.7825
Epoch 17/128
 - 8s - loss: 0.5373 - accuracy: 0.7963 - val_loss: 0.5718 - val_accuracy: 0.7920
Epoch 18/128
 - 8s - loss: 0.5266 - accuracy: 0.7985 - val_loss: 0.6062 - val_accuracy: 0.7737
Epoch 19/128
 - 8s - loss: 0.5087 - accuracy: 0.8016 - val_loss: 0.5729 - val_accuracy: 0.8015
Epoch 20/128
 - 8s - loss: 0.5115 - accuracy: 0.8003 - val_loss: 0.5625 - val_accuracy: 0.7942
Epoch 21/128
 - 8s - loss: 0.5044 - accuracy: 0.8039 - val_loss: 0.5955 - val_accuracy: 0.7752
Epoch 22/128
 - 8s - loss: 0.4985 - accuracy: 0.8061 - val_loss: 0.5606 - val_accuracy: 0.8015
Epoch 23/128
 - 9s - loss: 0.4881 - accuracy: 0.8091 - val_loss: 0.5653 - val_accuracy: 0.7883
Epoch 24/128
 - 8s - loss: 0.4854 - accuracy: 0.8122 - val_loss: 0.5489 - val_accuracy: 0.7978
Epoch 25/128
 - 8s - loss: 0.4910 - accuracy: 0.8091 - val_loss: 0.5617 - val_accuracy: 0.7883
Epoch 26/128
 - 8s - loss: 0.4772 - accuracy: 0.8123 - val_loss: 0.5660 - val_accuracy: 0.8051
Epoch 27/128
 - 8s - loss: 0.4662 - accuracy: 0.8160 - val_loss: 0.5293 - val_accuracy: 0.8124
Epoch 28/128
 - 8s - loss: 0.4642 - accuracy: 0.8195 - val_loss: 0.5275 - val_accuracy: 0.8088
Epoch 29/128
 - 8s - loss: 0.4610 - accuracy: 0.8167 - val_loss: 0.5423 - val_accuracy: 0.8007
Epoch 30/128
 - 8s - loss: 0.4558 - accuracy: 0.8180 - val_loss: 0.5043 - val_accuracy: 0.8190
Epoch 31/128
 - 8s - loss: 0.4550 - accuracy: 0.8258 - val_loss: 0.5168 - val_accuracy: 0.8051
Epoch 32/128
 - 8s - loss: 0.4462 - accuracy: 0.8237 - val_loss: 0.5177 - val_accuracy: 0.8161
Epoch 33/128
 - 8s - loss: 0.4384 - accuracy: 0.8264 - val_loss: 0.5079 - val_accuracy: 0.8182
Epoch 34/128
 - 8s - loss: 0.4388 - accuracy: 0.8260 - val_loss: 0.5061 - val_accuracy: 0.8095
Epoch 35/128
 - 8s - loss: 0.4299 - accuracy: 0.8321 - val_loss: 0.5030 - val_accuracy: 0.8248
Epoch 36/128
 - 8s - loss: 0.4255 - accuracy: 0.8304 - val_loss: 0.4869 - val_accuracy: 0.8314
Epoch 37/128
 - 8s - loss: 0.4295 - accuracy: 0.8311 - val_loss: 0.4901 - val_accuracy: 0.8380
Epoch 38/128
 - 8s - loss: 0.4221 - accuracy: 0.8315 - val_loss: 0.5057 - val_accuracy: 0.8226
Epoch 39/128
 - 8s - loss: 0.4275 - accuracy: 0.8280 - val_loss: 0.4776 - val_accuracy: 0.8277
Epoch 40/128
 - 8s - loss: 0.4202 - accuracy: 0.8342 - val_loss: 0.4940 - val_accuracy: 0.8292
Epoch 41/128
 - 8s - loss: 0.4183 - accuracy: 0.8341 - val_loss: 0.4900 - val_accuracy: 0.8226
Epoch 42/128
 - 8s - loss: 0.4072 - accuracy: 0.8342 - val_loss: 0.4948 - val_accuracy: 0.8255
Epoch 43/128
 - 8s - loss: 0.4051 - accuracy: 0.8412 - val_loss: 0.5015 - val_accuracy: 0.8314
Epoch 44/128
 - 8s - loss: 0.4099 - accuracy: 0.8377 - val_loss: 0.4993 - val_accuracy: 0.8307
Epoch 45/128
 - 8s - loss: 0.4013 - accuracy: 0.8406 - val_loss: 0.4713 - val_accuracy: 0.8343
Epoch 46/128
 - 8s - loss: 0.3931 - accuracy: 0.8414 - val_loss: 0.4512 - val_accuracy: 0.8358
Epoch 47/128
 - 8s - loss: 0.3978 - accuracy: 0.8397 - val_loss: 0.5093 - val_accuracy: 0.8270
Epoch 48/128
 - 8s - loss: 0.3981 - accuracy: 0.8408 - val_loss: 0.4873 - val_accuracy: 0.8336
Epoch 49/128
 - 8s - loss: 0.3854 - accuracy: 0.8454 - val_loss: 0.5056 - val_accuracy: 0.8307
Epoch 50/128
 - 8s - loss: 0.3909 - accuracy: 0.8417 - val_loss: 0.4787 - val_accuracy: 0.8380
Epoch 51/128
 - 8s - loss: 0.3848 - accuracy: 0.8441 - val_loss: 0.5010 - val_accuracy: 0.8321
Epoch 52/128
 - 8s - loss: 0.3818 - accuracy: 0.8465 - val_loss: 0.5289 - val_accuracy: 0.8241
Epoch 53/128
 - 8s - loss: 0.3860 - accuracy: 0.8474 - val_loss: 0.4565 - val_accuracy: 0.8401
Epoch 54/128
 - 8s - loss: 0.3925 - accuracy: 0.8414 - val_loss: 0.4719 - val_accuracy: 0.8292
Epoch 55/128
 - 8s - loss: 0.3740 - accuracy: 0.8468 - val_loss: 0.4687 - val_accuracy: 0.8423
Epoch 56/128
 - 8s - loss: 0.3724 - accuracy: 0.8507 - val_loss: 0.4771 - val_accuracy: 0.8394
Epoch 57/128
 - 8s - loss: 0.3720 - accuracy: 0.8450 - val_loss: 0.5080 - val_accuracy: 0.8292
Epoch 58/128
 - 8s - loss: 0.3716 - accuracy: 0.8505 - val_loss: 0.4671 - val_accuracy: 0.8482
Epoch 59/128
 - 8s - loss: 0.3636 - accuracy: 0.8499 - val_loss: 0.4762 - val_accuracy: 0.8336
Epoch 60/128
 - 8s - loss: 0.3797 - accuracy: 0.8456 - val_loss: 0.4775 - val_accuracy: 0.8394
Epoch 61/128
 - 8s - loss: 0.3803 - accuracy: 0.8441 - val_loss: 0.4810 - val_accuracy: 0.8453
Epoch 62/128
 - 8s - loss: 0.3731 - accuracy: 0.8483 - val_loss: 0.4728 - val_accuracy: 0.8409
Epoch 63/128
 - 9s - loss: 0.3826 - accuracy: 0.8457 - val_loss: 0.4647 - val_accuracy: 0.8416
Epoch 64/128
 - 9s - loss: 0.3649 - accuracy: 0.8527 - val_loss: 0.4646 - val_accuracy: 0.8416
Epoch 65/128
 - 8s - loss: 0.3667 - accuracy: 0.8529 - val_loss: 0.4610 - val_accuracy: 0.8394
Epoch 66/128
 - 8s - loss: 0.3620 - accuracy: 0.8498 - val_loss: 0.4552 - val_accuracy: 0.8467
Epoch 67/128
 - 8s - loss: 0.3540 - accuracy: 0.8549 - val_loss: 0.4677 - val_accuracy: 0.8423
Epoch 68/128
 - 8s - loss: 0.3563 - accuracy: 0.8547 - val_loss: 0.4652 - val_accuracy: 0.8409
Epoch 69/128
 - 8s - loss: 0.3544 - accuracy: 0.8536 - val_loss: 0.4717 - val_accuracy: 0.8482
Epoch 70/128
 - 8s - loss: 0.3536 - accuracy: 0.8527 - val_loss: 0.4588 - val_accuracy: 0.8533
Epoch 71/128
 - 8s - loss: 0.3515 - accuracy: 0.8520 - val_loss: 0.4473 - val_accuracy: 0.8504
Epoch 72/128
 - 8s - loss: 0.3570 - accuracy: 0.8543 - val_loss: 0.4346 - val_accuracy: 0.8453
Epoch 73/128
 - 8s - loss: 0.3601 - accuracy: 0.8487 - val_loss: 0.4590 - val_accuracy: 0.8431
Epoch 74/128
 - 8s - loss: 0.3513 - accuracy: 0.8516 - val_loss: 0.4514 - val_accuracy: 0.8453
Epoch 75/128
 - 8s - loss: 0.3544 - accuracy: 0.8492 - val_loss: 0.4841 - val_accuracy: 0.8504
Epoch 76/128
 - 8s - loss: 0.3524 - accuracy: 0.8578 - val_loss: 0.4662 - val_accuracy: 0.8518
Epoch 77/128
 - 8s - loss: 0.3494 - accuracy: 0.8534 - val_loss: 0.4548 - val_accuracy: 0.8496
Epoch 78/128
 - 8s - loss: 0.3403 - accuracy: 0.8540 - val_loss: 0.4586 - val_accuracy: 0.8562
Epoch 79/128
 - 8s - loss: 0.3417 - accuracy: 0.8567 - val_loss: 0.4819 - val_accuracy: 0.8416
Epoch 80/128
 - 8s - loss: 0.3362 - accuracy: 0.8571 - val_loss: 0.4739 - val_accuracy: 0.8358
Epoch 81/128
 - 8s - loss: 0.3516 - accuracy: 0.8565 - val_loss: 0.4457 - val_accuracy: 0.8562
Epoch 82/128
 - 8s - loss: 0.3417 - accuracy: 0.8549 - val_loss: 0.4585 - val_accuracy: 0.8467
Epoch 83/128
 - 8s - loss: 0.3417 - accuracy: 0.8571 - val_loss: 0.4393 - val_accuracy: 0.8453
Epoch 84/128
 - 8s - loss: 0.3403 - accuracy: 0.8549 - val_loss: 0.4434 - val_accuracy: 0.8533
Epoch 85/128
 - 8s - loss: 0.3453 - accuracy: 0.8571 - val_loss: 0.4687 - val_accuracy: 0.8372
Epoch 86/128
 - 8s - loss: 0.3368 - accuracy: 0.8563 - val_loss: 0.4570 - val_accuracy: 0.8445
Epoch 87/128
 - 8s - loss: 0.3441 - accuracy: 0.8530 - val_loss: 0.4590 - val_accuracy: 0.8518
Epoch 88/128
 - 8s - loss: 0.3384 - accuracy: 0.8572 - val_loss: 0.4813 - val_accuracy: 0.8416
Epoch 89/128
 - 8s - loss: 0.3350 - accuracy: 0.8565 - val_loss: 0.4690 - val_accuracy: 0.8365
Epoch 90/128
 - 8s - loss: 0.3395 - accuracy: 0.8556 - val_loss: 0.4675 - val_accuracy: 0.8467
Epoch 91/128
 - 8s - loss: 0.3368 - accuracy: 0.8569 - val_loss: 0.4534 - val_accuracy: 0.8489
Epoch 92/128
 - 8s - loss: 0.3371 - accuracy: 0.8583 - val_loss: 0.4605 - val_accuracy: 0.8496
Epoch 93/128
 - 8s - loss: 0.3406 - accuracy: 0.8543 - val_loss: 0.4603 - val_accuracy: 0.8474
Epoch 94/128
 - 8s - loss: 0.3303 - accuracy: 0.8602 - val_loss: 0.4806 - val_accuracy: 0.8409
Epoch 95/128
 - 8s - loss: 0.3309 - accuracy: 0.8594 - val_loss: 0.4637 - val_accuracy: 0.8504
Epoch 96/128
 - 8s - loss: 0.3293 - accuracy: 0.8633 - val_loss: 0.4455 - val_accuracy: 0.8562
Epoch 97/128
 - 8s - loss: 0.3293 - accuracy: 0.8596 - val_loss: 0.4995 - val_accuracy: 0.8328
Epoch 98/128
 - 8s - loss: 0.3470 - accuracy: 0.8547 - val_loss: 0.4502 - val_accuracy: 0.8584
Epoch 99/128
 - 8s - loss: 0.3388 - accuracy: 0.8604 - val_loss: 0.4712 - val_accuracy: 0.8526
Epoch 100/128
 - 8s - loss: 0.3245 - accuracy: 0.8651 - val_loss: 0.4953 - val_accuracy: 0.8416
Epoch 101/128
 - 8s - loss: 0.3377 - accuracy: 0.8613 - val_loss: 0.4783 - val_accuracy: 0.8343
Epoch 102/128
 - 8s - loss: 0.3324 - accuracy: 0.8582 - val_loss: 0.4774 - val_accuracy: 0.8431
Epoch 103/128
 - 8s - loss: 0.3293 - accuracy: 0.8600 - val_loss: 0.4773 - val_accuracy: 0.8453
Epoch 104/128
 - 8s - loss: 0.3272 - accuracy: 0.8618 - val_loss: 0.5061 - val_accuracy: 0.8248
Epoch 105/128
 - 8s - loss: 0.3440 - accuracy: 0.8567 - val_loss: 0.4851 - val_accuracy: 0.8409
Epoch 106/128
 - 8s - loss: 0.3217 - accuracy: 0.8638 - val_loss: 0.4837 - val_accuracy: 0.8474
Epoch 107/128
 - 8s - loss: 0.3250 - accuracy: 0.8611 - val_loss: 0.4765 - val_accuracy: 0.8504
Epoch 108/128
 - 8s - loss: 0.3244 - accuracy: 0.8618 - val_loss: 0.4756 - val_accuracy: 0.8489
Epoch 109/128
 - 8s - loss: 0.3277 - accuracy: 0.8587 - val_loss: 0.4622 - val_accuracy: 0.8591
Epoch 110/128
 - 8s - loss: 0.3217 - accuracy: 0.8627 - val_loss: 0.4930 - val_accuracy: 0.8401
Epoch 111/128
 - 8s - loss: 0.3312 - accuracy: 0.8618 - val_loss: 0.4916 - val_accuracy: 0.8482
Epoch 112/128
 - 8s - loss: 0.3417 - accuracy: 0.8609 - val_loss: 0.4658 - val_accuracy: 0.8482
Epoch 113/128
 - 8s - loss: 0.3178 - accuracy: 0.8656 - val_loss: 0.4796 - val_accuracy: 0.8438
Epoch 114/128
 - 8s - loss: 0.3173 - accuracy: 0.8651 - val_loss: 0.4741 - val_accuracy: 0.8511
Epoch 115/128
 - 8s - loss: 0.3252 - accuracy: 0.8644 - val_loss: 0.4893 - val_accuracy: 0.8328
Epoch 116/128
 - 8s - loss: 0.3285 - accuracy: 0.8622 - val_loss: 0.4635 - val_accuracy: 0.8438
Epoch 117/128
 - 8s - loss: 0.3130 - accuracy: 0.8660 - val_loss: 0.4865 - val_accuracy: 0.8504
Epoch 118/128
 - 8s - loss: 0.3151 - accuracy: 0.8678 - val_loss: 0.4531 - val_accuracy: 0.8511
Epoch 119/128
 - 8s - loss: 0.3211 - accuracy: 0.8622 - val_loss: 0.4709 - val_accuracy: 0.8489
Epoch 120/128
 - 8s - loss: 0.3120 - accuracy: 0.8662 - val_loss: 0.5090 - val_accuracy: 0.8307
Epoch 121/128
 - 8s - loss: 0.3194 - accuracy: 0.8605 - val_loss: 0.4797 - val_accuracy: 0.8511
Epoch 122/128
 - 8s - loss: 0.3177 - accuracy: 0.8607 - val_loss: 0.4636 - val_accuracy: 0.8460
Epoch 123/128
 - 8s - loss: 0.3189 - accuracy: 0.8605 - val_loss: 0.4694 - val_accuracy: 0.8511
Epoch 124/128
 - 8s - loss: 0.3212 - accuracy: 0.8622 - val_loss: 0.4797 - val_accuracy: 0.8533
Epoch 125/128
 - 8s - loss: 0.3190 - accuracy: 0.8642 - val_loss: 0.4647 - val_accuracy: 0.8526
Epoch 126/128
 - 8s - loss: 0.3267 - accuracy: 0.8611 - val_loss: 0.4921 - val_accuracy: 0.8387
Epoch 127/128
 - 8s - loss: 0.3246 - accuracy: 0.8602 - val_loss: 0.4452 - val_accuracy: 0.8474
Epoch 128/128
 - 8s - loss: 0.3153 - accuracy: 0.8645 - val_loss: 0.4987 - val_accuracy: 0.8372

Fit: epochs= 128 , batch_size= 32 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
bidirectional_1 (Bidirection (None, 1000)              2048000   
_________________________________________________________________
dropout_3 (Dropout)          (None, 1000)              0         
_________________________________________________________________
dense_13 (Dense)             (None, 300)               300300    
_________________________________________________________________
dense_14 (Dense)             (None, 200)               60200     
_________________________________________________________________
dense_15 (Dense)             (None, 100)               20100     
_________________________________________________________________
dense_16 (Dense)             (None, 50)                5050      
_________________________________________________________________
dense_17 (Dense)             (None, 20)                1020      
_________________________________________________________________
dense_18 (Dense)             (None, 4)                 84        
=================================================================
Total params: 2,434,754
Trainable params: 2,434,754
Non-trainable params: 0
_________________________________________________________________
None

Accuracy Train: 85.65%
Accuracy Test: 84.11%
Loss Train: 0.37
Loss Test: 0.46
Numero dati esaminati: 1712
True Positive 1440
False Positive 272
