Dataset used: ../../datasets/full_dataset.csv 

   Temperature  Humidity  Sound  ...     Z2  Classification  Feedback
0           32        95      1  ... -15596             100     Happy
1           32        86      1  ... -15628             100     Happy
2           -1        -1      1  ... -15612             100     Happy
3           -1        -1     -1  ...     -1             100     Happy
4           32        75      1  ... -15720             100     Happy

[5 rows x 12 columns]

Objservations: 8560

Layers:

{'name': 'dense_9', 'trainable': True, 'batch_input_shape': (None, 11), 'dtype': 'float32', 'units': 11, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 500, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 300, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 50, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='mean_squared_error', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 5478 samples, validate on 1370 samples
Epoch 1/128
 - 1s - loss: 0.1348 - accuracy: 0.5885 - val_loss: 0.1185 - val_accuracy: 0.6679
Epoch 2/128
 - 1s - loss: 0.1114 - accuracy: 0.6911 - val_loss: 0.1138 - val_accuracy: 0.6869
Epoch 3/128
 - 1s - loss: 0.1098 - accuracy: 0.6966 - val_loss: 0.1058 - val_accuracy: 0.7175
Epoch 4/128
 - 1s - loss: 0.1043 - accuracy: 0.7141 - val_loss: 0.1013 - val_accuracy: 0.7277
Epoch 5/128
 - 1s - loss: 0.1000 - accuracy: 0.7262 - val_loss: 0.0961 - val_accuracy: 0.7380
Epoch 6/128
 - 1s - loss: 0.0975 - accuracy: 0.7395 - val_loss: 0.0944 - val_accuracy: 0.7482
Epoch 7/128
 - 1s - loss: 0.0950 - accuracy: 0.7475 - val_loss: 0.0922 - val_accuracy: 0.7504
Epoch 8/128
 - 1s - loss: 0.0913 - accuracy: 0.7605 - val_loss: 0.0936 - val_accuracy: 0.7504
Epoch 9/128
 - 1s - loss: 0.0879 - accuracy: 0.7720 - val_loss: 0.0885 - val_accuracy: 0.7679
Epoch 10/128
 - 1s - loss: 0.0864 - accuracy: 0.7777 - val_loss: 0.0892 - val_accuracy: 0.7599
Epoch 11/128
 - 1s - loss: 0.0846 - accuracy: 0.7775 - val_loss: 0.0860 - val_accuracy: 0.7752
Epoch 12/128
 - 1s - loss: 0.0848 - accuracy: 0.7760 - val_loss: 0.0851 - val_accuracy: 0.7752
Epoch 13/128
 - 1s - loss: 0.0819 - accuracy: 0.7844 - val_loss: 0.0828 - val_accuracy: 0.7781
Epoch 14/128
 - 1s - loss: 0.0801 - accuracy: 0.7868 - val_loss: 0.0810 - val_accuracy: 0.7861
Epoch 15/128
 - 1s - loss: 0.0780 - accuracy: 0.7926 - val_loss: 0.0806 - val_accuracy: 0.7818
Epoch 16/128
 - 1s - loss: 0.0767 - accuracy: 0.7968 - val_loss: 0.0794 - val_accuracy: 0.7861
Epoch 17/128
 - 1s - loss: 0.0757 - accuracy: 0.7981 - val_loss: 0.0799 - val_accuracy: 0.7956
Epoch 18/128
 - 1s - loss: 0.0741 - accuracy: 0.8027 - val_loss: 0.0806 - val_accuracy: 0.7788
Epoch 19/128
 - 1s - loss: 0.0745 - accuracy: 0.8036 - val_loss: 0.0768 - val_accuracy: 0.8007
Epoch 20/128
 - 1s - loss: 0.0723 - accuracy: 0.8070 - val_loss: 0.0761 - val_accuracy: 0.8029
Epoch 21/128
 - 1s - loss: 0.0719 - accuracy: 0.8074 - val_loss: 0.0773 - val_accuracy: 0.7934
Epoch 22/128
 - 1s - loss: 0.0707 - accuracy: 0.8125 - val_loss: 0.0751 - val_accuracy: 0.7993
Epoch 23/128
 - 1s - loss: 0.0698 - accuracy: 0.8138 - val_loss: 0.0730 - val_accuracy: 0.8161
Epoch 24/128
 - 1s - loss: 0.0706 - accuracy: 0.8129 - val_loss: 0.0717 - val_accuracy: 0.8190
Epoch 25/128
 - 1s - loss: 0.0682 - accuracy: 0.8180 - val_loss: 0.0686 - val_accuracy: 0.8285
Epoch 26/128
 - 1s - loss: 0.0656 - accuracy: 0.8237 - val_loss: 0.0693 - val_accuracy: 0.8146
Epoch 27/128
 - 1s - loss: 0.0660 - accuracy: 0.8240 - val_loss: 0.0682 - val_accuracy: 0.8255
Epoch 28/128
 - 1s - loss: 0.0648 - accuracy: 0.8258 - val_loss: 0.0683 - val_accuracy: 0.8212
Epoch 29/128
 - 1s - loss: 0.0646 - accuracy: 0.8246 - val_loss: 0.0686 - val_accuracy: 0.8255
Epoch 30/128
 - 1s - loss: 0.0645 - accuracy: 0.8302 - val_loss: 0.0706 - val_accuracy: 0.8153
Epoch 31/128
 - 1s - loss: 0.0646 - accuracy: 0.8251 - val_loss: 0.0667 - val_accuracy: 0.8285
Epoch 32/128
 - 1s - loss: 0.0635 - accuracy: 0.8279 - val_loss: 0.0681 - val_accuracy: 0.8212
Epoch 33/128
 - 1s - loss: 0.0628 - accuracy: 0.8317 - val_loss: 0.0695 - val_accuracy: 0.8168
Epoch 34/128
 - 1s - loss: 0.0610 - accuracy: 0.8368 - val_loss: 0.0657 - val_accuracy: 0.8292
Epoch 35/128
 - 1s - loss: 0.0621 - accuracy: 0.8361 - val_loss: 0.0685 - val_accuracy: 0.8299
Epoch 36/128
 - 1s - loss: 0.0596 - accuracy: 0.8412 - val_loss: 0.0659 - val_accuracy: 0.8314
Epoch 37/128
 - 1s - loss: 0.0600 - accuracy: 0.8399 - val_loss: 0.0650 - val_accuracy: 0.8328
Epoch 38/128
 - 1s - loss: 0.0609 - accuracy: 0.8372 - val_loss: 0.0648 - val_accuracy: 0.8277
Epoch 39/128
 - 1s - loss: 0.0591 - accuracy: 0.8426 - val_loss: 0.0666 - val_accuracy: 0.8248
Epoch 40/128
 - 1s - loss: 0.0591 - accuracy: 0.8419 - val_loss: 0.0628 - val_accuracy: 0.8336
Epoch 41/128
 - 1s - loss: 0.0589 - accuracy: 0.8414 - val_loss: 0.0631 - val_accuracy: 0.8336
Epoch 42/128
 - 1s - loss: 0.0586 - accuracy: 0.8434 - val_loss: 0.0626 - val_accuracy: 0.8431
Epoch 43/128
 - 1s - loss: 0.0577 - accuracy: 0.8412 - val_loss: 0.0623 - val_accuracy: 0.8453
Epoch 44/128
 - 1s - loss: 0.0566 - accuracy: 0.8472 - val_loss: 0.0645 - val_accuracy: 0.8270
Epoch 45/128
 - 1s - loss: 0.0577 - accuracy: 0.8423 - val_loss: 0.0594 - val_accuracy: 0.8496
Epoch 46/128
 - 1s - loss: 0.0573 - accuracy: 0.8437 - val_loss: 0.0621 - val_accuracy: 0.8438
Epoch 47/128
 - 1s - loss: 0.0554 - accuracy: 0.8507 - val_loss: 0.0626 - val_accuracy: 0.8394
Epoch 48/128
 - 1s - loss: 0.0558 - accuracy: 0.8488 - val_loss: 0.0602 - val_accuracy: 0.8467
Epoch 49/128
 - 1s - loss: 0.0553 - accuracy: 0.8520 - val_loss: 0.0600 - val_accuracy: 0.8518
Epoch 50/128
 - 1s - loss: 0.0544 - accuracy: 0.8529 - val_loss: 0.0583 - val_accuracy: 0.8445
Epoch 51/128
 - 1s - loss: 0.0572 - accuracy: 0.8487 - val_loss: 0.0615 - val_accuracy: 0.8460
Epoch 52/128
 - 1s - loss: 0.0556 - accuracy: 0.8498 - val_loss: 0.0662 - val_accuracy: 0.8321
Epoch 53/128
 - 1s - loss: 0.0553 - accuracy: 0.8514 - val_loss: 0.0581 - val_accuracy: 0.8540
Epoch 54/128
 - 1s - loss: 0.0544 - accuracy: 0.8541 - val_loss: 0.0611 - val_accuracy: 0.8504
Epoch 55/128
 - 1s - loss: 0.0526 - accuracy: 0.8580 - val_loss: 0.0591 - val_accuracy: 0.8496
Epoch 56/128
 - 1s - loss: 0.0540 - accuracy: 0.8532 - val_loss: 0.0623 - val_accuracy: 0.8431
Epoch 57/128
 - 1s - loss: 0.0543 - accuracy: 0.8534 - val_loss: 0.0602 - val_accuracy: 0.8467
Epoch 58/128
 - 1s - loss: 0.0525 - accuracy: 0.8587 - val_loss: 0.0629 - val_accuracy: 0.8453
Epoch 59/128
 - 1s - loss: 0.0527 - accuracy: 0.8576 - val_loss: 0.0567 - val_accuracy: 0.8620
Epoch 60/128
 - 1s - loss: 0.0519 - accuracy: 0.8596 - val_loss: 0.0587 - val_accuracy: 0.8482
Epoch 61/128
 - 1s - loss: 0.0515 - accuracy: 0.8611 - val_loss: 0.0581 - val_accuracy: 0.8547
Epoch 62/128
 - 1s - loss: 0.0508 - accuracy: 0.8613 - val_loss: 0.0598 - val_accuracy: 0.8533
Epoch 63/128
 - 1s - loss: 0.0505 - accuracy: 0.8645 - val_loss: 0.0577 - val_accuracy: 0.8555
Epoch 64/128
 - 1s - loss: 0.0516 - accuracy: 0.8580 - val_loss: 0.0684 - val_accuracy: 0.8277
Epoch 65/128
 - 1s - loss: 0.0557 - accuracy: 0.8505 - val_loss: 0.0574 - val_accuracy: 0.8526
Epoch 66/128
 - 1s - loss: 0.0520 - accuracy: 0.8574 - val_loss: 0.0606 - val_accuracy: 0.8401
Epoch 67/128
 - 1s - loss: 0.0532 - accuracy: 0.8543 - val_loss: 0.0564 - val_accuracy: 0.8511
Epoch 68/128
 - 1s - loss: 0.0510 - accuracy: 0.8607 - val_loss: 0.0572 - val_accuracy: 0.8540
Epoch 69/128
 - 1s - loss: 0.0508 - accuracy: 0.8609 - val_loss: 0.0570 - val_accuracy: 0.8526
Epoch 70/128
 - 1s - loss: 0.0508 - accuracy: 0.8604 - val_loss: 0.0560 - val_accuracy: 0.8613
Epoch 71/128
 - 1s - loss: 0.0516 - accuracy: 0.8580 - val_loss: 0.0570 - val_accuracy: 0.8540
Epoch 72/128
 - 1s - loss: 0.0532 - accuracy: 0.8547 - val_loss: 0.0590 - val_accuracy: 0.8489
Epoch 73/128
 - 1s - loss: 0.0498 - accuracy: 0.8640 - val_loss: 0.0572 - val_accuracy: 0.8562
Epoch 74/128
 - 1s - loss: 0.0495 - accuracy: 0.8616 - val_loss: 0.0550 - val_accuracy: 0.8620
Epoch 75/128
 - 1s - loss: 0.0492 - accuracy: 0.8640 - val_loss: 0.0558 - val_accuracy: 0.8533
Epoch 76/128
 - 1s - loss: 0.0497 - accuracy: 0.8636 - val_loss: 0.0545 - val_accuracy: 0.8613
Epoch 77/128
 - 1s - loss: 0.0494 - accuracy: 0.8618 - val_loss: 0.0601 - val_accuracy: 0.8511
Epoch 78/128
 - 1s - loss: 0.0532 - accuracy: 0.8560 - val_loss: 0.0563 - val_accuracy: 0.8518
Epoch 79/128
 - 1s - loss: 0.0519 - accuracy: 0.8571 - val_loss: 0.0575 - val_accuracy: 0.8533
Epoch 80/128
 - 1s - loss: 0.0497 - accuracy: 0.8649 - val_loss: 0.0573 - val_accuracy: 0.8504
Epoch 81/128
 - 1s - loss: 0.0499 - accuracy: 0.8627 - val_loss: 0.0536 - val_accuracy: 0.8511
Epoch 82/128
 - 1s - loss: 0.0486 - accuracy: 0.8671 - val_loss: 0.0540 - val_accuracy: 0.8569
Epoch 83/128
 - 1s - loss: 0.0483 - accuracy: 0.8653 - val_loss: 0.0534 - val_accuracy: 0.8584
Epoch 84/128
 - 1s - loss: 0.0476 - accuracy: 0.8677 - val_loss: 0.0594 - val_accuracy: 0.8423
Epoch 85/128
 - 1s - loss: 0.0497 - accuracy: 0.8618 - val_loss: 0.0557 - val_accuracy: 0.8577
Epoch 86/128
 - 1s - loss: 0.0476 - accuracy: 0.8673 - val_loss: 0.0561 - val_accuracy: 0.8526
Epoch 87/128
 - 1s - loss: 0.0482 - accuracy: 0.8686 - val_loss: 0.0550 - val_accuracy: 0.8562
Epoch 88/128
 - 1s - loss: 0.0511 - accuracy: 0.8582 - val_loss: 0.0563 - val_accuracy: 0.8482
Epoch 89/128
 - 1s - loss: 0.0484 - accuracy: 0.8677 - val_loss: 0.0538 - val_accuracy: 0.8613
Epoch 90/128
 - 1s - loss: 0.0488 - accuracy: 0.8644 - val_loss: 0.0563 - val_accuracy: 0.8547
Epoch 91/128
 - 1s - loss: 0.0508 - accuracy: 0.8591 - val_loss: 0.0627 - val_accuracy: 0.8336
Epoch 92/128
 - 1s - loss: 0.0509 - accuracy: 0.8589 - val_loss: 0.0558 - val_accuracy: 0.8547
Epoch 93/128
 - 1s - loss: 0.0483 - accuracy: 0.8680 - val_loss: 0.0577 - val_accuracy: 0.8482
Epoch 94/128
 - 1s - loss: 0.0484 - accuracy: 0.8649 - val_loss: 0.0555 - val_accuracy: 0.8518
Epoch 95/128
 - 1s - loss: 0.0460 - accuracy: 0.8704 - val_loss: 0.0539 - val_accuracy: 0.8599
Epoch 96/128
 - 1s - loss: 0.0469 - accuracy: 0.8700 - val_loss: 0.0538 - val_accuracy: 0.8569
Epoch 97/128
 - 1s - loss: 0.0460 - accuracy: 0.8739 - val_loss: 0.0560 - val_accuracy: 0.8511
Epoch 98/128
 - 1s - loss: 0.0478 - accuracy: 0.8655 - val_loss: 0.0582 - val_accuracy: 0.8394
Epoch 99/128
 - 1s - loss: 0.0479 - accuracy: 0.8675 - val_loss: 0.0550 - val_accuracy: 0.8577
Epoch 100/128
 - 1s - loss: 0.0459 - accuracy: 0.8711 - val_loss: 0.0560 - val_accuracy: 0.8526
Epoch 101/128
 - 1s - loss: 0.0480 - accuracy: 0.8640 - val_loss: 0.0546 - val_accuracy: 0.8511
Epoch 102/128
 - 1s - loss: 0.0459 - accuracy: 0.8724 - val_loss: 0.0541 - val_accuracy: 0.8591
Epoch 103/128
 - 1s - loss: 0.0459 - accuracy: 0.8728 - val_loss: 0.0536 - val_accuracy: 0.8613
Epoch 104/128
 - 1s - loss: 0.0445 - accuracy: 0.8742 - val_loss: 0.0541 - val_accuracy: 0.8569
Epoch 105/128
 - 1s - loss: 0.0456 - accuracy: 0.8700 - val_loss: 0.0537 - val_accuracy: 0.8540
Epoch 106/128
 - 1s - loss: 0.0459 - accuracy: 0.8726 - val_loss: 0.0582 - val_accuracy: 0.8453
Epoch 107/128
 - 1s - loss: 0.0454 - accuracy: 0.8719 - val_loss: 0.0563 - val_accuracy: 0.8496
Epoch 108/128
 - 1s - loss: 0.0493 - accuracy: 0.8656 - val_loss: 0.0524 - val_accuracy: 0.8599
Epoch 109/128
 - 1s - loss: 0.0460 - accuracy: 0.8720 - val_loss: 0.0583 - val_accuracy: 0.8438
Epoch 110/128
 - 1s - loss: 0.0466 - accuracy: 0.8684 - val_loss: 0.0539 - val_accuracy: 0.8547
Epoch 111/128
 - 1s - loss: 0.0464 - accuracy: 0.8702 - val_loss: 0.0536 - val_accuracy: 0.8591
Epoch 112/128
 - 1s - loss: 0.0479 - accuracy: 0.8649 - val_loss: 0.0564 - val_accuracy: 0.8496
Epoch 113/128
 - 1s - loss: 0.0467 - accuracy: 0.8695 - val_loss: 0.0544 - val_accuracy: 0.8526
Epoch 114/128
 - 1s - loss: 0.0457 - accuracy: 0.8719 - val_loss: 0.0598 - val_accuracy: 0.8416
Epoch 115/128
 - 1s - loss: 0.0459 - accuracy: 0.8709 - val_loss: 0.0575 - val_accuracy: 0.8453
Epoch 116/128
 - 1s - loss: 0.0469 - accuracy: 0.8673 - val_loss: 0.0574 - val_accuracy: 0.8453
Epoch 117/128
 - 1s - loss: 0.0460 - accuracy: 0.8700 - val_loss: 0.0556 - val_accuracy: 0.8504
Epoch 118/128
 - 1s - loss: 0.0447 - accuracy: 0.8735 - val_loss: 0.0573 - val_accuracy: 0.8489
Epoch 119/128
 - 1s - loss: 0.0449 - accuracy: 0.8717 - val_loss: 0.0545 - val_accuracy: 0.8577
Epoch 120/128
 - 1s - loss: 0.0460 - accuracy: 0.8726 - val_loss: 0.0569 - val_accuracy: 0.8482
Epoch 121/128
 - 1s - loss: 0.0462 - accuracy: 0.8677 - val_loss: 0.0540 - val_accuracy: 0.8562
Epoch 122/128
 - 1s - loss: 0.0431 - accuracy: 0.8782 - val_loss: 0.0542 - val_accuracy: 0.8584
Epoch 123/128
 - 1s - loss: 0.0434 - accuracy: 0.8779 - val_loss: 0.0571 - val_accuracy: 0.8518
Epoch 124/128
 - 1s - loss: 0.0451 - accuracy: 0.8729 - val_loss: 0.0556 - val_accuracy: 0.8526
Epoch 125/128
 - 1s - loss: 0.0460 - accuracy: 0.8704 - val_loss: 0.0532 - val_accuracy: 0.8606
Epoch 126/128
 - 1s - loss: 0.0472 - accuracy: 0.8686 - val_loss: 0.0558 - val_accuracy: 0.8533
Epoch 127/128
 - 1s - loss: 0.0470 - accuracy: 0.8684 - val_loss: 0.0582 - val_accuracy: 0.8438
Epoch 128/128
 - 1s - loss: 0.0461 - accuracy: 0.8680 - val_loss: 0.0568 - val_accuracy: 0.8533

Fit: epochs= 128 , batch_size= 32 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_9 (Dense)              (None, 11)                132       
_________________________________________________________________
dense_10 (Dense)             (None, 500)               6000      
_________________________________________________________________
dense_11 (Dense)             (None, 300)               150300    
_________________________________________________________________
dense_12 (Dense)             (None, 200)               60200     
_________________________________________________________________
dense_13 (Dense)             (None, 100)               20100     
_________________________________________________________________
dense_14 (Dense)             (None, 50)                5050      
_________________________________________________________________
dense_15 (Dense)             (None, 20)                1020      
_________________________________________________________________
dense_16 (Dense)             (None, 4)                 84        
=================================================================
Total params: 242,886
Trainable params: 242,886
Non-trainable params: 0
_________________________________________________________________
None

Accuracy Train: 86.78%
Accuracy Test: 84.11%
Loss Train: 0.05
Loss Test: 0.06
Numero dati esaminati: 1712
True Positive 1440
False Positive 272
