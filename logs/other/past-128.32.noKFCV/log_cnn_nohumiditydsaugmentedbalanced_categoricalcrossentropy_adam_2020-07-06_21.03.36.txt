Dataset used: ../../datasets/full_dataset_without_humidity_augmented_balanced.csv 

      Temperature  Sound  Heartbeat   X1  ...  Y2  Z2  Classification  Feedback
9999           -1     -1         48   -1  ...  -1  -1             200     Angry
9998           35     -1         48  808  ...  -1  -1             150     Angry
9997           35     -1         48  860  ...  -1  -1             150     Angry
9996           -1     -1         48   -1  ...  -1  -1             150     Angry
9995           -1     -1         48   -1  ...  -1  -1             150     Angry

[5 rows x 11 columns]

Objservations: 20888
Reshaping:  ((16710, 10), (16710, 4), (4178, 10), (4178, 4))  -> ((16710, 10, 1), (16710, 4), (4178, 10, 1), (4178, 4))

Layers:

{'name': 'conv1d_7', 'trainable': True, 'batch_input_shape': (None, 10, 1), 'dtype': 'float32', 'filters': 500, 'kernel_size': (1,), 'strides': (1,), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'activation_13', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'} 

{'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.4, 'noise_shape': None, 'seed': None} 

{'name': 'dense_43', 'trainable': True, 'dtype': 'float32', 'units': 400, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_44', 'trainable': True, 'dtype': 'float32', 'units': 300, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_45', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_46', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_47', 'trainable': True, 'dtype': 'float32', 'units': 50, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_48', 'trainable': True, 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_49', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'activation_14', 'trainable': True, 'dtype': 'float32', 'activation': 'softmax'} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 13368 samples, validate on 3342 samples
Epoch 1/128
 - 17s - loss: 0.7871 - accuracy: 0.7102 - val_loss: 0.6729 - val_accuracy: 0.7651
Epoch 2/128
 - 16s - loss: 0.6793 - accuracy: 0.7623 - val_loss: 0.6162 - val_accuracy: 0.7798
Epoch 3/128
 - 16s - loss: 0.6353 - accuracy: 0.7760 - val_loss: 0.5716 - val_accuracy: 0.8046
Epoch 4/128
 - 16s - loss: 0.6068 - accuracy: 0.7872 - val_loss: 0.5584 - val_accuracy: 0.8013
Epoch 5/128
 - 16s - loss: 0.5805 - accuracy: 0.7929 - val_loss: 0.5374 - val_accuracy: 0.7986
Epoch 6/128
 - 16s - loss: 0.5620 - accuracy: 0.7962 - val_loss: 0.5172 - val_accuracy: 0.8127
Epoch 7/128
 - 16s - loss: 0.5392 - accuracy: 0.8033 - val_loss: 0.5086 - val_accuracy: 0.8157
Epoch 8/128
 - 16s - loss: 0.5257 - accuracy: 0.8071 - val_loss: 0.4869 - val_accuracy: 0.8202
Epoch 9/128
 - 16s - loss: 0.5071 - accuracy: 0.8113 - val_loss: 0.4746 - val_accuracy: 0.8229
Epoch 10/128
 - 16s - loss: 0.5015 - accuracy: 0.8101 - val_loss: 0.4650 - val_accuracy: 0.8330
Epoch 11/128
 - 16s - loss: 0.4837 - accuracy: 0.8177 - val_loss: 0.4488 - val_accuracy: 0.8321
Epoch 12/128
 - 16s - loss: 0.4761 - accuracy: 0.8174 - val_loss: 0.4360 - val_accuracy: 0.8363
Epoch 13/128
 - 16s - loss: 0.4634 - accuracy: 0.8226 - val_loss: 0.4402 - val_accuracy: 0.8309
Epoch 14/128
 - 16s - loss: 0.4580 - accuracy: 0.8236 - val_loss: 0.4125 - val_accuracy: 0.8456
Epoch 15/128
 - 16s - loss: 0.4459 - accuracy: 0.8282 - val_loss: 0.4255 - val_accuracy: 0.8342
Epoch 16/128
 - 16s - loss: 0.4427 - accuracy: 0.8288 - val_loss: 0.4030 - val_accuracy: 0.8441
Epoch 17/128
 - 16s - loss: 0.4316 - accuracy: 0.8343 - val_loss: 0.4013 - val_accuracy: 0.8447
Epoch 18/128
 - 17s - loss: 0.4273 - accuracy: 0.8352 - val_loss: 0.3928 - val_accuracy: 0.8474
Epoch 19/128
 - 16s - loss: 0.4221 - accuracy: 0.8351 - val_loss: 0.3894 - val_accuracy: 0.8495
Epoch 20/128
 - 16s - loss: 0.4149 - accuracy: 0.8407 - val_loss: 0.3894 - val_accuracy: 0.8531
Epoch 21/128
 - 16s - loss: 0.4146 - accuracy: 0.8377 - val_loss: 0.3763 - val_accuracy: 0.8582
Epoch 22/128
 - 16s - loss: 0.4028 - accuracy: 0.8398 - val_loss: 0.3890 - val_accuracy: 0.8507
Epoch 23/128
 - 16s - loss: 0.4015 - accuracy: 0.8387 - val_loss: 0.3853 - val_accuracy: 0.8513
Epoch 24/128
 - 16s - loss: 0.4018 - accuracy: 0.8420 - val_loss: 0.3747 - val_accuracy: 0.8519
Epoch 25/128
 - 16s - loss: 0.3946 - accuracy: 0.8448 - val_loss: 0.3786 - val_accuracy: 0.8564
Epoch 26/128
 - 16s - loss: 0.3926 - accuracy: 0.8431 - val_loss: 0.3716 - val_accuracy: 0.8564
Epoch 27/128
 - 16s - loss: 0.3907 - accuracy: 0.8434 - val_loss: 0.3896 - val_accuracy: 0.8495
Epoch 28/128
 - 17s - loss: 0.3864 - accuracy: 0.8461 - val_loss: 0.3543 - val_accuracy: 0.8588
Epoch 29/128
 - 16s - loss: 0.3866 - accuracy: 0.8448 - val_loss: 0.3625 - val_accuracy: 0.8648
Epoch 30/128
 - 16s - loss: 0.3869 - accuracy: 0.8471 - val_loss: 0.3564 - val_accuracy: 0.8609
Epoch 31/128
 - 16s - loss: 0.3799 - accuracy: 0.8461 - val_loss: 0.3553 - val_accuracy: 0.8621
Epoch 32/128
 - 16s - loss: 0.3754 - accuracy: 0.8478 - val_loss: 0.3688 - val_accuracy: 0.8612
Epoch 33/128
 - 16s - loss: 0.3750 - accuracy: 0.8487 - val_loss: 0.3658 - val_accuracy: 0.8615
Epoch 34/128
 - 16s - loss: 0.3736 - accuracy: 0.8512 - val_loss: 0.3542 - val_accuracy: 0.8567
Epoch 35/128
 - 16s - loss: 0.3703 - accuracy: 0.8509 - val_loss: 0.3617 - val_accuracy: 0.8615
Epoch 36/128
 - 16s - loss: 0.3716 - accuracy: 0.8509 - val_loss: 0.3586 - val_accuracy: 0.8594
Epoch 37/128
 - 17s - loss: 0.3644 - accuracy: 0.8522 - val_loss: 0.3468 - val_accuracy: 0.8651
Epoch 38/128
 - 17s - loss: 0.3664 - accuracy: 0.8519 - val_loss: 0.3646 - val_accuracy: 0.8582
Epoch 39/128
 - 16s - loss: 0.3626 - accuracy: 0.8548 - val_loss: 0.3588 - val_accuracy: 0.8645
Epoch 40/128
 - 16s - loss: 0.3623 - accuracy: 0.8513 - val_loss: 0.3558 - val_accuracy: 0.8588
Epoch 41/128
 - 16s - loss: 0.3623 - accuracy: 0.8529 - val_loss: 0.3560 - val_accuracy: 0.8671
Epoch 42/128
 - 16s - loss: 0.3593 - accuracy: 0.8554 - val_loss: 0.3443 - val_accuracy: 0.8645
Epoch 43/128
 - 16s - loss: 0.3617 - accuracy: 0.8538 - val_loss: 0.3465 - val_accuracy: 0.8668
Epoch 44/128
 - 16s - loss: 0.3540 - accuracy: 0.8534 - val_loss: 0.3528 - val_accuracy: 0.8594
Epoch 45/128
 - 16s - loss: 0.3452 - accuracy: 0.8603 - val_loss: 0.3510 - val_accuracy: 0.8662
Epoch 46/128
 - 16s - loss: 0.3491 - accuracy: 0.8564 - val_loss: 0.3437 - val_accuracy: 0.8662
Epoch 47/128
 - 16s - loss: 0.3453 - accuracy: 0.8576 - val_loss: 0.3383 - val_accuracy: 0.8659
Epoch 48/128
 - 16s - loss: 0.3528 - accuracy: 0.8585 - val_loss: 0.3311 - val_accuracy: 0.8683
Epoch 49/128
 - 16s - loss: 0.3426 - accuracy: 0.8602 - val_loss: 0.3327 - val_accuracy: 0.8707
Epoch 50/128
 - 16s - loss: 0.3432 - accuracy: 0.8615 - val_loss: 0.3521 - val_accuracy: 0.8662
Epoch 51/128
 - 16s - loss: 0.3485 - accuracy: 0.8600 - val_loss: 0.3324 - val_accuracy: 0.8630
Epoch 52/128
 - 16s - loss: 0.3373 - accuracy: 0.8627 - val_loss: 0.3367 - val_accuracy: 0.8719
Epoch 53/128
 - 16s - loss: 0.3450 - accuracy: 0.8600 - val_loss: 0.3435 - val_accuracy: 0.8677
Epoch 54/128
 - 16s - loss: 0.3464 - accuracy: 0.8564 - val_loss: 0.3445 - val_accuracy: 0.8671
Epoch 55/128
 - 16s - loss: 0.3410 - accuracy: 0.8614 - val_loss: 0.3256 - val_accuracy: 0.8680
Epoch 56/128
 - 16s - loss: 0.3308 - accuracy: 0.8637 - val_loss: 0.3285 - val_accuracy: 0.8734
Epoch 57/128
 - 16s - loss: 0.3295 - accuracy: 0.8638 - val_loss: 0.3313 - val_accuracy: 0.8716
Epoch 58/128
 - 16s - loss: 0.3351 - accuracy: 0.8612 - val_loss: 0.3357 - val_accuracy: 0.8728
Epoch 59/128
 - 16s - loss: 0.3423 - accuracy: 0.8592 - val_loss: 0.3320 - val_accuracy: 0.8680
Epoch 60/128
 - 16s - loss: 0.3341 - accuracy: 0.8633 - val_loss: 0.3850 - val_accuracy: 0.8453
Epoch 61/128
 - 16s - loss: 0.3385 - accuracy: 0.8616 - val_loss: 0.3669 - val_accuracy: 0.8668
Epoch 62/128
 - 16s - loss: 0.3315 - accuracy: 0.8624 - val_loss: 0.3328 - val_accuracy: 0.8728
Epoch 63/128
 - 16s - loss: 0.3313 - accuracy: 0.8619 - val_loss: 0.3335 - val_accuracy: 0.8755
Epoch 64/128
 - 16s - loss: 0.3285 - accuracy: 0.8635 - val_loss: 0.3467 - val_accuracy: 0.8683
Epoch 65/128
 - 16s - loss: 0.3283 - accuracy: 0.8638 - val_loss: 0.3351 - val_accuracy: 0.8683
Epoch 66/128
 - 16s - loss: 0.3294 - accuracy: 0.8672 - val_loss: 0.3331 - val_accuracy: 0.8746
Epoch 67/128
 - 16s - loss: 0.3233 - accuracy: 0.8652 - val_loss: 0.3284 - val_accuracy: 0.8713
Epoch 68/128
 - 16s - loss: 0.3333 - accuracy: 0.8625 - val_loss: 0.3720 - val_accuracy: 0.8594
Epoch 69/128
 - 16s - loss: 0.3332 - accuracy: 0.8635 - val_loss: 0.3260 - val_accuracy: 0.8686
Epoch 70/128
 - 16s - loss: 0.3283 - accuracy: 0.8638 - val_loss: 0.3274 - val_accuracy: 0.8758
Epoch 71/128
 - 16s - loss: 0.3244 - accuracy: 0.8659 - val_loss: 0.3373 - val_accuracy: 0.8683
Epoch 72/128
 - 16s - loss: 0.3251 - accuracy: 0.8652 - val_loss: 0.3343 - val_accuracy: 0.8713
Epoch 73/128
 - 16s - loss: 0.3204 - accuracy: 0.8665 - val_loss: 0.3180 - val_accuracy: 0.8752
Epoch 74/128
 - 16s - loss: 0.3198 - accuracy: 0.8667 - val_loss: 0.3198 - val_accuracy: 0.8752
Epoch 75/128
 - 16s - loss: 0.3191 - accuracy: 0.8654 - val_loss: 0.3425 - val_accuracy: 0.8710
Epoch 76/128
 - 17s - loss: 0.3235 - accuracy: 0.8677 - val_loss: 0.3515 - val_accuracy: 0.8701
Epoch 77/128
 - 16s - loss: 0.3144 - accuracy: 0.8692 - val_loss: 0.3285 - val_accuracy: 0.8767
Epoch 78/128
 - 16s - loss: 0.3172 - accuracy: 0.8701 - val_loss: 0.3303 - val_accuracy: 0.8761
Epoch 79/128
 - 16s - loss: 0.3174 - accuracy: 0.8695 - val_loss: 0.3295 - val_accuracy: 0.8809
Epoch 80/128
 - 16s - loss: 0.3130 - accuracy: 0.8701 - val_loss: 0.3549 - val_accuracy: 0.8713
Epoch 81/128
 - 16s - loss: 0.3234 - accuracy: 0.8666 - val_loss: 0.3297 - val_accuracy: 0.8770
Epoch 82/128
 - 16s - loss: 0.3177 - accuracy: 0.8691 - val_loss: 0.3328 - val_accuracy: 0.8779
Epoch 83/128
 - 16s - loss: 0.3159 - accuracy: 0.8686 - val_loss: 0.3386 - val_accuracy: 0.8683
Epoch 84/128
 - 16s - loss: 0.3165 - accuracy: 0.8681 - val_loss: 0.3378 - val_accuracy: 0.8761
Epoch 85/128
 - 17s - loss: 0.3153 - accuracy: 0.8674 - val_loss: 0.3253 - val_accuracy: 0.8785
Epoch 86/128
 - 16s - loss: 0.3158 - accuracy: 0.8688 - val_loss: 0.3324 - val_accuracy: 0.8776
Epoch 87/128
 - 16s - loss: 0.3131 - accuracy: 0.8701 - val_loss: 0.3158 - val_accuracy: 0.8791
Epoch 88/128
 - 16s - loss: 0.3137 - accuracy: 0.8698 - val_loss: 0.3251 - val_accuracy: 0.8815
Epoch 89/128
 - 16s - loss: 0.3170 - accuracy: 0.8681 - val_loss: 0.3146 - val_accuracy: 0.8827
Epoch 90/128
 - 16s - loss: 0.3062 - accuracy: 0.8719 - val_loss: 0.3308 - val_accuracy: 0.8734
Epoch 91/128
 - 16s - loss: 0.3086 - accuracy: 0.8683 - val_loss: 0.3282 - val_accuracy: 0.8707
Epoch 92/128
 - 16s - loss: 0.3060 - accuracy: 0.8722 - val_loss: 0.3332 - val_accuracy: 0.8719
Epoch 93/128
 - 17s - loss: 0.3062 - accuracy: 0.8708 - val_loss: 0.3366 - val_accuracy: 0.8755
Epoch 94/128
 - 17s - loss: 0.3130 - accuracy: 0.8704 - val_loss: 0.3318 - val_accuracy: 0.8755
Epoch 95/128
 - 17s - loss: 0.3043 - accuracy: 0.8715 - val_loss: 0.3754 - val_accuracy: 0.8588
Epoch 96/128
 - 16s - loss: 0.3049 - accuracy: 0.8704 - val_loss: 0.3287 - val_accuracy: 0.8767
Epoch 97/128
 - 16s - loss: 0.3067 - accuracy: 0.8714 - val_loss: 0.3261 - val_accuracy: 0.8797
Epoch 98/128
 - 17s - loss: 0.3072 - accuracy: 0.8713 - val_loss: 0.3173 - val_accuracy: 0.8761
Epoch 99/128
 - 17s - loss: 0.3064 - accuracy: 0.8721 - val_loss: 0.3251 - val_accuracy: 0.8776
Epoch 100/128
 - 17s - loss: 0.3145 - accuracy: 0.8681 - val_loss: 0.3616 - val_accuracy: 0.8692
Epoch 101/128
 - 17s - loss: 0.3040 - accuracy: 0.8718 - val_loss: 0.3303 - val_accuracy: 0.8827
Epoch 102/128
 - 17s - loss: 0.2983 - accuracy: 0.8743 - val_loss: 0.3240 - val_accuracy: 0.8806
Epoch 103/128
 - 16s - loss: 0.3046 - accuracy: 0.8728 - val_loss: 0.3488 - val_accuracy: 0.8713
Epoch 104/128
 - 16s - loss: 0.3024 - accuracy: 0.8754 - val_loss: 0.3265 - val_accuracy: 0.8797
Epoch 105/128
 - 16s - loss: 0.3036 - accuracy: 0.8728 - val_loss: 0.3332 - val_accuracy: 0.8836
Epoch 106/128
 - 16s - loss: 0.3025 - accuracy: 0.8725 - val_loss: 0.3132 - val_accuracy: 0.8818
Epoch 107/128
 - 16s - loss: 0.3083 - accuracy: 0.8712 - val_loss: 0.3244 - val_accuracy: 0.8842
Epoch 108/128
 - 16s - loss: 0.2972 - accuracy: 0.8742 - val_loss: 0.3524 - val_accuracy: 0.8710
Epoch 109/128
 - 17s - loss: 0.2945 - accuracy: 0.8735 - val_loss: 0.3426 - val_accuracy: 0.8740
Epoch 110/128
 - 16s - loss: 0.2998 - accuracy: 0.8749 - val_loss: 0.3199 - val_accuracy: 0.8746
Epoch 111/128
 - 16s - loss: 0.2986 - accuracy: 0.8725 - val_loss: 0.3161 - val_accuracy: 0.8833
Epoch 112/128
 - 16s - loss: 0.2960 - accuracy: 0.8745 - val_loss: 0.3221 - val_accuracy: 0.8818
Epoch 113/128
 - 17s - loss: 0.2993 - accuracy: 0.8740 - val_loss: 0.3327 - val_accuracy: 0.8788
Epoch 114/128
 - 16s - loss: 0.3024 - accuracy: 0.8716 - val_loss: 0.3176 - val_accuracy: 0.8836
Epoch 115/128
 - 16s - loss: 0.3081 - accuracy: 0.8724 - val_loss: 0.3244 - val_accuracy: 0.8773
Epoch 116/128
 - 16s - loss: 0.2923 - accuracy: 0.8745 - val_loss: 0.3188 - val_accuracy: 0.8782
Epoch 117/128
 - 16s - loss: 0.3028 - accuracy: 0.8734 - val_loss: 0.3123 - val_accuracy: 0.8818
Epoch 118/128
 - 16s - loss: 0.2975 - accuracy: 0.8749 - val_loss: 0.3190 - val_accuracy: 0.8791
Epoch 119/128
 - 16s - loss: 0.2977 - accuracy: 0.8743 - val_loss: 0.3335 - val_accuracy: 0.8695
Epoch 120/128
 - 16s - loss: 0.2935 - accuracy: 0.8757 - val_loss: 0.3241 - val_accuracy: 0.8782
Epoch 121/128
 - 16s - loss: 0.2955 - accuracy: 0.8750 - val_loss: 0.3248 - val_accuracy: 0.8770
Epoch 122/128
 - 16s - loss: 0.2957 - accuracy: 0.8743 - val_loss: 0.3419 - val_accuracy: 0.8698
Epoch 123/128
 - 16s - loss: 0.2919 - accuracy: 0.8765 - val_loss: 0.3130 - val_accuracy: 0.8818
Epoch 124/128
 - 16s - loss: 0.3007 - accuracy: 0.8732 - val_loss: 0.3051 - val_accuracy: 0.8830
Epoch 125/128
 - 16s - loss: 0.2952 - accuracy: 0.8747 - val_loss: 0.3123 - val_accuracy: 0.8818
Epoch 126/128
 - 16s - loss: 0.2960 - accuracy: 0.8745 - val_loss: 0.3479 - val_accuracy: 0.8701
Epoch 127/128
 - 16s - loss: 0.2923 - accuracy: 0.8765 - val_loss: 0.3127 - val_accuracy: 0.8797
Epoch 128/128
 - 16s - loss: 0.2963 - accuracy: 0.8751 - val_loss: 0.3158 - val_accuracy: 0.8821

Fit: epochs= 128 , batch_size= 32 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_7 (Conv1D)            (None, 10, 500)           1000      
_________________________________________________________________
activation_13 (Activation)   (None, 10, 500)           0         
_________________________________________________________________
flatten_7 (Flatten)          (None, 5000)              0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 5000)              0         
_________________________________________________________________
dense_43 (Dense)             (None, 400)               2000400   
_________________________________________________________________
dense_44 (Dense)             (None, 300)               120300    
_________________________________________________________________
dense_45 (Dense)             (None, 200)               60200     
_________________________________________________________________
dense_46 (Dense)             (None, 100)               20100     
_________________________________________________________________
dense_47 (Dense)             (None, 50)                5050      
_________________________________________________________________
dense_48 (Dense)             (None, 20)                1020      
_________________________________________________________________
dense_49 (Dense)             (None, 4)                 84        
_________________________________________________________________
activation_14 (Activation)   (None, 4)                 0         
=================================================================
Total params: 2,208,154
Trainable params: 2,208,154
Non-trainable params: 0
_________________________________________________________________
None

Accuracy Train: 88.07%
Accuracy Test: 86.96%
Loss Train: 0.28
Loss Test: 0.34
Numero dati esaminati: 4178
True Positive 3633
False Positive 545
