Dataset used: ../../datasets/full_dataset_without_humidity.csv 

   Temperature  Sound  Heartbeat   X1  ...    Y2     Z2  Classification  Feedback
0           32      1         60 -680  ... -7424 -15596             100     Happy
1           32      1         60 -780  ... -7408 -15628             100     Happy
2           -1      1         60   -1  ... -7276 -15612             100     Happy
3           -1     -1         60   -1  ...    -1     -1             100     Happy
4           32      1         60 -860  ... -7340 -15720             100     Happy

[5 rows x 11 columns]

Objservations: 8560

Layers:

{'name': 'dense_41', 'trainable': True, 'batch_input_shape': (None, 10), 'dtype': 'float32', 'units': 10, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_42', 'trainable': True, 'dtype': 'float32', 'units': 500, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_43', 'trainable': True, 'dtype': 'float32', 'units': 300, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_44', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_45', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_46', 'trainable': True, 'dtype': 'float32', 'units': 50, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_47', 'trainable': True, 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_48', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 5478 samples, validate on 1370 samples
Epoch 1/128
 - 1s - loss: 0.9819 - accuracy: 0.5913 - val_loss: 0.8571 - val_accuracy: 0.6730
Epoch 2/128
 - 1s - loss: 0.8051 - accuracy: 0.6866 - val_loss: 0.7615 - val_accuracy: 0.7029
Epoch 3/128
 - 1s - loss: 0.7386 - accuracy: 0.7074 - val_loss: 0.7028 - val_accuracy: 0.7102
Epoch 4/128
 - 1s - loss: 0.6851 - accuracy: 0.7335 - val_loss: 0.6659 - val_accuracy: 0.7343
Epoch 5/128
 - 1s - loss: 0.6425 - accuracy: 0.7523 - val_loss: 0.6264 - val_accuracy: 0.7569
Epoch 6/128
 - 1s - loss: 0.6024 - accuracy: 0.7656 - val_loss: 0.5957 - val_accuracy: 0.7708
Epoch 7/128
 - 1s - loss: 0.5753 - accuracy: 0.7755 - val_loss: 0.5832 - val_accuracy: 0.7759
Epoch 8/128
 - 1s - loss: 0.5445 - accuracy: 0.7861 - val_loss: 0.5689 - val_accuracy: 0.7818
Epoch 9/128
 - 1s - loss: 0.5187 - accuracy: 0.7915 - val_loss: 0.5558 - val_accuracy: 0.7832
Epoch 10/128
 - 1s - loss: 0.4963 - accuracy: 0.8007 - val_loss: 0.5618 - val_accuracy: 0.7832
Epoch 11/128
 - 1s - loss: 0.4756 - accuracy: 0.8078 - val_loss: 0.5485 - val_accuracy: 0.7883
Epoch 12/128
 - 1s - loss: 0.4699 - accuracy: 0.8125 - val_loss: 0.5512 - val_accuracy: 0.7905
Epoch 13/128
 - 1s - loss: 0.4533 - accuracy: 0.8142 - val_loss: 0.5342 - val_accuracy: 0.8000
Epoch 14/128
 - 1s - loss: 0.4306 - accuracy: 0.8235 - val_loss: 0.5654 - val_accuracy: 0.7825
Epoch 15/128
 - 1s - loss: 0.4179 - accuracy: 0.8290 - val_loss: 0.5386 - val_accuracy: 0.8109
Epoch 16/128
 - 1s - loss: 0.4135 - accuracy: 0.8282 - val_loss: 0.5101 - val_accuracy: 0.8051
Epoch 17/128
 - 1s - loss: 0.4004 - accuracy: 0.8337 - val_loss: 0.5143 - val_accuracy: 0.8146
Epoch 18/128
 - 1s - loss: 0.3877 - accuracy: 0.8397 - val_loss: 0.5324 - val_accuracy: 0.8007
Epoch 19/128
 - 1s - loss: 0.3742 - accuracy: 0.8472 - val_loss: 0.5603 - val_accuracy: 0.8109
Epoch 20/128
 - 1s - loss: 0.3713 - accuracy: 0.8459 - val_loss: 0.5357 - val_accuracy: 0.7971
Epoch 21/128
 - 1s - loss: 0.3646 - accuracy: 0.8496 - val_loss: 0.5122 - val_accuracy: 0.8197
Epoch 22/128
 - 1s - loss: 0.3575 - accuracy: 0.8512 - val_loss: 0.5348 - val_accuracy: 0.8088
Epoch 23/128
 - 1s - loss: 0.3488 - accuracy: 0.8538 - val_loss: 0.5151 - val_accuracy: 0.8161
Epoch 24/128
 - 1s - loss: 0.3452 - accuracy: 0.8572 - val_loss: 0.5232 - val_accuracy: 0.8168
Epoch 25/128
 - 1s - loss: 0.3432 - accuracy: 0.8530 - val_loss: 0.5248 - val_accuracy: 0.8168
Epoch 26/128
 - 1s - loss: 0.3292 - accuracy: 0.8611 - val_loss: 0.5472 - val_accuracy: 0.8197
Epoch 27/128
 - 1s - loss: 0.3365 - accuracy: 0.8558 - val_loss: 0.5378 - val_accuracy: 0.8161
Epoch 28/128
 - 1s - loss: 0.3239 - accuracy: 0.8607 - val_loss: 0.5242 - val_accuracy: 0.8277
Epoch 29/128
 - 1s - loss: 0.3262 - accuracy: 0.8633 - val_loss: 0.5267 - val_accuracy: 0.8204
Epoch 30/128
 - 1s - loss: 0.3283 - accuracy: 0.8604 - val_loss: 0.5353 - val_accuracy: 0.8175
Epoch 31/128
 - 1s - loss: 0.3175 - accuracy: 0.8580 - val_loss: 0.5173 - val_accuracy: 0.8241
Epoch 32/128
 - 1s - loss: 0.3070 - accuracy: 0.8662 - val_loss: 0.5415 - val_accuracy: 0.8168
Epoch 33/128
 - 1s - loss: 0.3058 - accuracy: 0.8658 - val_loss: 0.5430 - val_accuracy: 0.8131
Epoch 34/128
 - 1s - loss: 0.2970 - accuracy: 0.8667 - val_loss: 0.5235 - val_accuracy: 0.8270
Epoch 35/128
 - 1s - loss: 0.3023 - accuracy: 0.8656 - val_loss: 0.5179 - val_accuracy: 0.8292
Epoch 36/128
 - 1s - loss: 0.3042 - accuracy: 0.8669 - val_loss: 0.5086 - val_accuracy: 0.8314
Epoch 37/128
 - 1s - loss: 0.3046 - accuracy: 0.8664 - val_loss: 0.5186 - val_accuracy: 0.8314
Epoch 38/128
 - 1s - loss: 0.2821 - accuracy: 0.8742 - val_loss: 0.5060 - val_accuracy: 0.8372
Epoch 39/128
 - 1s - loss: 0.2773 - accuracy: 0.8782 - val_loss: 0.4972 - val_accuracy: 0.8314
Epoch 40/128
 - 1s - loss: 0.2815 - accuracy: 0.8757 - val_loss: 0.5428 - val_accuracy: 0.8372
Epoch 41/128
 - 1s - loss: 0.2815 - accuracy: 0.8784 - val_loss: 0.5273 - val_accuracy: 0.8292
Epoch 42/128
 - 1s - loss: 0.2799 - accuracy: 0.8740 - val_loss: 0.5106 - val_accuracy: 0.8350
Epoch 43/128
 - 1s - loss: 0.2862 - accuracy: 0.8786 - val_loss: 0.5088 - val_accuracy: 0.8372
Epoch 44/128
 - 1s - loss: 0.2653 - accuracy: 0.8788 - val_loss: 0.5189 - val_accuracy: 0.8416
Epoch 45/128
 - 1s - loss: 0.2614 - accuracy: 0.8824 - val_loss: 0.5287 - val_accuracy: 0.8416
Epoch 46/128
 - 1s - loss: 0.2617 - accuracy: 0.8854 - val_loss: 0.5006 - val_accuracy: 0.8460
Epoch 47/128
 - 1s - loss: 0.2600 - accuracy: 0.8854 - val_loss: 0.4986 - val_accuracy: 0.8445
Epoch 48/128
 - 1s - loss: 0.2742 - accuracy: 0.8819 - val_loss: 0.5142 - val_accuracy: 0.8445
Epoch 49/128
 - 1s - loss: 0.2566 - accuracy: 0.8846 - val_loss: 0.5429 - val_accuracy: 0.8350
Epoch 50/128
 - 1s - loss: 0.2613 - accuracy: 0.8865 - val_loss: 0.5278 - val_accuracy: 0.8255
Epoch 51/128
 - 1s - loss: 0.2679 - accuracy: 0.8812 - val_loss: 0.4864 - val_accuracy: 0.8423
Epoch 52/128
 - 1s - loss: 0.2672 - accuracy: 0.8801 - val_loss: 0.5546 - val_accuracy: 0.8409
Epoch 53/128
 - 1s - loss: 0.2589 - accuracy: 0.8896 - val_loss: 0.5319 - val_accuracy: 0.8299
Epoch 54/128
 - 1s - loss: 0.2501 - accuracy: 0.8890 - val_loss: 0.5072 - val_accuracy: 0.8409
Epoch 55/128
 - 1s - loss: 0.2405 - accuracy: 0.8925 - val_loss: 0.5268 - val_accuracy: 0.8526
Epoch 56/128
 - 1s - loss: 0.2468 - accuracy: 0.8907 - val_loss: 0.5191 - val_accuracy: 0.8423
Epoch 57/128
 - 1s - loss: 0.2544 - accuracy: 0.8874 - val_loss: 0.5305 - val_accuracy: 0.8445
Epoch 58/128
 - 1s - loss: 0.2400 - accuracy: 0.8897 - val_loss: 0.5060 - val_accuracy: 0.8409
Epoch 59/128
 - 1s - loss: 0.2385 - accuracy: 0.8894 - val_loss: 0.5452 - val_accuracy: 0.8467
Epoch 60/128
 - 1s - loss: 0.2413 - accuracy: 0.8912 - val_loss: 0.5111 - val_accuracy: 0.8467
Epoch 61/128
 - 1s - loss: 0.2339 - accuracy: 0.8965 - val_loss: 0.5029 - val_accuracy: 0.8453
Epoch 62/128
 - 1s - loss: 0.2366 - accuracy: 0.8938 - val_loss: 0.4872 - val_accuracy: 0.8467
Epoch 63/128
 - 1s - loss: 0.2364 - accuracy: 0.8914 - val_loss: 0.4944 - val_accuracy: 0.8577
Epoch 64/128
 - 1s - loss: 0.2329 - accuracy: 0.8958 - val_loss: 0.5187 - val_accuracy: 0.8540
Epoch 65/128
 - 1s - loss: 0.2293 - accuracy: 0.8939 - val_loss: 0.5003 - val_accuracy: 0.8555
Epoch 66/128
 - 1s - loss: 0.2403 - accuracy: 0.8919 - val_loss: 0.5122 - val_accuracy: 0.8533
Epoch 67/128
 - 1s - loss: 0.2531 - accuracy: 0.8852 - val_loss: 0.4900 - val_accuracy: 0.8496
Epoch 68/128
 - 1s - loss: 0.2358 - accuracy: 0.8934 - val_loss: 0.5123 - val_accuracy: 0.8613
Epoch 69/128
 - 1s - loss: 0.2382 - accuracy: 0.8901 - val_loss: 0.4906 - val_accuracy: 0.8577
Epoch 70/128
 - 1s - loss: 0.2323 - accuracy: 0.8939 - val_loss: 0.5226 - val_accuracy: 0.8606
Epoch 71/128
 - 1s - loss: 0.2282 - accuracy: 0.8938 - val_loss: 0.5098 - val_accuracy: 0.8533
Epoch 72/128
 - 1s - loss: 0.2220 - accuracy: 0.8998 - val_loss: 0.4940 - val_accuracy: 0.8577
Epoch 73/128
 - 1s - loss: 0.2163 - accuracy: 0.8974 - val_loss: 0.5409 - val_accuracy: 0.8526
Epoch 74/128
 - 1s - loss: 0.2468 - accuracy: 0.8930 - val_loss: 0.5088 - val_accuracy: 0.8511
Epoch 75/128
 - 1s - loss: 0.2201 - accuracy: 0.9020 - val_loss: 0.5229 - val_accuracy: 0.8562
Epoch 76/128
 - 1s - loss: 0.2210 - accuracy: 0.8978 - val_loss: 0.5160 - val_accuracy: 0.8569
Epoch 77/128
 - 1s - loss: 0.2166 - accuracy: 0.8996 - val_loss: 0.5460 - val_accuracy: 0.8591
Epoch 78/128
 - 1s - loss: 0.2126 - accuracy: 0.8987 - val_loss: 0.5490 - val_accuracy: 0.8445
Epoch 79/128
 - 1s - loss: 0.2105 - accuracy: 0.9034 - val_loss: 0.5097 - val_accuracy: 0.8620
Epoch 80/128
 - 1s - loss: 0.2087 - accuracy: 0.9018 - val_loss: 0.5305 - val_accuracy: 0.8620
Epoch 81/128
 - 1s - loss: 0.2069 - accuracy: 0.9029 - val_loss: 0.5379 - val_accuracy: 0.8526
Epoch 82/128
 - 1s - loss: 0.2432 - accuracy: 0.8980 - val_loss: 0.4991 - val_accuracy: 0.8569
Epoch 83/128
 - 1s - loss: 0.2238 - accuracy: 0.8980 - val_loss: 0.5211 - val_accuracy: 0.8613
Epoch 84/128
 - 1s - loss: 0.2034 - accuracy: 0.9053 - val_loss: 0.5124 - val_accuracy: 0.8526
Epoch 85/128
 - 1s - loss: 0.1999 - accuracy: 0.9016 - val_loss: 0.5310 - val_accuracy: 0.8620
Epoch 86/128
 - 1s - loss: 0.2290 - accuracy: 0.8996 - val_loss: 0.5282 - val_accuracy: 0.8562
Epoch 87/128
 - 1s - loss: 0.2070 - accuracy: 0.9049 - val_loss: 0.5455 - val_accuracy: 0.8584
Epoch 88/128
 - 1s - loss: 0.2064 - accuracy: 0.9054 - val_loss: 0.5702 - val_accuracy: 0.8555
Epoch 89/128
 - 1s - loss: 0.2039 - accuracy: 0.9089 - val_loss: 0.5287 - val_accuracy: 0.8569
Epoch 90/128
 - 1s - loss: 0.2018 - accuracy: 0.9032 - val_loss: 0.5491 - val_accuracy: 0.8569
Epoch 91/128
 - 1s - loss: 0.1985 - accuracy: 0.9084 - val_loss: 0.5904 - val_accuracy: 0.8620
Epoch 92/128
 - 1s - loss: 0.2232 - accuracy: 0.9034 - val_loss: 0.5718 - val_accuracy: 0.8679
Epoch 93/128
 - 1s - loss: 0.2155 - accuracy: 0.8996 - val_loss: 0.5484 - val_accuracy: 0.8547
Epoch 94/128
 - 1s - loss: 0.2105 - accuracy: 0.9053 - val_loss: 0.5613 - val_accuracy: 0.8672
Epoch 95/128
 - 1s - loss: 0.1973 - accuracy: 0.9085 - val_loss: 0.5180 - val_accuracy: 0.8664
Epoch 96/128
 - 1s - loss: 0.2052 - accuracy: 0.9071 - val_loss: 0.5330 - val_accuracy: 0.8569
Epoch 97/128
 - 1s - loss: 0.2040 - accuracy: 0.9053 - val_loss: 0.5367 - val_accuracy: 0.8562
Epoch 98/128
 - 1s - loss: 0.2190 - accuracy: 0.9032 - val_loss: 0.5531 - val_accuracy: 0.8540
Epoch 99/128
 - 1s - loss: 0.2058 - accuracy: 0.9064 - val_loss: 0.5865 - val_accuracy: 0.8657
Epoch 100/128
 - 1s - loss: 0.2018 - accuracy: 0.9078 - val_loss: 0.5616 - val_accuracy: 0.8642
Epoch 101/128
 - 1s - loss: 0.1954 - accuracy: 0.9096 - val_loss: 0.5650 - val_accuracy: 0.8642
Epoch 102/128
 - 1s - loss: 0.2018 - accuracy: 0.9054 - val_loss: 0.5610 - val_accuracy: 0.8635
Epoch 103/128
 - 1s - loss: 0.1967 - accuracy: 0.9091 - val_loss: 0.5670 - val_accuracy: 0.8686
Epoch 104/128
 - 1s - loss: 0.1868 - accuracy: 0.9106 - val_loss: 0.6301 - val_accuracy: 0.8577
Epoch 105/128
 - 1s - loss: 0.2142 - accuracy: 0.9022 - val_loss: 0.5967 - val_accuracy: 0.8650
Epoch 106/128
 - 1s - loss: 0.1954 - accuracy: 0.9104 - val_loss: 0.5776 - val_accuracy: 0.8613
Epoch 107/128
 - 1s - loss: 0.1915 - accuracy: 0.9102 - val_loss: 0.5914 - val_accuracy: 0.8635
Epoch 108/128
 - 1s - loss: 0.1933 - accuracy: 0.9074 - val_loss: 0.5895 - val_accuracy: 0.8642
Epoch 109/128
 - 1s - loss: 0.1903 - accuracy: 0.9111 - val_loss: 0.5986 - val_accuracy: 0.8701
Epoch 110/128
 - 1s - loss: 0.1847 - accuracy: 0.9173 - val_loss: 0.5789 - val_accuracy: 0.8701
Epoch 111/128
 - 1s - loss: 0.1978 - accuracy: 0.9122 - val_loss: 0.5846 - val_accuracy: 0.8650
Epoch 112/128
 - 1s - loss: 0.2126 - accuracy: 0.9038 - val_loss: 0.5214 - val_accuracy: 0.8657
Epoch 113/128
 - 1s - loss: 0.2188 - accuracy: 0.9034 - val_loss: 0.5381 - val_accuracy: 0.8664
Epoch 114/128
 - 1s - loss: 0.1967 - accuracy: 0.9074 - val_loss: 0.5438 - val_accuracy: 0.8730
Epoch 115/128
 - 1s - loss: 0.1842 - accuracy: 0.9168 - val_loss: 0.5574 - val_accuracy: 0.8730
Epoch 116/128
 - 1s - loss: 0.1870 - accuracy: 0.9098 - val_loss: 0.5649 - val_accuracy: 0.8730
Epoch 117/128
 - 1s - loss: 0.1805 - accuracy: 0.9169 - val_loss: 0.6008 - val_accuracy: 0.8679
Epoch 118/128
 - 1s - loss: 0.1810 - accuracy: 0.9182 - val_loss: 0.5764 - val_accuracy: 0.8620
Epoch 119/128
 - 1s - loss: 0.1809 - accuracy: 0.9160 - val_loss: 0.5965 - val_accuracy: 0.8620
Epoch 120/128
 - 1s - loss: 0.2154 - accuracy: 0.9047 - val_loss: 0.5797 - val_accuracy: 0.8562
Epoch 121/128
 - 1s - loss: 0.1962 - accuracy: 0.9107 - val_loss: 0.5593 - val_accuracy: 0.8723
Epoch 122/128
 - 1s - loss: 0.1789 - accuracy: 0.9180 - val_loss: 0.5800 - val_accuracy: 0.8715
Epoch 123/128
 - 1s - loss: 0.1796 - accuracy: 0.9142 - val_loss: 0.6425 - val_accuracy: 0.8686
Epoch 124/128
 - 1s - loss: 0.1814 - accuracy: 0.9151 - val_loss: 0.5932 - val_accuracy: 0.8635
Epoch 125/128
 - 1s - loss: 0.1861 - accuracy: 0.9135 - val_loss: 0.5803 - val_accuracy: 0.8672
Epoch 126/128
 - 1s - loss: 0.1762 - accuracy: 0.9175 - val_loss: 0.6273 - val_accuracy: 0.8620
Epoch 127/128
 - 1s - loss: 0.1881 - accuracy: 0.9162 - val_loss: 0.5876 - val_accuracy: 0.8708
Epoch 128/128
 - 1s - loss: 0.1840 - accuracy: 0.9146 - val_loss: 0.5881 - val_accuracy: 0.8650

Fit: epochs= 128 , batch_size= 32 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_41 (Dense)             (None, 10)                110       
_________________________________________________________________
dense_42 (Dense)             (None, 500)               5500      
_________________________________________________________________
dense_43 (Dense)             (None, 300)               150300    
_________________________________________________________________
dense_44 (Dense)             (None, 200)               60200     
_________________________________________________________________
dense_45 (Dense)             (None, 100)               20100     
_________________________________________________________________
dense_46 (Dense)             (None, 50)                5050      
_________________________________________________________________
dense_47 (Dense)             (None, 20)                1020      
_________________________________________________________________
dense_48 (Dense)             (None, 4)                 84        
=================================================================
Total params: 242,364
Trainable params: 242,364
Non-trainable params: 0
_________________________________________________________________
None

Accuracy Train: 90.36%
Accuracy Test: 85.11%
Loss Train: 0.26
Loss Test: 0.58
Numero dati esaminati: 1712
True Positive 1457
False Positive 255
