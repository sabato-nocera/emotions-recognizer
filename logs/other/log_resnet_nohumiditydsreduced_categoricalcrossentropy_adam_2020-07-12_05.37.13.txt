Dataset used: ../../datasets/full_dataset_without_humidity_reduced.csv 

   Temperature  Sound  Heartbeat   X1  ...    Y2     Z2  Classification  Feedback
0           32      1         60 -680  ... -7424 -15596             100     Happy
1           32      1         60 -780  ... -7408 -15628             100     Happy
2           -1      1         60   -1  ... -7276 -15612             100     Happy
3           -1     -1         60   -1  ...    -1     -1             100     Happy
4           32      1         60 -860  ... -7340 -15720             100     Happy

[5 rows x 11 columns]

Objservations: 3760
Reshaping:  ((3008, 10), (3008, 4), (752, 10), (752, 4))  -> ((3008, 10, 1), (3008, 4), (752, 10, 1), (752, 4))

Layers:

{'batch_input_shape': (None, 10, 1), 'dtype': 'float32', 'sparse': False, 'name': 'input_13'} 

{'name': 'conv1d_295', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_229', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_313', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_296', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_230', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_314', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_297', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_231', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_109', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_315', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_298', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_232', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_316', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_299', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_233', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_110', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_317', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_300', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_234', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_318', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_301', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_235', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_111', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_319', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_302', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_236', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_320', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_303', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_304', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_237', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_112', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_321', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_305', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_238', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_322', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_306', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_239', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_113', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_323', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_307', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_240', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_324', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_308', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_241', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_114', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_325', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_309', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_242', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_326', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_310', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_311', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_243', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_115', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_327', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_312', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_244', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_328', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_313', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_245', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_116', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_329', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_314', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_246', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_330', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_315', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_247', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_117', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_331', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'average_pooling1d_13', 'trainable': True, 'dtype': 'float32', 'strides': (1,), 'pool_size': (1,), 'padding': 'valid', 'data_format': 'channels_last'} 

{'name': 'flatten_55', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'} 

{'name': 'dense_1183', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 5s - loss: 1.1773 - accuracy: 0.6546 - val_loss: 2.2755 - val_accuracy: 0.3090
Epoch 2/110
 - 1s - loss: 0.8015 - accuracy: 0.7756 - val_loss: 1.2286 - val_accuracy: 0.5814
Epoch 3/110
 - 1s - loss: 0.7139 - accuracy: 0.7980 - val_loss: 0.9798 - val_accuracy: 0.6977
Epoch 4/110
 - 1s - loss: 0.6595 - accuracy: 0.8084 - val_loss: 0.9033 - val_accuracy: 0.7159
Epoch 5/110
 - 1s - loss: 0.6366 - accuracy: 0.8167 - val_loss: 0.7827 - val_accuracy: 0.7774
Epoch 6/110
 - 1s - loss: 0.6152 - accuracy: 0.8300 - val_loss: 0.6957 - val_accuracy: 0.7774
Epoch 7/110
 - 1s - loss: 0.5879 - accuracy: 0.8379 - val_loss: 0.6832 - val_accuracy: 0.8023
Epoch 8/110
 - 1s - loss: 0.5625 - accuracy: 0.8425 - val_loss: 0.7123 - val_accuracy: 0.7857
Epoch 9/110
 - 1s - loss: 0.5549 - accuracy: 0.8400 - val_loss: 0.7008 - val_accuracy: 0.8056
Epoch 10/110
 - 1s - loss: 0.5630 - accuracy: 0.8354 - val_loss: 0.7107 - val_accuracy: 0.7990
Epoch 11/110
 - 1s - loss: 0.5496 - accuracy: 0.8446 - val_loss: 0.7106 - val_accuracy: 0.7940
Epoch 12/110
 - 1s - loss: 0.5297 - accuracy: 0.8545 - val_loss: 0.6961 - val_accuracy: 0.8106
Epoch 13/110
 - 1s - loss: 0.5125 - accuracy: 0.8525 - val_loss: 0.6985 - val_accuracy: 0.7973
Epoch 14/110
 - 1s - loss: 0.5012 - accuracy: 0.8612 - val_loss: 0.7396 - val_accuracy: 0.8090
Epoch 15/110
 - 1s - loss: 0.5197 - accuracy: 0.8554 - val_loss: 0.7518 - val_accuracy: 0.7924
Epoch 16/110
 - 1s - loss: 0.5145 - accuracy: 0.8549 - val_loss: 0.7417 - val_accuracy: 0.7973
Epoch 17/110
 - 1s - loss: 0.4834 - accuracy: 0.8687 - val_loss: 0.7500 - val_accuracy: 0.7957
Epoch 18/110
 - 1s - loss: 0.4818 - accuracy: 0.8682 - val_loss: 0.7574 - val_accuracy: 0.7957
Epoch 19/110
 - 1s - loss: 0.4740 - accuracy: 0.8757 - val_loss: 0.7757 - val_accuracy: 0.8140
Epoch 20/110
 - 1s - loss: 0.4492 - accuracy: 0.8832 - val_loss: 0.7727 - val_accuracy: 0.8040
Epoch 21/110
 - 1s - loss: 0.4417 - accuracy: 0.8849 - val_loss: 0.7664 - val_accuracy: 0.8156
Epoch 22/110
 - 1s - loss: 0.4829 - accuracy: 0.8691 - val_loss: 0.8552 - val_accuracy: 0.7973
Epoch 23/110
 - 1s - loss: 0.4613 - accuracy: 0.8799 - val_loss: 0.8118 - val_accuracy: 0.8040
Epoch 24/110
 - 1s - loss: 0.4477 - accuracy: 0.8761 - val_loss: 0.7844 - val_accuracy: 0.8007
Epoch 25/110
 - 1s - loss: 0.4419 - accuracy: 0.8849 - val_loss: 0.8012 - val_accuracy: 0.7990
Epoch 26/110
 - 1s - loss: 0.4524 - accuracy: 0.8820 - val_loss: 0.8148 - val_accuracy: 0.7724
Epoch 27/110
 - 1s - loss: 0.4204 - accuracy: 0.8915 - val_loss: 0.8040 - val_accuracy: 0.8056
Epoch 28/110
 - 1s - loss: 0.4494 - accuracy: 0.8849 - val_loss: 0.7369 - val_accuracy: 0.7890
Epoch 29/110
 - 1s - loss: 0.4576 - accuracy: 0.8720 - val_loss: 0.7458 - val_accuracy: 0.7990
Epoch 30/110
 - 1s - loss: 0.4619 - accuracy: 0.8736 - val_loss: 0.7324 - val_accuracy: 0.7990
Epoch 31/110
 - 1s - loss: 0.4428 - accuracy: 0.8853 - val_loss: 0.7885 - val_accuracy: 0.7957
Epoch 32/110
 - 1s - loss: 0.4427 - accuracy: 0.8869 - val_loss: 0.7546 - val_accuracy: 0.7990
Epoch 33/110
 - 1s - loss: 0.4279 - accuracy: 0.8853 - val_loss: 0.8129 - val_accuracy: 0.7558
Epoch 34/110
 - 1s - loss: 0.4360 - accuracy: 0.8824 - val_loss: 0.8290 - val_accuracy: 0.7940
Epoch 35/110
 - 1s - loss: 0.4144 - accuracy: 0.8932 - val_loss: 0.7774 - val_accuracy: 0.8073
Epoch 36/110
 - 1s - loss: 0.4230 - accuracy: 0.8936 - val_loss: 0.7685 - val_accuracy: 0.8040
Epoch 37/110
 - 1s - loss: 0.4061 - accuracy: 0.8998 - val_loss: 0.7857 - val_accuracy: 0.7957
Epoch 38/110
 - 1s - loss: 0.4029 - accuracy: 0.9007 - val_loss: 0.8631 - val_accuracy: 0.7924
Epoch 39/110
 - 1s - loss: 0.3660 - accuracy: 0.9148 - val_loss: 0.7931 - val_accuracy: 0.8023
Epoch 40/110
 - 1s - loss: 0.3832 - accuracy: 0.9106 - val_loss: 0.8417 - val_accuracy: 0.7575
Epoch 41/110
 - 1s - loss: 0.3856 - accuracy: 0.9086 - val_loss: 0.8802 - val_accuracy: 0.7990
Epoch 42/110
 - 1s - loss: 0.3951 - accuracy: 0.9048 - val_loss: 0.8729 - val_accuracy: 0.8007
Epoch 43/110
 - 1s - loss: 0.3728 - accuracy: 0.9115 - val_loss: 0.8642 - val_accuracy: 0.7807
Epoch 44/110
 - 1s - loss: 0.3783 - accuracy: 0.9123 - val_loss: 0.8478 - val_accuracy: 0.7890
Epoch 45/110
 - 1s - loss: 0.3551 - accuracy: 0.9156 - val_loss: 0.8724 - val_accuracy: 0.7774
Epoch 46/110
 - 1s - loss: 0.3650 - accuracy: 0.9086 - val_loss: 0.8600 - val_accuracy: 0.8140
Epoch 47/110
 - 1s - loss: 0.3745 - accuracy: 0.9106 - val_loss: 0.8723 - val_accuracy: 0.7957
Epoch 48/110
 - 1s - loss: 0.3600 - accuracy: 0.9160 - val_loss: 0.8750 - val_accuracy: 0.7940
Epoch 49/110
 - 1s - loss: 0.3609 - accuracy: 0.9185 - val_loss: 0.8701 - val_accuracy: 0.8156
Epoch 50/110
 - 1s - loss: 0.3734 - accuracy: 0.9098 - val_loss: 0.8408 - val_accuracy: 0.8206
Epoch 51/110
 - 1s - loss: 0.3523 - accuracy: 0.9256 - val_loss: 0.8968 - val_accuracy: 0.7857
Epoch 52/110
 - 1s - loss: 0.3427 - accuracy: 0.9252 - val_loss: 0.9073 - val_accuracy: 0.8007
Epoch 53/110
 - 1s - loss: 0.3322 - accuracy: 0.9302 - val_loss: 0.8307 - val_accuracy: 0.8189
Epoch 54/110
 - 1s - loss: 0.3430 - accuracy: 0.9256 - val_loss: 0.8951 - val_accuracy: 0.8007
Epoch 55/110
 - 1s - loss: 0.3237 - accuracy: 0.9310 - val_loss: 0.8440 - val_accuracy: 0.8056
Epoch 56/110
 - 1s - loss: 0.3203 - accuracy: 0.9339 - val_loss: 0.8230 - val_accuracy: 0.7874
Epoch 57/110
 - 1s - loss: 0.3238 - accuracy: 0.9260 - val_loss: 0.8669 - val_accuracy: 0.8189
Epoch 58/110
 - 1s - loss: 0.3271 - accuracy: 0.9331 - val_loss: 0.8535 - val_accuracy: 0.8223
Epoch 59/110
 - 1s - loss: 0.3052 - accuracy: 0.9414 - val_loss: 0.9001 - val_accuracy: 0.7957
Epoch 60/110
 - 1s - loss: 0.3207 - accuracy: 0.9289 - val_loss: 0.8928 - val_accuracy: 0.8090
Epoch 61/110
 - 1s - loss: 0.3229 - accuracy: 0.9323 - val_loss: 0.8779 - val_accuracy: 0.8322
Epoch 62/110
 - 1s - loss: 0.3034 - accuracy: 0.9406 - val_loss: 0.9048 - val_accuracy: 0.8073
Epoch 63/110
 - 1s - loss: 0.3408 - accuracy: 0.9256 - val_loss: 0.9255 - val_accuracy: 0.7874
Epoch 64/110
 - 1s - loss: 0.3617 - accuracy: 0.9160 - val_loss: 0.9669 - val_accuracy: 0.7741
Epoch 65/110
 - 1s - loss: 0.3678 - accuracy: 0.9148 - val_loss: 0.9113 - val_accuracy: 0.7940
Epoch 66/110
 - 1s - loss: 0.3336 - accuracy: 0.9268 - val_loss: 0.9289 - val_accuracy: 0.8123
Epoch 67/110
 - 1s - loss: 0.3170 - accuracy: 0.9347 - val_loss: 0.8561 - val_accuracy: 0.8140
Epoch 68/110
 - 1s - loss: 0.3305 - accuracy: 0.9347 - val_loss: 0.8848 - val_accuracy: 0.8256
Epoch 69/110
 - 1s - loss: 0.3150 - accuracy: 0.9347 - val_loss: 0.9196 - val_accuracy: 0.7708
Epoch 70/110
 - 1s - loss: 0.2895 - accuracy: 0.9468 - val_loss: 0.9773 - val_accuracy: 0.7940
Epoch 71/110
 - 1s - loss: 0.2998 - accuracy: 0.9393 - val_loss: 1.0078 - val_accuracy: 0.7907
Epoch 72/110
 - 1s - loss: 0.3219 - accuracy: 0.9339 - val_loss: 0.9458 - val_accuracy: 0.8056
Epoch 73/110
 - 1s - loss: 0.3397 - accuracy: 0.9293 - val_loss: 0.9058 - val_accuracy: 0.7824
Epoch 74/110
 - 1s - loss: 0.3557 - accuracy: 0.9244 - val_loss: 1.0284 - val_accuracy: 0.7990
Epoch 75/110
 - 1s - loss: 0.3510 - accuracy: 0.9306 - val_loss: 0.8739 - val_accuracy: 0.7940
Epoch 76/110
 - 1s - loss: 0.3183 - accuracy: 0.9331 - val_loss: 0.8663 - val_accuracy: 0.8123
Epoch 77/110
 - 1s - loss: 0.2988 - accuracy: 0.9401 - val_loss: 0.8402 - val_accuracy: 0.8322
Epoch 78/110
 - 1s - loss: 0.2867 - accuracy: 0.9451 - val_loss: 0.9178 - val_accuracy: 0.8156
Epoch 79/110
 - 1s - loss: 0.2848 - accuracy: 0.9468 - val_loss: 0.9404 - val_accuracy: 0.8056
Epoch 80/110
 - 1s - loss: 0.2846 - accuracy: 0.9476 - val_loss: 0.9154 - val_accuracy: 0.8372
Epoch 81/110
 - 1s - loss: 0.2960 - accuracy: 0.9472 - val_loss: 0.8903 - val_accuracy: 0.8106
Epoch 82/110
 - 1s - loss: 0.2903 - accuracy: 0.9422 - val_loss: 0.8206 - val_accuracy: 0.8223
Epoch 83/110
 - 1s - loss: 0.2796 - accuracy: 0.9493 - val_loss: 0.8716 - val_accuracy: 0.8073
Epoch 84/110
 - 1s - loss: 0.2780 - accuracy: 0.9534 - val_loss: 0.8805 - val_accuracy: 0.8123
Epoch 85/110
 - 1s - loss: 0.2752 - accuracy: 0.9505 - val_loss: 0.9469 - val_accuracy: 0.8173
Epoch 86/110
 - 1s - loss: 0.2818 - accuracy: 0.9501 - val_loss: 0.9454 - val_accuracy: 0.8056
Epoch 87/110
 - 1s - loss: 0.2887 - accuracy: 0.9456 - val_loss: 0.8543 - val_accuracy: 0.8239
Epoch 88/110
 - 1s - loss: 0.3155 - accuracy: 0.9393 - val_loss: 0.9255 - val_accuracy: 0.8123
Epoch 89/110
 - 1s - loss: 0.3062 - accuracy: 0.9393 - val_loss: 0.9075 - val_accuracy: 0.8040
Epoch 90/110
 - 1s - loss: 0.3376 - accuracy: 0.9244 - val_loss: 0.9069 - val_accuracy: 0.8189
Epoch 91/110
 - 1s - loss: 0.2981 - accuracy: 0.9422 - val_loss: 0.8603 - val_accuracy: 0.8256
Epoch 92/110
 - 1s - loss: 0.2699 - accuracy: 0.9539 - val_loss: 0.9051 - val_accuracy: 0.8140
Epoch 93/110
 - 1s - loss: 0.2928 - accuracy: 0.9464 - val_loss: 0.9214 - val_accuracy: 0.8140
Epoch 94/110
 - 1s - loss: 0.2891 - accuracy: 0.9464 - val_loss: 0.8850 - val_accuracy: 0.8040
Epoch 95/110
 - 1s - loss: 0.2759 - accuracy: 0.9547 - val_loss: 0.8929 - val_accuracy: 0.8040
Epoch 96/110
 - 1s - loss: 0.2834 - accuracy: 0.9451 - val_loss: 0.9537 - val_accuracy: 0.8189
Epoch 97/110
 - 1s - loss: 0.2756 - accuracy: 0.9501 - val_loss: 0.8328 - val_accuracy: 0.8289
Epoch 98/110
 - 1s - loss: 0.3102 - accuracy: 0.9439 - val_loss: 0.9299 - val_accuracy: 0.8090
Epoch 99/110
 - 1s - loss: 0.2917 - accuracy: 0.9456 - val_loss: 0.9318 - val_accuracy: 0.8189
Epoch 100/110
 - 1s - loss: 0.2943 - accuracy: 0.9476 - val_loss: 0.9104 - val_accuracy: 0.8073
Epoch 101/110
 - 1s - loss: 0.2666 - accuracy: 0.9514 - val_loss: 0.9157 - val_accuracy: 0.8040
Epoch 102/110
 - 1s - loss: 0.2665 - accuracy: 0.9559 - val_loss: 0.9972 - val_accuracy: 0.7990
Epoch 103/110
 - 1s - loss: 0.2667 - accuracy: 0.9547 - val_loss: 0.9842 - val_accuracy: 0.8040
Epoch 104/110
 - 1s - loss: 0.2768 - accuracy: 0.9485 - val_loss: 1.0185 - val_accuracy: 0.8189
Epoch 105/110
 - 1s - loss: 0.2824 - accuracy: 0.9518 - val_loss: 0.8566 - val_accuracy: 0.8156
Epoch 106/110
 - 1s - loss: 0.2623 - accuracy: 0.9547 - val_loss: 0.9912 - val_accuracy: 0.7907
Epoch 107/110
 - 1s - loss: 0.2596 - accuracy: 0.9597 - val_loss: 0.8639 - val_accuracy: 0.8339
Epoch 108/110
 - 1s - loss: 0.2446 - accuracy: 0.9655 - val_loss: 0.9735 - val_accuracy: 0.8073
Epoch 109/110
 - 1s - loss: 0.2414 - accuracy: 0.9647 - val_loss: 0.9182 - val_accuracy: 0.8522
Epoch 110/110
 - 1s - loss: 0.2627 - accuracy: 0.9622 - val_loss: 0.9574 - val_accuracy: 0.8223

Number of filters: 16 , Kernel Size: 3 , Strides: 1 Batch Normalization: True , Conv_First: True , Depth Value: 20

Fit: epochs= 110 , batch_size= 64 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "model_13"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 10, 1)        0                                            
__________________________________________________________________________________________________
conv1d_295 (Conv1D)             (None, 10, 16)       64          input_13[0][0]                   
__________________________________________________________________________________________________
batch_normalization_229 (BatchN (None, 10, 16)       64          conv1d_295[0][0]                 
__________________________________________________________________________________________________
activation_313 (Activation)     (None, 10, 16)       0           batch_normalization_229[0][0]    
__________________________________________________________________________________________________
conv1d_296 (Conv1D)             (None, 10, 16)       784         activation_313[0][0]             
__________________________________________________________________________________________________
batch_normalization_230 (BatchN (None, 10, 16)       64          conv1d_296[0][0]                 
__________________________________________________________________________________________________
activation_314 (Activation)     (None, 10, 16)       0           batch_normalization_230[0][0]    
__________________________________________________________________________________________________
conv1d_297 (Conv1D)             (None, 10, 16)       784         activation_314[0][0]             
__________________________________________________________________________________________________
batch_normalization_231 (BatchN (None, 10, 16)       64          conv1d_297[0][0]                 
__________________________________________________________________________________________________
add_109 (Add)                   (None, 10, 16)       0           activation_313[0][0]             
                                                                 batch_normalization_231[0][0]    
__________________________________________________________________________________________________
activation_315 (Activation)     (None, 10, 16)       0           add_109[0][0]                    
__________________________________________________________________________________________________
conv1d_298 (Conv1D)             (None, 10, 16)       784         activation_315[0][0]             
__________________________________________________________________________________________________
batch_normalization_232 (BatchN (None, 10, 16)       64          conv1d_298[0][0]                 
__________________________________________________________________________________________________
activation_316 (Activation)     (None, 10, 16)       0           batch_normalization_232[0][0]    
__________________________________________________________________________________________________
conv1d_299 (Conv1D)             (None, 10, 16)       784         activation_316[0][0]             
__________________________________________________________________________________________________
batch_normalization_233 (BatchN (None, 10, 16)       64          conv1d_299[0][0]                 
__________________________________________________________________________________________________
add_110 (Add)                   (None, 10, 16)       0           activation_315[0][0]             
                                                                 batch_normalization_233[0][0]    
__________________________________________________________________________________________________
activation_317 (Activation)     (None, 10, 16)       0           add_110[0][0]                    
__________________________________________________________________________________________________
conv1d_300 (Conv1D)             (None, 10, 16)       784         activation_317[0][0]             
__________________________________________________________________________________________________
batch_normalization_234 (BatchN (None, 10, 16)       64          conv1d_300[0][0]                 
__________________________________________________________________________________________________
activation_318 (Activation)     (None, 10, 16)       0           batch_normalization_234[0][0]    
__________________________________________________________________________________________________
conv1d_301 (Conv1D)             (None, 10, 16)       784         activation_318[0][0]             
__________________________________________________________________________________________________
batch_normalization_235 (BatchN (None, 10, 16)       64          conv1d_301[0][0]                 
__________________________________________________________________________________________________
add_111 (Add)                   (None, 10, 16)       0           activation_317[0][0]             
                                                                 batch_normalization_235[0][0]    
__________________________________________________________________________________________________
activation_319 (Activation)     (None, 10, 16)       0           add_111[0][0]                    
__________________________________________________________________________________________________
conv1d_302 (Conv1D)             (None, 5, 32)        1568        activation_319[0][0]             
__________________________________________________________________________________________________
batch_normalization_236 (BatchN (None, 5, 32)        128         conv1d_302[0][0]                 
__________________________________________________________________________________________________
activation_320 (Activation)     (None, 5, 32)        0           batch_normalization_236[0][0]    
__________________________________________________________________________________________________
conv1d_303 (Conv1D)             (None, 5, 32)        3104        activation_320[0][0]             
__________________________________________________________________________________________________
conv1d_304 (Conv1D)             (None, 5, 32)        544         activation_319[0][0]             
__________________________________________________________________________________________________
batch_normalization_237 (BatchN (None, 5, 32)        128         conv1d_303[0][0]                 
__________________________________________________________________________________________________
add_112 (Add)                   (None, 5, 32)        0           conv1d_304[0][0]                 
                                                                 batch_normalization_237[0][0]    
__________________________________________________________________________________________________
activation_321 (Activation)     (None, 5, 32)        0           add_112[0][0]                    
__________________________________________________________________________________________________
conv1d_305 (Conv1D)             (None, 5, 32)        3104        activation_321[0][0]             
__________________________________________________________________________________________________
batch_normalization_238 (BatchN (None, 5, 32)        128         conv1d_305[0][0]                 
__________________________________________________________________________________________________
activation_322 (Activation)     (None, 5, 32)        0           batch_normalization_238[0][0]    
__________________________________________________________________________________________________
conv1d_306 (Conv1D)             (None, 5, 32)        3104        activation_322[0][0]             
__________________________________________________________________________________________________
batch_normalization_239 (BatchN (None, 5, 32)        128         conv1d_306[0][0]                 
__________________________________________________________________________________________________
add_113 (Add)                   (None, 5, 32)        0           activation_321[0][0]             
                                                                 batch_normalization_239[0][0]    
__________________________________________________________________________________________________
activation_323 (Activation)     (None, 5, 32)        0           add_113[0][0]                    
__________________________________________________________________________________________________
conv1d_307 (Conv1D)             (None, 5, 32)        3104        activation_323[0][0]             
__________________________________________________________________________________________________
batch_normalization_240 (BatchN (None, 5, 32)        128         conv1d_307[0][0]                 
__________________________________________________________________________________________________
activation_324 (Activation)     (None, 5, 32)        0           batch_normalization_240[0][0]    
__________________________________________________________________________________________________
conv1d_308 (Conv1D)             (None, 5, 32)        3104        activation_324[0][0]             
__________________________________________________________________________________________________
batch_normalization_241 (BatchN (None, 5, 32)        128         conv1d_308[0][0]                 
__________________________________________________________________________________________________
add_114 (Add)                   (None, 5, 32)        0           activation_323[0][0]             
                                                                 batch_normalization_241[0][0]    
__________________________________________________________________________________________________
activation_325 (Activation)     (None, 5, 32)        0           add_114[0][0]                    
__________________________________________________________________________________________________
conv1d_309 (Conv1D)             (None, 3, 64)        6208        activation_325[0][0]             
__________________________________________________________________________________________________
batch_normalization_242 (BatchN (None, 3, 64)        256         conv1d_309[0][0]                 
__________________________________________________________________________________________________
activation_326 (Activation)     (None, 3, 64)        0           batch_normalization_242[0][0]    
__________________________________________________________________________________________________
conv1d_310 (Conv1D)             (None, 3, 64)        12352       activation_326[0][0]             
__________________________________________________________________________________________________
conv1d_311 (Conv1D)             (None, 3, 64)        2112        activation_325[0][0]             
__________________________________________________________________________________________________
batch_normalization_243 (BatchN (None, 3, 64)        256         conv1d_310[0][0]                 
__________________________________________________________________________________________________
add_115 (Add)                   (None, 3, 64)        0           conv1d_311[0][0]                 
                                                                 batch_normalization_243[0][0]    
__________________________________________________________________________________________________
activation_327 (Activation)     (None, 3, 64)        0           add_115[0][0]                    
__________________________________________________________________________________________________
conv1d_312 (Conv1D)             (None, 3, 64)        12352       activation_327[0][0]             
__________________________________________________________________________________________________
batch_normalization_244 (BatchN (None, 3, 64)        256         conv1d_312[0][0]                 
__________________________________________________________________________________________________
activation_328 (Activation)     (None, 3, 64)        0           batch_normalization_244[0][0]    
__________________________________________________________________________________________________
conv1d_313 (Conv1D)             (None, 3, 64)        12352       activation_328[0][0]             
__________________________________________________________________________________________________
batch_normalization_245 (BatchN (None, 3, 64)        256         conv1d_313[0][0]                 
__________________________________________________________________________________________________
add_116 (Add)                   (None, 3, 64)        0           activation_327[0][0]             
                                                                 batch_normalization_245[0][0]    
__________________________________________________________________________________________________
activation_329 (Activation)     (None, 3, 64)        0           add_116[0][0]                    
__________________________________________________________________________________________________
conv1d_314 (Conv1D)             (None, 3, 64)        12352       activation_329[0][0]             
__________________________________________________________________________________________________
batch_normalization_246 (BatchN (None, 3, 64)        256         conv1d_314[0][0]                 
__________________________________________________________________________________________________
activation_330 (Activation)     (None, 3, 64)        0           batch_normalization_246[0][0]    
__________________________________________________________________________________________________
conv1d_315 (Conv1D)             (None, 3, 64)        12352       activation_330[0][0]             
__________________________________________________________________________________________________
batch_normalization_247 (BatchN (None, 3, 64)        256         conv1d_315[0][0]                 
__________________________________________________________________________________________________
add_117 (Add)                   (None, 3, 64)        0           activation_329[0][0]             
                                                                 batch_normalization_247[0][0]    
__________________________________________________________________________________________________
activation_331 (Activation)     (None, 3, 64)        0           add_117[0][0]                    
__________________________________________________________________________________________________
average_pooling1d_13 (AveragePo (None, 3, 64)        0           activation_331[0][0]             
__________________________________________________________________________________________________
flatten_55 (Flatten)            (None, 192)          0           average_pooling1d_13[0][0]       
__________________________________________________________________________________________________
dense_1183 (Dense)              (None, 4)            772         flatten_55[0][0]                 
==================================================================================================
Total params: 96,004
Trainable params: 94,628
Non-trainable params: 1,376
__________________________________________________________________________________________________
None

Accuracy Train: 85.70%
Accuracy Test: 78.72%
Loss Train: 0.67
Loss Test: 1.08
Numero dati esaminati: 752
True Positive 592
False Positive 160


------------------------------------------------------------------------
K-fold Cross Validation
------------------------------------------------------------------------
Training for fold 1 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 1s - loss: 0.2641 - accuracy: 0.9605 - val_loss: 0.9041 - val_accuracy: 0.8223
Epoch 2/110
 - 1s - loss: 0.2670 - accuracy: 0.9576 - val_loss: 0.9624 - val_accuracy: 0.8206
Epoch 3/110
 - 1s - loss: 0.2777 - accuracy: 0.9489 - val_loss: 0.8646 - val_accuracy: 0.8272
Epoch 4/110
 - 1s - loss: 0.2458 - accuracy: 0.9613 - val_loss: 0.9005 - val_accuracy: 0.8422
Epoch 5/110
 - 1s - loss: 0.2412 - accuracy: 0.9659 - val_loss: 0.9425 - val_accuracy: 0.8289
Epoch 6/110
 - 1s - loss: 0.2440 - accuracy: 0.9622 - val_loss: 1.0781 - val_accuracy: 0.8206
Epoch 7/110
 - 1s - loss: 0.2505 - accuracy: 0.9551 - val_loss: 0.9125 - val_accuracy: 0.8023
Epoch 8/110
 - 1s - loss: 0.2501 - accuracy: 0.9609 - val_loss: 0.9085 - val_accuracy: 0.8339
Epoch 9/110
 - 1s - loss: 0.3010 - accuracy: 0.9505 - val_loss: 0.9929 - val_accuracy: 0.8007
Epoch 10/110
 - 1s - loss: 0.2666 - accuracy: 0.9572 - val_loss: 0.9156 - val_accuracy: 0.8306
Epoch 11/110
 - 1s - loss: 0.2753 - accuracy: 0.9568 - val_loss: 0.9275 - val_accuracy: 0.8339
Epoch 12/110
 - 1s - loss: 0.2868 - accuracy: 0.9460 - val_loss: 0.9737 - val_accuracy: 0.8073
Epoch 13/110
 - 1s - loss: 0.2716 - accuracy: 0.9518 - val_loss: 0.8763 - val_accuracy: 0.8173
Epoch 14/110
 - 1s - loss: 0.2582 - accuracy: 0.9551 - val_loss: 0.8668 - val_accuracy: 0.8306
Epoch 15/110
 - 1s - loss: 0.2524 - accuracy: 0.9626 - val_loss: 0.8286 - val_accuracy: 0.8405
Epoch 16/110
 - 1s - loss: 0.2244 - accuracy: 0.9734 - val_loss: 0.8588 - val_accuracy: 0.8505
Epoch 17/110
 - 1s - loss: 0.2355 - accuracy: 0.9655 - val_loss: 0.9143 - val_accuracy: 0.8206
Epoch 18/110
 - 1s - loss: 0.2319 - accuracy: 0.9676 - val_loss: 0.9732 - val_accuracy: 0.8339
Epoch 19/110
 - 1s - loss: 0.2520 - accuracy: 0.9613 - val_loss: 0.9274 - val_accuracy: 0.8289
Epoch 20/110
 - 1s - loss: 0.2551 - accuracy: 0.9605 - val_loss: 1.0383 - val_accuracy: 0.7973
Epoch 21/110
 - 1s - loss: 0.2306 - accuracy: 0.9692 - val_loss: 0.9259 - val_accuracy: 0.8355
Epoch 22/110
 - 1s - loss: 0.2354 - accuracy: 0.9655 - val_loss: 0.8314 - val_accuracy: 0.8256
Epoch 23/110
 - 1s - loss: 0.2504 - accuracy: 0.9643 - val_loss: 1.0280 - val_accuracy: 0.7940
Epoch 24/110
 - 1s - loss: 0.2665 - accuracy: 0.9601 - val_loss: 0.9753 - val_accuracy: 0.8040
Epoch 25/110
 - 1s - loss: 0.2390 - accuracy: 0.9634 - val_loss: 0.9038 - val_accuracy: 0.8372
Epoch 26/110
 - 1s - loss: 0.2278 - accuracy: 0.9663 - val_loss: 0.9032 - val_accuracy: 0.8339
Epoch 27/110
 - 1s - loss: 0.2353 - accuracy: 0.9672 - val_loss: 0.9964 - val_accuracy: 0.8355
Epoch 28/110
 - 1s - loss: 0.2225 - accuracy: 0.9705 - val_loss: 0.9157 - val_accuracy: 0.8372
Epoch 29/110
 - 1s - loss: 0.2362 - accuracy: 0.9609 - val_loss: 0.9682 - val_accuracy: 0.8256
Epoch 30/110
 - 1s - loss: 0.2679 - accuracy: 0.9580 - val_loss: 0.9531 - val_accuracy: 0.8106
Epoch 31/110
 - 1s - loss: 0.2570 - accuracy: 0.9613 - val_loss: 0.9499 - val_accuracy: 0.8272
Epoch 32/110
 - 1s - loss: 0.2333 - accuracy: 0.9659 - val_loss: 0.9459 - val_accuracy: 0.8256
Epoch 33/110
 - 1s - loss: 0.2325 - accuracy: 0.9676 - val_loss: 0.9756 - val_accuracy: 0.8140
Epoch 34/110
 - 1s - loss: 0.2522 - accuracy: 0.9601 - val_loss: 0.9864 - val_accuracy: 0.8156
Epoch 35/110
 - 1s - loss: 0.2510 - accuracy: 0.9593 - val_loss: 0.8974 - val_accuracy: 0.8372
Epoch 36/110
 - 1s - loss: 0.2140 - accuracy: 0.9709 - val_loss: 0.9847 - val_accuracy: 0.8239
Epoch 37/110
 - 1s - loss: 0.2336 - accuracy: 0.9676 - val_loss: 1.0306 - val_accuracy: 0.8040
Epoch 38/110
 - 1s - loss: 0.2321 - accuracy: 0.9647 - val_loss: 1.0377 - val_accuracy: 0.8256
Epoch 39/110
 - 1s - loss: 0.2729 - accuracy: 0.9522 - val_loss: 0.8951 - val_accuracy: 0.8173
Epoch 40/110
 - 1s - loss: 0.2630 - accuracy: 0.9589 - val_loss: 1.0602 - val_accuracy: 0.8073
Epoch 41/110
 - 1s - loss: 0.2684 - accuracy: 0.9597 - val_loss: 0.9545 - val_accuracy: 0.8123
Epoch 42/110
 - 1s - loss: 0.2525 - accuracy: 0.9622 - val_loss: 0.9854 - val_accuracy: 0.8073
Epoch 43/110
 - 1s - loss: 0.2225 - accuracy: 0.9663 - val_loss: 1.1048 - val_accuracy: 0.8040
Epoch 44/110
 - 1s - loss: 0.2536 - accuracy: 0.9613 - val_loss: 1.1470 - val_accuracy: 0.8040
Epoch 45/110
 - 1s - loss: 0.2624 - accuracy: 0.9584 - val_loss: 1.0380 - val_accuracy: 0.8090
Epoch 46/110
 - 1s - loss: 0.2223 - accuracy: 0.9692 - val_loss: 1.0592 - val_accuracy: 0.8272
Epoch 47/110
 - 1s - loss: 0.2197 - accuracy: 0.9713 - val_loss: 1.0369 - val_accuracy: 0.8140
Epoch 48/110
 - 1s - loss: 0.2328 - accuracy: 0.9667 - val_loss: 1.1315 - val_accuracy: 0.8023
Epoch 49/110
 - 1s - loss: 0.2312 - accuracy: 0.9647 - val_loss: 1.0062 - val_accuracy: 0.8173
Epoch 50/110
 - 1s - loss: 0.2275 - accuracy: 0.9667 - val_loss: 0.9707 - val_accuracy: 0.8256
Epoch 51/110
 - 1s - loss: 0.2834 - accuracy: 0.9522 - val_loss: 0.9907 - val_accuracy: 0.7907
Epoch 52/110
 - 1s - loss: 0.2617 - accuracy: 0.9576 - val_loss: 1.0364 - val_accuracy: 0.8040
Epoch 53/110
 - 1s - loss: 0.2289 - accuracy: 0.9626 - val_loss: 1.0041 - val_accuracy: 0.8322
Epoch 54/110
 - 1s - loss: 0.2284 - accuracy: 0.9634 - val_loss: 1.0503 - val_accuracy: 0.8056
Epoch 55/110
 - 1s - loss: 0.2469 - accuracy: 0.9634 - val_loss: 1.0133 - val_accuracy: 0.8023
Epoch 56/110
 - 1s - loss: 0.2337 - accuracy: 0.9705 - val_loss: 0.9777 - val_accuracy: 0.8289
Epoch 57/110
 - 1s - loss: 0.2123 - accuracy: 0.9734 - val_loss: 0.9889 - val_accuracy: 0.8306
Epoch 58/110
 - 1s - loss: 0.2126 - accuracy: 0.9776 - val_loss: 0.9419 - val_accuracy: 0.8272
Epoch 59/110
 - 1s - loss: 0.2223 - accuracy: 0.9692 - val_loss: 1.0417 - val_accuracy: 0.8206
Epoch 60/110
 - 1s - loss: 0.2185 - accuracy: 0.9726 - val_loss: 1.0649 - val_accuracy: 0.8023
Epoch 61/110
 - 1s - loss: 0.2090 - accuracy: 0.9759 - val_loss: 1.0012 - val_accuracy: 0.8106
Epoch 62/110
 - 1s - loss: 0.2063 - accuracy: 0.9792 - val_loss: 1.0007 - val_accuracy: 0.8173
Epoch 63/110
 - 1s - loss: 0.2209 - accuracy: 0.9722 - val_loss: 0.9983 - val_accuracy: 0.8405
Epoch 64/110
 - 1s - loss: 0.2210 - accuracy: 0.9697 - val_loss: 0.9829 - val_accuracy: 0.8272
Epoch 65/110
 - 1s - loss: 0.2159 - accuracy: 0.9713 - val_loss: 0.9749 - val_accuracy: 0.8239
Epoch 66/110
 - 1s - loss: 0.2338 - accuracy: 0.9672 - val_loss: 1.0137 - val_accuracy: 0.8223
Epoch 67/110
 - 1s - loss: 0.2627 - accuracy: 0.9576 - val_loss: 0.9287 - val_accuracy: 0.7924
Epoch 68/110
 - 1s - loss: 0.2434 - accuracy: 0.9618 - val_loss: 1.1069 - val_accuracy: 0.7791
Epoch 69/110
 - 1s - loss: 0.2414 - accuracy: 0.9659 - val_loss: 0.9469 - val_accuracy: 0.8306
Epoch 70/110
 - 1s - loss: 0.2186 - accuracy: 0.9667 - val_loss: 0.8349 - val_accuracy: 0.8123
Epoch 71/110
 - 1s - loss: 0.2139 - accuracy: 0.9692 - val_loss: 1.0090 - val_accuracy: 0.8223
Epoch 72/110
 - 1s - loss: 0.2052 - accuracy: 0.9759 - val_loss: 0.9925 - val_accuracy: 0.8256
Epoch 73/110
 - 1s - loss: 0.2106 - accuracy: 0.9730 - val_loss: 0.9914 - val_accuracy: 0.8322
Epoch 74/110
 - 1s - loss: 0.2201 - accuracy: 0.9697 - val_loss: 0.9900 - val_accuracy: 0.8223
Epoch 75/110
 - 1s - loss: 0.2233 - accuracy: 0.9655 - val_loss: 0.9766 - val_accuracy: 0.8289
Epoch 76/110
 - 1s - loss: 0.2440 - accuracy: 0.9593 - val_loss: 1.0185 - val_accuracy: 0.8256
Epoch 77/110
 - 1s - loss: 0.2555 - accuracy: 0.9589 - val_loss: 1.2325 - val_accuracy: 0.7957
Epoch 78/110
 - 1s - loss: 0.2465 - accuracy: 0.9622 - val_loss: 0.9770 - val_accuracy: 0.8306
Epoch 79/110
 - 1s - loss: 0.2336 - accuracy: 0.9655 - val_loss: 1.0854 - val_accuracy: 0.7957
Epoch 80/110
 - 1s - loss: 0.2311 - accuracy: 0.9651 - val_loss: 1.0721 - val_accuracy: 0.8239
Epoch 81/110
 - 1s - loss: 0.2443 - accuracy: 0.9618 - val_loss: 1.0357 - val_accuracy: 0.8140
Epoch 82/110
 - 1s - loss: 0.2045 - accuracy: 0.9726 - val_loss: 1.1228 - val_accuracy: 0.8123
Epoch 83/110
 - 1s - loss: 0.2127 - accuracy: 0.9746 - val_loss: 0.9804 - val_accuracy: 0.8455
Epoch 84/110
 - 1s - loss: 0.1917 - accuracy: 0.9771 - val_loss: 0.9835 - val_accuracy: 0.8522
Epoch 85/110
 - 1s - loss: 0.2039 - accuracy: 0.9755 - val_loss: 0.9753 - val_accuracy: 0.8339
Epoch 86/110
 - 1s - loss: 0.2223 - accuracy: 0.9751 - val_loss: 0.9604 - val_accuracy: 0.8272
Epoch 87/110
 - 1s - loss: 0.2119 - accuracy: 0.9726 - val_loss: 1.0401 - val_accuracy: 0.8322
Epoch 88/110
 - 1s - loss: 0.1982 - accuracy: 0.9780 - val_loss: 1.0381 - val_accuracy: 0.8173
Epoch 89/110
 - 1s - loss: 0.1954 - accuracy: 0.9767 - val_loss: 1.0616 - val_accuracy: 0.8239
Epoch 90/110
 - 1s - loss: 0.2010 - accuracy: 0.9763 - val_loss: 1.0894 - val_accuracy: 0.7940
Epoch 91/110
 - 1s - loss: 0.2125 - accuracy: 0.9742 - val_loss: 1.0302 - val_accuracy: 0.8439
Epoch 92/110
 - 1s - loss: 0.2176 - accuracy: 0.9697 - val_loss: 1.0247 - val_accuracy: 0.8189
Epoch 93/110
 - 1s - loss: 0.1985 - accuracy: 0.9759 - val_loss: 0.9979 - val_accuracy: 0.8355
Epoch 94/110
 - 1s - loss: 0.1909 - accuracy: 0.9800 - val_loss: 0.9965 - val_accuracy: 0.8322
Epoch 95/110
 - 1s - loss: 0.2037 - accuracy: 0.9751 - val_loss: 1.0296 - val_accuracy: 0.8455
Epoch 96/110
 - 1s - loss: 0.2109 - accuracy: 0.9709 - val_loss: 1.0203 - val_accuracy: 0.8272
Epoch 97/110
 - 1s - loss: 0.2263 - accuracy: 0.9722 - val_loss: 1.0398 - val_accuracy: 0.8422
Epoch 98/110
 - 1s - loss: 0.2094 - accuracy: 0.9746 - val_loss: 0.9750 - val_accuracy: 0.8189
Epoch 99/110
 - 1s - loss: 0.2103 - accuracy: 0.9684 - val_loss: 1.0345 - val_accuracy: 0.8256
Epoch 100/110
 - 1s - loss: 0.2434 - accuracy: 0.9634 - val_loss: 1.0695 - val_accuracy: 0.8156
Epoch 101/110
 - 1s - loss: 0.2312 - accuracy: 0.9647 - val_loss: 0.9687 - val_accuracy: 0.8272
Epoch 102/110
 - 1s - loss: 0.2365 - accuracy: 0.9618 - val_loss: 0.9197 - val_accuracy: 0.8239
Epoch 103/110
 - 1s - loss: 0.2501 - accuracy: 0.9651 - val_loss: 1.0773 - val_accuracy: 0.8073
Epoch 104/110
 - 1s - loss: 0.2559 - accuracy: 0.9618 - val_loss: 0.8893 - val_accuracy: 0.8239
Epoch 105/110
 - 1s - loss: 0.2029 - accuracy: 0.9717 - val_loss: 0.9274 - val_accuracy: 0.8372
Epoch 106/110
 - 1s - loss: 0.1852 - accuracy: 0.9825 - val_loss: 0.9188 - val_accuracy: 0.8405
Epoch 107/110
 - 1s - loss: 0.1864 - accuracy: 0.9821 - val_loss: 1.0805 - val_accuracy: 0.8206
Epoch 108/110
 - 1s - loss: 0.1857 - accuracy: 0.9796 - val_loss: 0.9828 - val_accuracy: 0.8206
Epoch 109/110
 - 1s - loss: 0.1878 - accuracy: 0.9788 - val_loss: 1.0477 - val_accuracy: 0.8156
Epoch 110/110
 - 1s - loss: 0.2083 - accuracy: 0.9759 - val_loss: 1.0070 - val_accuracy: 0.8256
------------------------------------------------------------------------
Training for fold 2 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 1s - loss: 0.1965 - accuracy: 0.9746 - val_loss: 0.9790 - val_accuracy: 0.8372
Epoch 2/110
 - 1s - loss: 0.2071 - accuracy: 0.9726 - val_loss: 1.1645 - val_accuracy: 0.8056
Epoch 3/110
 - 1s - loss: 0.2452 - accuracy: 0.9597 - val_loss: 0.9472 - val_accuracy: 0.8239
Epoch 4/110
 - 1s - loss: 0.2374 - accuracy: 0.9651 - val_loss: 0.9826 - val_accuracy: 0.8256
Epoch 5/110
 - 1s - loss: 0.1969 - accuracy: 0.9788 - val_loss: 1.0177 - val_accuracy: 0.8256
Epoch 6/110
 - 1s - loss: 0.1969 - accuracy: 0.9805 - val_loss: 0.9877 - val_accuracy: 0.8389
Epoch 7/110
 - 1s - loss: 0.2096 - accuracy: 0.9709 - val_loss: 1.0420 - val_accuracy: 0.8173
Epoch 8/110
 - 1s - loss: 0.2430 - accuracy: 0.9576 - val_loss: 0.9977 - val_accuracy: 0.8272
Epoch 9/110
 - 1s - loss: 0.2786 - accuracy: 0.9518 - val_loss: 0.9842 - val_accuracy: 0.8123
Epoch 10/110
 - 1s - loss: 0.2421 - accuracy: 0.9584 - val_loss: 0.9313 - val_accuracy: 0.8289
Epoch 11/110
 - 1s - loss: 0.2484 - accuracy: 0.9605 - val_loss: 0.9594 - val_accuracy: 0.8389
Epoch 12/110
 - 1s - loss: 0.1967 - accuracy: 0.9771 - val_loss: 1.0446 - val_accuracy: 0.8123
Epoch 13/110
 - 1s - loss: 0.2136 - accuracy: 0.9692 - val_loss: 1.0109 - val_accuracy: 0.8322
Epoch 14/110
 - 1s - loss: 0.2196 - accuracy: 0.9688 - val_loss: 1.1032 - val_accuracy: 0.8256
Epoch 15/110
 - 1s - loss: 0.2038 - accuracy: 0.9734 - val_loss: 1.0522 - val_accuracy: 0.8040
Epoch 16/110
 - 1s - loss: 0.2096 - accuracy: 0.9697 - val_loss: 1.0334 - val_accuracy: 0.8156
Epoch 17/110
 - 1s - loss: 0.2049 - accuracy: 0.9784 - val_loss: 1.0934 - val_accuracy: 0.8256
Epoch 18/110
 - 1s - loss: 0.2219 - accuracy: 0.9659 - val_loss: 1.0722 - val_accuracy: 0.8256
Epoch 19/110
 - 1s - loss: 0.1992 - accuracy: 0.9746 - val_loss: 1.0248 - val_accuracy: 0.8488
Epoch 20/110
 - 1s - loss: 0.1876 - accuracy: 0.9792 - val_loss: 0.9735 - val_accuracy: 0.8339
Epoch 21/110
 - 1s - loss: 0.1817 - accuracy: 0.9813 - val_loss: 1.0459 - val_accuracy: 0.8322
Epoch 22/110
 - 1s - loss: 0.1841 - accuracy: 0.9834 - val_loss: 1.0693 - val_accuracy: 0.8405
Epoch 23/110
 - 1s - loss: 0.1867 - accuracy: 0.9796 - val_loss: 0.9478 - val_accuracy: 0.8322
Epoch 24/110
 - 1s - loss: 0.1879 - accuracy: 0.9817 - val_loss: 0.9986 - val_accuracy: 0.8339
Epoch 25/110
 - 1s - loss: 0.1821 - accuracy: 0.9834 - val_loss: 0.9966 - val_accuracy: 0.8355
Epoch 26/110
 - 1s - loss: 0.1796 - accuracy: 0.9809 - val_loss: 0.9764 - val_accuracy: 0.8405
Epoch 27/110
 - 1s - loss: 0.1837 - accuracy: 0.9809 - val_loss: 0.9693 - val_accuracy: 0.8405
Epoch 28/110
 - 1s - loss: 0.2061 - accuracy: 0.9726 - val_loss: 1.0062 - val_accuracy: 0.8256
Epoch 29/110
 - 1s - loss: 0.1815 - accuracy: 0.9821 - val_loss: 0.9469 - val_accuracy: 0.8522
Epoch 30/110
 - 1s - loss: 0.1720 - accuracy: 0.9821 - val_loss: 0.9792 - val_accuracy: 0.8422
Epoch 31/110
 - 1s - loss: 0.1833 - accuracy: 0.9796 - val_loss: 0.9910 - val_accuracy: 0.8439
Epoch 32/110
 - 1s - loss: 0.1772 - accuracy: 0.9817 - val_loss: 1.0044 - val_accuracy: 0.8355
Epoch 33/110
 - 1s - loss: 0.1858 - accuracy: 0.9780 - val_loss: 1.0232 - val_accuracy: 0.8389
Epoch 34/110
 - 1s - loss: 0.1944 - accuracy: 0.9776 - val_loss: 1.0300 - val_accuracy: 0.8289
Epoch 35/110
 - 1s - loss: 0.1915 - accuracy: 0.9771 - val_loss: 1.1082 - val_accuracy: 0.8023
Epoch 36/110
 - 1s - loss: 0.1956 - accuracy: 0.9734 - val_loss: 0.9923 - val_accuracy: 0.8355
Epoch 37/110
 - 1s - loss: 0.2117 - accuracy: 0.9688 - val_loss: 1.0789 - val_accuracy: 0.8173
Epoch 38/110
 - 1s - loss: 0.2352 - accuracy: 0.9609 - val_loss: 0.9597 - val_accuracy: 0.8056
Epoch 39/110
 - 1s - loss: 0.2480 - accuracy: 0.9601 - val_loss: 1.0299 - val_accuracy: 0.8106
Epoch 40/110
 - 1s - loss: 0.2161 - accuracy: 0.9726 - val_loss: 0.9957 - val_accuracy: 0.8289
Epoch 41/110
 - 1s - loss: 0.2120 - accuracy: 0.9717 - val_loss: 1.0696 - val_accuracy: 0.8322
Epoch 42/110
 - 1s - loss: 0.2246 - accuracy: 0.9734 - val_loss: 0.9513 - val_accuracy: 0.7990
Epoch 43/110
 - 1s - loss: 0.2393 - accuracy: 0.9613 - val_loss: 0.9884 - val_accuracy: 0.8156
Epoch 44/110
 - 1s - loss: 0.2334 - accuracy: 0.9692 - val_loss: 0.9198 - val_accuracy: 0.8355
Epoch 45/110
 - 1s - loss: 0.2112 - accuracy: 0.9680 - val_loss: 0.9059 - val_accuracy: 0.8272
Epoch 46/110
 - 1s - loss: 0.2012 - accuracy: 0.9751 - val_loss: 0.9304 - val_accuracy: 0.8372
Epoch 47/110
 - 1s - loss: 0.1900 - accuracy: 0.9763 - val_loss: 0.9662 - val_accuracy: 0.8223
Epoch 48/110
 - 1s - loss: 0.2068 - accuracy: 0.9726 - val_loss: 0.9462 - val_accuracy: 0.8322
Epoch 49/110
 - 1s - loss: 0.2201 - accuracy: 0.9717 - val_loss: 0.8074 - val_accuracy: 0.8289
Epoch 50/110
 - 1s - loss: 0.2048 - accuracy: 0.9738 - val_loss: 0.9472 - val_accuracy: 0.8355
Epoch 51/110
 - 1s - loss: 0.2055 - accuracy: 0.9734 - val_loss: 0.9305 - val_accuracy: 0.8355
Epoch 52/110
 - 1s - loss: 0.2041 - accuracy: 0.9726 - val_loss: 1.1242 - val_accuracy: 0.8239
Epoch 53/110
 - 1s - loss: 0.2280 - accuracy: 0.9643 - val_loss: 1.0857 - val_accuracy: 0.8090
Epoch 54/110
 - 1s - loss: 0.1986 - accuracy: 0.9705 - val_loss: 0.9680 - val_accuracy: 0.8355
Epoch 55/110
 - 1s - loss: 0.2137 - accuracy: 0.9709 - val_loss: 1.0166 - val_accuracy: 0.8289
Epoch 56/110
 - 1s - loss: 0.2235 - accuracy: 0.9713 - val_loss: 1.0857 - val_accuracy: 0.7890
Epoch 57/110
 - 1s - loss: 0.1989 - accuracy: 0.9722 - val_loss: 0.9632 - val_accuracy: 0.8256
Epoch 58/110
 - 1s - loss: 0.1793 - accuracy: 0.9817 - val_loss: 0.9212 - val_accuracy: 0.8505
Epoch 59/110
 - 1s - loss: 0.1610 - accuracy: 0.9892 - val_loss: 0.9809 - val_accuracy: 0.8422
Epoch 60/110
 - 1s - loss: 0.1627 - accuracy: 0.9875 - val_loss: 0.9881 - val_accuracy: 0.8372
Epoch 61/110
 - 1s - loss: 0.1613 - accuracy: 0.9850 - val_loss: 1.0009 - val_accuracy: 0.8555
Epoch 62/110
 - 1s - loss: 0.1589 - accuracy: 0.9875 - val_loss: 1.0534 - val_accuracy: 0.8289
Epoch 63/110
 - 1s - loss: 0.1604 - accuracy: 0.9855 - val_loss: 1.0876 - val_accuracy: 0.8256
Epoch 64/110
 - 1s - loss: 0.1706 - accuracy: 0.9825 - val_loss: 1.0212 - val_accuracy: 0.8156
Epoch 65/110
 - 1s - loss: 0.1704 - accuracy: 0.9838 - val_loss: 1.0163 - val_accuracy: 0.8538
Epoch 66/110
 - 1s - loss: 0.1671 - accuracy: 0.9830 - val_loss: 1.0382 - val_accuracy: 0.8339
Epoch 67/110
 - 1s - loss: 0.1744 - accuracy: 0.9825 - val_loss: 1.0194 - val_accuracy: 0.8289
Epoch 68/110
 - 1s - loss: 0.1967 - accuracy: 0.9734 - val_loss: 1.1389 - val_accuracy: 0.8189
Epoch 69/110
 - 1s - loss: 0.2325 - accuracy: 0.9663 - val_loss: 0.9748 - val_accuracy: 0.8289
Epoch 70/110
 - 1s - loss: 0.2194 - accuracy: 0.9680 - val_loss: 0.9417 - val_accuracy: 0.8422
Epoch 71/110
 - 1s - loss: 0.2653 - accuracy: 0.9539 - val_loss: 1.0343 - val_accuracy: 0.8206
Epoch 72/110
 - 1s - loss: 0.2264 - accuracy: 0.9626 - val_loss: 0.9786 - val_accuracy: 0.8223
Epoch 73/110
 - 1s - loss: 0.2209 - accuracy: 0.9680 - val_loss: 1.1580 - val_accuracy: 0.8140
Epoch 74/110
 - 1s - loss: 0.2098 - accuracy: 0.9688 - val_loss: 0.9583 - val_accuracy: 0.8472
Epoch 75/110
 - 1s - loss: 0.2540 - accuracy: 0.9597 - val_loss: 0.9052 - val_accuracy: 0.8140
Epoch 76/110
 - 1s - loss: 0.2476 - accuracy: 0.9580 - val_loss: 0.8769 - val_accuracy: 0.8339
Epoch 77/110
 - 1s - loss: 0.2182 - accuracy: 0.9684 - val_loss: 1.0227 - val_accuracy: 0.8189
Epoch 78/110
 - 1s - loss: 0.2027 - accuracy: 0.9680 - val_loss: 1.0448 - val_accuracy: 0.8256
Epoch 79/110
 - 1s - loss: 0.1953 - accuracy: 0.9759 - val_loss: 1.1399 - val_accuracy: 0.8040
Epoch 80/110
 - 1s - loss: 0.1807 - accuracy: 0.9800 - val_loss: 0.9150 - val_accuracy: 0.8422
Epoch 81/110
 - 1s - loss: 0.1681 - accuracy: 0.9842 - val_loss: 0.9836 - val_accuracy: 0.8322
Epoch 82/110
 - 1s - loss: 0.1718 - accuracy: 0.9825 - val_loss: 1.0362 - val_accuracy: 0.8256
Epoch 83/110
 - 1s - loss: 0.1663 - accuracy: 0.9838 - val_loss: 1.0475 - val_accuracy: 0.8322
Epoch 84/110
 - 1s - loss: 0.1653 - accuracy: 0.9821 - val_loss: 1.0015 - val_accuracy: 0.8289
Epoch 85/110
 - 1s - loss: 0.1969 - accuracy: 0.9746 - val_loss: 1.1200 - val_accuracy: 0.8140
Epoch 86/110
 - 1s - loss: 0.1923 - accuracy: 0.9730 - val_loss: 0.9946 - val_accuracy: 0.8405
Epoch 87/110
 - 1s - loss: 0.1856 - accuracy: 0.9771 - val_loss: 0.9359 - val_accuracy: 0.8206
Epoch 88/110
 - 1s - loss: 0.2011 - accuracy: 0.9742 - val_loss: 1.0075 - val_accuracy: 0.8073
Epoch 89/110
 - 1s - loss: 0.1869 - accuracy: 0.9792 - val_loss: 0.9980 - val_accuracy: 0.8223
Epoch 90/110
 - 1s - loss: 0.2011 - accuracy: 0.9751 - val_loss: 0.9514 - val_accuracy: 0.8355
Epoch 91/110
 - 1s - loss: 0.1915 - accuracy: 0.9780 - val_loss: 0.9382 - val_accuracy: 0.8223
Epoch 92/110
 - 1s - loss: 0.1851 - accuracy: 0.9751 - val_loss: 0.8983 - val_accuracy: 0.8455
Epoch 93/110
 - 1s - loss: 0.1687 - accuracy: 0.9850 - val_loss: 0.8777 - val_accuracy: 0.8372
Epoch 94/110
 - 1s - loss: 0.1614 - accuracy: 0.9863 - val_loss: 1.0267 - val_accuracy: 0.8090
Epoch 95/110
 - 1s - loss: 0.1650 - accuracy: 0.9863 - val_loss: 0.9740 - val_accuracy: 0.8289
Epoch 96/110
 - 1s - loss: 0.1572 - accuracy: 0.9879 - val_loss: 0.9890 - val_accuracy: 0.8339
Epoch 97/110
 - 1s - loss: 0.1641 - accuracy: 0.9830 - val_loss: 0.9865 - val_accuracy: 0.8355
Epoch 98/110
 - 1s - loss: 0.1749 - accuracy: 0.9788 - val_loss: 0.9501 - val_accuracy: 0.8289
Epoch 99/110
 - 1s - loss: 0.1901 - accuracy: 0.9755 - val_loss: 0.9429 - val_accuracy: 0.8439
Epoch 100/110
 - 1s - loss: 0.1607 - accuracy: 0.9838 - val_loss: 1.0039 - val_accuracy: 0.8372
Epoch 101/110
 - 1s - loss: 0.1707 - accuracy: 0.9821 - val_loss: 0.9460 - val_accuracy: 0.8372
Epoch 102/110
 - 1s - loss: 0.1850 - accuracy: 0.9755 - val_loss: 1.0135 - val_accuracy: 0.8173
Epoch 103/110
 - 1s - loss: 0.1848 - accuracy: 0.9771 - val_loss: 0.9861 - val_accuracy: 0.8256
Epoch 104/110
 - 1s - loss: 0.1875 - accuracy: 0.9792 - val_loss: 1.0425 - val_accuracy: 0.8306
Epoch 105/110
 - 1s - loss: 0.2368 - accuracy: 0.9630 - val_loss: 0.9943 - val_accuracy: 0.8239
Epoch 106/110
 - 1s - loss: 0.2969 - accuracy: 0.9422 - val_loss: 1.1189 - val_accuracy: 0.8023
Epoch 107/110
 - 1s - loss: 0.2485 - accuracy: 0.9568 - val_loss: 0.9526 - val_accuracy: 0.8090
Epoch 108/110
 - 1s - loss: 0.2272 - accuracy: 0.9638 - val_loss: 0.9521 - val_accuracy: 0.7990
Epoch 109/110
 - 1s - loss: 0.2009 - accuracy: 0.9709 - val_loss: 1.0669 - val_accuracy: 0.8023
Epoch 110/110
 - 1s - loss: 0.1935 - accuracy: 0.9767 - val_loss: 0.9053 - val_accuracy: 0.8272
------------------------------------------------------------------------
Training for fold 3 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 1s - loss: 0.1843 - accuracy: 0.9767 - val_loss: 0.9334 - val_accuracy: 0.8322
Epoch 2/110
 - 1s - loss: 0.2041 - accuracy: 0.9742 - val_loss: 0.9364 - val_accuracy: 0.8306
Epoch 3/110
 - 1s - loss: 0.1888 - accuracy: 0.9746 - val_loss: 0.9230 - val_accuracy: 0.8372
Epoch 4/110
 - 1s - loss: 0.1688 - accuracy: 0.9825 - val_loss: 0.9168 - val_accuracy: 0.8488
Epoch 5/110
 - 1s - loss: 0.1717 - accuracy: 0.9834 - val_loss: 1.0163 - val_accuracy: 0.8389
Epoch 6/110
 - 1s - loss: 0.1609 - accuracy: 0.9846 - val_loss: 0.9717 - val_accuracy: 0.8355
Epoch 7/110
 - 1s - loss: 0.1805 - accuracy: 0.9805 - val_loss: 0.9973 - val_accuracy: 0.8272
Epoch 8/110
 - 1s - loss: 0.1643 - accuracy: 0.9842 - val_loss: 0.9601 - val_accuracy: 0.8355
Epoch 9/110
 - 1s - loss: 0.1530 - accuracy: 0.9875 - val_loss: 0.9794 - val_accuracy: 0.8339
Epoch 10/110
 - 1s - loss: 0.1642 - accuracy: 0.9850 - val_loss: 0.9952 - val_accuracy: 0.8322
Epoch 11/110
 - 1s - loss: 0.1728 - accuracy: 0.9834 - val_loss: 0.9788 - val_accuracy: 0.8289
Epoch 12/110
 - 1s - loss: 0.1763 - accuracy: 0.9788 - val_loss: 1.0117 - val_accuracy: 0.8040
Epoch 13/110
 - 1s - loss: 0.1871 - accuracy: 0.9746 - val_loss: 1.0512 - val_accuracy: 0.8322
Epoch 14/110
 - 1s - loss: 0.2341 - accuracy: 0.9634 - val_loss: 1.0418 - val_accuracy: 0.8173
Epoch 15/110
 - 1s - loss: 0.2322 - accuracy: 0.9601 - val_loss: 1.1441 - val_accuracy: 0.8123
Epoch 16/110
 - 1s - loss: 0.2232 - accuracy: 0.9638 - val_loss: 1.0477 - val_accuracy: 0.8106
Epoch 17/110
 - 1s - loss: 0.2202 - accuracy: 0.9651 - val_loss: 1.0956 - val_accuracy: 0.8173
Epoch 18/110
 - 1s - loss: 0.1897 - accuracy: 0.9759 - val_loss: 0.9000 - val_accuracy: 0.8173
Epoch 19/110
 - 1s - loss: 0.1834 - accuracy: 0.9780 - val_loss: 1.0615 - val_accuracy: 0.8056
Epoch 20/110
 - 1s - loss: 0.1755 - accuracy: 0.9755 - val_loss: 1.0895 - val_accuracy: 0.8090
Epoch 21/110
 - 1s - loss: 0.1617 - accuracy: 0.9859 - val_loss: 0.9662 - val_accuracy: 0.8422
Epoch 22/110
 - 1s - loss: 0.1577 - accuracy: 0.9846 - val_loss: 1.0513 - val_accuracy: 0.8355
Epoch 23/110
 - 1s - loss: 0.1673 - accuracy: 0.9834 - val_loss: 0.9731 - val_accuracy: 0.8339
Epoch 24/110
 - 1s - loss: 0.1620 - accuracy: 0.9850 - val_loss: 1.0074 - val_accuracy: 0.8372
Epoch 25/110
 - 1s - loss: 0.1735 - accuracy: 0.9825 - val_loss: 0.9423 - val_accuracy: 0.8322
Epoch 26/110
 - 1s - loss: 0.1661 - accuracy: 0.9830 - val_loss: 1.0574 - val_accuracy: 0.8422
Epoch 27/110
 - 1s - loss: 0.1773 - accuracy: 0.9767 - val_loss: 1.0835 - val_accuracy: 0.8256
Epoch 28/110
 - 1s - loss: 0.1689 - accuracy: 0.9796 - val_loss: 1.0109 - val_accuracy: 0.8306
Epoch 29/110
 - 1s - loss: 0.1749 - accuracy: 0.9788 - val_loss: 1.0925 - val_accuracy: 0.8040
Epoch 30/110
 - 1s - loss: 0.1790 - accuracy: 0.9784 - val_loss: 1.0505 - val_accuracy: 0.8156
Epoch 31/110
 - 1s - loss: 0.1597 - accuracy: 0.9830 - val_loss: 0.9855 - val_accuracy: 0.8256
Epoch 32/110
 - 1s - loss: 0.1673 - accuracy: 0.9813 - val_loss: 1.0173 - val_accuracy: 0.8389
Epoch 33/110
 - 1s - loss: 0.1906 - accuracy: 0.9763 - val_loss: 0.9846 - val_accuracy: 0.8223
Epoch 34/110
 - 1s - loss: 0.1932 - accuracy: 0.9751 - val_loss: 0.9522 - val_accuracy: 0.8007
Epoch 35/110
 - 1s - loss: 0.1770 - accuracy: 0.9817 - val_loss: 0.9533 - val_accuracy: 0.8090
Epoch 36/110
 - 1s - loss: 0.1752 - accuracy: 0.9796 - val_loss: 0.9818 - val_accuracy: 0.8206
Epoch 37/110
 - 1s - loss: 0.1895 - accuracy: 0.9746 - val_loss: 1.0528 - val_accuracy: 0.8156
Epoch 38/110
 - 1s - loss: 0.1801 - accuracy: 0.9788 - val_loss: 1.1603 - val_accuracy: 0.8056
Epoch 39/110
 - 1s - loss: 0.1811 - accuracy: 0.9771 - val_loss: 0.9765 - val_accuracy: 0.8405
Epoch 40/110
 - 1s - loss: 0.1903 - accuracy: 0.9717 - val_loss: 1.1259 - val_accuracy: 0.8223
Epoch 41/110
 - 1s - loss: 0.1863 - accuracy: 0.9742 - val_loss: 1.0489 - val_accuracy: 0.8289
Epoch 42/110
 - 1s - loss: 0.2279 - accuracy: 0.9647 - val_loss: 1.1077 - val_accuracy: 0.8372
Epoch 43/110
 - 1s - loss: 0.2051 - accuracy: 0.9722 - val_loss: 0.9621 - val_accuracy: 0.8106
Epoch 44/110
 - 1s - loss: 0.1708 - accuracy: 0.9776 - val_loss: 0.9276 - val_accuracy: 0.8355
Epoch 45/110
 - 1s - loss: 0.1721 - accuracy: 0.9813 - val_loss: 0.9795 - val_accuracy: 0.8189
Epoch 46/110
 - 1s - loss: 0.1790 - accuracy: 0.9792 - val_loss: 0.9326 - val_accuracy: 0.8206
Epoch 47/110
 - 1s - loss: 0.1816 - accuracy: 0.9767 - val_loss: 0.9985 - val_accuracy: 0.8073
Epoch 48/110
 - 1s - loss: 0.1959 - accuracy: 0.9713 - val_loss: 0.9492 - val_accuracy: 0.8322
Epoch 49/110
 - 1s - loss: 0.1785 - accuracy: 0.9784 - val_loss: 0.9395 - val_accuracy: 0.8372
Epoch 50/110
 - 1s - loss: 0.1636 - accuracy: 0.9817 - val_loss: 1.0217 - val_accuracy: 0.8173
Epoch 51/110
 - 1s - loss: 0.1659 - accuracy: 0.9834 - val_loss: 0.9716 - val_accuracy: 0.8173
Epoch 52/110
 - 1s - loss: 0.1753 - accuracy: 0.9796 - val_loss: 0.9418 - val_accuracy: 0.8223
Epoch 53/110
 - 1s - loss: 0.1717 - accuracy: 0.9780 - val_loss: 1.0468 - val_accuracy: 0.8239
Epoch 54/110
 - 1s - loss: 0.1843 - accuracy: 0.9771 - val_loss: 1.0146 - val_accuracy: 0.8007
Epoch 55/110
 - 1s - loss: 0.1684 - accuracy: 0.9805 - val_loss: 1.0198 - val_accuracy: 0.8173
Epoch 56/110
 - 1s - loss: 0.1649 - accuracy: 0.9846 - val_loss: 1.0028 - val_accuracy: 0.8289
Epoch 57/110
 - 1s - loss: 0.1729 - accuracy: 0.9784 - val_loss: 1.0270 - val_accuracy: 0.8223
Epoch 58/110
 - 1s - loss: 0.1659 - accuracy: 0.9792 - val_loss: 1.0104 - val_accuracy: 0.8173
Epoch 59/110
 - 1s - loss: 0.1586 - accuracy: 0.9834 - val_loss: 0.9413 - val_accuracy: 0.8322
Epoch 60/110
 - 1s - loss: 0.1742 - accuracy: 0.9771 - val_loss: 1.0629 - val_accuracy: 0.8073
Epoch 61/110
 - 1s - loss: 0.1942 - accuracy: 0.9742 - val_loss: 1.0636 - val_accuracy: 0.7973
Epoch 62/110
 - 1s - loss: 0.1657 - accuracy: 0.9796 - val_loss: 0.9781 - val_accuracy: 0.8007
Epoch 63/110
 - 1s - loss: 0.1653 - accuracy: 0.9813 - val_loss: 0.9754 - val_accuracy: 0.8306
Epoch 64/110
 - 1s - loss: 0.1569 - accuracy: 0.9842 - val_loss: 0.9113 - val_accuracy: 0.8223
Epoch 65/110
 - 1s - loss: 0.1687 - accuracy: 0.9813 - val_loss: 1.0335 - val_accuracy: 0.8073
Epoch 66/110
 - 1s - loss: 0.1841 - accuracy: 0.9771 - val_loss: 0.9790 - val_accuracy: 0.8306
Epoch 67/110
 - 1s - loss: 0.1768 - accuracy: 0.9759 - val_loss: 0.9793 - val_accuracy: 0.8173
Epoch 68/110
 - 1s - loss: 0.1612 - accuracy: 0.9838 - val_loss: 0.9474 - val_accuracy: 0.8355
Epoch 69/110
 - 1s - loss: 0.1637 - accuracy: 0.9813 - val_loss: 0.9370 - val_accuracy: 0.8405
Epoch 70/110
 - 1s - loss: 0.1847 - accuracy: 0.9742 - val_loss: 0.9091 - val_accuracy: 0.8289
Epoch 71/110
 - 1s - loss: 0.1873 - accuracy: 0.9771 - val_loss: 0.9504 - val_accuracy: 0.8272
Epoch 72/110
 - 1s - loss: 0.1872 - accuracy: 0.9759 - val_loss: 1.0043 - val_accuracy: 0.8239
Epoch 73/110
 - 1s - loss: 0.2281 - accuracy: 0.9722 - val_loss: 0.9955 - val_accuracy: 0.8372
Epoch 74/110
 - 1s - loss: 0.1910 - accuracy: 0.9738 - val_loss: 0.9611 - val_accuracy: 0.8256
Epoch 75/110
 - 1s - loss: 0.1733 - accuracy: 0.9800 - val_loss: 0.9938 - val_accuracy: 0.8223
Epoch 76/110
 - 1s - loss: 0.1744 - accuracy: 0.9800 - val_loss: 1.0103 - val_accuracy: 0.8322
Epoch 77/110
 - 1s - loss: 0.1677 - accuracy: 0.9805 - val_loss: 1.0007 - val_accuracy: 0.8189
Epoch 78/110
 - 1s - loss: 0.1582 - accuracy: 0.9825 - val_loss: 1.0513 - val_accuracy: 0.8289
Epoch 79/110
 - 1s - loss: 0.1475 - accuracy: 0.9879 - val_loss: 1.0452 - val_accuracy: 0.8306
Epoch 80/110
 - 1s - loss: 0.1489 - accuracy: 0.9875 - val_loss: 1.0046 - val_accuracy: 0.8239
Epoch 81/110
 - 1s - loss: 0.1561 - accuracy: 0.9838 - val_loss: 0.9127 - val_accuracy: 0.8339
Epoch 82/110
 - 1s - loss: 0.1643 - accuracy: 0.9805 - val_loss: 1.0645 - val_accuracy: 0.8173
Epoch 83/110
 - 1s - loss: 0.1788 - accuracy: 0.9734 - val_loss: 1.1003 - val_accuracy: 0.8306
Epoch 84/110
 - 1s - loss: 0.1972 - accuracy: 0.9705 - val_loss: 1.0992 - val_accuracy: 0.8123
Epoch 85/110
 - 1s - loss: 0.1980 - accuracy: 0.9705 - val_loss: 1.1295 - val_accuracy: 0.7940
Epoch 86/110
 - 1s - loss: 0.1877 - accuracy: 0.9726 - val_loss: 1.0791 - val_accuracy: 0.8140
Epoch 87/110
 - 1s - loss: 0.2029 - accuracy: 0.9705 - val_loss: 1.0927 - val_accuracy: 0.8256
Epoch 88/110
 - 1s - loss: 0.2388 - accuracy: 0.9597 - val_loss: 1.0739 - val_accuracy: 0.8206
Epoch 89/110
 - 1s - loss: 0.2054 - accuracy: 0.9647 - val_loss: 1.0934 - val_accuracy: 0.7957
Epoch 90/110
 - 1s - loss: 0.1950 - accuracy: 0.9738 - val_loss: 1.1442 - val_accuracy: 0.8023
Epoch 91/110
 - 1s - loss: 0.1993 - accuracy: 0.9726 - val_loss: 1.0206 - val_accuracy: 0.8040
Epoch 92/110
 - 1s - loss: 0.1718 - accuracy: 0.9805 - val_loss: 0.9544 - val_accuracy: 0.8189
Epoch 93/110
 - 1s - loss: 0.1528 - accuracy: 0.9830 - val_loss: 0.9648 - val_accuracy: 0.8322
Epoch 94/110
 - 1s - loss: 0.1884 - accuracy: 0.9726 - val_loss: 1.0043 - val_accuracy: 0.8322
Epoch 95/110
 - 1s - loss: 0.1954 - accuracy: 0.9713 - val_loss: 1.1222 - val_accuracy: 0.7957
Epoch 96/110
 - 1s - loss: 0.1789 - accuracy: 0.9763 - val_loss: 1.0763 - val_accuracy: 0.8056
Epoch 97/110
 - 1s - loss: 0.1828 - accuracy: 0.9746 - val_loss: 0.9802 - val_accuracy: 0.8173
Epoch 98/110
 - 1s - loss: 0.1706 - accuracy: 0.9788 - val_loss: 0.9211 - val_accuracy: 0.8505
Epoch 99/110
 - 1s - loss: 0.1555 - accuracy: 0.9846 - val_loss: 1.0152 - val_accuracy: 0.8256
Epoch 100/110
 - 1s - loss: 0.1562 - accuracy: 0.9850 - val_loss: 1.0547 - val_accuracy: 0.8156
Epoch 101/110
 - 1s - loss: 0.1476 - accuracy: 0.9842 - val_loss: 0.9812 - val_accuracy: 0.8405
Epoch 102/110
 - 1s - loss: 0.1555 - accuracy: 0.9830 - val_loss: 0.9110 - val_accuracy: 0.8339
Epoch 103/110
 - 1s - loss: 0.1807 - accuracy: 0.9776 - val_loss: 1.1507 - val_accuracy: 0.8106
Epoch 104/110
 - 1s - loss: 0.1809 - accuracy: 0.9742 - val_loss: 1.1054 - val_accuracy: 0.8173
Epoch 105/110
 - 1s - loss: 0.1658 - accuracy: 0.9817 - val_loss: 1.0434 - val_accuracy: 0.8223
Epoch 106/110
 - 1s - loss: 0.1982 - accuracy: 0.9730 - val_loss: 0.9590 - val_accuracy: 0.8272
Epoch 107/110
 - 1s - loss: 0.1905 - accuracy: 0.9722 - val_loss: 1.0129 - val_accuracy: 0.7890
Epoch 108/110
 - 1s - loss: 0.1762 - accuracy: 0.9767 - val_loss: 1.0326 - val_accuracy: 0.8073
Epoch 109/110
 - 1s - loss: 0.1789 - accuracy: 0.9767 - val_loss: 1.0094 - val_accuracy: 0.8272
Epoch 110/110
 - 1s - loss: 0.1666 - accuracy: 0.9834 - val_loss: 0.9751 - val_accuracy: 0.8306
------------------------------------------------------------------------
Training for fold 4 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 1s - loss: 0.1598 - accuracy: 0.9821 - val_loss: 0.9689 - val_accuracy: 0.8355
Epoch 2/110
 - 1s - loss: 0.1686 - accuracy: 0.9796 - val_loss: 0.9317 - val_accuracy: 0.8555
Epoch 3/110
 - 1s - loss: 0.1611 - accuracy: 0.9842 - val_loss: 1.0992 - val_accuracy: 0.8189
Epoch 4/110
 - 1s - loss: 0.1489 - accuracy: 0.9850 - val_loss: 1.0076 - val_accuracy: 0.8173
Epoch 5/110
 - 1s - loss: 0.1502 - accuracy: 0.9838 - val_loss: 1.0655 - val_accuracy: 0.8173
Epoch 6/110
 - 1s - loss: 0.1489 - accuracy: 0.9850 - val_loss: 1.0370 - val_accuracy: 0.8256
Epoch 7/110
 - 1s - loss: 0.1412 - accuracy: 0.9875 - val_loss: 1.0150 - val_accuracy: 0.8455
Epoch 8/110
 - 1s - loss: 0.1460 - accuracy: 0.9859 - val_loss: 1.0545 - val_accuracy: 0.8256
Epoch 9/110
 - 1s - loss: 0.1410 - accuracy: 0.9871 - val_loss: 1.0646 - val_accuracy: 0.8206
Epoch 10/110
 - 1s - loss: 0.1508 - accuracy: 0.9830 - val_loss: 1.0486 - val_accuracy: 0.8156
Epoch 11/110
 - 1s - loss: 0.1739 - accuracy: 0.9784 - val_loss: 1.0491 - val_accuracy: 0.8189
Epoch 12/110
 - 1s - loss: 0.1720 - accuracy: 0.9800 - val_loss: 1.0073 - val_accuracy: 0.8106
Epoch 13/110
 - 1s - loss: 0.1703 - accuracy: 0.9771 - val_loss: 1.0227 - val_accuracy: 0.8223
Epoch 14/110
 - 1s - loss: 0.1804 - accuracy: 0.9780 - val_loss: 1.0600 - val_accuracy: 0.8372
Epoch 15/110
 - 1s - loss: 0.1884 - accuracy: 0.9742 - val_loss: 0.9935 - val_accuracy: 0.8422
Epoch 16/110
 - 1s - loss: 0.1730 - accuracy: 0.9780 - val_loss: 1.0019 - val_accuracy: 0.8239
Epoch 17/110
 - 1s - loss: 0.1601 - accuracy: 0.9825 - val_loss: 0.9654 - val_accuracy: 0.8355
Epoch 18/110
 - 1s - loss: 0.1524 - accuracy: 0.9821 - val_loss: 0.9581 - val_accuracy: 0.8372
Epoch 19/110
 - 1s - loss: 0.1647 - accuracy: 0.9809 - val_loss: 0.9387 - val_accuracy: 0.8256
Epoch 20/110
 - 1s - loss: 0.1612 - accuracy: 0.9800 - val_loss: 1.0275 - val_accuracy: 0.8289
Epoch 21/110
 - 1s - loss: 0.1554 - accuracy: 0.9813 - val_loss: 1.0213 - val_accuracy: 0.8389
Epoch 22/110
 - 1s - loss: 0.1508 - accuracy: 0.9825 - val_loss: 0.9782 - val_accuracy: 0.8223
Epoch 23/110
 - 1s - loss: 0.1644 - accuracy: 0.9809 - val_loss: 1.0498 - val_accuracy: 0.8289
Epoch 24/110
 - 1s - loss: 0.1416 - accuracy: 0.9875 - val_loss: 0.9407 - val_accuracy: 0.8472
Epoch 25/110
 - 1s - loss: 0.1513 - accuracy: 0.9838 - val_loss: 1.0072 - val_accuracy: 0.8339
Epoch 26/110
 - 1s - loss: 0.1690 - accuracy: 0.9788 - val_loss: 0.9972 - val_accuracy: 0.8223
Epoch 27/110
 - 1s - loss: 0.1620 - accuracy: 0.9796 - val_loss: 1.0879 - val_accuracy: 0.8056
Epoch 28/110
 - 1s - loss: 0.2023 - accuracy: 0.9726 - val_loss: 1.1548 - val_accuracy: 0.7957
Epoch 29/110
 - 1s - loss: 0.2081 - accuracy: 0.9688 - val_loss: 1.1001 - val_accuracy: 0.8140
Epoch 30/110
 - 1s - loss: 0.1943 - accuracy: 0.9697 - val_loss: 0.9078 - val_accuracy: 0.8389
Epoch 31/110
 - 1s - loss: 0.1978 - accuracy: 0.9713 - val_loss: 1.0766 - val_accuracy: 0.8140
Epoch 32/110
 - 1s - loss: 0.1857 - accuracy: 0.9759 - val_loss: 1.0322 - val_accuracy: 0.8189
Epoch 33/110
 - 1s - loss: 0.1537 - accuracy: 0.9842 - val_loss: 0.9258 - val_accuracy: 0.8106
Epoch 34/110
 - 1s - loss: 0.1427 - accuracy: 0.9867 - val_loss: 0.9298 - val_accuracy: 0.8173
Epoch 35/110
 - 1s - loss: 0.1464 - accuracy: 0.9875 - val_loss: 0.9740 - val_accuracy: 0.8256
Epoch 36/110
 - 1s - loss: 0.1372 - accuracy: 0.9871 - val_loss: 0.9912 - val_accuracy: 0.8239
Epoch 37/110
 - 1s - loss: 0.1409 - accuracy: 0.9884 - val_loss: 1.0002 - val_accuracy: 0.8488
Epoch 38/110
 - 1s - loss: 0.1396 - accuracy: 0.9884 - val_loss: 1.0009 - val_accuracy: 0.8223
Epoch 39/110
 - 1s - loss: 0.1378 - accuracy: 0.9875 - val_loss: 0.9813 - val_accuracy: 0.8306
Epoch 40/110
 - 1s - loss: 0.1444 - accuracy: 0.9855 - val_loss: 1.0124 - val_accuracy: 0.8372
Epoch 41/110
 - 1s - loss: 0.1617 - accuracy: 0.9780 - val_loss: 1.0254 - val_accuracy: 0.8306
Epoch 42/110
 - 1s - loss: 0.1551 - accuracy: 0.9825 - val_loss: 1.0205 - val_accuracy: 0.8206
Epoch 43/110
 - 1s - loss: 0.1678 - accuracy: 0.9805 - val_loss: 1.0918 - val_accuracy: 0.8355
Epoch 44/110
 - 1s - loss: 0.1887 - accuracy: 0.9730 - val_loss: 1.1042 - val_accuracy: 0.8106
Epoch 45/110
 - 1s - loss: 0.1890 - accuracy: 0.9701 - val_loss: 0.9992 - val_accuracy: 0.8073
Epoch 46/110
 - 1s - loss: 0.2086 - accuracy: 0.9638 - val_loss: 0.9462 - val_accuracy: 0.8439
Epoch 47/110
 - 1s - loss: 0.2284 - accuracy: 0.9680 - val_loss: 0.8743 - val_accuracy: 0.8173
Epoch 48/110
 - 1s - loss: 0.2117 - accuracy: 0.9638 - val_loss: 1.0077 - val_accuracy: 0.8156
Epoch 49/110
 - 1s - loss: 0.1834 - accuracy: 0.9746 - val_loss: 0.9384 - val_accuracy: 0.8156
Epoch 50/110
 - 1s - loss: 0.1624 - accuracy: 0.9788 - val_loss: 0.8998 - val_accuracy: 0.8306
Epoch 51/110
 - 1s - loss: 0.1461 - accuracy: 0.9846 - val_loss: 0.9537 - val_accuracy: 0.8306
Epoch 52/110
 - 1s - loss: 0.1481 - accuracy: 0.9846 - val_loss: 0.9814 - val_accuracy: 0.8123
Epoch 53/110
 - 1s - loss: 0.1607 - accuracy: 0.9788 - val_loss: 0.9668 - val_accuracy: 0.8339
Epoch 54/110
 - 1s - loss: 0.1511 - accuracy: 0.9871 - val_loss: 1.0078 - val_accuracy: 0.8156
Epoch 55/110
 - 1s - loss: 0.1449 - accuracy: 0.9838 - val_loss: 0.9733 - val_accuracy: 0.8355
Epoch 56/110
 - 1s - loss: 0.1468 - accuracy: 0.9850 - val_loss: 0.9356 - val_accuracy: 0.8405
Epoch 57/110
 - 1s - loss: 0.1554 - accuracy: 0.9855 - val_loss: 0.9673 - val_accuracy: 0.8272
Epoch 58/110
 - 1s - loss: 0.1505 - accuracy: 0.9838 - val_loss: 0.9111 - val_accuracy: 0.8355
Epoch 59/110
 - 1s - loss: 0.1362 - accuracy: 0.9884 - val_loss: 0.9747 - val_accuracy: 0.8289
Epoch 60/110
 - 1s - loss: 0.1348 - accuracy: 0.9892 - val_loss: 1.0169 - val_accuracy: 0.8256
Epoch 61/110
 - 1s - loss: 0.1421 - accuracy: 0.9855 - val_loss: 1.0612 - val_accuracy: 0.8206
Epoch 62/110
 - 1s - loss: 0.1629 - accuracy: 0.9813 - val_loss: 0.9775 - val_accuracy: 0.8189
Epoch 63/110
 - 1s - loss: 0.1536 - accuracy: 0.9776 - val_loss: 1.0256 - val_accuracy: 0.7990
Epoch 64/110
 - 1s - loss: 0.1513 - accuracy: 0.9842 - val_loss: 1.0076 - val_accuracy: 0.8306
Epoch 65/110
 - 1s - loss: 0.1506 - accuracy: 0.9825 - val_loss: 1.1243 - val_accuracy: 0.8056
Epoch 66/110
 - 1s - loss: 0.1611 - accuracy: 0.9809 - val_loss: 0.9540 - val_accuracy: 0.8073
Epoch 67/110
 - 1s - loss: 0.1457 - accuracy: 0.9834 - val_loss: 0.9071 - val_accuracy: 0.8339
Epoch 68/110
 - 1s - loss: 0.1358 - accuracy: 0.9871 - val_loss: 0.9896 - val_accuracy: 0.8223
Epoch 69/110
 - 1s - loss: 0.1507 - accuracy: 0.9838 - val_loss: 0.9481 - val_accuracy: 0.8223
Epoch 70/110
 - 1s - loss: 0.1466 - accuracy: 0.9842 - val_loss: 1.0039 - val_accuracy: 0.8223
Epoch 71/110
 - 1s - loss: 0.1356 - accuracy: 0.9888 - val_loss: 1.0279 - val_accuracy: 0.8306
Epoch 72/110
 - 1s - loss: 0.1394 - accuracy: 0.9855 - val_loss: 1.0758 - val_accuracy: 0.8289
Epoch 73/110
 - 1s - loss: 0.1516 - accuracy: 0.9821 - val_loss: 1.0611 - val_accuracy: 0.8206
Epoch 74/110
 - 1s - loss: 0.1584 - accuracy: 0.9830 - val_loss: 1.0291 - val_accuracy: 0.8123
Epoch 75/110
 - 1s - loss: 0.1574 - accuracy: 0.9780 - val_loss: 0.9727 - val_accuracy: 0.8123
Epoch 76/110
 - 1s - loss: 0.1536 - accuracy: 0.9821 - val_loss: 0.9403 - val_accuracy: 0.8189
Epoch 77/110
 - 1s - loss: 0.1704 - accuracy: 0.9742 - val_loss: 1.0818 - val_accuracy: 0.7907
Epoch 78/110
 - 1s - loss: 0.1630 - accuracy: 0.9792 - val_loss: 0.9829 - val_accuracy: 0.8289
Epoch 79/110
 - 1s - loss: 0.1685 - accuracy: 0.9784 - val_loss: 0.9875 - val_accuracy: 0.8272
Epoch 80/110
 - 1s - loss: 0.1796 - accuracy: 0.9717 - val_loss: 1.0014 - val_accuracy: 0.8173
Epoch 81/110
 - 1s - loss: 0.1594 - accuracy: 0.9767 - val_loss: 1.0523 - val_accuracy: 0.8223
Epoch 82/110
 - 1s - loss: 0.1692 - accuracy: 0.9776 - val_loss: 1.0771 - val_accuracy: 0.8189
Epoch 83/110
 - 1s - loss: 0.2055 - accuracy: 0.9705 - val_loss: 1.0474 - val_accuracy: 0.8073
Epoch 84/110
 - 1s - loss: 0.2196 - accuracy: 0.9605 - val_loss: 1.2306 - val_accuracy: 0.7841
Epoch 85/110
 - 1s - loss: 0.2486 - accuracy: 0.9522 - val_loss: 0.9177 - val_accuracy: 0.7857
Epoch 86/110
 - 1s - loss: 0.1891 - accuracy: 0.9709 - val_loss: 0.8872 - val_accuracy: 0.8123
Epoch 87/110
 - 1s - loss: 0.1675 - accuracy: 0.9784 - val_loss: 1.0348 - val_accuracy: 0.8322
Epoch 88/110
 - 1s - loss: 0.1556 - accuracy: 0.9825 - val_loss: 0.9653 - val_accuracy: 0.8372
Epoch 89/110
 - 1s - loss: 0.1607 - accuracy: 0.9780 - val_loss: 0.9242 - val_accuracy: 0.8339
Epoch 90/110
 - 1s - loss: 0.1508 - accuracy: 0.9842 - val_loss: 0.9742 - val_accuracy: 0.8272
Epoch 91/110
 - 1s - loss: 0.1473 - accuracy: 0.9859 - val_loss: 1.0280 - val_accuracy: 0.8272
Epoch 92/110
 - 1s - loss: 0.1416 - accuracy: 0.9863 - val_loss: 0.9696 - val_accuracy: 0.8355
Epoch 93/110
 - 1s - loss: 0.1504 - accuracy: 0.9817 - val_loss: 1.0164 - val_accuracy: 0.8173
Epoch 94/110
 - 1s - loss: 0.1375 - accuracy: 0.9875 - val_loss: 0.9406 - val_accuracy: 0.8306
Epoch 95/110
 - 1s - loss: 0.1390 - accuracy: 0.9859 - val_loss: 0.9160 - val_accuracy: 0.8272
Epoch 96/110
 - 1s - loss: 0.1453 - accuracy: 0.9842 - val_loss: 1.1087 - val_accuracy: 0.7874
Epoch 97/110
 - 1s - loss: 0.1434 - accuracy: 0.9859 - val_loss: 1.0000 - val_accuracy: 0.8239
Epoch 98/110
 - 1s - loss: 0.1426 - accuracy: 0.9863 - val_loss: 1.0677 - val_accuracy: 0.8206
Epoch 99/110
 - 1s - loss: 0.1353 - accuracy: 0.9884 - val_loss: 0.9827 - val_accuracy: 0.8422
Epoch 100/110
 - 1s - loss: 0.1445 - accuracy: 0.9846 - val_loss: 1.0762 - val_accuracy: 0.8123
Epoch 101/110
 - 1s - loss: 0.1401 - accuracy: 0.9871 - val_loss: 1.0148 - val_accuracy: 0.8156
Epoch 102/110
 - 1s - loss: 0.1478 - accuracy: 0.9834 - val_loss: 1.1371 - val_accuracy: 0.8106
Epoch 103/110
 - 1s - loss: 0.1432 - accuracy: 0.9813 - val_loss: 0.9946 - val_accuracy: 0.8355
Epoch 104/110
 - 1s - loss: 0.1457 - accuracy: 0.9846 - val_loss: 1.0551 - val_accuracy: 0.8389
Epoch 105/110
 - 1s - loss: 0.1462 - accuracy: 0.9834 - val_loss: 1.1198 - val_accuracy: 0.8339
Epoch 106/110
 - 1s - loss: 0.1522 - accuracy: 0.9855 - val_loss: 1.0491 - val_accuracy: 0.8272
Epoch 107/110
 - 1s - loss: 0.1399 - accuracy: 0.9855 - val_loss: 1.0901 - val_accuracy: 0.8156
Epoch 108/110
 - 1s - loss: 0.1478 - accuracy: 0.9821 - val_loss: 0.9682 - val_accuracy: 0.8272
Epoch 109/110
 - 1s - loss: 0.1437 - accuracy: 0.9838 - val_loss: 1.0177 - val_accuracy: 0.8455
Epoch 110/110
 - 1s - loss: 0.1768 - accuracy: 0.9763 - val_loss: 1.1818 - val_accuracy: 0.8173
------------------------------------------------------------------------
Training for fold 5 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 1s - loss: 0.1957 - accuracy: 0.9709 - val_loss: 1.1992 - val_accuracy: 0.8223
Epoch 2/110
 - 1s - loss: 0.2347 - accuracy: 0.9659 - val_loss: 0.9721 - val_accuracy: 0.8156
Epoch 3/110
 - 1s - loss: 0.2436 - accuracy: 0.9505 - val_loss: 1.1720 - val_accuracy: 0.7990
Epoch 4/110
 - 1s - loss: 0.2327 - accuracy: 0.9584 - val_loss: 1.0677 - val_accuracy: 0.8289
Epoch 5/110
 - 1s - loss: 0.1851 - accuracy: 0.9713 - val_loss: 1.1007 - val_accuracy: 0.7824
Epoch 6/110
 - 1s - loss: 0.1803 - accuracy: 0.9705 - val_loss: 0.8846 - val_accuracy: 0.8272
Epoch 7/110
 - 1s - loss: 0.1425 - accuracy: 0.9850 - val_loss: 0.9393 - val_accuracy: 0.8306
Epoch 8/110
 - 1s - loss: 0.1394 - accuracy: 0.9850 - val_loss: 1.0127 - val_accuracy: 0.8372
Epoch 9/110
 - 1s - loss: 0.1314 - accuracy: 0.9892 - val_loss: 1.0116 - val_accuracy: 0.8322
Epoch 10/110
 - 1s - loss: 0.1313 - accuracy: 0.9879 - val_loss: 1.0040 - val_accuracy: 0.8289
Epoch 11/110
 - 1s - loss: 0.1309 - accuracy: 0.9892 - val_loss: 1.0398 - val_accuracy: 0.8289
Epoch 12/110
 - 1s - loss: 0.1276 - accuracy: 0.9896 - val_loss: 1.0646 - val_accuracy: 0.8339
Epoch 13/110
 - 1s - loss: 0.1397 - accuracy: 0.9879 - val_loss: 1.0800 - val_accuracy: 0.8239
Epoch 14/110
 - 1s - loss: 0.1288 - accuracy: 0.9875 - val_loss: 1.1007 - val_accuracy: 0.8239
Epoch 15/110
 - 1s - loss: 0.1413 - accuracy: 0.9850 - val_loss: 1.1802 - val_accuracy: 0.8090
Epoch 16/110
 - 1s - loss: 0.1482 - accuracy: 0.9817 - val_loss: 0.9995 - val_accuracy: 0.8339
Epoch 17/110
 - 1s - loss: 0.1466 - accuracy: 0.9825 - val_loss: 1.0812 - val_accuracy: 0.8090
Epoch 18/110
 - 1s - loss: 0.1592 - accuracy: 0.9817 - val_loss: 1.1103 - val_accuracy: 0.8189
Epoch 19/110
 - 1s - loss: 0.1438 - accuracy: 0.9834 - val_loss: 1.0078 - val_accuracy: 0.8106
Epoch 20/110
 - 1s - loss: 0.1540 - accuracy: 0.9792 - val_loss: 1.0956 - val_accuracy: 0.8289
Epoch 21/110
 - 1s - loss: 0.1515 - accuracy: 0.9834 - val_loss: 1.0753 - val_accuracy: 0.8123
Epoch 22/110
 - 1s - loss: 0.1416 - accuracy: 0.9821 - val_loss: 1.1108 - val_accuracy: 0.8073
Epoch 23/110
 - 1s - loss: 0.1484 - accuracy: 0.9825 - val_loss: 1.0700 - val_accuracy: 0.8090
Epoch 24/110
 - 1s - loss: 0.1500 - accuracy: 0.9825 - val_loss: 1.0489 - val_accuracy: 0.8090
Epoch 25/110
 - 1s - loss: 0.1689 - accuracy: 0.9771 - val_loss: 1.1676 - val_accuracy: 0.7907
Epoch 26/110
 - 1s - loss: 0.1825 - accuracy: 0.9709 - val_loss: 1.0477 - val_accuracy: 0.7990
Epoch 27/110
 - 1s - loss: 0.1455 - accuracy: 0.9830 - val_loss: 1.0102 - val_accuracy: 0.8073
Epoch 28/110
 - 1s - loss: 0.1551 - accuracy: 0.9800 - val_loss: 1.0087 - val_accuracy: 0.8106
Epoch 29/110
 - 1s - loss: 0.1486 - accuracy: 0.9821 - val_loss: 0.9372 - val_accuracy: 0.8439
Epoch 30/110
 - 1s - loss: 0.1295 - accuracy: 0.9900 - val_loss: 0.9168 - val_accuracy: 0.8355
Epoch 31/110
 - 1s - loss: 0.1257 - accuracy: 0.9888 - val_loss: 1.0154 - val_accuracy: 0.8140
Epoch 32/110
 - 1s - loss: 0.1383 - accuracy: 0.9855 - val_loss: 0.9834 - val_accuracy: 0.8422
Epoch 33/110
 - 1s - loss: 0.1358 - accuracy: 0.9859 - val_loss: 1.0453 - val_accuracy: 0.8239
Epoch 34/110
 - 1s - loss: 0.1361 - accuracy: 0.9855 - val_loss: 0.9884 - val_accuracy: 0.8272
Epoch 35/110
 - 1s - loss: 0.1506 - accuracy: 0.9825 - val_loss: 1.0129 - val_accuracy: 0.8505
Epoch 36/110
 - 1s - loss: 0.1661 - accuracy: 0.9792 - val_loss: 0.9618 - val_accuracy: 0.8372
Epoch 37/110
 - 1s - loss: 0.1559 - accuracy: 0.9817 - val_loss: 1.0415 - val_accuracy: 0.8339
Epoch 38/110
 - 1s - loss: 0.1346 - accuracy: 0.9871 - val_loss: 1.0485 - val_accuracy: 0.8339
Epoch 39/110
 - 1s - loss: 0.1498 - accuracy: 0.9838 - val_loss: 0.9751 - val_accuracy: 0.8256
Epoch 40/110
 - 1s - loss: 0.1676 - accuracy: 0.9751 - val_loss: 1.0994 - val_accuracy: 0.8073
Epoch 41/110
 - 1s - loss: 0.1686 - accuracy: 0.9742 - val_loss: 1.0468 - val_accuracy: 0.8206
Epoch 42/110
 - 1s - loss: 0.2005 - accuracy: 0.9713 - val_loss: 0.9282 - val_accuracy: 0.7907
Epoch 43/110
 - 1s - loss: 0.1870 - accuracy: 0.9746 - val_loss: 0.9845 - val_accuracy: 0.8206
Epoch 44/110
 - 1s - loss: 0.1836 - accuracy: 0.9722 - val_loss: 0.8556 - val_accuracy: 0.8023
Epoch 45/110
 - 1s - loss: 0.1745 - accuracy: 0.9738 - val_loss: 1.0003 - val_accuracy: 0.8040
Epoch 46/110
 - 1s - loss: 0.1769 - accuracy: 0.9684 - val_loss: 1.0402 - val_accuracy: 0.8206
Epoch 47/110
 - 1s - loss: 0.1858 - accuracy: 0.9705 - val_loss: 1.0385 - val_accuracy: 0.8173
Epoch 48/110
 - 1s - loss: 0.1560 - accuracy: 0.9821 - val_loss: 0.9370 - val_accuracy: 0.8322
Epoch 49/110
 - 1s - loss: 0.1438 - accuracy: 0.9817 - val_loss: 1.0717 - val_accuracy: 0.8156
Epoch 50/110
 - 1s - loss: 0.1379 - accuracy: 0.9850 - val_loss: 0.9713 - val_accuracy: 0.8256
Epoch 51/110
 - 1s - loss: 0.1246 - accuracy: 0.9909 - val_loss: 0.9659 - val_accuracy: 0.8339
Epoch 52/110
 - 1s - loss: 0.1241 - accuracy: 0.9896 - val_loss: 1.0079 - val_accuracy: 0.8223
Epoch 53/110
 - 1s - loss: 0.1268 - accuracy: 0.9879 - val_loss: 1.0811 - val_accuracy: 0.8223
Epoch 54/110
 - 1s - loss: 0.1264 - accuracy: 0.9888 - val_loss: 1.0091 - val_accuracy: 0.8306
Epoch 55/110
 - 1s - loss: 0.1257 - accuracy: 0.9888 - val_loss: 0.9928 - val_accuracy: 0.8405
Epoch 56/110
 - 1s - loss: 0.1234 - accuracy: 0.9900 - val_loss: 1.0422 - val_accuracy: 0.8322
Epoch 57/110
 - 1s - loss: 0.1326 - accuracy: 0.9875 - val_loss: 1.0045 - val_accuracy: 0.8472
Epoch 58/110
 - 1s - loss: 0.1289 - accuracy: 0.9888 - val_loss: 1.0983 - val_accuracy: 0.8272
Epoch 59/110
 - 1s - loss: 0.1305 - accuracy: 0.9867 - val_loss: 1.1425 - val_accuracy: 0.8206
Epoch 60/110
 - 1s - loss: 0.1480 - accuracy: 0.9817 - val_loss: 1.0911 - val_accuracy: 0.8339
Epoch 61/110
 - 1s - loss: 0.1496 - accuracy: 0.9825 - val_loss: 1.1021 - val_accuracy: 0.8073
Epoch 62/110
 - 1s - loss: 0.1607 - accuracy: 0.9776 - val_loss: 1.1883 - val_accuracy: 0.8173
Epoch 63/110
 - 1s - loss: 0.1697 - accuracy: 0.9755 - val_loss: 1.1619 - val_accuracy: 0.8056
Epoch 64/110
 - 1s - loss: 0.2199 - accuracy: 0.9605 - val_loss: 1.0378 - val_accuracy: 0.8206
Epoch 65/110
 - 1s - loss: 0.1855 - accuracy: 0.9705 - val_loss: 1.0144 - val_accuracy: 0.8339
Epoch 66/110
 - 1s - loss: 0.1638 - accuracy: 0.9763 - val_loss: 0.9094 - val_accuracy: 0.8272
Epoch 67/110
 - 1s - loss: 0.1366 - accuracy: 0.9850 - val_loss: 0.9569 - val_accuracy: 0.8189
Epoch 68/110
 - 1s - loss: 0.1406 - accuracy: 0.9830 - val_loss: 0.9329 - val_accuracy: 0.8256
Epoch 69/110
 - 1s - loss: 0.1475 - accuracy: 0.9830 - val_loss: 0.9403 - val_accuracy: 0.8322
Epoch 70/110
 - 1s - loss: 0.1352 - accuracy: 0.9850 - val_loss: 0.9024 - val_accuracy: 0.8339
Epoch 71/110
 - 1s - loss: 0.1443 - accuracy: 0.9825 - val_loss: 0.9565 - val_accuracy: 0.8272
Epoch 72/110
 - 1s - loss: 0.1332 - accuracy: 0.9846 - val_loss: 0.9779 - val_accuracy: 0.8090
Epoch 73/110
 - 1s - loss: 0.1346 - accuracy: 0.9888 - val_loss: 0.9701 - val_accuracy: 0.8223
Epoch 74/110
 - 1s - loss: 0.1252 - accuracy: 0.9879 - val_loss: 0.9566 - val_accuracy: 0.8189
Epoch 75/110
 - 1s - loss: 0.1432 - accuracy: 0.9838 - val_loss: 0.8989 - val_accuracy: 0.8140
Epoch 76/110
 - 1s - loss: 0.1487 - accuracy: 0.9809 - val_loss: 1.0190 - val_accuracy: 0.7990
Epoch 77/110
 - 1s - loss: 0.1430 - accuracy: 0.9830 - val_loss: 0.8892 - val_accuracy: 0.8223
Epoch 78/110
 - 1s - loss: 0.1295 - accuracy: 0.9863 - val_loss: 0.9837 - val_accuracy: 0.8339
Epoch 79/110
 - 1s - loss: 0.1316 - accuracy: 0.9871 - val_loss: 0.9491 - val_accuracy: 0.8355
Epoch 80/110
 - 1s - loss: 0.1303 - accuracy: 0.9863 - val_loss: 0.9671 - val_accuracy: 0.8206
Epoch 81/110
 - 1s - loss: 0.1288 - accuracy: 0.9871 - val_loss: 1.0333 - val_accuracy: 0.8189
Epoch 82/110
 - 1s - loss: 0.1270 - accuracy: 0.9871 - val_loss: 1.0081 - val_accuracy: 0.8173
Epoch 83/110
 - 1s - loss: 0.1197 - accuracy: 0.9913 - val_loss: 0.9884 - val_accuracy: 0.8289
Epoch 84/110
 - 1s - loss: 0.1205 - accuracy: 0.9879 - val_loss: 0.9611 - val_accuracy: 0.8422
Epoch 85/110
 - 1s - loss: 0.1306 - accuracy: 0.9863 - val_loss: 1.0983 - val_accuracy: 0.8189
Epoch 86/110
 - 1s - loss: 0.1631 - accuracy: 0.9796 - val_loss: 1.1433 - val_accuracy: 0.8140
Epoch 87/110
 - 1s - loss: 0.1682 - accuracy: 0.9780 - val_loss: 1.0335 - val_accuracy: 0.8073
Epoch 88/110
 - 1s - loss: 0.1600 - accuracy: 0.9796 - val_loss: 1.1259 - val_accuracy: 0.8106
Epoch 89/110
 - 1s - loss: 0.2407 - accuracy: 0.9534 - val_loss: 1.1058 - val_accuracy: 0.7841
Epoch 90/110
 - 1s - loss: 0.2980 - accuracy: 0.9368 - val_loss: 1.1155 - val_accuracy: 0.7957
Epoch 91/110
 - 1s - loss: 0.2095 - accuracy: 0.9634 - val_loss: 1.0732 - val_accuracy: 0.8239
Epoch 92/110
 - 1s - loss: 0.1728 - accuracy: 0.9763 - val_loss: 0.9468 - val_accuracy: 0.8223
Epoch 93/110
 - 1s - loss: 0.1439 - accuracy: 0.9838 - val_loss: 0.9249 - val_accuracy: 0.8239
Epoch 94/110
 - 1s - loss: 0.1301 - accuracy: 0.9884 - val_loss: 0.9907 - val_accuracy: 0.8023
Epoch 95/110
 - 1s - loss: 0.1283 - accuracy: 0.9879 - val_loss: 1.0166 - val_accuracy: 0.8156
Epoch 96/110
 - 1s - loss: 0.1293 - accuracy: 0.9875 - val_loss: 0.9504 - val_accuracy: 0.8355
Epoch 97/110
 - 1s - loss: 0.1348 - accuracy: 0.9842 - val_loss: 1.0268 - val_accuracy: 0.8223
Epoch 98/110
 - 1s - loss: 0.1316 - accuracy: 0.9863 - val_loss: 0.9887 - val_accuracy: 0.8156
Epoch 99/110
 - 1s - loss: 0.1298 - accuracy: 0.9863 - val_loss: 0.9579 - val_accuracy: 0.8405
Epoch 100/110
 - 1s - loss: 0.1254 - accuracy: 0.9892 - val_loss: 1.0115 - val_accuracy: 0.8140
Epoch 101/110
 - 1s - loss: 0.1204 - accuracy: 0.9888 - val_loss: 0.9937 - val_accuracy: 0.8355
Epoch 102/110
 - 1s - loss: 0.1209 - accuracy: 0.9892 - val_loss: 1.0670 - val_accuracy: 0.8389
Epoch 103/110
 - 1s - loss: 0.1201 - accuracy: 0.9896 - val_loss: 1.0623 - val_accuracy: 0.8140
Epoch 104/110
 - 1s - loss: 0.1216 - accuracy: 0.9888 - val_loss: 0.9682 - val_accuracy: 0.8256
Epoch 105/110
 - 1s - loss: 0.1188 - accuracy: 0.9900 - val_loss: 1.0843 - val_accuracy: 0.8223
Epoch 106/110
 - 1s - loss: 0.1426 - accuracy: 0.9825 - val_loss: 1.0573 - val_accuracy: 0.8189
Epoch 107/110
 - 1s - loss: 0.1506 - accuracy: 0.9813 - val_loss: 0.9927 - val_accuracy: 0.8289
Epoch 108/110
 - 1s - loss: 0.1284 - accuracy: 0.9879 - val_loss: 1.1241 - val_accuracy: 0.8206
Epoch 109/110
 - 1s - loss: 0.1249 - accuracy: 0.9879 - val_loss: 1.1953 - val_accuracy: 0.7973
Epoch 110/110
 - 1s - loss: 0.1238 - accuracy: 0.9879 - val_loss: 1.0277 - val_accuracy: 0.8306
------------------------------------------------------------------------
Score per fold
------------------------------------------------------------------------
Score for fold 1
Accuracy_Train: 26.26%
Accuracy_Test: 26.60%
Loss_Train: 34.35
Loss_Test: 34.20
------------------------------------------------------------------------
Score for fold 2
Accuracy_Train: 23.40%
Accuracy_Test: 25.40%
Loss_Train: 56.50
Loss_Test: 54.76
------------------------------------------------------------------------
Score for fold 3
Accuracy_Train: 23.60%
Accuracy_Test: 22.87%
Loss_Train: 17.34
Loss_Test: 16.63
------------------------------------------------------------------------
Score for fold 4
Accuracy_Train: 29.45%
Accuracy_Test: 30.98%
Loss_Train: 18.87
Loss_Test: 18.33
------------------------------------------------------------------------
Score for fold 5
Accuracy_Train: 25.80%
Accuracy_Test: 25.13%
Loss_Train: 48.13
Loss_Test: 48.82
------------------------------------------------------------------------
Average scores for all folds:
Average_Accuracy_Train: 25.70%
	-> (+- 2.1949952605130956 )
Average_Accuracy_Test: 26.20%
	-> (+- 2.6794464610071334 )
Average_Loss_Train: 35.04
	-> (+- 15.537006892046048 )
Average_Loss_Test: 34.55
	-> (+- 15.468867791515722 )
------------------------------------------------------------------------
