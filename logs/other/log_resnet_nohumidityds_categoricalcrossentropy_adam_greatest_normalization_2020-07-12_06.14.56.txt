Dataset used: ../../datasets/full_dataset_without_humidity.csv 

   Temperature  Sound  Heartbeat   X1  ...    Y2     Z2  Classification  Feedback
0           32      1         60 -680  ... -7424 -15596             100     Happy
1           32      1         60 -780  ... -7408 -15628             100     Happy
2           -1      1         60   -1  ... -7276 -15612             100     Happy
3           -1     -1         60   -1  ...    -1     -1             100     Happy
4           32      1         60 -860  ... -7340 -15720             100     Happy

[5 rows x 11 columns]

Objservations: 8560
Reshaping:  ((6848, 10), (6848, 4), (1712, 10), (1712, 4))  -> ((6848, 10, 1), (6848, 4), (1712, 10, 1), (1712, 4))

Layers:

{'batch_input_shape': (None, 10, 1), 'dtype': 'float32', 'sparse': False, 'name': 'input_25'} 

{'name': 'conv1d_547', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_457', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_541', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_548', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_458', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_542', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_549', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_459', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_217', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_543', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_550', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_460', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_544', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_551', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_461', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_218', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_545', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_552', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_462', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_546', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_553', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_463', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_219', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_547', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_554', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_464', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_548', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_555', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_556', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_465', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_220', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_549', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_557', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_466', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_550', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_558', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_467', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_221', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_551', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_559', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_468', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_552', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_560', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_469', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_222', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_553', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_561', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_470', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_554', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_562', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_563', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_471', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_223', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_555', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_564', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_472', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_556', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_565', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_473', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_224', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_557', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_566', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_474', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_558', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_567', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_475', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_225', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_559', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'average_pooling1d_25', 'trainable': True, 'dtype': 'float32', 'strides': (1,), 'pool_size': (1,), 'padding': 'valid', 'data_format': 'channels_last'} 

{'name': 'flatten_67', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'} 

{'name': 'dense_1195', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 7s - loss: 1.2401 - accuracy: 0.6444 - val_loss: 1.8257 - val_accuracy: 0.4474
Epoch 2/110
 - 3s - loss: 0.7341 - accuracy: 0.7881 - val_loss: 0.9568 - val_accuracy: 0.6934
Epoch 3/110
 - 2s - loss: 0.6361 - accuracy: 0.8249 - val_loss: 0.7554 - val_accuracy: 0.7891
Epoch 4/110
 - 2s - loss: 0.5738 - accuracy: 0.8488 - val_loss: 0.7285 - val_accuracy: 0.8058
Epoch 5/110
 - 2s - loss: 0.5319 - accuracy: 0.8627 - val_loss: 0.7626 - val_accuracy: 0.7964
Epoch 6/110
 - 2s - loss: 0.5122 - accuracy: 0.8658 - val_loss: 0.8355 - val_accuracy: 0.7708
Epoch 7/110
 - 2s - loss: 0.5016 - accuracy: 0.8744 - val_loss: 0.8282 - val_accuracy: 0.7774
Epoch 8/110
 - 2s - loss: 0.4824 - accuracy: 0.8793 - val_loss: 0.9257 - val_accuracy: 0.7620
Epoch 9/110
 - 3s - loss: 0.4808 - accuracy: 0.8801 - val_loss: 0.8785 - val_accuracy: 0.7752
Epoch 10/110
 - 2s - loss: 0.4680 - accuracy: 0.8815 - val_loss: 0.8128 - val_accuracy: 0.7956
Epoch 11/110
 - 2s - loss: 0.4382 - accuracy: 0.8912 - val_loss: 0.7589 - val_accuracy: 0.8219
Epoch 12/110
 - 2s - loss: 0.4285 - accuracy: 0.8936 - val_loss: 0.8217 - val_accuracy: 0.7818
Epoch 13/110
 - 2s - loss: 0.4407 - accuracy: 0.8861 - val_loss: 0.8227 - val_accuracy: 0.7949
Epoch 14/110
 - 2s - loss: 0.4405 - accuracy: 0.8885 - val_loss: 0.7829 - val_accuracy: 0.8044
Epoch 15/110
 - 3s - loss: 0.4234 - accuracy: 0.8958 - val_loss: 0.7590 - val_accuracy: 0.8212
Epoch 16/110
 - 3s - loss: 0.4101 - accuracy: 0.9049 - val_loss: 0.7322 - val_accuracy: 0.8219
Epoch 17/110
 - 2s - loss: 0.3802 - accuracy: 0.9169 - val_loss: 0.7334 - val_accuracy: 0.8263
Epoch 18/110
 - 2s - loss: 0.3855 - accuracy: 0.9109 - val_loss: 0.7639 - val_accuracy: 0.8226
Epoch 19/110
 - 3s - loss: 0.3834 - accuracy: 0.9153 - val_loss: 0.7936 - val_accuracy: 0.8131
Epoch 20/110
 - 2s - loss: 0.3790 - accuracy: 0.9164 - val_loss: 0.7220 - val_accuracy: 0.8292
Epoch 21/110
 - 3s - loss: 0.3708 - accuracy: 0.9166 - val_loss: 0.7440 - val_accuracy: 0.8190
Epoch 22/110
 - 2s - loss: 0.3607 - accuracy: 0.9142 - val_loss: 0.7535 - val_accuracy: 0.8299
Epoch 23/110
 - 2s - loss: 0.3661 - accuracy: 0.9186 - val_loss: 0.8312 - val_accuracy: 0.8146
Epoch 24/110
 - 2s - loss: 0.3632 - accuracy: 0.9204 - val_loss: 0.7709 - val_accuracy: 0.8234
Epoch 25/110
 - 2s - loss: 0.3503 - accuracy: 0.9228 - val_loss: 0.7811 - val_accuracy: 0.8248
Epoch 26/110
 - 2s - loss: 0.3552 - accuracy: 0.9235 - val_loss: 0.8579 - val_accuracy: 0.8117
Epoch 27/110
 - 2s - loss: 0.3589 - accuracy: 0.9202 - val_loss: 0.8206 - val_accuracy: 0.8190
Epoch 28/110
 - 2s - loss: 0.3591 - accuracy: 0.9215 - val_loss: 0.8483 - val_accuracy: 0.8146
Epoch 29/110
 - 2s - loss: 0.3688 - accuracy: 0.9175 - val_loss: 0.8169 - val_accuracy: 0.8285
Epoch 30/110
 - 2s - loss: 0.3594 - accuracy: 0.9211 - val_loss: 0.7750 - val_accuracy: 0.8248
Epoch 31/110
 - 3s - loss: 0.3489 - accuracy: 0.9241 - val_loss: 0.8408 - val_accuracy: 0.8248
Epoch 32/110
 - 3s - loss: 0.3383 - accuracy: 0.9261 - val_loss: 0.8253 - val_accuracy: 0.8204
Epoch 33/110
 - 2s - loss: 0.3294 - accuracy: 0.9299 - val_loss: 0.7650 - val_accuracy: 0.8321
Epoch 34/110
 - 3s - loss: 0.3322 - accuracy: 0.9292 - val_loss: 0.7184 - val_accuracy: 0.8358
Epoch 35/110
 - 2s - loss: 0.3185 - accuracy: 0.9361 - val_loss: 0.7674 - val_accuracy: 0.8380
Epoch 36/110
 - 2s - loss: 0.3295 - accuracy: 0.9326 - val_loss: 0.7938 - val_accuracy: 0.8248
Epoch 37/110
 - 2s - loss: 0.3198 - accuracy: 0.9350 - val_loss: 0.8095 - val_accuracy: 0.8299
Epoch 38/110
 - 2s - loss: 0.3051 - accuracy: 0.9376 - val_loss: 0.7606 - val_accuracy: 0.8394
Epoch 39/110
 - 2s - loss: 0.3084 - accuracy: 0.9387 - val_loss: 0.7647 - val_accuracy: 0.8358
Epoch 40/110
 - 2s - loss: 0.3123 - accuracy: 0.9390 - val_loss: 0.8373 - val_accuracy: 0.8285
Epoch 41/110
 - 2s - loss: 0.2857 - accuracy: 0.9524 - val_loss: 0.7407 - val_accuracy: 0.8453
Epoch 42/110
 - 2s - loss: 0.2896 - accuracy: 0.9480 - val_loss: 0.7974 - val_accuracy: 0.8504
Epoch 43/110
 - 2s - loss: 0.3053 - accuracy: 0.9447 - val_loss: 0.7914 - val_accuracy: 0.8460
Epoch 44/110
 - 2s - loss: 0.2855 - accuracy: 0.9502 - val_loss: 0.8088 - val_accuracy: 0.8328
Epoch 45/110
 - 3s - loss: 0.2886 - accuracy: 0.9507 - val_loss: 0.8808 - val_accuracy: 0.8358
Epoch 46/110
 - 3s - loss: 0.2817 - accuracy: 0.9520 - val_loss: 0.9106 - val_accuracy: 0.8270
Epoch 47/110
 - 2s - loss: 0.2874 - accuracy: 0.9487 - val_loss: 0.8285 - val_accuracy: 0.8394
Epoch 48/110
 - 2s - loss: 0.2763 - accuracy: 0.9562 - val_loss: 0.8574 - val_accuracy: 0.8336
Epoch 49/110
 - 2s - loss: 0.2628 - accuracy: 0.9589 - val_loss: 0.8540 - val_accuracy: 0.8299
Epoch 50/110
 - 2s - loss: 0.2730 - accuracy: 0.9533 - val_loss: 0.8036 - val_accuracy: 0.8299
Epoch 51/110
 - 2s - loss: 0.2785 - accuracy: 0.9542 - val_loss: 0.8493 - val_accuracy: 0.8314
Epoch 52/110
 - 2s - loss: 0.2622 - accuracy: 0.9597 - val_loss: 0.8127 - val_accuracy: 0.8460
Epoch 53/110
 - 2s - loss: 0.2810 - accuracy: 0.9522 - val_loss: 0.8261 - val_accuracy: 0.8409
Epoch 54/110
 - 2s - loss: 0.2802 - accuracy: 0.9545 - val_loss: 0.8340 - val_accuracy: 0.8372
Epoch 55/110
 - 2s - loss: 0.2728 - accuracy: 0.9536 - val_loss: 0.8546 - val_accuracy: 0.8409
Epoch 56/110
 - 2s - loss: 0.2613 - accuracy: 0.9576 - val_loss: 0.9022 - val_accuracy: 0.8292
Epoch 57/110
 - 2s - loss: 0.2554 - accuracy: 0.9582 - val_loss: 0.9410 - val_accuracy: 0.8314
Epoch 58/110
 - 2s - loss: 0.2667 - accuracy: 0.9549 - val_loss: 0.9654 - val_accuracy: 0.8263
Epoch 59/110
 - 2s - loss: 0.2698 - accuracy: 0.9564 - val_loss: 0.8679 - val_accuracy: 0.8328
Epoch 60/110
 - 2s - loss: 0.2924 - accuracy: 0.9494 - val_loss: 0.7973 - val_accuracy: 0.8489
Epoch 61/110
 - 3s - loss: 0.2760 - accuracy: 0.9551 - val_loss: 0.8680 - val_accuracy: 0.8409
Epoch 62/110
 - 3s - loss: 0.2521 - accuracy: 0.9631 - val_loss: 0.8184 - val_accuracy: 0.8453
Epoch 63/110
 - 2s - loss: 0.2643 - accuracy: 0.9609 - val_loss: 0.8555 - val_accuracy: 0.8438
Epoch 64/110
 - 2s - loss: 0.2660 - accuracy: 0.9591 - val_loss: 0.8331 - val_accuracy: 0.8445
Epoch 65/110
 - 2s - loss: 0.2435 - accuracy: 0.9659 - val_loss: 0.9538 - val_accuracy: 0.8263
Epoch 66/110
 - 2s - loss: 0.2692 - accuracy: 0.9560 - val_loss: 0.9188 - val_accuracy: 0.8336
Epoch 67/110
 - 2s - loss: 0.2687 - accuracy: 0.9597 - val_loss: 0.8943 - val_accuracy: 0.8387
Epoch 68/110
 - 2s - loss: 0.2497 - accuracy: 0.9646 - val_loss: 0.9716 - val_accuracy: 0.8277
Epoch 69/110
 - 2s - loss: 0.2584 - accuracy: 0.9591 - val_loss: 0.8850 - val_accuracy: 0.8380
Epoch 70/110
 - 2s - loss: 0.2528 - accuracy: 0.9642 - val_loss: 0.8808 - val_accuracy: 0.8504
Epoch 71/110
 - 2s - loss: 0.2402 - accuracy: 0.9662 - val_loss: 0.8658 - val_accuracy: 0.8438
Epoch 72/110
 - 2s - loss: 0.2283 - accuracy: 0.9723 - val_loss: 0.9738 - val_accuracy: 0.8277
Epoch 73/110
 - 2s - loss: 0.2277 - accuracy: 0.9733 - val_loss: 0.9099 - val_accuracy: 0.8343
Epoch 74/110
 - 2s - loss: 0.2383 - accuracy: 0.9684 - val_loss: 0.8462 - val_accuracy: 0.8453
Epoch 75/110
 - 2s - loss: 0.2348 - accuracy: 0.9697 - val_loss: 0.9157 - val_accuracy: 0.8394
Epoch 76/110
 - 2s - loss: 0.2424 - accuracy: 0.9677 - val_loss: 0.8547 - val_accuracy: 0.8394
Epoch 77/110
 - 2s - loss: 0.2578 - accuracy: 0.9620 - val_loss: 0.8917 - val_accuracy: 0.8372
Epoch 78/110
 - 2s - loss: 0.2472 - accuracy: 0.9626 - val_loss: 0.9107 - val_accuracy: 0.8358
Epoch 79/110
 - 2s - loss: 0.2470 - accuracy: 0.9646 - val_loss: 0.8358 - val_accuracy: 0.8496
Epoch 80/110
 - 2s - loss: 0.2272 - accuracy: 0.9706 - val_loss: 0.8382 - val_accuracy: 0.8453
Epoch 81/110
 - 2s - loss: 0.2409 - accuracy: 0.9681 - val_loss: 0.9268 - val_accuracy: 0.8387
Epoch 82/110
 - 2s - loss: 0.2499 - accuracy: 0.9666 - val_loss: 0.9618 - val_accuracy: 0.8365
Epoch 83/110
 - 2s - loss: 0.2407 - accuracy: 0.9655 - val_loss: 0.8620 - val_accuracy: 0.8496
Epoch 84/110
 - 2s - loss: 0.2322 - accuracy: 0.9732 - val_loss: 0.8451 - val_accuracy: 0.8489
Epoch 85/110
 - 2s - loss: 0.2409 - accuracy: 0.9693 - val_loss: 0.8680 - val_accuracy: 0.8453
Epoch 86/110
 - 2s - loss: 0.2370 - accuracy: 0.9691 - val_loss: 0.8831 - val_accuracy: 0.8394
Epoch 87/110
 - 2s - loss: 0.2187 - accuracy: 0.9748 - val_loss: 0.8462 - val_accuracy: 0.8504
Epoch 88/110
 - 2s - loss: 0.2261 - accuracy: 0.9726 - val_loss: 0.9399 - val_accuracy: 0.8380
Epoch 89/110
 - 2s - loss: 0.2417 - accuracy: 0.9668 - val_loss: 0.9157 - val_accuracy: 0.8482
Epoch 90/110
 - 2s - loss: 0.2398 - accuracy: 0.9659 - val_loss: 0.8293 - val_accuracy: 0.8511
Epoch 91/110
 - 2s - loss: 0.2456 - accuracy: 0.9650 - val_loss: 0.8943 - val_accuracy: 0.8453
Epoch 92/110
 - 2s - loss: 0.2126 - accuracy: 0.9786 - val_loss: 0.8649 - val_accuracy: 0.8526
Epoch 93/110
 - 2s - loss: 0.2291 - accuracy: 0.9728 - val_loss: 0.8120 - val_accuracy: 0.8547
Epoch 94/110
 - 2s - loss: 0.2165 - accuracy: 0.9759 - val_loss: 0.8263 - val_accuracy: 0.8518
Epoch 95/110
 - 2s - loss: 0.2161 - accuracy: 0.9765 - val_loss: 0.8464 - val_accuracy: 0.8526
Epoch 96/110
 - 2s - loss: 0.2092 - accuracy: 0.9790 - val_loss: 0.8975 - val_accuracy: 0.8467
Epoch 97/110
 - 2s - loss: 0.2391 - accuracy: 0.9655 - val_loss: 1.0110 - val_accuracy: 0.8431
Epoch 98/110
 - 2s - loss: 0.2664 - accuracy: 0.9589 - val_loss: 0.8333 - val_accuracy: 0.8569
Epoch 99/110
 - 2s - loss: 0.2380 - accuracy: 0.9651 - val_loss: 0.8399 - val_accuracy: 0.8482
Epoch 100/110
 - 2s - loss: 0.2332 - accuracy: 0.9693 - val_loss: 0.8538 - val_accuracy: 0.8423
Epoch 101/110
 - 2s - loss: 0.2192 - accuracy: 0.9726 - val_loss: 0.8519 - val_accuracy: 0.8423
Epoch 102/110
 - 2s - loss: 0.2105 - accuracy: 0.9781 - val_loss: 0.8407 - val_accuracy: 0.8635
Epoch 103/110
 - 2s - loss: 0.2163 - accuracy: 0.9763 - val_loss: 0.8659 - val_accuracy: 0.8511
Epoch 104/110
 - 2s - loss: 0.2326 - accuracy: 0.9690 - val_loss: 0.8985 - val_accuracy: 0.8416
Epoch 105/110
 - 2s - loss: 0.2259 - accuracy: 0.9717 - val_loss: 0.8547 - val_accuracy: 0.8635
Epoch 106/110
 - 2s - loss: 0.2181 - accuracy: 0.9726 - val_loss: 0.8853 - val_accuracy: 0.8482
Epoch 107/110
 - 2s - loss: 0.2103 - accuracy: 0.9766 - val_loss: 0.8712 - val_accuracy: 0.8569
Epoch 108/110
 - 2s - loss: 0.2087 - accuracy: 0.9799 - val_loss: 0.9062 - val_accuracy: 0.8642
Epoch 109/110
 - 2s - loss: 0.2162 - accuracy: 0.9754 - val_loss: 0.8497 - val_accuracy: 0.8511
Epoch 110/110
 - 2s - loss: 0.2353 - accuracy: 0.9675 - val_loss: 0.8089 - val_accuracy: 0.8606

Number of filters: 16 , Kernel Size: 3 , Strides: 1 Batch Normalization: True , Conv_First: True , Depth Value: 20

Fit: epochs= 110 , batch_size= 64 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "model_25"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_25 (InputLayer)           (None, 10, 1)        0                                            
__________________________________________________________________________________________________
conv1d_547 (Conv1D)             (None, 10, 16)       64          input_25[0][0]                   
__________________________________________________________________________________________________
batch_normalization_457 (BatchN (None, 10, 16)       64          conv1d_547[0][0]                 
__________________________________________________________________________________________________
activation_541 (Activation)     (None, 10, 16)       0           batch_normalization_457[0][0]    
__________________________________________________________________________________________________
conv1d_548 (Conv1D)             (None, 10, 16)       784         activation_541[0][0]             
__________________________________________________________________________________________________
batch_normalization_458 (BatchN (None, 10, 16)       64          conv1d_548[0][0]                 
__________________________________________________________________________________________________
activation_542 (Activation)     (None, 10, 16)       0           batch_normalization_458[0][0]    
__________________________________________________________________________________________________
conv1d_549 (Conv1D)             (None, 10, 16)       784         activation_542[0][0]             
__________________________________________________________________________________________________
batch_normalization_459 (BatchN (None, 10, 16)       64          conv1d_549[0][0]                 
__________________________________________________________________________________________________
add_217 (Add)                   (None, 10, 16)       0           activation_541[0][0]             
                                                                 batch_normalization_459[0][0]    
__________________________________________________________________________________________________
activation_543 (Activation)     (None, 10, 16)       0           add_217[0][0]                    
__________________________________________________________________________________________________
conv1d_550 (Conv1D)             (None, 10, 16)       784         activation_543[0][0]             
__________________________________________________________________________________________________
batch_normalization_460 (BatchN (None, 10, 16)       64          conv1d_550[0][0]                 
__________________________________________________________________________________________________
activation_544 (Activation)     (None, 10, 16)       0           batch_normalization_460[0][0]    
__________________________________________________________________________________________________
conv1d_551 (Conv1D)             (None, 10, 16)       784         activation_544[0][0]             
__________________________________________________________________________________________________
batch_normalization_461 (BatchN (None, 10, 16)       64          conv1d_551[0][0]                 
__________________________________________________________________________________________________
add_218 (Add)                   (None, 10, 16)       0           activation_543[0][0]             
                                                                 batch_normalization_461[0][0]    
__________________________________________________________________________________________________
activation_545 (Activation)     (None, 10, 16)       0           add_218[0][0]                    
__________________________________________________________________________________________________
conv1d_552 (Conv1D)             (None, 10, 16)       784         activation_545[0][0]             
__________________________________________________________________________________________________
batch_normalization_462 (BatchN (None, 10, 16)       64          conv1d_552[0][0]                 
__________________________________________________________________________________________________
activation_546 (Activation)     (None, 10, 16)       0           batch_normalization_462[0][0]    
__________________________________________________________________________________________________
conv1d_553 (Conv1D)             (None, 10, 16)       784         activation_546[0][0]             
__________________________________________________________________________________________________
batch_normalization_463 (BatchN (None, 10, 16)       64          conv1d_553[0][0]                 
__________________________________________________________________________________________________
add_219 (Add)                   (None, 10, 16)       0           activation_545[0][0]             
                                                                 batch_normalization_463[0][0]    
__________________________________________________________________________________________________
activation_547 (Activation)     (None, 10, 16)       0           add_219[0][0]                    
__________________________________________________________________________________________________
conv1d_554 (Conv1D)             (None, 5, 32)        1568        activation_547[0][0]             
__________________________________________________________________________________________________
batch_normalization_464 (BatchN (None, 5, 32)        128         conv1d_554[0][0]                 
__________________________________________________________________________________________________
activation_548 (Activation)     (None, 5, 32)        0           batch_normalization_464[0][0]    
__________________________________________________________________________________________________
conv1d_555 (Conv1D)             (None, 5, 32)        3104        activation_548[0][0]             
__________________________________________________________________________________________________
conv1d_556 (Conv1D)             (None, 5, 32)        544         activation_547[0][0]             
__________________________________________________________________________________________________
batch_normalization_465 (BatchN (None, 5, 32)        128         conv1d_555[0][0]                 
__________________________________________________________________________________________________
add_220 (Add)                   (None, 5, 32)        0           conv1d_556[0][0]                 
                                                                 batch_normalization_465[0][0]    
__________________________________________________________________________________________________
activation_549 (Activation)     (None, 5, 32)        0           add_220[0][0]                    
__________________________________________________________________________________________________
conv1d_557 (Conv1D)             (None, 5, 32)        3104        activation_549[0][0]             
__________________________________________________________________________________________________
batch_normalization_466 (BatchN (None, 5, 32)        128         conv1d_557[0][0]                 
__________________________________________________________________________________________________
activation_550 (Activation)     (None, 5, 32)        0           batch_normalization_466[0][0]    
__________________________________________________________________________________________________
conv1d_558 (Conv1D)             (None, 5, 32)        3104        activation_550[0][0]             
__________________________________________________________________________________________________
batch_normalization_467 (BatchN (None, 5, 32)        128         conv1d_558[0][0]                 
__________________________________________________________________________________________________
add_221 (Add)                   (None, 5, 32)        0           activation_549[0][0]             
                                                                 batch_normalization_467[0][0]    
__________________________________________________________________________________________________
activation_551 (Activation)     (None, 5, 32)        0           add_221[0][0]                    
__________________________________________________________________________________________________
conv1d_559 (Conv1D)             (None, 5, 32)        3104        activation_551[0][0]             
__________________________________________________________________________________________________
batch_normalization_468 (BatchN (None, 5, 32)        128         conv1d_559[0][0]                 
__________________________________________________________________________________________________
activation_552 (Activation)     (None, 5, 32)        0           batch_normalization_468[0][0]    
__________________________________________________________________________________________________
conv1d_560 (Conv1D)             (None, 5, 32)        3104        activation_552[0][0]             
__________________________________________________________________________________________________
batch_normalization_469 (BatchN (None, 5, 32)        128         conv1d_560[0][0]                 
__________________________________________________________________________________________________
add_222 (Add)                   (None, 5, 32)        0           activation_551[0][0]             
                                                                 batch_normalization_469[0][0]    
__________________________________________________________________________________________________
activation_553 (Activation)     (None, 5, 32)        0           add_222[0][0]                    
__________________________________________________________________________________________________
conv1d_561 (Conv1D)             (None, 3, 64)        6208        activation_553[0][0]             
__________________________________________________________________________________________________
batch_normalization_470 (BatchN (None, 3, 64)        256         conv1d_561[0][0]                 
__________________________________________________________________________________________________
activation_554 (Activation)     (None, 3, 64)        0           batch_normalization_470[0][0]    
__________________________________________________________________________________________________
conv1d_562 (Conv1D)             (None, 3, 64)        12352       activation_554[0][0]             
__________________________________________________________________________________________________
conv1d_563 (Conv1D)             (None, 3, 64)        2112        activation_553[0][0]             
__________________________________________________________________________________________________
batch_normalization_471 (BatchN (None, 3, 64)        256         conv1d_562[0][0]                 
__________________________________________________________________________________________________
add_223 (Add)                   (None, 3, 64)        0           conv1d_563[0][0]                 
                                                                 batch_normalization_471[0][0]    
__________________________________________________________________________________________________
activation_555 (Activation)     (None, 3, 64)        0           add_223[0][0]                    
__________________________________________________________________________________________________
conv1d_564 (Conv1D)             (None, 3, 64)        12352       activation_555[0][0]             
__________________________________________________________________________________________________
batch_normalization_472 (BatchN (None, 3, 64)        256         conv1d_564[0][0]                 
__________________________________________________________________________________________________
activation_556 (Activation)     (None, 3, 64)        0           batch_normalization_472[0][0]    
__________________________________________________________________________________________________
conv1d_565 (Conv1D)             (None, 3, 64)        12352       activation_556[0][0]             
__________________________________________________________________________________________________
batch_normalization_473 (BatchN (None, 3, 64)        256         conv1d_565[0][0]                 
__________________________________________________________________________________________________
add_224 (Add)                   (None, 3, 64)        0           activation_555[0][0]             
                                                                 batch_normalization_473[0][0]    
__________________________________________________________________________________________________
activation_557 (Activation)     (None, 3, 64)        0           add_224[0][0]                    
__________________________________________________________________________________________________
conv1d_566 (Conv1D)             (None, 3, 64)        12352       activation_557[0][0]             
__________________________________________________________________________________________________
batch_normalization_474 (BatchN (None, 3, 64)        256         conv1d_566[0][0]                 
__________________________________________________________________________________________________
activation_558 (Activation)     (None, 3, 64)        0           batch_normalization_474[0][0]    
__________________________________________________________________________________________________
conv1d_567 (Conv1D)             (None, 3, 64)        12352       activation_558[0][0]             
__________________________________________________________________________________________________
batch_normalization_475 (BatchN (None, 3, 64)        256         conv1d_567[0][0]                 
__________________________________________________________________________________________________
add_225 (Add)                   (None, 3, 64)        0           activation_557[0][0]             
                                                                 batch_normalization_475[0][0]    
__________________________________________________________________________________________________
activation_559 (Activation)     (None, 3, 64)        0           add_225[0][0]                    
__________________________________________________________________________________________________
average_pooling1d_25 (AveragePo (None, 3, 64)        0           activation_559[0][0]             
__________________________________________________________________________________________________
flatten_67 (Flatten)            (None, 192)          0           average_pooling1d_25[0][0]       
__________________________________________________________________________________________________
dense_1195 (Dense)              (None, 4)            772         flatten_67[0][0]                 
==================================================================================================
Total params: 96,004
Trainable params: 94,628
Non-trainable params: 1,376
__________________________________________________________________________________________________
None

Accuracy Train: 89.63%
Accuracy Test: 83.59%
Loss Train: 0.53
Loss Test: 0.93
Numero dati esaminati: 1712
True Positive 1431
False Positive 281


------------------------------------------------------------------------
K-fold Cross Validation
------------------------------------------------------------------------
Training for fold 1 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 2s - loss: 0.2414 - accuracy: 0.9671 - val_loss: 0.8712 - val_accuracy: 0.8555
Epoch 2/110
 - 2s - loss: 0.2170 - accuracy: 0.9765 - val_loss: 0.8283 - val_accuracy: 0.8650
Epoch 3/110
 - 2s - loss: 0.2190 - accuracy: 0.9770 - val_loss: 0.8692 - val_accuracy: 0.8562
Epoch 4/110
 - 2s - loss: 0.1976 - accuracy: 0.9816 - val_loss: 0.8200 - val_accuracy: 0.8686
Epoch 5/110
 - 2s - loss: 0.1928 - accuracy: 0.9848 - val_loss: 0.9200 - val_accuracy: 0.8606
Epoch 6/110
 - 2s - loss: 0.1939 - accuracy: 0.9817 - val_loss: 0.8669 - val_accuracy: 0.8511
Epoch 7/110
 - 2s - loss: 0.2140 - accuracy: 0.9775 - val_loss: 0.8704 - val_accuracy: 0.8620
Epoch 8/110
 - 2s - loss: 0.2319 - accuracy: 0.9708 - val_loss: 1.0485 - val_accuracy: 0.8226
Epoch 9/110
 - 2s - loss: 0.2484 - accuracy: 0.9691 - val_loss: 0.8364 - val_accuracy: 0.8511
Epoch 10/110
 - 2s - loss: 0.2152 - accuracy: 0.9741 - val_loss: 0.9111 - val_accuracy: 0.8533
Epoch 11/110
 - 2s - loss: 0.1992 - accuracy: 0.9801 - val_loss: 0.9171 - val_accuracy: 0.8547
Epoch 12/110
 - 2s - loss: 0.1999 - accuracy: 0.9805 - val_loss: 0.8700 - val_accuracy: 0.8438
Epoch 13/110
 - 2s - loss: 0.1919 - accuracy: 0.9832 - val_loss: 0.8423 - val_accuracy: 0.8606
Epoch 14/110
 - 2s - loss: 0.1908 - accuracy: 0.9838 - val_loss: 0.8829 - val_accuracy: 0.8628
Epoch 15/110
 - 2s - loss: 0.2231 - accuracy: 0.9730 - val_loss: 0.9022 - val_accuracy: 0.8526
Epoch 16/110
 - 2s - loss: 0.2398 - accuracy: 0.9648 - val_loss: 0.8451 - val_accuracy: 0.8562
Epoch 17/110
 - 2s - loss: 0.2164 - accuracy: 0.9755 - val_loss: 0.9569 - val_accuracy: 0.8453
Epoch 18/110
 - 2s - loss: 0.2102 - accuracy: 0.9766 - val_loss: 0.8044 - val_accuracy: 0.8591
Epoch 19/110
 - 2s - loss: 0.2063 - accuracy: 0.9774 - val_loss: 0.9360 - val_accuracy: 0.8496
Epoch 20/110
 - 2s - loss: 0.2086 - accuracy: 0.9766 - val_loss: 0.9440 - val_accuracy: 0.8489
Epoch 21/110
 - 2s - loss: 0.2030 - accuracy: 0.9796 - val_loss: 0.8868 - val_accuracy: 0.8547
Epoch 22/110
 - 2s - loss: 0.1859 - accuracy: 0.9847 - val_loss: 0.9342 - val_accuracy: 0.8613
Epoch 23/110
 - 2s - loss: 0.1916 - accuracy: 0.9827 - val_loss: 0.8807 - val_accuracy: 0.8569
Epoch 24/110
 - 2s - loss: 0.2245 - accuracy: 0.9781 - val_loss: 0.8578 - val_accuracy: 0.8489
Epoch 25/110
 - 2s - loss: 0.2099 - accuracy: 0.9765 - val_loss: 0.8588 - val_accuracy: 0.8445
Epoch 26/110
 - 2s - loss: 0.1971 - accuracy: 0.9816 - val_loss: 0.8129 - val_accuracy: 0.8664
Epoch 27/110
 - 2s - loss: 0.1996 - accuracy: 0.9786 - val_loss: 0.8704 - val_accuracy: 0.8526
Epoch 28/110
 - 2s - loss: 0.2254 - accuracy: 0.9715 - val_loss: 0.9895 - val_accuracy: 0.8482
Epoch 29/110
 - 2s - loss: 0.2192 - accuracy: 0.9730 - val_loss: 0.8431 - val_accuracy: 0.8584
Epoch 30/110
 - 2s - loss: 0.2115 - accuracy: 0.9757 - val_loss: 0.8478 - val_accuracy: 0.8504
Epoch 31/110
 - 2s - loss: 0.1916 - accuracy: 0.9828 - val_loss: 0.8557 - val_accuracy: 0.8606
Epoch 32/110
 - 2s - loss: 0.1803 - accuracy: 0.9872 - val_loss: 0.9679 - val_accuracy: 0.8401
Epoch 33/110
 - 2s - loss: 0.1824 - accuracy: 0.9854 - val_loss: 0.8885 - val_accuracy: 0.8438
Epoch 34/110
 - 2s - loss: 0.2055 - accuracy: 0.9763 - val_loss: 1.0563 - val_accuracy: 0.8394
Epoch 35/110
 - 2s - loss: 0.2491 - accuracy: 0.9651 - val_loss: 0.9064 - val_accuracy: 0.8533
Epoch 36/110
 - 2s - loss: 0.2192 - accuracy: 0.9733 - val_loss: 0.8864 - val_accuracy: 0.8518
Epoch 37/110
 - 2s - loss: 0.1847 - accuracy: 0.9847 - val_loss: 0.8488 - val_accuracy: 0.8606
Epoch 38/110
 - 2s - loss: 0.1870 - accuracy: 0.9858 - val_loss: 0.8684 - val_accuracy: 0.8540
Epoch 39/110
 - 2s - loss: 0.2016 - accuracy: 0.9788 - val_loss: 0.8680 - val_accuracy: 0.8628
Epoch 40/110
 - 2s - loss: 0.2050 - accuracy: 0.9803 - val_loss: 0.9007 - val_accuracy: 0.8555
Epoch 41/110
 - 2s - loss: 0.1929 - accuracy: 0.9825 - val_loss: 0.9091 - val_accuracy: 0.8533
Epoch 42/110
 - 2s - loss: 0.1888 - accuracy: 0.9848 - val_loss: 0.9117 - val_accuracy: 0.8467
Epoch 43/110
 - 2s - loss: 0.1854 - accuracy: 0.9848 - val_loss: 0.9295 - val_accuracy: 0.8504
Epoch 44/110
 - 2s - loss: 0.1790 - accuracy: 0.9874 - val_loss: 0.8927 - val_accuracy: 0.8635
Epoch 45/110
 - 2s - loss: 0.1846 - accuracy: 0.9859 - val_loss: 0.9184 - val_accuracy: 0.8504
Epoch 46/110
 - 2s - loss: 0.2083 - accuracy: 0.9754 - val_loss: 0.9829 - val_accuracy: 0.8270
Epoch 47/110
 - 2s - loss: 0.2200 - accuracy: 0.9739 - val_loss: 0.9355 - val_accuracy: 0.8496
Epoch 48/110
 - 2s - loss: 0.2000 - accuracy: 0.9801 - val_loss: 0.9132 - val_accuracy: 0.8511
Epoch 49/110
 - 2s - loss: 0.2050 - accuracy: 0.9772 - val_loss: 0.8674 - val_accuracy: 0.8613
Epoch 50/110
 - 2s - loss: 0.2024 - accuracy: 0.9759 - val_loss: 0.8143 - val_accuracy: 0.8547
Epoch 51/110
 - 2s - loss: 0.2189 - accuracy: 0.9735 - val_loss: 0.8971 - val_accuracy: 0.8496
Epoch 52/110
 - 2s - loss: 0.1947 - accuracy: 0.9839 - val_loss: 0.8855 - val_accuracy: 0.8577
Epoch 53/110
 - 2s - loss: 0.1812 - accuracy: 0.9838 - val_loss: 0.9340 - val_accuracy: 0.8416
Epoch 54/110
 - 2s - loss: 0.2158 - accuracy: 0.9750 - val_loss: 0.9130 - val_accuracy: 0.8504
Epoch 55/110
 - 2s - loss: 0.1942 - accuracy: 0.9801 - val_loss: 0.8741 - val_accuracy: 0.8584
Epoch 56/110
 - 2s - loss: 0.2003 - accuracy: 0.9796 - val_loss: 0.8391 - val_accuracy: 0.8591
Epoch 57/110
 - 2s - loss: 0.1878 - accuracy: 0.9838 - val_loss: 0.9584 - val_accuracy: 0.8547
Epoch 58/110
 - 2s - loss: 0.1779 - accuracy: 0.9878 - val_loss: 0.9529 - val_accuracy: 0.8591
Epoch 59/110
 - 2s - loss: 0.1766 - accuracy: 0.9863 - val_loss: 0.8876 - val_accuracy: 0.8679
Epoch 60/110
 - 2s - loss: 0.1842 - accuracy: 0.9836 - val_loss: 0.9327 - val_accuracy: 0.8526
Epoch 61/110
 - 2s - loss: 0.1776 - accuracy: 0.9867 - val_loss: 0.8612 - val_accuracy: 0.8620
Epoch 62/110
 - 2s - loss: 0.1898 - accuracy: 0.9828 - val_loss: 0.9358 - val_accuracy: 0.8526
Epoch 63/110
 - 2s - loss: 0.2289 - accuracy: 0.9690 - val_loss: 0.9872 - val_accuracy: 0.8416
Epoch 64/110
 - 2s - loss: 0.2019 - accuracy: 0.9783 - val_loss: 0.9468 - val_accuracy: 0.8423
Epoch 65/110
 - 2s - loss: 0.1758 - accuracy: 0.9865 - val_loss: 0.8761 - val_accuracy: 0.8526
Epoch 66/110
 - 2s - loss: 0.1800 - accuracy: 0.9876 - val_loss: 0.8308 - val_accuracy: 0.8599
Epoch 67/110
 - 2s - loss: 0.1722 - accuracy: 0.9870 - val_loss: 0.8762 - val_accuracy: 0.8562
Epoch 68/110
 - 2s - loss: 0.1911 - accuracy: 0.9819 - val_loss: 0.9261 - val_accuracy: 0.8394
Epoch 69/110
 - 2s - loss: 0.2105 - accuracy: 0.9746 - val_loss: 0.9865 - val_accuracy: 0.8380
Epoch 70/110
 - 2s - loss: 0.2575 - accuracy: 0.9618 - val_loss: 0.9167 - val_accuracy: 0.8533
Epoch 71/110
 - 2s - loss: 0.2107 - accuracy: 0.9750 - val_loss: 0.8160 - val_accuracy: 0.8540
Epoch 72/110
 - 2s - loss: 0.1872 - accuracy: 0.9836 - val_loss: 0.8708 - val_accuracy: 0.8467
Epoch 73/110
 - 2s - loss: 0.1653 - accuracy: 0.9896 - val_loss: 0.8710 - val_accuracy: 0.8635
Epoch 74/110
 - 2s - loss: 0.1721 - accuracy: 0.9885 - val_loss: 0.8414 - val_accuracy: 0.8606
Epoch 75/110
 - 2s - loss: 0.1701 - accuracy: 0.9900 - val_loss: 0.8341 - val_accuracy: 0.8664
Epoch 76/110
 - 2s - loss: 0.1546 - accuracy: 0.9932 - val_loss: 0.8387 - val_accuracy: 0.8657
Epoch 77/110
 - 2s - loss: 0.1509 - accuracy: 0.9956 - val_loss: 0.9527 - val_accuracy: 0.8613
Epoch 78/110
 - 2s - loss: 0.1658 - accuracy: 0.9907 - val_loss: 0.8413 - val_accuracy: 0.8642
Epoch 79/110
 - 2s - loss: 0.1772 - accuracy: 0.9856 - val_loss: 0.9274 - val_accuracy: 0.8591
Epoch 80/110
 - 2s - loss: 0.2370 - accuracy: 0.9664 - val_loss: 1.0629 - val_accuracy: 0.8321
Epoch 81/110
 - 2s - loss: 0.2641 - accuracy: 0.9558 - val_loss: 0.9847 - val_accuracy: 0.8387
Epoch 82/110
 - 2s - loss: 0.2354 - accuracy: 0.9637 - val_loss: 0.9023 - val_accuracy: 0.8577
Epoch 83/110
 - 2s - loss: 0.1930 - accuracy: 0.9819 - val_loss: 0.9081 - val_accuracy: 0.8591
Epoch 84/110
 - 2s - loss: 0.1759 - accuracy: 0.9867 - val_loss: 0.8424 - val_accuracy: 0.8591
Epoch 85/110
 - 2s - loss: 0.1580 - accuracy: 0.9922 - val_loss: 0.8486 - val_accuracy: 0.8642
Epoch 86/110
 - 2s - loss: 0.1533 - accuracy: 0.9932 - val_loss: 0.8288 - val_accuracy: 0.8650
Epoch 87/110
 - 2s - loss: 0.1539 - accuracy: 0.9925 - val_loss: 0.9230 - val_accuracy: 0.8584
Epoch 88/110
 - 2s - loss: 0.1623 - accuracy: 0.9907 - val_loss: 0.9463 - val_accuracy: 0.8569
Epoch 89/110
 - 2s - loss: 0.1791 - accuracy: 0.9856 - val_loss: 0.9270 - val_accuracy: 0.8460
Epoch 90/110
 - 2s - loss: 0.1953 - accuracy: 0.9810 - val_loss: 0.9752 - val_accuracy: 0.8423
Epoch 91/110
 - 2s - loss: 0.2203 - accuracy: 0.9713 - val_loss: 0.8220 - val_accuracy: 0.8562
Epoch 92/110
 - 2s - loss: 0.2080 - accuracy: 0.9744 - val_loss: 0.8349 - val_accuracy: 0.8577
Epoch 93/110
 - 2s - loss: 0.1872 - accuracy: 0.9797 - val_loss: 0.8289 - val_accuracy: 0.8642
Epoch 94/110
 - 2s - loss: 0.1706 - accuracy: 0.9880 - val_loss: 0.8190 - val_accuracy: 0.8635
Epoch 95/110
 - 2s - loss: 0.1702 - accuracy: 0.9872 - val_loss: 0.8949 - val_accuracy: 0.8613
Epoch 96/110
 - 3s - loss: 0.1683 - accuracy: 0.9883 - val_loss: 0.9264 - val_accuracy: 0.8628
Epoch 97/110
 - 2s - loss: 0.1830 - accuracy: 0.9838 - val_loss: 0.8225 - val_accuracy: 0.8679
Epoch 98/110
 - 2s - loss: 0.1738 - accuracy: 0.9861 - val_loss: 0.9163 - val_accuracy: 0.8584
Epoch 99/110
 - 2s - loss: 0.1591 - accuracy: 0.9903 - val_loss: 0.9186 - val_accuracy: 0.8591
Epoch 100/110
 - 2s - loss: 0.1707 - accuracy: 0.9861 - val_loss: 0.9036 - val_accuracy: 0.8555
Epoch 101/110
 - 2s - loss: 0.1877 - accuracy: 0.9814 - val_loss: 0.9041 - val_accuracy: 0.8511
Epoch 102/110
 - 2s - loss: 0.2447 - accuracy: 0.9671 - val_loss: 0.9409 - val_accuracy: 0.8526
Epoch 103/110
 - 3s - loss: 0.1873 - accuracy: 0.9805 - val_loss: 0.8159 - val_accuracy: 0.8599
Epoch 104/110
 - 2s - loss: 0.1752 - accuracy: 0.9867 - val_loss: 0.8349 - val_accuracy: 0.8511
Epoch 105/110
 - 3s - loss: 0.1708 - accuracy: 0.9870 - val_loss: 0.8887 - val_accuracy: 0.8518
Epoch 106/110
 - 3s - loss: 0.1547 - accuracy: 0.9911 - val_loss: 0.9039 - val_accuracy: 0.8628
Epoch 107/110
 - 3s - loss: 0.1678 - accuracy: 0.9885 - val_loss: 0.9632 - val_accuracy: 0.8482
Epoch 108/110
 - 3s - loss: 0.1737 - accuracy: 0.9854 - val_loss: 0.9480 - val_accuracy: 0.8628
Epoch 109/110
 - 3s - loss: 0.1792 - accuracy: 0.9850 - val_loss: 0.8892 - val_accuracy: 0.8533
Epoch 110/110
 - 3s - loss: 0.1776 - accuracy: 0.9836 - val_loss: 0.9544 - val_accuracy: 0.8606
------------------------------------------------------------------------
Training for fold 2 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 2s - loss: 0.1869 - accuracy: 0.9825 - val_loss: 0.8659 - val_accuracy: 0.8482
Epoch 2/110
 - 2s - loss: 0.1823 - accuracy: 0.9810 - val_loss: 0.8612 - val_accuracy: 0.8518
Epoch 3/110
 - 2s - loss: 0.1917 - accuracy: 0.9790 - val_loss: 0.9135 - val_accuracy: 0.8496
Epoch 4/110
 - 2s - loss: 0.2068 - accuracy: 0.9765 - val_loss: 0.8217 - val_accuracy: 0.8635
Epoch 5/110
 - 3s - loss: 0.1815 - accuracy: 0.9812 - val_loss: 0.8382 - val_accuracy: 0.8664
Epoch 6/110
 - 2s - loss: 0.1778 - accuracy: 0.9850 - val_loss: 0.8350 - val_accuracy: 0.8555
Epoch 7/110
 - 2s - loss: 0.1777 - accuracy: 0.9830 - val_loss: 0.9114 - val_accuracy: 0.8591
Epoch 8/110
 - 2s - loss: 0.1602 - accuracy: 0.9894 - val_loss: 0.8602 - val_accuracy: 0.8555
Epoch 9/110
 - 2s - loss: 0.1595 - accuracy: 0.9911 - val_loss: 0.9025 - val_accuracy: 0.8672
Epoch 10/110
 - 2s - loss: 0.1556 - accuracy: 0.9916 - val_loss: 0.8950 - val_accuracy: 0.8635
Epoch 11/110
 - 2s - loss: 0.1592 - accuracy: 0.9923 - val_loss: 0.9351 - val_accuracy: 0.8533
Epoch 12/110
 - 2s - loss: 0.2177 - accuracy: 0.9728 - val_loss: 0.9822 - val_accuracy: 0.8474
Epoch 13/110
 - 2s - loss: 0.1944 - accuracy: 0.9788 - val_loss: 0.8147 - val_accuracy: 0.8613
Epoch 14/110
 - 2s - loss: 0.2134 - accuracy: 0.9723 - val_loss: 0.9077 - val_accuracy: 0.8482
Epoch 15/110
 - 2s - loss: 0.1848 - accuracy: 0.9819 - val_loss: 0.8335 - val_accuracy: 0.8591
Epoch 16/110
 - 2s - loss: 0.1595 - accuracy: 0.9889 - val_loss: 0.8483 - val_accuracy: 0.8577
Epoch 17/110
 - 2s - loss: 0.1578 - accuracy: 0.9918 - val_loss: 0.8186 - val_accuracy: 0.8562
Epoch 18/110
 - 2s - loss: 0.1504 - accuracy: 0.9923 - val_loss: 0.8042 - val_accuracy: 0.8679
Epoch 19/110
 - 2s - loss: 0.1551 - accuracy: 0.9916 - val_loss: 0.8532 - val_accuracy: 0.8679
Epoch 20/110
 - 2s - loss: 0.1513 - accuracy: 0.9925 - val_loss: 0.8797 - val_accuracy: 0.8562
Epoch 21/110
 - 2s - loss: 0.1611 - accuracy: 0.9900 - val_loss: 0.8953 - val_accuracy: 0.8526
Epoch 22/110
 - 3s - loss: 0.1733 - accuracy: 0.9859 - val_loss: 0.8634 - val_accuracy: 0.8613
Epoch 23/110
 - 3s - loss: 0.1935 - accuracy: 0.9786 - val_loss: 0.9503 - val_accuracy: 0.8511
Epoch 24/110
 - 3s - loss: 0.1932 - accuracy: 0.9790 - val_loss: 0.8977 - val_accuracy: 0.8533
Epoch 25/110
 - 3s - loss: 0.1885 - accuracy: 0.9817 - val_loss: 0.8726 - val_accuracy: 0.8547
Epoch 26/110
 - 2s - loss: 0.1821 - accuracy: 0.9839 - val_loss: 0.8600 - val_accuracy: 0.8569
Epoch 27/110
 - 2s - loss: 0.1867 - accuracy: 0.9828 - val_loss: 0.8645 - val_accuracy: 0.8657
Epoch 28/110
 - 2s - loss: 0.1533 - accuracy: 0.9931 - val_loss: 0.8580 - val_accuracy: 0.8686
Epoch 29/110
 - 2s - loss: 0.1426 - accuracy: 0.9943 - val_loss: 0.8826 - val_accuracy: 0.8540
Epoch 30/110
 - 2s - loss: 0.1536 - accuracy: 0.9922 - val_loss: 0.9445 - val_accuracy: 0.8613
Epoch 31/110
 - 2s - loss: 0.1793 - accuracy: 0.9841 - val_loss: 0.8554 - val_accuracy: 0.8708
Epoch 32/110
 - 2s - loss: 0.1687 - accuracy: 0.9870 - val_loss: 0.8996 - val_accuracy: 0.8547
Epoch 33/110
 - 2s - loss: 0.1633 - accuracy: 0.9870 - val_loss: 0.8531 - val_accuracy: 0.8599
Epoch 34/110
 - 2s - loss: 0.1900 - accuracy: 0.9781 - val_loss: 0.8736 - val_accuracy: 0.8584
Epoch 35/110
 - 2s - loss: 0.1839 - accuracy: 0.9812 - val_loss: 0.8147 - val_accuracy: 0.8635
Epoch 36/110
 - 2s - loss: 0.1700 - accuracy: 0.9861 - val_loss: 0.8470 - val_accuracy: 0.8628
Epoch 37/110
 - 2s - loss: 0.1637 - accuracy: 0.9889 - val_loss: 0.8905 - val_accuracy: 0.8504
Epoch 38/110
 - 2s - loss: 0.1902 - accuracy: 0.9817 - val_loss: 0.8620 - val_accuracy: 0.8496
Epoch 39/110
 - 2s - loss: 0.1700 - accuracy: 0.9850 - val_loss: 0.8366 - val_accuracy: 0.8504
Epoch 40/110
 - 2s - loss: 0.2066 - accuracy: 0.9746 - val_loss: 0.8998 - val_accuracy: 0.8511
Epoch 41/110
 - 2s - loss: 0.1670 - accuracy: 0.9874 - val_loss: 0.8107 - val_accuracy: 0.8672
Epoch 42/110
 - 2s - loss: 0.1663 - accuracy: 0.9883 - val_loss: 0.7753 - val_accuracy: 0.8672
Epoch 43/110
 - 2s - loss: 0.1629 - accuracy: 0.9896 - val_loss: 0.8245 - val_accuracy: 0.8489
Epoch 44/110
 - 2s - loss: 0.1557 - accuracy: 0.9900 - val_loss: 0.8654 - val_accuracy: 0.8533
Epoch 45/110
 - 2s - loss: 0.1606 - accuracy: 0.9883 - val_loss: 0.8090 - val_accuracy: 0.8657
Epoch 46/110
 - 2s - loss: 0.1575 - accuracy: 0.9900 - val_loss: 0.9260 - val_accuracy: 0.8562
Epoch 47/110
 - 2s - loss: 0.1769 - accuracy: 0.9819 - val_loss: 0.9332 - val_accuracy: 0.8453
Epoch 48/110
 - 2s - loss: 0.1865 - accuracy: 0.9814 - val_loss: 0.8936 - val_accuracy: 0.8518
Epoch 49/110
 - 2s - loss: 0.1652 - accuracy: 0.9869 - val_loss: 0.8755 - val_accuracy: 0.8606
Epoch 50/110
 - 2s - loss: 0.1759 - accuracy: 0.9819 - val_loss: 0.8876 - val_accuracy: 0.8635
Epoch 51/110
 - 2s - loss: 0.2136 - accuracy: 0.9695 - val_loss: 0.9445 - val_accuracy: 0.8467
Epoch 52/110
 - 2s - loss: 0.1680 - accuracy: 0.9865 - val_loss: 0.8349 - val_accuracy: 0.8555
Epoch 53/110
 - 2s - loss: 0.1730 - accuracy: 0.9847 - val_loss: 0.8310 - val_accuracy: 0.8708
Epoch 54/110
 - 2s - loss: 0.1620 - accuracy: 0.9896 - val_loss: 0.8729 - val_accuracy: 0.8650
Epoch 55/110
 - 2s - loss: 0.1538 - accuracy: 0.9916 - val_loss: 0.8076 - val_accuracy: 0.8701
Epoch 56/110
 - 2s - loss: 0.1485 - accuracy: 0.9943 - val_loss: 0.8385 - val_accuracy: 0.8562
Epoch 57/110
 - 2s - loss: 0.1474 - accuracy: 0.9931 - val_loss: 0.8545 - val_accuracy: 0.8613
Epoch 58/110
 - 2s - loss: 0.1362 - accuracy: 0.9960 - val_loss: 0.8677 - val_accuracy: 0.8628
Epoch 59/110
 - 2s - loss: 0.1398 - accuracy: 0.9953 - val_loss: 0.8456 - val_accuracy: 0.8672
Epoch 60/110
 - 2s - loss: 0.1344 - accuracy: 0.9954 - val_loss: 0.8407 - val_accuracy: 0.8737
Epoch 61/110
 - 2s - loss: 0.1433 - accuracy: 0.9925 - val_loss: 0.8675 - val_accuracy: 0.8642
Epoch 62/110
 - 2s - loss: 0.1985 - accuracy: 0.9805 - val_loss: 0.9718 - val_accuracy: 0.8526
Epoch 63/110
 - 2s - loss: 0.2058 - accuracy: 0.9741 - val_loss: 0.8912 - val_accuracy: 0.8445
Epoch 64/110
 - 2s - loss: 0.1720 - accuracy: 0.9834 - val_loss: 0.8758 - val_accuracy: 0.8533
Epoch 65/110
 - 2s - loss: 0.1922 - accuracy: 0.9754 - val_loss: 0.8087 - val_accuracy: 0.8657
Epoch 66/110
 - 2s - loss: 0.1613 - accuracy: 0.9883 - val_loss: 0.8123 - val_accuracy: 0.8635
Epoch 67/110
 - 2s - loss: 0.1524 - accuracy: 0.9914 - val_loss: 0.7969 - val_accuracy: 0.8628
Epoch 68/110
 - 2s - loss: 0.1473 - accuracy: 0.9918 - val_loss: 0.8817 - val_accuracy: 0.8606
Epoch 69/110
 - 2s - loss: 0.1487 - accuracy: 0.9918 - val_loss: 0.9110 - val_accuracy: 0.8613
Epoch 70/110
 - 2s - loss: 0.1905 - accuracy: 0.9781 - val_loss: 0.8938 - val_accuracy: 0.8453
Epoch 71/110
 - 2s - loss: 0.1824 - accuracy: 0.9825 - val_loss: 0.8582 - val_accuracy: 0.8620
Epoch 72/110
 - 2s - loss: 0.1680 - accuracy: 0.9861 - val_loss: 0.9161 - val_accuracy: 0.8489
Epoch 73/110
 - 2s - loss: 0.1546 - accuracy: 0.9898 - val_loss: 0.9205 - val_accuracy: 0.8606
Epoch 74/110
 - 2s - loss: 0.1476 - accuracy: 0.9911 - val_loss: 0.9288 - val_accuracy: 0.8540
Epoch 75/110
 - 2s - loss: 0.1445 - accuracy: 0.9923 - val_loss: 0.8535 - val_accuracy: 0.8584
Epoch 76/110
 - 2s - loss: 0.1452 - accuracy: 0.9920 - val_loss: 0.9093 - val_accuracy: 0.8613
Epoch 77/110
 - 2s - loss: 0.1483 - accuracy: 0.9927 - val_loss: 0.8536 - val_accuracy: 0.8606
Epoch 78/110
 - 2s - loss: 0.1588 - accuracy: 0.9869 - val_loss: 0.8641 - val_accuracy: 0.8562
Epoch 79/110
 - 2s - loss: 0.1860 - accuracy: 0.9796 - val_loss: 0.8682 - val_accuracy: 0.8518
Epoch 80/110
 - 2s - loss: 0.1674 - accuracy: 0.9838 - val_loss: 0.8600 - val_accuracy: 0.8591
Epoch 81/110
 - 2s - loss: 0.1737 - accuracy: 0.9817 - val_loss: 0.9189 - val_accuracy: 0.8540
Epoch 82/110
 - 2s - loss: 0.1692 - accuracy: 0.9843 - val_loss: 0.8620 - val_accuracy: 0.8613
Epoch 83/110
 - 2s - loss: 0.1724 - accuracy: 0.9832 - val_loss: 0.8156 - val_accuracy: 0.8599
Epoch 84/110
 - 2s - loss: 0.1569 - accuracy: 0.9867 - val_loss: 0.8660 - val_accuracy: 0.8642
Epoch 85/110
 - 2s - loss: 0.1647 - accuracy: 0.9858 - val_loss: 0.8836 - val_accuracy: 0.8547
Epoch 86/110
 - 2s - loss: 0.1712 - accuracy: 0.9823 - val_loss: 0.8078 - val_accuracy: 0.8679
Epoch 87/110
 - 2s - loss: 0.1558 - accuracy: 0.9881 - val_loss: 0.8148 - val_accuracy: 0.8628
Epoch 88/110
 - 2s - loss: 0.1710 - accuracy: 0.9814 - val_loss: 0.9465 - val_accuracy: 0.8409
Epoch 89/110
 - 2s - loss: 0.1872 - accuracy: 0.9790 - val_loss: 0.7975 - val_accuracy: 0.8620
Epoch 90/110
 - 2s - loss: 0.1538 - accuracy: 0.9890 - val_loss: 0.7750 - val_accuracy: 0.8642
Epoch 91/110
 - 2s - loss: 0.1466 - accuracy: 0.9912 - val_loss: 0.8564 - val_accuracy: 0.8686
Epoch 92/110
 - 2s - loss: 0.1834 - accuracy: 0.9790 - val_loss: 0.8904 - val_accuracy: 0.8409
Epoch 93/110
 - 2s - loss: 0.1592 - accuracy: 0.9878 - val_loss: 0.8716 - val_accuracy: 0.8445
Epoch 94/110
 - 2s - loss: 0.1639 - accuracy: 0.9885 - val_loss: 0.8530 - val_accuracy: 0.8591
Epoch 95/110
 - 2s - loss: 0.1434 - accuracy: 0.9927 - val_loss: 0.8876 - val_accuracy: 0.8584
Epoch 96/110
 - 2s - loss: 0.1354 - accuracy: 0.9953 - val_loss: 0.8805 - val_accuracy: 0.8599
Epoch 97/110
 - 2s - loss: 0.1394 - accuracy: 0.9934 - val_loss: 0.9484 - val_accuracy: 0.8547
Epoch 98/110
 - 2s - loss: 0.1453 - accuracy: 0.9907 - val_loss: 0.9054 - val_accuracy: 0.8555
Epoch 99/110
 - 2s - loss: 0.1558 - accuracy: 0.9876 - val_loss: 0.9065 - val_accuracy: 0.8591
Epoch 100/110
 - 2s - loss: 0.1515 - accuracy: 0.9872 - val_loss: 0.9910 - val_accuracy: 0.8533
Epoch 101/110
 - 2s - loss: 0.2265 - accuracy: 0.9675 - val_loss: 0.9852 - val_accuracy: 0.8175
Epoch 102/110
 - 2s - loss: 0.2369 - accuracy: 0.9604 - val_loss: 0.8463 - val_accuracy: 0.8591
Epoch 103/110
 - 2s - loss: 0.1604 - accuracy: 0.9861 - val_loss: 0.8104 - val_accuracy: 0.8642
Epoch 104/110
 - 2s - loss: 0.1412 - accuracy: 0.9945 - val_loss: 0.8493 - val_accuracy: 0.8650
Epoch 105/110
 - 2s - loss: 0.1376 - accuracy: 0.9947 - val_loss: 0.8342 - val_accuracy: 0.8679
Epoch 106/110
 - 2s - loss: 0.1339 - accuracy: 0.9962 - val_loss: 0.8498 - val_accuracy: 0.8701
Epoch 107/110
 - 2s - loss: 0.1280 - accuracy: 0.9965 - val_loss: 0.8658 - val_accuracy: 0.8745
Epoch 108/110
 - 2s - loss: 0.1290 - accuracy: 0.9971 - val_loss: 0.9174 - val_accuracy: 0.8569
Epoch 109/110
 - 2s - loss: 0.1324 - accuracy: 0.9954 - val_loss: 0.8805 - val_accuracy: 0.8562
Epoch 110/110
 - 2s - loss: 0.1479 - accuracy: 0.9900 - val_loss: 0.9066 - val_accuracy: 0.8504
------------------------------------------------------------------------
Training for fold 3 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 2s - loss: 0.1723 - accuracy: 0.9816 - val_loss: 0.9404 - val_accuracy: 0.8533
Epoch 2/110
 - 2s - loss: 0.1985 - accuracy: 0.9733 - val_loss: 0.8919 - val_accuracy: 0.8547
Epoch 3/110
 - 2s - loss: 0.1675 - accuracy: 0.9832 - val_loss: 0.8151 - val_accuracy: 0.8613
Epoch 4/110
 - 2s - loss: 0.1507 - accuracy: 0.9865 - val_loss: 0.8419 - val_accuracy: 0.8453
Epoch 5/110
 - 2s - loss: 0.1468 - accuracy: 0.9905 - val_loss: 0.8399 - val_accuracy: 0.8715
Epoch 6/110
 - 2s - loss: 0.1496 - accuracy: 0.9903 - val_loss: 0.8592 - val_accuracy: 0.8650
Epoch 7/110
 - 2s - loss: 0.1640 - accuracy: 0.9863 - val_loss: 0.8857 - val_accuracy: 0.8511
Epoch 8/110
 - 2s - loss: 0.1581 - accuracy: 0.9858 - val_loss: 0.9906 - val_accuracy: 0.8504
Epoch 9/110
 - 2s - loss: 0.1801 - accuracy: 0.9797 - val_loss: 0.9217 - val_accuracy: 0.8423
Epoch 10/110
 - 2s - loss: 0.1732 - accuracy: 0.9819 - val_loss: 0.8864 - val_accuracy: 0.8416
Epoch 11/110
 - 2s - loss: 0.1785 - accuracy: 0.9801 - val_loss: 0.8201 - val_accuracy: 0.8679
Epoch 12/110
 - 2s - loss: 0.1533 - accuracy: 0.9892 - val_loss: 0.8319 - val_accuracy: 0.8642
Epoch 13/110
 - 2s - loss: 0.1457 - accuracy: 0.9907 - val_loss: 0.8120 - val_accuracy: 0.8664
Epoch 14/110
 - 2s - loss: 0.1537 - accuracy: 0.9905 - val_loss: 0.8771 - val_accuracy: 0.8664
Epoch 15/110
 - 3s - loss: 0.1358 - accuracy: 0.9936 - val_loss: 0.8324 - val_accuracy: 0.8657
Epoch 16/110
 - 2s - loss: 0.1311 - accuracy: 0.9947 - val_loss: 0.8716 - val_accuracy: 0.8650
Epoch 17/110
 - 2s - loss: 0.1406 - accuracy: 0.9932 - val_loss: 0.8913 - val_accuracy: 0.8650
Epoch 18/110
 - 2s - loss: 0.1377 - accuracy: 0.9936 - val_loss: 0.8349 - val_accuracy: 0.8679
Epoch 19/110
 - 2s - loss: 0.1305 - accuracy: 0.9949 - val_loss: 0.8462 - val_accuracy: 0.8781
Epoch 20/110
 - 2s - loss: 0.1282 - accuracy: 0.9949 - val_loss: 0.8792 - val_accuracy: 0.8657
Epoch 21/110
 - 2s - loss: 0.1438 - accuracy: 0.9916 - val_loss: 0.8898 - val_accuracy: 0.8613
Epoch 22/110
 - 2s - loss: 0.1478 - accuracy: 0.9903 - val_loss: 0.9514 - val_accuracy: 0.8591
Epoch 23/110
 - 2s - loss: 0.1428 - accuracy: 0.9894 - val_loss: 0.9428 - val_accuracy: 0.8518
Epoch 24/110
 - 2s - loss: 0.1900 - accuracy: 0.9766 - val_loss: 0.8979 - val_accuracy: 0.8504
Epoch 25/110
 - 2s - loss: 0.2096 - accuracy: 0.9688 - val_loss: 0.8822 - val_accuracy: 0.8423
Epoch 26/110
 - 2s - loss: 0.2008 - accuracy: 0.9730 - val_loss: 0.8559 - val_accuracy: 0.8511
Epoch 27/110
 - 2s - loss: 0.1725 - accuracy: 0.9841 - val_loss: 0.8327 - val_accuracy: 0.8562
Epoch 28/110
 - 2s - loss: 0.1463 - accuracy: 0.9890 - val_loss: 0.8173 - val_accuracy: 0.8642
Epoch 29/110
 - 2s - loss: 0.1298 - accuracy: 0.9953 - val_loss: 0.8104 - val_accuracy: 0.8613
Epoch 30/110
 - 2s - loss: 0.1278 - accuracy: 0.9962 - val_loss: 0.8982 - val_accuracy: 0.8577
Epoch 31/110
 - 2s - loss: 0.1265 - accuracy: 0.9967 - val_loss: 0.8574 - val_accuracy: 0.8664
Epoch 32/110
 - 2s - loss: 0.1301 - accuracy: 0.9958 - val_loss: 0.9168 - val_accuracy: 0.8504
Epoch 33/110
 - 2s - loss: 0.1553 - accuracy: 0.9867 - val_loss: 0.9488 - val_accuracy: 0.8518
Epoch 34/110
 - 2s - loss: 0.1562 - accuracy: 0.9850 - val_loss: 0.8633 - val_accuracy: 0.8511
Epoch 35/110
 - 2s - loss: 0.1593 - accuracy: 0.9863 - val_loss: 0.8981 - val_accuracy: 0.8438
Epoch 36/110
 - 2s - loss: 0.1622 - accuracy: 0.9839 - val_loss: 0.9478 - val_accuracy: 0.8467
Epoch 37/110
 - 2s - loss: 0.1408 - accuracy: 0.9916 - val_loss: 0.8337 - val_accuracy: 0.8657
Epoch 38/110
 - 2s - loss: 0.1407 - accuracy: 0.9934 - val_loss: 0.8787 - val_accuracy: 0.8453
Epoch 39/110
 - 2s - loss: 0.1584 - accuracy: 0.9870 - val_loss: 0.8063 - val_accuracy: 0.8533
Epoch 40/110
 - 3s - loss: 0.1663 - accuracy: 0.9828 - val_loss: 0.9058 - val_accuracy: 0.8445
Epoch 41/110
 - 2s - loss: 0.1634 - accuracy: 0.9845 - val_loss: 0.8736 - val_accuracy: 0.8467
Epoch 42/110
 - 2s - loss: 0.1612 - accuracy: 0.9861 - val_loss: 0.8065 - val_accuracy: 0.8679
Epoch 43/110
 - 2s - loss: 0.1692 - accuracy: 0.9832 - val_loss: 0.8155 - val_accuracy: 0.8445
Epoch 44/110
 - 2s - loss: 0.1548 - accuracy: 0.9876 - val_loss: 0.8271 - val_accuracy: 0.8547
Epoch 45/110
 - 2s - loss: 0.1411 - accuracy: 0.9907 - val_loss: 0.8240 - val_accuracy: 0.8591
Epoch 46/110
 - 2s - loss: 0.1409 - accuracy: 0.9932 - val_loss: 0.7727 - val_accuracy: 0.8650
Epoch 47/110
 - 2s - loss: 0.1503 - accuracy: 0.9901 - val_loss: 0.8667 - val_accuracy: 0.8474
Epoch 48/110
 - 2s - loss: 0.1430 - accuracy: 0.9911 - val_loss: 0.8370 - val_accuracy: 0.8635
Epoch 49/110
 - 2s - loss: 0.1307 - accuracy: 0.9936 - val_loss: 0.8584 - val_accuracy: 0.8613
Epoch 50/110
 - 2s - loss: 0.1358 - accuracy: 0.9936 - val_loss: 0.8705 - val_accuracy: 0.8533
Epoch 51/110
 - 3s - loss: 0.1769 - accuracy: 0.9814 - val_loss: 0.9038 - val_accuracy: 0.8547
Epoch 52/110
 - 2s - loss: 0.1605 - accuracy: 0.9861 - val_loss: 0.8223 - val_accuracy: 0.8577
Epoch 53/110
 - 3s - loss: 0.1552 - accuracy: 0.9861 - val_loss: 0.8370 - val_accuracy: 0.8533
Epoch 54/110
 - 2s - loss: 0.1377 - accuracy: 0.9925 - val_loss: 0.8622 - val_accuracy: 0.8584
Epoch 55/110
 - 2s - loss: 0.1335 - accuracy: 0.9940 - val_loss: 0.8260 - val_accuracy: 0.8562
Epoch 56/110
 - 2s - loss: 0.1351 - accuracy: 0.9938 - val_loss: 0.8366 - val_accuracy: 0.8599
Epoch 57/110
 - 2s - loss: 0.1322 - accuracy: 0.9936 - val_loss: 0.8535 - val_accuracy: 0.8533
Epoch 58/110
 - 2s - loss: 0.1740 - accuracy: 0.9819 - val_loss: 0.8949 - val_accuracy: 0.8489
Epoch 59/110
 - 2s - loss: 0.1600 - accuracy: 0.9838 - val_loss: 0.8603 - val_accuracy: 0.8518
Epoch 60/110
 - 3s - loss: 0.1724 - accuracy: 0.9825 - val_loss: 0.8769 - val_accuracy: 0.8467
Epoch 61/110
 - 2s - loss: 0.1638 - accuracy: 0.9834 - val_loss: 0.8060 - val_accuracy: 0.8628
Epoch 62/110
 - 3s - loss: 0.1333 - accuracy: 0.9934 - val_loss: 0.7619 - val_accuracy: 0.8620
Epoch 63/110
 - 2s - loss: 0.1264 - accuracy: 0.9962 - val_loss: 0.8096 - val_accuracy: 0.8693
Epoch 64/110
 - 2s - loss: 0.1170 - accuracy: 0.9985 - val_loss: 0.8118 - val_accuracy: 0.8657
Epoch 65/110
 - 2s - loss: 0.1179 - accuracy: 0.9978 - val_loss: 0.8173 - val_accuracy: 0.8730
Epoch 66/110
 - 2s - loss: 0.1197 - accuracy: 0.9969 - val_loss: 0.9059 - val_accuracy: 0.8555
Epoch 67/110
 - 2s - loss: 0.1342 - accuracy: 0.9934 - val_loss: 0.9330 - val_accuracy: 0.8540
Epoch 68/110
 - 3s - loss: 0.1870 - accuracy: 0.9766 - val_loss: 0.9879 - val_accuracy: 0.8482
Epoch 69/110
 - 3s - loss: 0.2161 - accuracy: 0.9682 - val_loss: 0.7564 - val_accuracy: 0.8504
Epoch 70/110
 - 2s - loss: 0.1885 - accuracy: 0.9777 - val_loss: 0.7585 - val_accuracy: 0.8606
Epoch 71/110
 - 2s - loss: 0.1455 - accuracy: 0.9894 - val_loss: 0.7548 - val_accuracy: 0.8672
Epoch 72/110
 - 2s - loss: 0.1339 - accuracy: 0.9938 - val_loss: 0.7883 - val_accuracy: 0.8599
Epoch 73/110
 - 2s - loss: 0.1238 - accuracy: 0.9958 - val_loss: 0.8014 - val_accuracy: 0.8723
Epoch 74/110
 - 2s - loss: 0.1290 - accuracy: 0.9945 - val_loss: 0.7785 - val_accuracy: 0.8745
Epoch 75/110
 - 2s - loss: 0.1309 - accuracy: 0.9931 - val_loss: 0.8227 - val_accuracy: 0.8555
Epoch 76/110
 - 2s - loss: 0.1367 - accuracy: 0.9912 - val_loss: 0.8253 - val_accuracy: 0.8650
Epoch 77/110
 - 2s - loss: 0.1380 - accuracy: 0.9914 - val_loss: 0.7554 - val_accuracy: 0.8686
Epoch 78/110
 - 3s - loss: 0.1688 - accuracy: 0.9814 - val_loss: 0.8966 - val_accuracy: 0.8511
Epoch 79/110
 - 2s - loss: 0.1812 - accuracy: 0.9781 - val_loss: 0.8622 - val_accuracy: 0.8540
Epoch 80/110
 - 2s - loss: 0.1659 - accuracy: 0.9827 - val_loss: 0.8199 - val_accuracy: 0.8584
Epoch 81/110
 - 2s - loss: 0.1603 - accuracy: 0.9845 - val_loss: 0.9156 - val_accuracy: 0.8467
Epoch 82/110
 - 2s - loss: 0.1418 - accuracy: 0.9912 - val_loss: 0.8226 - val_accuracy: 0.8650
Epoch 83/110
 - 2s - loss: 0.1224 - accuracy: 0.9963 - val_loss: 0.8432 - val_accuracy: 0.8650
Epoch 84/110
 - 2s - loss: 0.1178 - accuracy: 0.9969 - val_loss: 0.8372 - val_accuracy: 0.8657
Epoch 85/110
 - 3s - loss: 0.1206 - accuracy: 0.9969 - val_loss: 0.8685 - val_accuracy: 0.8701
Epoch 86/110
 - 2s - loss: 0.1166 - accuracy: 0.9976 - val_loss: 0.8660 - val_accuracy: 0.8650
Epoch 87/110
 - 2s - loss: 0.1125 - accuracy: 0.9980 - val_loss: 0.8441 - val_accuracy: 0.8730
Epoch 88/110
 - 2s - loss: 0.1186 - accuracy: 0.9954 - val_loss: 0.9321 - val_accuracy: 0.8555
Epoch 89/110
 - 2s - loss: 0.1915 - accuracy: 0.9743 - val_loss: 0.8940 - val_accuracy: 0.8482
Epoch 90/110
 - 2s - loss: 0.1674 - accuracy: 0.9810 - val_loss: 0.9292 - val_accuracy: 0.8270
Epoch 91/110
 - 2s - loss: 0.2287 - accuracy: 0.9633 - val_loss: 0.7791 - val_accuracy: 0.8277
Epoch 92/110
 - 2s - loss: 0.1789 - accuracy: 0.9785 - val_loss: 0.7727 - val_accuracy: 0.8533
Epoch 93/110
 - 2s - loss: 0.1445 - accuracy: 0.9889 - val_loss: 0.7650 - val_accuracy: 0.8613
Epoch 94/110
 - 2s - loss: 0.1271 - accuracy: 0.9945 - val_loss: 0.7893 - val_accuracy: 0.8606
Epoch 95/110
 - 2s - loss: 0.1244 - accuracy: 0.9956 - val_loss: 0.7914 - val_accuracy: 0.8708
Epoch 96/110
 - 2s - loss: 0.1179 - accuracy: 0.9969 - val_loss: 0.8117 - val_accuracy: 0.8693
Epoch 97/110
 - 2s - loss: 0.1169 - accuracy: 0.9965 - val_loss: 0.8351 - val_accuracy: 0.8752
Epoch 98/110
 - 2s - loss: 0.1146 - accuracy: 0.9976 - val_loss: 0.8835 - val_accuracy: 0.8635
Epoch 99/110
 - 2s - loss: 0.1239 - accuracy: 0.9953 - val_loss: 0.8468 - val_accuracy: 0.8745
Epoch 100/110
 - 2s - loss: 0.1171 - accuracy: 0.9960 - val_loss: 0.8318 - val_accuracy: 0.8672
Epoch 101/110
 - 2s - loss: 0.1231 - accuracy: 0.9953 - val_loss: 0.8157 - val_accuracy: 0.8664
Epoch 102/110
 - 2s - loss: 0.1481 - accuracy: 0.9870 - val_loss: 0.9729 - val_accuracy: 0.8533
Epoch 103/110
 - 2s - loss: 0.1714 - accuracy: 0.9799 - val_loss: 0.8693 - val_accuracy: 0.8511
Epoch 104/110
 - 2s - loss: 0.1719 - accuracy: 0.9796 - val_loss: 0.8051 - val_accuracy: 0.8562
Epoch 105/110
 - 2s - loss: 0.1723 - accuracy: 0.9772 - val_loss: 0.8260 - val_accuracy: 0.8635
Epoch 106/110
 - 2s - loss: 0.1593 - accuracy: 0.9819 - val_loss: 0.8117 - val_accuracy: 0.8518
Epoch 107/110
 - 2s - loss: 0.1455 - accuracy: 0.9892 - val_loss: 0.7919 - val_accuracy: 0.8642
Epoch 108/110
 - 2s - loss: 0.1342 - accuracy: 0.9903 - val_loss: 0.8228 - val_accuracy: 0.8635
Epoch 109/110
 - 2s - loss: 0.1367 - accuracy: 0.9896 - val_loss: 0.9034 - val_accuracy: 0.8511
Epoch 110/110
 - 2s - loss: 0.1456 - accuracy: 0.9861 - val_loss: 0.8442 - val_accuracy: 0.8620
------------------------------------------------------------------------
Training for fold 4 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 2s - loss: 0.1456 - accuracy: 0.9896 - val_loss: 0.8676 - val_accuracy: 0.8438
Epoch 2/110
 - 2s - loss: 0.1682 - accuracy: 0.9817 - val_loss: 0.8191 - val_accuracy: 0.8650
Epoch 3/110
 - 2s - loss: 0.1402 - accuracy: 0.9887 - val_loss: 0.7819 - val_accuracy: 0.8650
Epoch 4/110
 - 2s - loss: 0.1489 - accuracy: 0.9889 - val_loss: 0.8438 - val_accuracy: 0.8555
Epoch 5/110
 - 2s - loss: 0.1349 - accuracy: 0.9947 - val_loss: 0.8252 - val_accuracy: 0.8650
Epoch 6/110
 - 2s - loss: 0.1164 - accuracy: 0.9967 - val_loss: 0.8248 - val_accuracy: 0.8759
Epoch 7/110
 - 3s - loss: 0.1140 - accuracy: 0.9973 - val_loss: 0.9226 - val_accuracy: 0.8686
Epoch 8/110
 - 3s - loss: 0.1351 - accuracy: 0.9920 - val_loss: 0.8774 - val_accuracy: 0.8730
Epoch 9/110
 - 3s - loss: 0.1226 - accuracy: 0.9949 - val_loss: 0.8071 - val_accuracy: 0.8650
Epoch 10/110
 - 3s - loss: 0.1392 - accuracy: 0.9905 - val_loss: 0.9393 - val_accuracy: 0.8562
Epoch 11/110
 - 2s - loss: 0.1777 - accuracy: 0.9783 - val_loss: 0.8435 - val_accuracy: 0.8635
Epoch 12/110
 - 3s - loss: 0.1498 - accuracy: 0.9852 - val_loss: 0.8055 - val_accuracy: 0.8628
Epoch 13/110
 - 2s - loss: 0.1495 - accuracy: 0.9859 - val_loss: 0.8714 - val_accuracy: 0.8569
Epoch 14/110
 - 2s - loss: 0.1232 - accuracy: 0.9947 - val_loss: 0.8196 - val_accuracy: 0.8664
Epoch 15/110
 - 3s - loss: 0.1159 - accuracy: 0.9971 - val_loss: 0.8727 - val_accuracy: 0.8664
Epoch 16/110
 - 3s - loss: 0.1166 - accuracy: 0.9962 - val_loss: 0.8718 - val_accuracy: 0.8569
Epoch 17/110
 - 2s - loss: 0.1192 - accuracy: 0.9960 - val_loss: 0.8678 - val_accuracy: 0.8613
Epoch 18/110
 - 2s - loss: 0.1215 - accuracy: 0.9956 - val_loss: 0.8887 - val_accuracy: 0.8599
Epoch 19/110
 - 2s - loss: 0.1447 - accuracy: 0.9887 - val_loss: 0.8660 - val_accuracy: 0.8555
Epoch 20/110
 - 2s - loss: 0.1744 - accuracy: 0.9792 - val_loss: 0.9405 - val_accuracy: 0.8321
Epoch 21/110
 - 2s - loss: 0.1819 - accuracy: 0.9744 - val_loss: 0.9168 - val_accuracy: 0.8526
Epoch 22/110
 - 2s - loss: 0.1510 - accuracy: 0.9854 - val_loss: 0.9237 - val_accuracy: 0.8606
Epoch 23/110
 - 3s - loss: 0.1466 - accuracy: 0.9880 - val_loss: 0.8530 - val_accuracy: 0.8737
Epoch 24/110
 - 3s - loss: 0.1461 - accuracy: 0.9881 - val_loss: 0.8371 - val_accuracy: 0.8635
Epoch 25/110
 - 3s - loss: 0.1329 - accuracy: 0.9916 - val_loss: 0.8322 - val_accuracy: 0.8642
Epoch 26/110
 - 3s - loss: 0.1429 - accuracy: 0.9911 - val_loss: 0.8522 - val_accuracy: 0.8664
Epoch 27/110
 - 2s - loss: 0.1266 - accuracy: 0.9942 - val_loss: 0.7954 - val_accuracy: 0.8599
Epoch 28/110
 - 2s - loss: 0.1149 - accuracy: 0.9967 - val_loss: 0.7820 - val_accuracy: 0.8642
Epoch 29/110
 - 2s - loss: 0.1099 - accuracy: 0.9982 - val_loss: 0.7964 - val_accuracy: 0.8730
Epoch 30/110
 - 2s - loss: 0.1123 - accuracy: 0.9969 - val_loss: 0.8216 - val_accuracy: 0.8701
Epoch 31/110
 - 2s - loss: 0.1146 - accuracy: 0.9962 - val_loss: 0.8987 - val_accuracy: 0.8664
Epoch 32/110
 - 3s - loss: 0.1278 - accuracy: 0.9929 - val_loss: 0.8558 - val_accuracy: 0.8562
Epoch 33/110
 - 2s - loss: 0.2019 - accuracy: 0.9670 - val_loss: 0.8393 - val_accuracy: 0.8474
Epoch 34/110
 - 3s - loss: 0.1634 - accuracy: 0.9790 - val_loss: 0.8663 - val_accuracy: 0.8577
Epoch 35/110
 - 3s - loss: 0.1828 - accuracy: 0.9750 - val_loss: 0.8424 - val_accuracy: 0.8555
Epoch 36/110
 - 3s - loss: 0.1592 - accuracy: 0.9847 - val_loss: 0.8900 - val_accuracy: 0.8482
Epoch 37/110
 - 2s - loss: 0.1508 - accuracy: 0.9876 - val_loss: 0.8332 - val_accuracy: 0.8606
Epoch 38/110
 - 3s - loss: 0.1275 - accuracy: 0.9925 - val_loss: 0.8218 - val_accuracy: 0.8701
Epoch 39/110
 - 2s - loss: 0.1283 - accuracy: 0.9934 - val_loss: 0.8704 - val_accuracy: 0.8635
Epoch 40/110
 - 2s - loss: 0.1300 - accuracy: 0.9927 - val_loss: 0.9333 - val_accuracy: 0.8555
Epoch 41/110
 - 2s - loss: 0.1200 - accuracy: 0.9951 - val_loss: 0.8688 - val_accuracy: 0.8708
Epoch 42/110
 - 2s - loss: 0.1157 - accuracy: 0.9963 - val_loss: 0.8670 - val_accuracy: 0.8642
Epoch 43/110
 - 2s - loss: 0.1105 - accuracy: 0.9976 - val_loss: 0.8568 - val_accuracy: 0.8752
Epoch 44/110
 - 2s - loss: 0.1124 - accuracy: 0.9963 - val_loss: 0.8522 - val_accuracy: 0.8628
Epoch 45/110
 - 2s - loss: 0.1449 - accuracy: 0.9890 - val_loss: 0.9101 - val_accuracy: 0.8511
Epoch 46/110
 - 3s - loss: 0.1705 - accuracy: 0.9808 - val_loss: 0.9467 - val_accuracy: 0.8511
Epoch 47/110
 - 2s - loss: 0.1703 - accuracy: 0.9770 - val_loss: 0.9180 - val_accuracy: 0.8431
Epoch 48/110
 - 2s - loss: 0.1554 - accuracy: 0.9843 - val_loss: 0.8051 - val_accuracy: 0.8555
Epoch 49/110
 - 2s - loss: 0.1333 - accuracy: 0.9903 - val_loss: 0.8154 - val_accuracy: 0.8577
Epoch 50/110
 - 2s - loss: 0.1202 - accuracy: 0.9949 - val_loss: 0.7872 - val_accuracy: 0.8613
Epoch 51/110
 - 2s - loss: 0.1148 - accuracy: 0.9963 - val_loss: 0.8459 - val_accuracy: 0.8620
Epoch 52/110
 - 3s - loss: 0.1162 - accuracy: 0.9956 - val_loss: 0.9010 - val_accuracy: 0.8613
Epoch 53/110
 - 3s - loss: 0.1248 - accuracy: 0.9934 - val_loss: 0.8549 - val_accuracy: 0.8657
Epoch 54/110
 - 3s - loss: 0.1408 - accuracy: 0.9898 - val_loss: 0.9579 - val_accuracy: 0.8599
Epoch 55/110
 - 2s - loss: 0.1321 - accuracy: 0.9912 - val_loss: 0.8269 - val_accuracy: 0.8650
Epoch 56/110
 - 2s - loss: 0.1652 - accuracy: 0.9810 - val_loss: 0.9225 - val_accuracy: 0.8511
Epoch 57/110
 - 2s - loss: 0.1596 - accuracy: 0.9799 - val_loss: 0.8798 - val_accuracy: 0.8394
Epoch 58/110
 - 2s - loss: 0.1833 - accuracy: 0.9717 - val_loss: 0.8172 - val_accuracy: 0.8606
Epoch 59/110
 - 2s - loss: 0.1556 - accuracy: 0.9832 - val_loss: 0.7749 - val_accuracy: 0.8606
Epoch 60/110
 - 2s - loss: 0.1335 - accuracy: 0.9909 - val_loss: 0.7898 - val_accuracy: 0.8693
Epoch 61/110
 - 2s - loss: 0.1135 - accuracy: 0.9973 - val_loss: 0.7981 - val_accuracy: 0.8679
Epoch 62/110
 - 2s - loss: 0.1213 - accuracy: 0.9932 - val_loss: 0.8054 - val_accuracy: 0.8672
Epoch 63/110
 - 2s - loss: 0.1321 - accuracy: 0.9918 - val_loss: 0.8699 - val_accuracy: 0.8606
Epoch 64/110
 - 2s - loss: 0.1353 - accuracy: 0.9894 - val_loss: 0.8881 - val_accuracy: 0.8650
Epoch 65/110
 - 2s - loss: 0.1331 - accuracy: 0.9914 - val_loss: 0.8275 - val_accuracy: 0.8686
Epoch 66/110
 - 3s - loss: 0.1321 - accuracy: 0.9903 - val_loss: 0.8760 - val_accuracy: 0.8657
Epoch 67/110
 - 2s - loss: 0.1449 - accuracy: 0.9865 - val_loss: 0.8521 - val_accuracy: 0.8664
Epoch 68/110
 - 2s - loss: 0.1515 - accuracy: 0.9856 - val_loss: 0.8246 - val_accuracy: 0.8620
Epoch 69/110
 - 2s - loss: 0.1412 - accuracy: 0.9890 - val_loss: 0.7945 - val_accuracy: 0.8591
Epoch 70/110
 - 2s - loss: 0.1254 - accuracy: 0.9931 - val_loss: 0.7956 - val_accuracy: 0.8635
Epoch 71/110
 - 3s - loss: 0.1302 - accuracy: 0.9914 - val_loss: 0.8080 - val_accuracy: 0.8679
Epoch 72/110
 - 3s - loss: 0.1261 - accuracy: 0.9934 - val_loss: 0.8823 - val_accuracy: 0.8635
Epoch 73/110
 - 3s - loss: 0.1195 - accuracy: 0.9943 - val_loss: 0.8487 - val_accuracy: 0.8650
Epoch 74/110
 - 2s - loss: 0.1093 - accuracy: 0.9971 - val_loss: 0.8789 - val_accuracy: 0.8628
Epoch 75/110
 - 3s - loss: 0.1069 - accuracy: 0.9978 - val_loss: 0.8639 - val_accuracy: 0.8628
Epoch 76/110
 - 2s - loss: 0.1084 - accuracy: 0.9978 - val_loss: 0.8979 - val_accuracy: 0.8635
Epoch 77/110
 - 2s - loss: 0.1043 - accuracy: 0.9985 - val_loss: 0.8697 - val_accuracy: 0.8657
Epoch 78/110
 - 2s - loss: 0.1239 - accuracy: 0.9936 - val_loss: 0.8646 - val_accuracy: 0.8628
Epoch 79/110
 - 2s - loss: 0.1241 - accuracy: 0.9916 - val_loss: 0.9001 - val_accuracy: 0.8628
Epoch 80/110
 - 2s - loss: 0.2166 - accuracy: 0.9660 - val_loss: 0.8344 - val_accuracy: 0.8453
Epoch 81/110
 - 2s - loss: 0.2085 - accuracy: 0.9624 - val_loss: 0.7764 - val_accuracy: 0.8642
Epoch 82/110
 - 2s - loss: 0.1540 - accuracy: 0.9850 - val_loss: 0.7797 - val_accuracy: 0.8642
Epoch 83/110
 - 2s - loss: 0.1292 - accuracy: 0.9923 - val_loss: 0.8217 - val_accuracy: 0.8577
Epoch 84/110
 - 2s - loss: 0.1235 - accuracy: 0.9945 - val_loss: 0.8247 - val_accuracy: 0.8606
Epoch 85/110
 - 2s - loss: 0.1245 - accuracy: 0.9912 - val_loss: 0.8250 - val_accuracy: 0.8599
Epoch 86/110
 - 2s - loss: 0.1194 - accuracy: 0.9945 - val_loss: 0.8484 - val_accuracy: 0.8701
Epoch 87/110
 - 2s - loss: 0.1158 - accuracy: 0.9947 - val_loss: 0.8076 - val_accuracy: 0.8693
Epoch 88/110
 - 2s - loss: 0.1082 - accuracy: 0.9978 - val_loss: 0.8381 - val_accuracy: 0.8723
Epoch 89/110
 - 2s - loss: 0.1053 - accuracy: 0.9980 - val_loss: 0.8485 - val_accuracy: 0.8766
Epoch 90/110
 - 2s - loss: 0.1046 - accuracy: 0.9984 - val_loss: 0.8650 - val_accuracy: 0.8737
Epoch 91/110
 - 2s - loss: 0.1036 - accuracy: 0.9980 - val_loss: 0.8806 - val_accuracy: 0.8650
Epoch 92/110
 - 2s - loss: 0.1045 - accuracy: 0.9976 - val_loss: 0.9222 - val_accuracy: 0.8650
Epoch 93/110
 - 2s - loss: 0.1377 - accuracy: 0.9892 - val_loss: 0.9643 - val_accuracy: 0.8409
Epoch 94/110
 - 2s - loss: 0.2548 - accuracy: 0.9584 - val_loss: 0.9068 - val_accuracy: 0.8161
Epoch 95/110
 - 2s - loss: 0.2330 - accuracy: 0.9531 - val_loss: 0.8837 - val_accuracy: 0.8467
Epoch 96/110
 - 2s - loss: 0.1515 - accuracy: 0.9832 - val_loss: 0.7726 - val_accuracy: 0.8591
Epoch 97/110
 - 2s - loss: 0.1500 - accuracy: 0.9854 - val_loss: 0.7565 - val_accuracy: 0.8562
Epoch 98/110
 - 2s - loss: 0.1288 - accuracy: 0.9912 - val_loss: 0.7545 - val_accuracy: 0.8642
Epoch 99/110
 - 2s - loss: 0.1133 - accuracy: 0.9967 - val_loss: 0.7839 - val_accuracy: 0.8628
Epoch 100/110
 - 2s - loss: 0.1102 - accuracy: 0.9974 - val_loss: 0.8096 - val_accuracy: 0.8657
Epoch 101/110
 - 2s - loss: 0.1115 - accuracy: 0.9962 - val_loss: 0.8454 - val_accuracy: 0.8657
Epoch 102/110
 - 2s - loss: 0.1230 - accuracy: 0.9947 - val_loss: 0.8520 - val_accuracy: 0.8650
Epoch 103/110
 - 3s - loss: 0.1145 - accuracy: 0.9954 - val_loss: 0.8183 - val_accuracy: 0.8730
Epoch 104/110
 - 3s - loss: 0.1054 - accuracy: 0.9984 - val_loss: 0.8502 - val_accuracy: 0.8672
Epoch 105/110
 - 2s - loss: 0.1009 - accuracy: 0.9993 - val_loss: 0.8496 - val_accuracy: 0.8723
Epoch 106/110
 - 3s - loss: 0.1011 - accuracy: 0.9989 - val_loss: 0.8442 - val_accuracy: 0.8803
Epoch 107/110
 - 3s - loss: 0.1005 - accuracy: 0.9987 - val_loss: 0.8752 - val_accuracy: 0.8766
Epoch 108/110
 - 3s - loss: 0.1074 - accuracy: 0.9967 - val_loss: 0.8975 - val_accuracy: 0.8730
Epoch 109/110
 - 3s - loss: 0.1156 - accuracy: 0.9951 - val_loss: 0.8919 - val_accuracy: 0.8555
Epoch 110/110
 - 3s - loss: 0.1737 - accuracy: 0.9772 - val_loss: 1.0097 - val_accuracy: 0.8336
------------------------------------------------------------------------
Training for fold 5 ...
Train on 5478 samples, validate on 1370 samples
Epoch 1/110
 - 3s - loss: 0.2469 - accuracy: 0.9494 - val_loss: 0.8831 - val_accuracy: 0.8255
Epoch 2/110
 - 3s - loss: 0.2145 - accuracy: 0.9618 - val_loss: 0.7302 - val_accuracy: 0.8584
Epoch 3/110
 - 3s - loss: 0.1448 - accuracy: 0.9854 - val_loss: 0.7773 - val_accuracy: 0.8584
Epoch 4/110
 - 3s - loss: 0.1214 - accuracy: 0.9954 - val_loss: 0.7734 - val_accuracy: 0.8708
Epoch 5/110
 - 3s - loss: 0.1142 - accuracy: 0.9958 - val_loss: 0.7648 - val_accuracy: 0.8730
Epoch 6/110
 - 3s - loss: 0.1099 - accuracy: 0.9965 - val_loss: 0.8388 - val_accuracy: 0.8708
Epoch 7/110
 - 3s - loss: 0.1061 - accuracy: 0.9974 - val_loss: 0.8194 - val_accuracy: 0.8693
Epoch 8/110
 - 3s - loss: 0.1366 - accuracy: 0.9890 - val_loss: 0.8650 - val_accuracy: 0.8591
Epoch 9/110
 - 3s - loss: 0.1484 - accuracy: 0.9836 - val_loss: 0.8876 - val_accuracy: 0.8511
Epoch 10/110
 - 3s - loss: 0.1482 - accuracy: 0.9834 - val_loss: 0.9118 - val_accuracy: 0.8482
Epoch 11/110
 - 3s - loss: 0.1532 - accuracy: 0.9836 - val_loss: 0.8385 - val_accuracy: 0.8606
Epoch 12/110
 - 3s - loss: 0.1288 - accuracy: 0.9912 - val_loss: 0.8885 - val_accuracy: 0.8620
Epoch 13/110
 - 2s - loss: 0.1236 - accuracy: 0.9927 - val_loss: 0.8626 - val_accuracy: 0.8613
Epoch 14/110
 - 3s - loss: 0.1181 - accuracy: 0.9949 - val_loss: 0.8322 - val_accuracy: 0.8620
Epoch 15/110
 - 3s - loss: 0.1102 - accuracy: 0.9965 - val_loss: 0.9499 - val_accuracy: 0.8562
Epoch 16/110
 - 3s - loss: 0.1180 - accuracy: 0.9932 - val_loss: 0.8801 - val_accuracy: 0.8664
Epoch 17/110
 - 3s - loss: 0.1392 - accuracy: 0.9865 - val_loss: 0.9202 - val_accuracy: 0.8555
Epoch 18/110
 - 2s - loss: 0.1402 - accuracy: 0.9872 - val_loss: 0.9098 - val_accuracy: 0.8569
Epoch 19/110
 - 2s - loss: 0.1341 - accuracy: 0.9892 - val_loss: 0.8479 - val_accuracy: 0.8620
Epoch 20/110
 - 3s - loss: 0.1347 - accuracy: 0.9894 - val_loss: 0.8495 - val_accuracy: 0.8679
Epoch 21/110
 - 3s - loss: 0.1148 - accuracy: 0.9945 - val_loss: 0.8694 - val_accuracy: 0.8693
Epoch 22/110
 - 2s - loss: 0.1293 - accuracy: 0.9900 - val_loss: 0.9138 - val_accuracy: 0.8635
Epoch 23/110
 - 3s - loss: 0.1244 - accuracy: 0.9912 - val_loss: 0.9400 - val_accuracy: 0.8504
Epoch 24/110
 - 3s - loss: 0.1414 - accuracy: 0.9874 - val_loss: 0.8790 - val_accuracy: 0.8518
Epoch 25/110
 - 3s - loss: 0.1505 - accuracy: 0.9847 - val_loss: 0.8962 - val_accuracy: 0.8496
Epoch 26/110
 - 3s - loss: 0.1482 - accuracy: 0.9823 - val_loss: 0.8597 - val_accuracy: 0.8599
Epoch 27/110
 - 3s - loss: 0.1299 - accuracy: 0.9894 - val_loss: 0.8237 - val_accuracy: 0.8606
Epoch 28/110
 - 3s - loss: 0.1218 - accuracy: 0.9940 - val_loss: 0.8295 - val_accuracy: 0.8672
Epoch 29/110
 - 3s - loss: 0.1139 - accuracy: 0.9947 - val_loss: 0.8926 - val_accuracy: 0.8628
Epoch 30/110
 - 3s - loss: 0.1346 - accuracy: 0.9887 - val_loss: 0.8428 - val_accuracy: 0.8599
Epoch 31/110
 - 2s - loss: 0.1243 - accuracy: 0.9914 - val_loss: 0.9217 - val_accuracy: 0.8460
Epoch 32/110
 - 2s - loss: 0.1273 - accuracy: 0.9916 - val_loss: 0.8225 - val_accuracy: 0.8679
Epoch 33/110
 - 3s - loss: 0.1159 - accuracy: 0.9956 - val_loss: 0.9183 - val_accuracy: 0.8540
Epoch 34/110
 - 3s - loss: 0.1287 - accuracy: 0.9909 - val_loss: 0.8482 - val_accuracy: 0.8511
Epoch 35/110
 - 3s - loss: 0.1274 - accuracy: 0.9912 - val_loss: 0.8941 - val_accuracy: 0.8569
Epoch 36/110
 - 3s - loss: 0.1135 - accuracy: 0.9958 - val_loss: 0.8883 - val_accuracy: 0.8606
Epoch 37/110
 - 2s - loss: 0.1061 - accuracy: 0.9974 - val_loss: 0.9040 - val_accuracy: 0.8613
Epoch 38/110
 - 2s - loss: 0.1109 - accuracy: 0.9960 - val_loss: 0.9131 - val_accuracy: 0.8613
Epoch 39/110
 - 2s - loss: 0.1197 - accuracy: 0.9931 - val_loss: 0.8682 - val_accuracy: 0.8599
Epoch 40/110
 - 3s - loss: 0.1188 - accuracy: 0.9932 - val_loss: 0.8987 - val_accuracy: 0.8613
Epoch 41/110
 - 3s - loss: 0.1498 - accuracy: 0.9834 - val_loss: 0.8870 - val_accuracy: 0.8482
Epoch 42/110
 - 3s - loss: 0.2131 - accuracy: 0.9629 - val_loss: 0.8885 - val_accuracy: 0.8518
Epoch 43/110
 - 3s - loss: 0.1554 - accuracy: 0.9836 - val_loss: 0.8136 - val_accuracy: 0.8584
Epoch 44/110
 - 3s - loss: 0.1251 - accuracy: 0.9916 - val_loss: 0.7457 - val_accuracy: 0.8664
Epoch 45/110
 - 3s - loss: 0.1242 - accuracy: 0.9940 - val_loss: 0.7640 - val_accuracy: 0.8679
Epoch 46/110
 - 3s - loss: 0.1137 - accuracy: 0.9947 - val_loss: 0.8137 - val_accuracy: 0.8737
Epoch 47/110
 - 3s - loss: 0.1057 - accuracy: 0.9978 - val_loss: 0.7819 - val_accuracy: 0.8788
Epoch 48/110
 - 3s - loss: 0.1178 - accuracy: 0.9951 - val_loss: 0.8499 - val_accuracy: 0.8620
Epoch 49/110
 - 3s - loss: 0.1158 - accuracy: 0.9934 - val_loss: 0.8403 - val_accuracy: 0.8599
Epoch 50/110
 - 3s - loss: 0.1088 - accuracy: 0.9965 - val_loss: 0.8327 - val_accuracy: 0.8650
Epoch 51/110
 - 2s - loss: 0.1096 - accuracy: 0.9958 - val_loss: 0.8287 - val_accuracy: 0.8672
Epoch 52/110
 - 3s - loss: 0.1090 - accuracy: 0.9949 - val_loss: 0.7971 - val_accuracy: 0.8642
Epoch 53/110
 - 3s - loss: 0.1463 - accuracy: 0.9856 - val_loss: 0.7969 - val_accuracy: 0.8460
Epoch 54/110
 - 3s - loss: 0.1573 - accuracy: 0.9805 - val_loss: 0.7555 - val_accuracy: 0.8686
Epoch 55/110
 - 2s - loss: 0.1248 - accuracy: 0.9911 - val_loss: 0.7573 - val_accuracy: 0.8650
Epoch 56/110
 - 2s - loss: 0.1214 - accuracy: 0.9922 - val_loss: 0.7556 - val_accuracy: 0.8672
Epoch 57/110
 - 2s - loss: 0.1237 - accuracy: 0.9905 - val_loss: 0.9078 - val_accuracy: 0.8591
Epoch 58/110
 - 3s - loss: 0.1326 - accuracy: 0.9901 - val_loss: 0.8181 - val_accuracy: 0.8657
Epoch 59/110
 - 3s - loss: 0.1257 - accuracy: 0.9912 - val_loss: 0.8559 - val_accuracy: 0.8569
Epoch 60/110
 - 2s - loss: 0.1273 - accuracy: 0.9927 - val_loss: 0.8214 - val_accuracy: 0.8650
Epoch 61/110
 - 2s - loss: 0.1205 - accuracy: 0.9931 - val_loss: 0.8578 - val_accuracy: 0.8547
Epoch 62/110
 - 2s - loss: 0.1318 - accuracy: 0.9905 - val_loss: 0.8404 - val_accuracy: 0.8562
Epoch 63/110
 - 3s - loss: 0.1292 - accuracy: 0.9909 - val_loss: 0.8210 - val_accuracy: 0.8584
Epoch 64/110
 - 3s - loss: 0.1444 - accuracy: 0.9850 - val_loss: 0.8241 - val_accuracy: 0.8606
Epoch 65/110
 - 3s - loss: 0.1222 - accuracy: 0.9907 - val_loss: 0.8075 - val_accuracy: 0.8606
Epoch 66/110
 - 3s - loss: 0.1244 - accuracy: 0.9909 - val_loss: 0.7866 - val_accuracy: 0.8679
Epoch 67/110
 - 2s - loss: 0.1150 - accuracy: 0.9945 - val_loss: 0.8276 - val_accuracy: 0.8679
Epoch 68/110
 - 2s - loss: 0.1157 - accuracy: 0.9949 - val_loss: 0.8981 - val_accuracy: 0.8664
Epoch 69/110
 - 3s - loss: 0.1234 - accuracy: 0.9912 - val_loss: 0.9571 - val_accuracy: 0.8482
Epoch 70/110
 - 2s - loss: 0.1603 - accuracy: 0.9794 - val_loss: 0.8237 - val_accuracy: 0.8453
Epoch 71/110
 - 3s - loss: 0.1481 - accuracy: 0.9828 - val_loss: 0.7964 - val_accuracy: 0.8547
Epoch 72/110
 - 3s - loss: 0.1367 - accuracy: 0.9859 - val_loss: 0.7576 - val_accuracy: 0.8642
Epoch 73/110
 - 2s - loss: 0.1203 - accuracy: 0.9931 - val_loss: 0.7718 - val_accuracy: 0.8577
Epoch 74/110
 - 3s - loss: 0.1099 - accuracy: 0.9958 - val_loss: 0.7856 - val_accuracy: 0.8723
Epoch 75/110
 - 2s - loss: 0.1037 - accuracy: 0.9976 - val_loss: 0.7992 - val_accuracy: 0.8723
Epoch 76/110
 - 2s - loss: 0.1060 - accuracy: 0.9965 - val_loss: 0.8345 - val_accuracy: 0.8664
Epoch 77/110
 - 2s - loss: 0.1073 - accuracy: 0.9967 - val_loss: 0.8443 - val_accuracy: 0.8657
Epoch 78/110
 - 3s - loss: 0.1042 - accuracy: 0.9960 - val_loss: 0.8532 - val_accuracy: 0.8635
Epoch 79/110
 - 3s - loss: 0.1119 - accuracy: 0.9940 - val_loss: 0.9381 - val_accuracy: 0.8599
Epoch 80/110
 - 2s - loss: 0.1507 - accuracy: 0.9850 - val_loss: 0.8539 - val_accuracy: 0.8606
Epoch 81/110
 - 3s - loss: 0.1743 - accuracy: 0.9759 - val_loss: 0.8704 - val_accuracy: 0.8474
Epoch 82/110
 - 2s - loss: 0.1716 - accuracy: 0.9754 - val_loss: 0.7891 - val_accuracy: 0.8657
Epoch 83/110
 - 2s - loss: 0.1517 - accuracy: 0.9830 - val_loss: 0.8298 - val_accuracy: 0.8562
Epoch 84/110
 - 2s - loss: 0.1291 - accuracy: 0.9901 - val_loss: 0.7379 - val_accuracy: 0.8642
Epoch 85/110
 - 2s - loss: 0.1113 - accuracy: 0.9954 - val_loss: 0.7320 - val_accuracy: 0.8715
Epoch 86/110
 - 2s - loss: 0.1068 - accuracy: 0.9962 - val_loss: 0.7894 - val_accuracy: 0.8745
Epoch 87/110
 - 2s - loss: 0.1116 - accuracy: 0.9951 - val_loss: 0.7865 - val_accuracy: 0.8701
Epoch 88/110
 - 2s - loss: 0.1248 - accuracy: 0.9923 - val_loss: 0.7643 - val_accuracy: 0.8686
Epoch 89/110
 - 2s - loss: 0.1138 - accuracy: 0.9949 - val_loss: 0.7892 - val_accuracy: 0.8686
Epoch 90/110
 - 3s - loss: 0.1080 - accuracy: 0.9962 - val_loss: 0.7553 - val_accuracy: 0.8715
Epoch 91/110
 - 2s - loss: 0.1010 - accuracy: 0.9982 - val_loss: 0.7701 - val_accuracy: 0.8701
Epoch 92/110
 - 2s - loss: 0.0975 - accuracy: 0.9985 - val_loss: 0.7830 - val_accuracy: 0.8708
Epoch 93/110
 - 3s - loss: 0.0972 - accuracy: 0.9980 - val_loss: 0.7995 - val_accuracy: 0.8701
Epoch 94/110
 - 2s - loss: 0.0952 - accuracy: 0.9987 - val_loss: 0.7769 - val_accuracy: 0.8752
Epoch 95/110
 - 2s - loss: 0.0955 - accuracy: 0.9984 - val_loss: 0.7990 - val_accuracy: 0.8730
Epoch 96/110
 - 3s - loss: 0.0933 - accuracy: 0.9989 - val_loss: 0.8059 - val_accuracy: 0.8745
Epoch 97/110
 - 3s - loss: 0.0947 - accuracy: 0.9987 - val_loss: 0.7880 - val_accuracy: 0.8759
Epoch 98/110
 - 3s - loss: 0.0950 - accuracy: 0.9980 - val_loss: 0.7989 - val_accuracy: 0.8686
Epoch 99/110
 - 3s - loss: 0.0917 - accuracy: 0.9987 - val_loss: 0.8090 - val_accuracy: 0.8730
Epoch 100/110
 - 3s - loss: 0.0922 - accuracy: 0.9984 - val_loss: 0.8211 - val_accuracy: 0.8693
Epoch 101/110
 - 3s - loss: 0.1011 - accuracy: 0.9963 - val_loss: 0.8734 - val_accuracy: 0.8657
Epoch 102/110
 - 3s - loss: 0.1685 - accuracy: 0.9766 - val_loss: 1.0321 - val_accuracy: 0.8153
Epoch 103/110
 - 3s - loss: 0.3329 - accuracy: 0.9208 - val_loss: 0.8272 - val_accuracy: 0.8285
Epoch 104/110
 - 3s - loss: 0.2534 - accuracy: 0.9527 - val_loss: 0.7098 - val_accuracy: 0.8431
Epoch 105/110
 - 2s - loss: 0.1455 - accuracy: 0.9832 - val_loss: 0.7132 - val_accuracy: 0.8650
Epoch 106/110
 - 2s - loss: 0.1115 - accuracy: 0.9958 - val_loss: 0.7284 - val_accuracy: 0.8657
Epoch 107/110
 - 3s - loss: 0.1049 - accuracy: 0.9969 - val_loss: 0.7577 - val_accuracy: 0.8672
Epoch 108/110
 - 3s - loss: 0.1017 - accuracy: 0.9971 - val_loss: 0.7927 - val_accuracy: 0.8715
Epoch 109/110
 - 2s - loss: 0.1022 - accuracy: 0.9978 - val_loss: 0.7963 - val_accuracy: 0.8708
Epoch 110/110
 - 3s - loss: 0.0984 - accuracy: 0.9978 - val_loss: 0.7995 - val_accuracy: 0.8752
------------------------------------------------------------------------
Score per fold
------------------------------------------------------------------------
Score for fold 1
Accuracy_Train: 28.10%
Accuracy_Test: 29.50%
Loss_Train: 53.03
Loss_Test: 51.98
------------------------------------------------------------------------
Score for fold 2
Accuracy_Train: 28.17%
Accuracy_Test: 28.39%
Loss_Train: 22.19
Loss_Test: 22.00
------------------------------------------------------------------------
Score for fold 3
Accuracy_Train: 28.43%
Accuracy_Test: 28.15%
Loss_Train: 44.30
Loss_Test: 44.41
------------------------------------------------------------------------
Score for fold 4
Accuracy_Train: 23.36%
Accuracy_Test: 24.18%
Loss_Train: 49.30
Loss_Test: 48.49
------------------------------------------------------------------------
Score for fold 5
Accuracy_Train: 23.88%
Accuracy_Test: 22.96%
Loss_Train: 19.96
Loss_Test: 19.74
------------------------------------------------------------------------
Average scores for all folds:
Average_Accuracy_Train: 26.39%
	-> (+- 2.2679620172829353 )
Average_Accuracy_Test: 26.64%
	-> (+- 2.5740727892887163 )
Average_Loss_Train: 37.76
	-> (+- 13.914870211979393 )
Average_Loss_Test: 37.32
	-> (+- 13.665385935019032 )
------------------------------------------------------------------------
