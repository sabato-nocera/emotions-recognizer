Dataset used: ../../datasets/full_dataset_without_humidity_reduced.csv 

   Temperature  Sound  Heartbeat   X1  ...    Y2     Z2  Classification  Feedback
0           32      1         60 -680  ... -7424 -15596             100     Happy
1           32      1         60 -780  ... -7408 -15628             100     Happy
2           -1      1         60   -1  ... -7276 -15612             100     Happy
3           -1     -1         60   -1  ...    -1     -1             100     Happy
4           32      1         60 -860  ... -7340 -15720             100     Happy

[5 rows x 11 columns]

Objservations: 3760
Reshaping:  ((3008, 10), (3008, 4), (752, 10), (752, 4))  -> ((3008, 10, 1), (3008, 4), (752, 10, 1), (752, 4))

Layers:

{'batch_input_shape': (None, 10, 1), 'dtype': 'float32', 'sparse': False, 'name': 'input_23'} 

{'name': 'conv1d_540', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_419', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_573', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_541', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_420', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_574', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_542', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_421', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_199', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_575', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_543', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_422', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_576', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_544', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_423', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_200', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_577', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_545', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_424', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_578', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_546', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_425', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_201', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_579', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_547', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_426', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_580', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_548', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_549', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_427', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_202', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_581', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_550', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_428', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_582', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_551', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_429', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_203', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_583', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_552', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_430', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_584', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_553', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_431', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_204', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_585', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_554', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_432', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_586', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_555', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'conv1d_556', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (1,), 'strides': (2,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_433', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_205', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_587', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_557', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_434', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_588', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_558', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_435', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_206', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_589', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_559', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_436', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'activation_590', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'conv1d_560', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 9.999999747378752e-05}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'batch_normalization_437', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None} 

{'name': 'add_207', 'trainable': True, 'dtype': 'float32'} 

{'name': 'activation_591', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'average_pooling1d_23', 'trainable': True, 'dtype': 'float32', 'strides': (1,), 'pool_size': (1,), 'padding': 'valid', 'data_format': 'channels_last'} 

{'name': 'flatten_100', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'} 

{'name': 'dense_2168', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 5s - loss: 1.1486 - accuracy: 0.6584 - val_loss: 2.1718 - val_accuracy: 0.3289
Epoch 2/110
 - 1s - loss: 0.7922 - accuracy: 0.7727 - val_loss: 1.2631 - val_accuracy: 0.5449
Epoch 3/110
 - 1s - loss: 0.7017 - accuracy: 0.8026 - val_loss: 0.9847 - val_accuracy: 0.7043
Epoch 4/110
 - 1s - loss: 0.6501 - accuracy: 0.8126 - val_loss: 0.8489 - val_accuracy: 0.7525
Epoch 5/110
 - 1s - loss: 0.6291 - accuracy: 0.8209 - val_loss: 0.7230 - val_accuracy: 0.8156
Epoch 6/110
 - 1s - loss: 0.6015 - accuracy: 0.8217 - val_loss: 0.7077 - val_accuracy: 0.8056
Epoch 7/110
 - 1s - loss: 0.5737 - accuracy: 0.8375 - val_loss: 0.7310 - val_accuracy: 0.7907
Epoch 8/110
 - 1s - loss: 0.5694 - accuracy: 0.8379 - val_loss: 0.7107 - val_accuracy: 0.7824
Epoch 9/110
 - 1s - loss: 0.5884 - accuracy: 0.8346 - val_loss: 0.7220 - val_accuracy: 0.7957
Epoch 10/110
 - 1s - loss: 0.5806 - accuracy: 0.8333 - val_loss: 0.6466 - val_accuracy: 0.8239
Epoch 11/110
 - 1s - loss: 0.5436 - accuracy: 0.8421 - val_loss: 0.6677 - val_accuracy: 0.8007
Epoch 12/110
 - 1s - loss: 0.5254 - accuracy: 0.8462 - val_loss: 0.7144 - val_accuracy: 0.8256
Epoch 13/110
 - 1s - loss: 0.5099 - accuracy: 0.8566 - val_loss: 0.7321 - val_accuracy: 0.8140
Epoch 14/110
 - 1s - loss: 0.5006 - accuracy: 0.8608 - val_loss: 0.7223 - val_accuracy: 0.7990
Epoch 15/110
 - 1s - loss: 0.5228 - accuracy: 0.8570 - val_loss: 0.7244 - val_accuracy: 0.8223
Epoch 16/110
 - 1s - loss: 0.5030 - accuracy: 0.8558 - val_loss: 0.7187 - val_accuracy: 0.8256
Epoch 17/110
 - 1s - loss: 0.4882 - accuracy: 0.8633 - val_loss: 0.8110 - val_accuracy: 0.7990
Epoch 18/110
 - 1s - loss: 0.4856 - accuracy: 0.8678 - val_loss: 0.7457 - val_accuracy: 0.8040
Epoch 19/110
 - 1s - loss: 0.4707 - accuracy: 0.8732 - val_loss: 0.7773 - val_accuracy: 0.8023
Epoch 20/110
 - 1s - loss: 0.4707 - accuracy: 0.8699 - val_loss: 0.8067 - val_accuracy: 0.7990
Epoch 21/110
 - 1s - loss: 0.4633 - accuracy: 0.8749 - val_loss: 0.7635 - val_accuracy: 0.8023
Epoch 22/110
 - 1s - loss: 0.4633 - accuracy: 0.8741 - val_loss: 0.8400 - val_accuracy: 0.7824
Epoch 23/110
 - 1s - loss: 0.4482 - accuracy: 0.8853 - val_loss: 0.8594 - val_accuracy: 0.7741
Epoch 24/110
 - 1s - loss: 0.4532 - accuracy: 0.8807 - val_loss: 0.6991 - val_accuracy: 0.8372
Epoch 25/110
 - 1s - loss: 0.4428 - accuracy: 0.8903 - val_loss: 0.7579 - val_accuracy: 0.8156
Epoch 26/110
 - 1s - loss: 0.4813 - accuracy: 0.8666 - val_loss: 0.8290 - val_accuracy: 0.8123
Epoch 27/110
 - 1s - loss: 0.4626 - accuracy: 0.8732 - val_loss: 0.8159 - val_accuracy: 0.7841
Epoch 28/110
 - 1s - loss: 0.4819 - accuracy: 0.8674 - val_loss: 0.7877 - val_accuracy: 0.7940
Epoch 29/110
 - 1s - loss: 0.4673 - accuracy: 0.8795 - val_loss: 0.7915 - val_accuracy: 0.7791
Epoch 30/110
 - 1s - loss: 0.4338 - accuracy: 0.8936 - val_loss: 0.8428 - val_accuracy: 0.7724
Epoch 31/110
 - 1s - loss: 0.4517 - accuracy: 0.8795 - val_loss: 0.8520 - val_accuracy: 0.7924
Epoch 32/110
 - 1s - loss: 0.4550 - accuracy: 0.8803 - val_loss: 0.7832 - val_accuracy: 0.8023
Epoch 33/110
 - 1s - loss: 0.4607 - accuracy: 0.8795 - val_loss: 0.7923 - val_accuracy: 0.7724
Epoch 34/110
 - 1s - loss: 0.4390 - accuracy: 0.8882 - val_loss: 0.8142 - val_accuracy: 0.8090
Epoch 35/110
 - 1s - loss: 0.4174 - accuracy: 0.8936 - val_loss: 0.8008 - val_accuracy: 0.7874
Epoch 36/110
 - 1s - loss: 0.3962 - accuracy: 0.9027 - val_loss: 0.9041 - val_accuracy: 0.7924
Epoch 37/110
 - 1s - loss: 0.4048 - accuracy: 0.8953 - val_loss: 0.9214 - val_accuracy: 0.7691
Epoch 38/110
 - 1s - loss: 0.3994 - accuracy: 0.9015 - val_loss: 0.9455 - val_accuracy: 0.7741
Epoch 39/110
 - 1s - loss: 0.4059 - accuracy: 0.9048 - val_loss: 0.8900 - val_accuracy: 0.7774
Epoch 40/110
 - 1s - loss: 0.4111 - accuracy: 0.9027 - val_loss: 0.8899 - val_accuracy: 0.7857
Epoch 41/110
 - 1s - loss: 0.4308 - accuracy: 0.8924 - val_loss: 0.8968 - val_accuracy: 0.7857
Epoch 42/110
 - 1s - loss: 0.4254 - accuracy: 0.8978 - val_loss: 0.8596 - val_accuracy: 0.7907
Epoch 43/110
 - 1s - loss: 0.3974 - accuracy: 0.9044 - val_loss: 0.8291 - val_accuracy: 0.8140
Epoch 44/110
 - 1s - loss: 0.3975 - accuracy: 0.9032 - val_loss: 0.8553 - val_accuracy: 0.7990
Epoch 45/110
 - 1s - loss: 0.3959 - accuracy: 0.9002 - val_loss: 0.7733 - val_accuracy: 0.8173
Epoch 46/110
 - 1s - loss: 0.3727 - accuracy: 0.9086 - val_loss: 0.7651 - val_accuracy: 0.8007
Epoch 47/110
 - 1s - loss: 0.3675 - accuracy: 0.9119 - val_loss: 0.8187 - val_accuracy: 0.8073
Epoch 48/110
 - 1s - loss: 0.3673 - accuracy: 0.9102 - val_loss: 0.7756 - val_accuracy: 0.8189
Epoch 49/110
 - 1s - loss: 0.3438 - accuracy: 0.9235 - val_loss: 0.8105 - val_accuracy: 0.8173
Epoch 50/110
 - 1s - loss: 0.3549 - accuracy: 0.9194 - val_loss: 0.8473 - val_accuracy: 0.8106
Epoch 51/110
 - 1s - loss: 0.3525 - accuracy: 0.9152 - val_loss: 0.8056 - val_accuracy: 0.8056
Epoch 52/110
 - 1s - loss: 0.3483 - accuracy: 0.9227 - val_loss: 0.7800 - val_accuracy: 0.8206
Epoch 53/110
 - 1s - loss: 0.3458 - accuracy: 0.9185 - val_loss: 0.7824 - val_accuracy: 0.8355
Epoch 54/110
 - 1s - loss: 0.3583 - accuracy: 0.9165 - val_loss: 0.9055 - val_accuracy: 0.8090
Epoch 55/110
 - 1s - loss: 0.3465 - accuracy: 0.9214 - val_loss: 0.9090 - val_accuracy: 0.7890
Epoch 56/110
 - 1s - loss: 0.3407 - accuracy: 0.9264 - val_loss: 0.9202 - val_accuracy: 0.8073
Epoch 57/110
 - 1s - loss: 0.3281 - accuracy: 0.9298 - val_loss: 0.9479 - val_accuracy: 0.7791
Epoch 58/110
 - 1s - loss: 0.3549 - accuracy: 0.9181 - val_loss: 0.9430 - val_accuracy: 0.8040
Epoch 59/110
 - 1s - loss: 0.3349 - accuracy: 0.9310 - val_loss: 0.8747 - val_accuracy: 0.8239
Epoch 60/110
 - 1s - loss: 0.3180 - accuracy: 0.9368 - val_loss: 0.8542 - val_accuracy: 0.8206
Epoch 61/110
 - 1s - loss: 0.3212 - accuracy: 0.9372 - val_loss: 0.9359 - val_accuracy: 0.7741
Epoch 62/110
 - 1s - loss: 0.3305 - accuracy: 0.9256 - val_loss: 0.8818 - val_accuracy: 0.8223
Epoch 63/110
 - 1s - loss: 0.3359 - accuracy: 0.9285 - val_loss: 0.9500 - val_accuracy: 0.8023
Epoch 64/110
 - 1s - loss: 0.3513 - accuracy: 0.9214 - val_loss: 0.8721 - val_accuracy: 0.8173
Epoch 65/110
 - 1s - loss: 0.3273 - accuracy: 0.9368 - val_loss: 0.8415 - val_accuracy: 0.8056
Epoch 66/110
 - 1s - loss: 0.3442 - accuracy: 0.9268 - val_loss: 0.8790 - val_accuracy: 0.8023
Epoch 67/110
 - 1s - loss: 0.3229 - accuracy: 0.9360 - val_loss: 0.9233 - val_accuracy: 0.7807
Epoch 68/110
 - 1s - loss: 0.3138 - accuracy: 0.9356 - val_loss: 0.8907 - val_accuracy: 0.7990
Epoch 69/110
 - 1s - loss: 0.2920 - accuracy: 0.9501 - val_loss: 0.9675 - val_accuracy: 0.8023
Epoch 70/110
 - 1s - loss: 0.3136 - accuracy: 0.9343 - val_loss: 1.0175 - val_accuracy: 0.8040
Epoch 71/110
 - 1s - loss: 0.3299 - accuracy: 0.9302 - val_loss: 0.9423 - val_accuracy: 0.7940
Epoch 72/110
 - 1s - loss: 0.3313 - accuracy: 0.9289 - val_loss: 0.9590 - val_accuracy: 0.7924
Epoch 73/110
 - 1s - loss: 0.3036 - accuracy: 0.9381 - val_loss: 0.9783 - val_accuracy: 0.7857
Epoch 74/110
 - 1s - loss: 0.2945 - accuracy: 0.9460 - val_loss: 0.8664 - val_accuracy: 0.8206
Epoch 75/110
 - 1s - loss: 0.2835 - accuracy: 0.9464 - val_loss: 0.9094 - val_accuracy: 0.8189
Epoch 76/110
 - 1s - loss: 0.2743 - accuracy: 0.9497 - val_loss: 0.9446 - val_accuracy: 0.8106
Epoch 77/110
 - 1s - loss: 0.2777 - accuracy: 0.9505 - val_loss: 0.9138 - val_accuracy: 0.8007
Epoch 78/110
 - 1s - loss: 0.3146 - accuracy: 0.9356 - val_loss: 0.9919 - val_accuracy: 0.8073
Epoch 79/110
 - 1s - loss: 0.3135 - accuracy: 0.9385 - val_loss: 0.9687 - val_accuracy: 0.7990
Epoch 80/110
 - 1s - loss: 0.3209 - accuracy: 0.9314 - val_loss: 0.9293 - val_accuracy: 0.8007
Epoch 81/110
 - 1s - loss: 0.3173 - accuracy: 0.9331 - val_loss: 0.9097 - val_accuracy: 0.8206
Epoch 82/110
 - 1s - loss: 0.2881 - accuracy: 0.9493 - val_loss: 1.0198 - val_accuracy: 0.7674
Epoch 83/110
 - 1s - loss: 0.2921 - accuracy: 0.9439 - val_loss: 0.9083 - val_accuracy: 0.7907
Epoch 84/110
 - 1s - loss: 0.2862 - accuracy: 0.9447 - val_loss: 0.9566 - val_accuracy: 0.7708
Epoch 85/110
 - 1s - loss: 0.2943 - accuracy: 0.9435 - val_loss: 0.9191 - val_accuracy: 0.8140
Epoch 86/110
 - 1s - loss: 0.3001 - accuracy: 0.9485 - val_loss: 0.9242 - val_accuracy: 0.8090
Epoch 87/110
 - 1s - loss: 0.2934 - accuracy: 0.9385 - val_loss: 0.9128 - val_accuracy: 0.8239
Epoch 88/110
 - 1s - loss: 0.3003 - accuracy: 0.9418 - val_loss: 0.9045 - val_accuracy: 0.8007
Epoch 89/110
 - 1s - loss: 0.2924 - accuracy: 0.9435 - val_loss: 0.9198 - val_accuracy: 0.8189
Epoch 90/110
 - 1s - loss: 0.3043 - accuracy: 0.9364 - val_loss: 0.9434 - val_accuracy: 0.8173
Epoch 91/110
 - 1s - loss: 0.3129 - accuracy: 0.9451 - val_loss: 0.9327 - val_accuracy: 0.8106
Epoch 92/110
 - 1s - loss: 0.2936 - accuracy: 0.9447 - val_loss: 0.9521 - val_accuracy: 0.8073
Epoch 93/110
 - 1s - loss: 0.2732 - accuracy: 0.9559 - val_loss: 1.0053 - val_accuracy: 0.7807
Epoch 94/110
 - 1s - loss: 0.2795 - accuracy: 0.9489 - val_loss: 0.9267 - val_accuracy: 0.8156
Epoch 95/110
 - 1s - loss: 0.2999 - accuracy: 0.9443 - val_loss: 0.9454 - val_accuracy: 0.8040
Epoch 96/110
 - 1s - loss: 0.2950 - accuracy: 0.9480 - val_loss: 0.8950 - val_accuracy: 0.8306
Epoch 97/110
 - 1s - loss: 0.2707 - accuracy: 0.9539 - val_loss: 0.8507 - val_accuracy: 0.8223
Epoch 98/110
 - 1s - loss: 0.2550 - accuracy: 0.9609 - val_loss: 0.9996 - val_accuracy: 0.8173
Epoch 99/110
 - 1s - loss: 0.2583 - accuracy: 0.9580 - val_loss: 0.9988 - val_accuracy: 0.8256
Epoch 100/110
 - 1s - loss: 0.2714 - accuracy: 0.9534 - val_loss: 1.0075 - val_accuracy: 0.7973
Epoch 101/110
 - 1s - loss: 0.2492 - accuracy: 0.9618 - val_loss: 0.9096 - val_accuracy: 0.8355
Epoch 102/110
 - 1s - loss: 0.2664 - accuracy: 0.9568 - val_loss: 0.8777 - val_accuracy: 0.8306
Epoch 103/110
 - 1s - loss: 0.2632 - accuracy: 0.9622 - val_loss: 0.8643 - val_accuracy: 0.8389
Epoch 104/110
 - 1s - loss: 0.2533 - accuracy: 0.9589 - val_loss: 0.9761 - val_accuracy: 0.8173
Epoch 105/110
 - 1s - loss: 0.2459 - accuracy: 0.9593 - val_loss: 1.0076 - val_accuracy: 0.8007
Epoch 106/110
 - 1s - loss: 0.2605 - accuracy: 0.9572 - val_loss: 1.1175 - val_accuracy: 0.8056
Epoch 107/110
 - 1s - loss: 0.2520 - accuracy: 0.9634 - val_loss: 0.9503 - val_accuracy: 0.8239
Epoch 108/110
 - 1s - loss: 0.2475 - accuracy: 0.9626 - val_loss: 1.0127 - val_accuracy: 0.8289
Epoch 109/110
 - 1s - loss: 0.2643 - accuracy: 0.9543 - val_loss: 1.0089 - val_accuracy: 0.8239
Epoch 110/110
 - 1s - loss: 0.2510 - accuracy: 0.9634 - val_loss: 1.0248 - val_accuracy: 0.8239

Number of filters: 16 , Kernel Size: 3 , Strides: 1 Batch Normalization: True , Conv_First: True , Depth Value: 20

Fit: epochs= 110 , batch_size= 64 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "model_23"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_23 (InputLayer)           (None, 10, 1)        0                                            
__________________________________________________________________________________________________
conv1d_540 (Conv1D)             (None, 10, 16)       64          input_23[0][0]                   
__________________________________________________________________________________________________
batch_normalization_419 (BatchN (None, 10, 16)       64          conv1d_540[0][0]                 
__________________________________________________________________________________________________
activation_573 (Activation)     (None, 10, 16)       0           batch_normalization_419[0][0]    
__________________________________________________________________________________________________
conv1d_541 (Conv1D)             (None, 10, 16)       784         activation_573[0][0]             
__________________________________________________________________________________________________
batch_normalization_420 (BatchN (None, 10, 16)       64          conv1d_541[0][0]                 
__________________________________________________________________________________________________
activation_574 (Activation)     (None, 10, 16)       0           batch_normalization_420[0][0]    
__________________________________________________________________________________________________
conv1d_542 (Conv1D)             (None, 10, 16)       784         activation_574[0][0]             
__________________________________________________________________________________________________
batch_normalization_421 (BatchN (None, 10, 16)       64          conv1d_542[0][0]                 
__________________________________________________________________________________________________
add_199 (Add)                   (None, 10, 16)       0           activation_573[0][0]             
                                                                 batch_normalization_421[0][0]    
__________________________________________________________________________________________________
activation_575 (Activation)     (None, 10, 16)       0           add_199[0][0]                    
__________________________________________________________________________________________________
conv1d_543 (Conv1D)             (None, 10, 16)       784         activation_575[0][0]             
__________________________________________________________________________________________________
batch_normalization_422 (BatchN (None, 10, 16)       64          conv1d_543[0][0]                 
__________________________________________________________________________________________________
activation_576 (Activation)     (None, 10, 16)       0           batch_normalization_422[0][0]    
__________________________________________________________________________________________________
conv1d_544 (Conv1D)             (None, 10, 16)       784         activation_576[0][0]             
__________________________________________________________________________________________________
batch_normalization_423 (BatchN (None, 10, 16)       64          conv1d_544[0][0]                 
__________________________________________________________________________________________________
add_200 (Add)                   (None, 10, 16)       0           activation_575[0][0]             
                                                                 batch_normalization_423[0][0]    
__________________________________________________________________________________________________
activation_577 (Activation)     (None, 10, 16)       0           add_200[0][0]                    
__________________________________________________________________________________________________
conv1d_545 (Conv1D)             (None, 10, 16)       784         activation_577[0][0]             
__________________________________________________________________________________________________
batch_normalization_424 (BatchN (None, 10, 16)       64          conv1d_545[0][0]                 
__________________________________________________________________________________________________
activation_578 (Activation)     (None, 10, 16)       0           batch_normalization_424[0][0]    
__________________________________________________________________________________________________
conv1d_546 (Conv1D)             (None, 10, 16)       784         activation_578[0][0]             
__________________________________________________________________________________________________
batch_normalization_425 (BatchN (None, 10, 16)       64          conv1d_546[0][0]                 
__________________________________________________________________________________________________
add_201 (Add)                   (None, 10, 16)       0           activation_577[0][0]             
                                                                 batch_normalization_425[0][0]    
__________________________________________________________________________________________________
activation_579 (Activation)     (None, 10, 16)       0           add_201[0][0]                    
__________________________________________________________________________________________________
conv1d_547 (Conv1D)             (None, 5, 32)        1568        activation_579[0][0]             
__________________________________________________________________________________________________
batch_normalization_426 (BatchN (None, 5, 32)        128         conv1d_547[0][0]                 
__________________________________________________________________________________________________
activation_580 (Activation)     (None, 5, 32)        0           batch_normalization_426[0][0]    
__________________________________________________________________________________________________
conv1d_548 (Conv1D)             (None, 5, 32)        3104        activation_580[0][0]             
__________________________________________________________________________________________________
conv1d_549 (Conv1D)             (None, 5, 32)        544         activation_579[0][0]             
__________________________________________________________________________________________________
batch_normalization_427 (BatchN (None, 5, 32)        128         conv1d_548[0][0]                 
__________________________________________________________________________________________________
add_202 (Add)                   (None, 5, 32)        0           conv1d_549[0][0]                 
                                                                 batch_normalization_427[0][0]    
__________________________________________________________________________________________________
activation_581 (Activation)     (None, 5, 32)        0           add_202[0][0]                    
__________________________________________________________________________________________________
conv1d_550 (Conv1D)             (None, 5, 32)        3104        activation_581[0][0]             
__________________________________________________________________________________________________
batch_normalization_428 (BatchN (None, 5, 32)        128         conv1d_550[0][0]                 
__________________________________________________________________________________________________
activation_582 (Activation)     (None, 5, 32)        0           batch_normalization_428[0][0]    
__________________________________________________________________________________________________
conv1d_551 (Conv1D)             (None, 5, 32)        3104        activation_582[0][0]             
__________________________________________________________________________________________________
batch_normalization_429 (BatchN (None, 5, 32)        128         conv1d_551[0][0]                 
__________________________________________________________________________________________________
add_203 (Add)                   (None, 5, 32)        0           activation_581[0][0]             
                                                                 batch_normalization_429[0][0]    
__________________________________________________________________________________________________
activation_583 (Activation)     (None, 5, 32)        0           add_203[0][0]                    
__________________________________________________________________________________________________
conv1d_552 (Conv1D)             (None, 5, 32)        3104        activation_583[0][0]             
__________________________________________________________________________________________________
batch_normalization_430 (BatchN (None, 5, 32)        128         conv1d_552[0][0]                 
__________________________________________________________________________________________________
activation_584 (Activation)     (None, 5, 32)        0           batch_normalization_430[0][0]    
__________________________________________________________________________________________________
conv1d_553 (Conv1D)             (None, 5, 32)        3104        activation_584[0][0]             
__________________________________________________________________________________________________
batch_normalization_431 (BatchN (None, 5, 32)        128         conv1d_553[0][0]                 
__________________________________________________________________________________________________
add_204 (Add)                   (None, 5, 32)        0           activation_583[0][0]             
                                                                 batch_normalization_431[0][0]    
__________________________________________________________________________________________________
activation_585 (Activation)     (None, 5, 32)        0           add_204[0][0]                    
__________________________________________________________________________________________________
conv1d_554 (Conv1D)             (None, 3, 64)        6208        activation_585[0][0]             
__________________________________________________________________________________________________
batch_normalization_432 (BatchN (None, 3, 64)        256         conv1d_554[0][0]                 
__________________________________________________________________________________________________
activation_586 (Activation)     (None, 3, 64)        0           batch_normalization_432[0][0]    
__________________________________________________________________________________________________
conv1d_555 (Conv1D)             (None, 3, 64)        12352       activation_586[0][0]             
__________________________________________________________________________________________________
conv1d_556 (Conv1D)             (None, 3, 64)        2112        activation_585[0][0]             
__________________________________________________________________________________________________
batch_normalization_433 (BatchN (None, 3, 64)        256         conv1d_555[0][0]                 
__________________________________________________________________________________________________
add_205 (Add)                   (None, 3, 64)        0           conv1d_556[0][0]                 
                                                                 batch_normalization_433[0][0]    
__________________________________________________________________________________________________
activation_587 (Activation)     (None, 3, 64)        0           add_205[0][0]                    
__________________________________________________________________________________________________
conv1d_557 (Conv1D)             (None, 3, 64)        12352       activation_587[0][0]             
__________________________________________________________________________________________________
batch_normalization_434 (BatchN (None, 3, 64)        256         conv1d_557[0][0]                 
__________________________________________________________________________________________________
activation_588 (Activation)     (None, 3, 64)        0           batch_normalization_434[0][0]    
__________________________________________________________________________________________________
conv1d_558 (Conv1D)             (None, 3, 64)        12352       activation_588[0][0]             
__________________________________________________________________________________________________
batch_normalization_435 (BatchN (None, 3, 64)        256         conv1d_558[0][0]                 
__________________________________________________________________________________________________
add_206 (Add)                   (None, 3, 64)        0           activation_587[0][0]             
                                                                 batch_normalization_435[0][0]    
__________________________________________________________________________________________________
activation_589 (Activation)     (None, 3, 64)        0           add_206[0][0]                    
__________________________________________________________________________________________________
conv1d_559 (Conv1D)             (None, 3, 64)        12352       activation_589[0][0]             
__________________________________________________________________________________________________
batch_normalization_436 (BatchN (None, 3, 64)        256         conv1d_559[0][0]                 
__________________________________________________________________________________________________
activation_590 (Activation)     (None, 3, 64)        0           batch_normalization_436[0][0]    
__________________________________________________________________________________________________
conv1d_560 (Conv1D)             (None, 3, 64)        12352       activation_590[0][0]             
__________________________________________________________________________________________________
batch_normalization_437 (BatchN (None, 3, 64)        256         conv1d_560[0][0]                 
__________________________________________________________________________________________________
add_207 (Add)                   (None, 3, 64)        0           activation_589[0][0]             
                                                                 batch_normalization_437[0][0]    
__________________________________________________________________________________________________
activation_591 (Activation)     (None, 3, 64)        0           add_207[0][0]                    
__________________________________________________________________________________________________
average_pooling1d_23 (AveragePo (None, 3, 64)        0           activation_591[0][0]             
__________________________________________________________________________________________________
flatten_100 (Flatten)           (None, 192)          0           average_pooling1d_23[0][0]       
__________________________________________________________________________________________________
dense_2168 (Dense)              (None, 4)            772         flatten_100[0][0]                
==================================================================================================
Total params: 96,004
Trainable params: 94,628
Non-trainable params: 1,376
__________________________________________________________________________________________________
None

Accuracy Train: 85.11%
Accuracy Test: 80.45%
Loss Train: 0.72
Loss Test: 1.12
Numero dati esaminati: 752
True Positive 605
False Positive 147


------------------------------------------------------------------------
K-fold Cross Validation
------------------------------------------------------------------------
Training for fold 1 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 1s - loss: 0.2511 - accuracy: 0.9622 - val_loss: 0.9974 - val_accuracy: 0.7957
Epoch 2/110
 - 1s - loss: 0.2461 - accuracy: 0.9626 - val_loss: 1.0767 - val_accuracy: 0.8007
Epoch 3/110
 - 1s - loss: 0.2581 - accuracy: 0.9647 - val_loss: 1.0580 - val_accuracy: 0.8189
Epoch 4/110
 - 1s - loss: 0.2544 - accuracy: 0.9601 - val_loss: 1.1094 - val_accuracy: 0.8056
Epoch 5/110
 - 1s - loss: 0.2801 - accuracy: 0.9522 - val_loss: 0.9891 - val_accuracy: 0.8206
Epoch 6/110
 - 1s - loss: 0.2757 - accuracy: 0.9539 - val_loss: 1.1644 - val_accuracy: 0.7973
Epoch 7/110
 - 1s - loss: 0.2487 - accuracy: 0.9601 - val_loss: 0.9907 - val_accuracy: 0.8023
Epoch 8/110
 - 1s - loss: 0.2621 - accuracy: 0.9568 - val_loss: 0.9643 - val_accuracy: 0.8306
Epoch 9/110
 - 1s - loss: 0.2555 - accuracy: 0.9597 - val_loss: 1.0328 - val_accuracy: 0.8272
Epoch 10/110
 - 1s - loss: 0.2522 - accuracy: 0.9638 - val_loss: 1.0806 - val_accuracy: 0.8123
Epoch 11/110
 - 1s - loss: 0.2417 - accuracy: 0.9618 - val_loss: 1.0079 - val_accuracy: 0.7791
Epoch 12/110
 - 1s - loss: 0.2508 - accuracy: 0.9601 - val_loss: 1.1170 - val_accuracy: 0.8040
Epoch 13/110
 - 1s - loss: 0.2386 - accuracy: 0.9643 - val_loss: 1.0488 - val_accuracy: 0.8073
Epoch 14/110
 - 1s - loss: 0.2597 - accuracy: 0.9589 - val_loss: 1.0241 - val_accuracy: 0.8090
Epoch 15/110
 - 1s - loss: 0.2604 - accuracy: 0.9551 - val_loss: 1.0923 - val_accuracy: 0.8106
Epoch 16/110
 - 1s - loss: 0.2699 - accuracy: 0.9514 - val_loss: 1.0566 - val_accuracy: 0.8106
Epoch 17/110
 - 1s - loss: 0.2692 - accuracy: 0.9584 - val_loss: 1.0253 - val_accuracy: 0.8140
Epoch 18/110
 - 1s - loss: 0.2685 - accuracy: 0.9618 - val_loss: 1.0187 - val_accuracy: 0.8156
Epoch 19/110
 - 1s - loss: 0.2411 - accuracy: 0.9659 - val_loss: 1.0796 - val_accuracy: 0.8223
Epoch 20/110
 - 1s - loss: 0.2488 - accuracy: 0.9618 - val_loss: 1.0882 - val_accuracy: 0.7924
Epoch 21/110
 - 1s - loss: 0.2445 - accuracy: 0.9626 - val_loss: 1.0709 - val_accuracy: 0.8372
Epoch 22/110
 - 1s - loss: 0.2283 - accuracy: 0.9672 - val_loss: 1.0918 - val_accuracy: 0.8189
Epoch 23/110
 - 1s - loss: 0.2451 - accuracy: 0.9626 - val_loss: 1.0668 - val_accuracy: 0.7957
Epoch 24/110
 - 1s - loss: 0.2446 - accuracy: 0.9618 - val_loss: 1.0242 - val_accuracy: 0.8090
Epoch 25/110
 - 1s - loss: 0.2521 - accuracy: 0.9613 - val_loss: 1.1823 - val_accuracy: 0.8040
Epoch 26/110
 - 1s - loss: 0.2897 - accuracy: 0.9530 - val_loss: 1.1406 - val_accuracy: 0.8140
Epoch 27/110
 - 1s - loss: 0.2947 - accuracy: 0.9505 - val_loss: 1.1502 - val_accuracy: 0.8040
Epoch 28/110
 - 1s - loss: 0.2652 - accuracy: 0.9605 - val_loss: 1.1679 - val_accuracy: 0.8073
Epoch 29/110
 - 1s - loss: 0.2380 - accuracy: 0.9659 - val_loss: 1.0152 - val_accuracy: 0.8355
Epoch 30/110
 - 1s - loss: 0.2249 - accuracy: 0.9713 - val_loss: 1.0765 - val_accuracy: 0.8173
Epoch 31/110
 - 1s - loss: 0.2284 - accuracy: 0.9709 - val_loss: 1.1002 - val_accuracy: 0.8173
Epoch 32/110
 - 1s - loss: 0.2082 - accuracy: 0.9759 - val_loss: 1.0774 - val_accuracy: 0.8040
Epoch 33/110
 - 1s - loss: 0.2043 - accuracy: 0.9792 - val_loss: 1.0888 - val_accuracy: 0.8422
Epoch 34/110
 - 1s - loss: 0.2265 - accuracy: 0.9705 - val_loss: 1.1859 - val_accuracy: 0.8023
Epoch 35/110
 - 1s - loss: 0.2446 - accuracy: 0.9643 - val_loss: 1.1708 - val_accuracy: 0.8007
Epoch 36/110
 - 1s - loss: 0.2120 - accuracy: 0.9746 - val_loss: 1.1242 - val_accuracy: 0.8173
Epoch 37/110
 - 1s - loss: 0.2367 - accuracy: 0.9659 - val_loss: 1.2281 - val_accuracy: 0.8223
Epoch 38/110
 - 1s - loss: 0.2419 - accuracy: 0.9643 - val_loss: 1.2151 - val_accuracy: 0.8223
Epoch 39/110
 - 1s - loss: 0.2597 - accuracy: 0.9584 - val_loss: 1.1000 - val_accuracy: 0.8140
Epoch 40/110
 - 1s - loss: 0.2542 - accuracy: 0.9572 - val_loss: 1.0293 - val_accuracy: 0.7973
Epoch 41/110
 - 1s - loss: 0.2405 - accuracy: 0.9601 - val_loss: 1.0199 - val_accuracy: 0.8272
Epoch 42/110
 - 1s - loss: 0.2407 - accuracy: 0.9638 - val_loss: 1.0400 - val_accuracy: 0.8322
Epoch 43/110
 - 1s - loss: 0.2317 - accuracy: 0.9643 - val_loss: 1.2117 - val_accuracy: 0.8007
Epoch 44/110
 - 1s - loss: 0.2457 - accuracy: 0.9622 - val_loss: 1.2239 - val_accuracy: 0.7791
Epoch 45/110
 - 1s - loss: 0.2660 - accuracy: 0.9539 - val_loss: 1.0216 - val_accuracy: 0.8339
Epoch 46/110
 - 1s - loss: 0.2532 - accuracy: 0.9597 - val_loss: 1.0886 - val_accuracy: 0.8090
Epoch 47/110
 - 1s - loss: 0.2291 - accuracy: 0.9659 - val_loss: 1.0600 - val_accuracy: 0.8322
Epoch 48/110
 - 1s - loss: 0.2274 - accuracy: 0.9709 - val_loss: 1.0452 - val_accuracy: 0.8189
Epoch 49/110
 - 1s - loss: 0.2077 - accuracy: 0.9751 - val_loss: 1.0456 - val_accuracy: 0.8272
Epoch 50/110
 - 1s - loss: 0.2029 - accuracy: 0.9767 - val_loss: 1.0357 - val_accuracy: 0.8123
Epoch 51/110
 - 1s - loss: 0.2016 - accuracy: 0.9759 - val_loss: 1.1230 - val_accuracy: 0.8272
Epoch 52/110
 - 1s - loss: 0.2094 - accuracy: 0.9763 - val_loss: 1.1342 - val_accuracy: 0.8289
Epoch 53/110
 - 1s - loss: 0.2940 - accuracy: 0.9605 - val_loss: 1.3137 - val_accuracy: 0.7641
Epoch 54/110
 - 1s - loss: 0.2632 - accuracy: 0.9534 - val_loss: 1.1801 - val_accuracy: 0.8007
Epoch 55/110
 - 1s - loss: 0.2470 - accuracy: 0.9580 - val_loss: 1.1203 - val_accuracy: 0.7907
Epoch 56/110
 - 1s - loss: 0.2726 - accuracy: 0.9593 - val_loss: 1.1309 - val_accuracy: 0.8056
Epoch 57/110
 - 1s - loss: 0.2324 - accuracy: 0.9655 - val_loss: 0.9778 - val_accuracy: 0.8455
Epoch 58/110
 - 1s - loss: 0.2362 - accuracy: 0.9667 - val_loss: 1.0370 - val_accuracy: 0.8339
Epoch 59/110
 - 1s - loss: 0.2374 - accuracy: 0.9630 - val_loss: 1.0906 - val_accuracy: 0.8206
Epoch 60/110
 - 1s - loss: 0.2305 - accuracy: 0.9663 - val_loss: 1.0672 - val_accuracy: 0.8256
Epoch 61/110
 - 1s - loss: 0.2265 - accuracy: 0.9701 - val_loss: 1.1269 - val_accuracy: 0.8156
Epoch 62/110
 - 1s - loss: 0.2161 - accuracy: 0.9709 - val_loss: 1.1150 - val_accuracy: 0.8189
Epoch 63/110
 - 1s - loss: 0.2222 - accuracy: 0.9672 - val_loss: 1.1297 - val_accuracy: 0.8289
Epoch 64/110
 - 1s - loss: 0.2516 - accuracy: 0.9643 - val_loss: 1.1292 - val_accuracy: 0.8256
Epoch 65/110
 - 1s - loss: 0.2355 - accuracy: 0.9676 - val_loss: 1.0398 - val_accuracy: 0.8289
Epoch 66/110
 - 1s - loss: 0.2143 - accuracy: 0.9734 - val_loss: 1.1336 - val_accuracy: 0.8106
Epoch 67/110
 - 1s - loss: 0.2071 - accuracy: 0.9763 - val_loss: 1.1623 - val_accuracy: 0.8073
Epoch 68/110
 - 1s - loss: 0.1926 - accuracy: 0.9784 - val_loss: 1.0515 - val_accuracy: 0.8073
Epoch 69/110
 - 1s - loss: 0.1852 - accuracy: 0.9838 - val_loss: 1.1023 - val_accuracy: 0.8289
Epoch 70/110
 - 1s - loss: 0.2113 - accuracy: 0.9726 - val_loss: 1.1478 - val_accuracy: 0.8439
Epoch 71/110
 - 1s - loss: 0.2249 - accuracy: 0.9680 - val_loss: 1.2012 - val_accuracy: 0.8056
Epoch 72/110
 - 1s - loss: 0.2230 - accuracy: 0.9676 - val_loss: 1.1028 - val_accuracy: 0.8106
Epoch 73/110
 - 1s - loss: 0.2359 - accuracy: 0.9643 - val_loss: 1.1963 - val_accuracy: 0.8056
Epoch 74/110
 - 1s - loss: 0.2208 - accuracy: 0.9692 - val_loss: 1.0288 - val_accuracy: 0.8389
Epoch 75/110
 - 1s - loss: 0.2520 - accuracy: 0.9643 - val_loss: 1.0219 - val_accuracy: 0.8073
Epoch 76/110
 - 1s - loss: 0.2151 - accuracy: 0.9717 - val_loss: 1.0759 - val_accuracy: 0.8239
Epoch 77/110
 - 1s - loss: 0.1922 - accuracy: 0.9784 - val_loss: 1.1193 - val_accuracy: 0.8123
Epoch 78/110
 - 1s - loss: 0.1848 - accuracy: 0.9813 - val_loss: 1.0702 - val_accuracy: 0.8289
Epoch 79/110
 - 1s - loss: 0.1983 - accuracy: 0.9759 - val_loss: 1.1317 - val_accuracy: 0.8322
Epoch 80/110
 - 1s - loss: 0.2525 - accuracy: 0.9572 - val_loss: 1.1380 - val_accuracy: 0.8339
Epoch 81/110
 - 1s - loss: 0.2138 - accuracy: 0.9730 - val_loss: 1.0180 - val_accuracy: 0.8256
Epoch 82/110
 - 1s - loss: 0.2147 - accuracy: 0.9705 - val_loss: 1.3038 - val_accuracy: 0.7907
Epoch 83/110
 - 1s - loss: 0.2188 - accuracy: 0.9676 - val_loss: 1.1028 - val_accuracy: 0.8173
Epoch 84/110
 - 1s - loss: 0.2037 - accuracy: 0.9796 - val_loss: 1.1505 - val_accuracy: 0.8189
Epoch 85/110
 - 1s - loss: 0.1950 - accuracy: 0.9788 - val_loss: 1.1361 - val_accuracy: 0.8239
Epoch 86/110
 - 1s - loss: 0.2204 - accuracy: 0.9726 - val_loss: 1.2084 - val_accuracy: 0.8056
Epoch 87/110
 - 1s - loss: 0.2572 - accuracy: 0.9605 - val_loss: 1.1559 - val_accuracy: 0.8073
Epoch 88/110
 - 1s - loss: 0.2404 - accuracy: 0.9597 - val_loss: 1.1147 - val_accuracy: 0.8123
Epoch 89/110
 - 1s - loss: 0.2287 - accuracy: 0.9692 - val_loss: 1.0738 - val_accuracy: 0.8389
Epoch 90/110
 - 1s - loss: 0.2053 - accuracy: 0.9763 - val_loss: 1.1416 - val_accuracy: 0.8405
Epoch 91/110
 - 1s - loss: 0.2109 - accuracy: 0.9734 - val_loss: 1.0510 - val_accuracy: 0.8488
Epoch 92/110
 - 1s - loss: 0.2112 - accuracy: 0.9751 - val_loss: 1.1758 - val_accuracy: 0.8306
Epoch 93/110
 - 1s - loss: 0.2077 - accuracy: 0.9755 - val_loss: 1.1605 - val_accuracy: 0.8372
Epoch 94/110
 - 1s - loss: 0.2089 - accuracy: 0.9722 - val_loss: 1.0531 - val_accuracy: 0.8389
Epoch 95/110
 - 1s - loss: 0.2109 - accuracy: 0.9746 - val_loss: 1.1282 - val_accuracy: 0.8239
Epoch 96/110
 - 1s - loss: 0.2230 - accuracy: 0.9688 - val_loss: 1.2913 - val_accuracy: 0.7890
Epoch 97/110
 - 1s - loss: 0.2769 - accuracy: 0.9597 - val_loss: 1.0353 - val_accuracy: 0.8040
Epoch 98/110
 - 1s - loss: 0.2369 - accuracy: 0.9676 - val_loss: 1.1348 - val_accuracy: 0.8056
Epoch 99/110
 - 1s - loss: 0.2299 - accuracy: 0.9672 - val_loss: 0.9928 - val_accuracy: 0.8355
Epoch 100/110
 - 1s - loss: 0.2155 - accuracy: 0.9726 - val_loss: 1.0056 - val_accuracy: 0.8173
Epoch 101/110
 - 1s - loss: 0.2081 - accuracy: 0.9709 - val_loss: 1.0567 - val_accuracy: 0.8405
Epoch 102/110
 - 1s - loss: 0.2020 - accuracy: 0.9746 - val_loss: 1.1127 - val_accuracy: 0.8488
Epoch 103/110
 - 1s - loss: 0.1955 - accuracy: 0.9788 - val_loss: 1.0435 - val_accuracy: 0.8372
Epoch 104/110
 - 1s - loss: 0.1889 - accuracy: 0.9821 - val_loss: 1.0691 - val_accuracy: 0.8272
Epoch 105/110
 - 1s - loss: 0.1815 - accuracy: 0.9792 - val_loss: 1.0903 - val_accuracy: 0.8472
Epoch 106/110
 - 1s - loss: 0.2028 - accuracy: 0.9771 - val_loss: 1.1392 - val_accuracy: 0.8505
Epoch 107/110
 - 1s - loss: 0.2106 - accuracy: 0.9738 - val_loss: 1.1526 - val_accuracy: 0.8339
Epoch 108/110
 - 1s - loss: 0.1975 - accuracy: 0.9788 - val_loss: 1.1011 - val_accuracy: 0.8355
Epoch 109/110
 - 1s - loss: 0.2051 - accuracy: 0.9730 - val_loss: 1.0024 - val_accuracy: 0.8405
Epoch 110/110
 - 1s - loss: 0.2298 - accuracy: 0.9638 - val_loss: 1.1649 - val_accuracy: 0.8140
------------------------------------------------------------------------
Training for fold 2 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 1s - loss: 0.2845 - accuracy: 0.9460 - val_loss: 1.2879 - val_accuracy: 0.8023
Epoch 2/110
 - 1s - loss: 0.2758 - accuracy: 0.9464 - val_loss: 1.0986 - val_accuracy: 0.8156
Epoch 3/110
 - 1s - loss: 0.2478 - accuracy: 0.9605 - val_loss: 1.0888 - val_accuracy: 0.8223
Epoch 4/110
 - 1s - loss: 0.2471 - accuracy: 0.9618 - val_loss: 1.1575 - val_accuracy: 0.8239
Epoch 5/110
 - 1s - loss: 0.2105 - accuracy: 0.9717 - val_loss: 1.1051 - val_accuracy: 0.8339
Epoch 6/110
 - 1s - loss: 0.1904 - accuracy: 0.9771 - val_loss: 1.0568 - val_accuracy: 0.8455
Epoch 7/110
 - 1s - loss: 0.1860 - accuracy: 0.9792 - val_loss: 1.1141 - val_accuracy: 0.8389
Epoch 8/110
 - 1s - loss: 0.1859 - accuracy: 0.9792 - val_loss: 1.1313 - val_accuracy: 0.8123
Epoch 9/110
 - 1s - loss: 0.1823 - accuracy: 0.9805 - val_loss: 1.0849 - val_accuracy: 0.8289
Epoch 10/110
 - 1s - loss: 0.1958 - accuracy: 0.9763 - val_loss: 1.0415 - val_accuracy: 0.8372
Epoch 11/110
 - 1s - loss: 0.1996 - accuracy: 0.9717 - val_loss: 1.0667 - val_accuracy: 0.8322
Epoch 12/110
 - 1s - loss: 0.1874 - accuracy: 0.9800 - val_loss: 1.1123 - val_accuracy: 0.8272
Epoch 13/110
 - 1s - loss: 0.1752 - accuracy: 0.9834 - val_loss: 1.0996 - val_accuracy: 0.8372
Epoch 14/110
 - 1s - loss: 0.1964 - accuracy: 0.9780 - val_loss: 1.1196 - val_accuracy: 0.8289
Epoch 15/110
 - 1s - loss: 0.1992 - accuracy: 0.9713 - val_loss: 1.0985 - val_accuracy: 0.8422
Epoch 16/110
 - 1s - loss: 0.2235 - accuracy: 0.9630 - val_loss: 1.1298 - val_accuracy: 0.8239
Epoch 17/110
 - 1s - loss: 0.2265 - accuracy: 0.9634 - val_loss: 1.0506 - val_accuracy: 0.8090
Epoch 18/110
 - 1s - loss: 0.2115 - accuracy: 0.9759 - val_loss: 1.1141 - val_accuracy: 0.8422
Epoch 19/110
 - 1s - loss: 0.2039 - accuracy: 0.9717 - val_loss: 1.1404 - val_accuracy: 0.8123
Epoch 20/110
 - 1s - loss: 0.2202 - accuracy: 0.9663 - val_loss: 1.1631 - val_accuracy: 0.8023
Epoch 21/110
 - 1s - loss: 0.2181 - accuracy: 0.9697 - val_loss: 1.1006 - val_accuracy: 0.8405
Epoch 22/110
 - 1s - loss: 0.2100 - accuracy: 0.9713 - val_loss: 1.0340 - val_accuracy: 0.8588
Epoch 23/110
 - 1s - loss: 0.1938 - accuracy: 0.9767 - val_loss: 1.1012 - val_accuracy: 0.8223
Epoch 24/110
 - 1s - loss: 0.2198 - accuracy: 0.9692 - val_loss: 1.1085 - val_accuracy: 0.8256
Epoch 25/110
 - 1s - loss: 0.2373 - accuracy: 0.9626 - val_loss: 1.1928 - val_accuracy: 0.8306
Epoch 26/110
 - 1s - loss: 0.2600 - accuracy: 0.9564 - val_loss: 1.0900 - val_accuracy: 0.7924
Epoch 27/110
 - 1s - loss: 0.2184 - accuracy: 0.9730 - val_loss: 1.1323 - val_accuracy: 0.8040
Epoch 28/110
 - 1s - loss: 0.1938 - accuracy: 0.9776 - val_loss: 1.0634 - val_accuracy: 0.8339
Epoch 29/110
 - 1s - loss: 0.1736 - accuracy: 0.9850 - val_loss: 1.0689 - val_accuracy: 0.8439
Epoch 30/110
 - 1s - loss: 0.1703 - accuracy: 0.9855 - val_loss: 1.0593 - val_accuracy: 0.8472
Epoch 31/110
 - 1s - loss: 0.1729 - accuracy: 0.9821 - val_loss: 1.0574 - val_accuracy: 0.8505
Epoch 32/110
 - 1s - loss: 0.1752 - accuracy: 0.9809 - val_loss: 1.1287 - val_accuracy: 0.8306
Epoch 33/110
 - 1s - loss: 0.1748 - accuracy: 0.9830 - val_loss: 1.1130 - val_accuracy: 0.8289
Epoch 34/110
 - 1s - loss: 0.1937 - accuracy: 0.9755 - val_loss: 1.1314 - val_accuracy: 0.8289
Epoch 35/110
 - 1s - loss: 0.2276 - accuracy: 0.9709 - val_loss: 1.0965 - val_accuracy: 0.8339
Epoch 36/110
 - 1s - loss: 0.1868 - accuracy: 0.9800 - val_loss: 1.0864 - val_accuracy: 0.8289
Epoch 37/110
 - 1s - loss: 0.1933 - accuracy: 0.9776 - val_loss: 1.0960 - val_accuracy: 0.8289
Epoch 38/110
 - 1s - loss: 0.1959 - accuracy: 0.9776 - val_loss: 1.0722 - val_accuracy: 0.8056
Epoch 39/110
 - 1s - loss: 0.2147 - accuracy: 0.9659 - val_loss: 1.1683 - val_accuracy: 0.8306
Epoch 40/110
 - 1s - loss: 0.2041 - accuracy: 0.9730 - val_loss: 1.1017 - val_accuracy: 0.8339
Epoch 41/110
 - 1s - loss: 0.1895 - accuracy: 0.9776 - val_loss: 1.1975 - val_accuracy: 0.8272
Epoch 42/110
 - 1s - loss: 0.1981 - accuracy: 0.9746 - val_loss: 1.1974 - val_accuracy: 0.8256
Epoch 43/110
 - 1s - loss: 0.2054 - accuracy: 0.9717 - val_loss: 1.1963 - val_accuracy: 0.8189
Epoch 44/110
 - 1s - loss: 0.2018 - accuracy: 0.9742 - val_loss: 1.1821 - val_accuracy: 0.8189
Epoch 45/110
 - 1s - loss: 0.1861 - accuracy: 0.9780 - val_loss: 1.1583 - val_accuracy: 0.8123
Epoch 46/110
 - 1s - loss: 0.2225 - accuracy: 0.9692 - val_loss: 1.1338 - val_accuracy: 0.8090
Epoch 47/110
 - 1s - loss: 0.2068 - accuracy: 0.9709 - val_loss: 1.0447 - val_accuracy: 0.8256
Epoch 48/110
 - 1s - loss: 0.2004 - accuracy: 0.9734 - val_loss: 1.0686 - val_accuracy: 0.8173
Epoch 49/110
 - 1s - loss: 0.2022 - accuracy: 0.9722 - val_loss: 1.0022 - val_accuracy: 0.8522
Epoch 50/110
 - 1s - loss: 0.1952 - accuracy: 0.9788 - val_loss: 1.2659 - val_accuracy: 0.8322
Epoch 51/110
 - 1s - loss: 0.2257 - accuracy: 0.9672 - val_loss: 1.1161 - val_accuracy: 0.8073
Epoch 52/110
 - 1s - loss: 0.2141 - accuracy: 0.9734 - val_loss: 1.0958 - val_accuracy: 0.8272
Epoch 53/110
 - 1s - loss: 0.2009 - accuracy: 0.9759 - val_loss: 1.0910 - val_accuracy: 0.8389
Epoch 54/110
 - 1s - loss: 0.2124 - accuracy: 0.9672 - val_loss: 1.0738 - val_accuracy: 0.8439
Epoch 55/110
 - 1s - loss: 0.2400 - accuracy: 0.9593 - val_loss: 1.0198 - val_accuracy: 0.8256
Epoch 56/110
 - 1s - loss: 0.2311 - accuracy: 0.9638 - val_loss: 1.1289 - val_accuracy: 0.7940
Epoch 57/110
 - 1s - loss: 0.2039 - accuracy: 0.9705 - val_loss: 1.1111 - val_accuracy: 0.8156
Epoch 58/110
 - 1s - loss: 0.2155 - accuracy: 0.9697 - val_loss: 1.0577 - val_accuracy: 0.8322
Epoch 59/110
 - 1s - loss: 0.1985 - accuracy: 0.9751 - val_loss: 1.0615 - val_accuracy: 0.8123
Epoch 60/110
 - 1s - loss: 0.1806 - accuracy: 0.9796 - val_loss: 1.0854 - val_accuracy: 0.8422
Epoch 61/110
 - 1s - loss: 0.1840 - accuracy: 0.9792 - val_loss: 1.1216 - val_accuracy: 0.8389
Epoch 62/110
 - 1s - loss: 0.1812 - accuracy: 0.9800 - val_loss: 1.1305 - val_accuracy: 0.8140
Epoch 63/110
 - 1s - loss: 0.1705 - accuracy: 0.9842 - val_loss: 1.0999 - val_accuracy: 0.8339
Epoch 64/110
 - 1s - loss: 0.1685 - accuracy: 0.9830 - val_loss: 1.0122 - val_accuracy: 0.8472
Epoch 65/110
 - 1s - loss: 0.1797 - accuracy: 0.9788 - val_loss: 1.0859 - val_accuracy: 0.8339
Epoch 66/110
 - 1s - loss: 0.2103 - accuracy: 0.9705 - val_loss: 1.0235 - val_accuracy: 0.8389
Epoch 67/110
 - 1s - loss: 0.1998 - accuracy: 0.9730 - val_loss: 0.9959 - val_accuracy: 0.8405
Epoch 68/110
 - 1s - loss: 0.1772 - accuracy: 0.9830 - val_loss: 1.1020 - val_accuracy: 0.8239
Epoch 69/110
 - 1s - loss: 0.1684 - accuracy: 0.9830 - val_loss: 1.0512 - val_accuracy: 0.8289
Epoch 70/110
 - 1s - loss: 0.1784 - accuracy: 0.9780 - val_loss: 1.0748 - val_accuracy: 0.8439
Epoch 71/110
 - 1s - loss: 0.1819 - accuracy: 0.9800 - val_loss: 1.0919 - val_accuracy: 0.8189
Epoch 72/110
 - 1s - loss: 0.1761 - accuracy: 0.9809 - val_loss: 1.0162 - val_accuracy: 0.8455
Epoch 73/110
 - 1s - loss: 0.1791 - accuracy: 0.9767 - val_loss: 1.1534 - val_accuracy: 0.8023
Epoch 74/110
 - 1s - loss: 0.1977 - accuracy: 0.9751 - val_loss: 1.2203 - val_accuracy: 0.8106
Epoch 75/110
 - 1s - loss: 0.1907 - accuracy: 0.9776 - val_loss: 1.0644 - val_accuracy: 0.8289
Epoch 76/110
 - 1s - loss: 0.2099 - accuracy: 0.9692 - val_loss: 1.1233 - val_accuracy: 0.8272
Epoch 77/110
 - 1s - loss: 0.1954 - accuracy: 0.9746 - val_loss: 1.1004 - val_accuracy: 0.8272
Epoch 78/110
 - 1s - loss: 0.1948 - accuracy: 0.9692 - val_loss: 1.0905 - val_accuracy: 0.8189
Epoch 79/110
 - 1s - loss: 0.1846 - accuracy: 0.9751 - val_loss: 1.1275 - val_accuracy: 0.8156
Epoch 80/110
 - 1s - loss: 0.1922 - accuracy: 0.9763 - val_loss: 1.1581 - val_accuracy: 0.8156
Epoch 81/110
 - 1s - loss: 0.1848 - accuracy: 0.9796 - val_loss: 1.0789 - val_accuracy: 0.8156
Epoch 82/110
 - 1s - loss: 0.1709 - accuracy: 0.9817 - val_loss: 1.1799 - val_accuracy: 0.8239
Epoch 83/110
 - 1s - loss: 0.1762 - accuracy: 0.9813 - val_loss: 1.2000 - val_accuracy: 0.8106
Epoch 84/110
 - 1s - loss: 0.1848 - accuracy: 0.9796 - val_loss: 1.0857 - val_accuracy: 0.8322
Epoch 85/110
 - 1s - loss: 0.1991 - accuracy: 0.9734 - val_loss: 1.2878 - val_accuracy: 0.7990
Epoch 86/110
 - 1s - loss: 0.2474 - accuracy: 0.9597 - val_loss: 1.1324 - val_accuracy: 0.8090
Epoch 87/110
 - 1s - loss: 0.2370 - accuracy: 0.9630 - val_loss: 1.0876 - val_accuracy: 0.8106
Epoch 88/110
 - 1s - loss: 0.2035 - accuracy: 0.9759 - val_loss: 1.1065 - val_accuracy: 0.8405
Epoch 89/110
 - 1s - loss: 0.1963 - accuracy: 0.9755 - val_loss: 1.0780 - val_accuracy: 0.8422
Epoch 90/110
 - 1s - loss: 0.1785 - accuracy: 0.9821 - val_loss: 1.0292 - val_accuracy: 0.8339
Epoch 91/110
 - 1s - loss: 0.1654 - accuracy: 0.9825 - val_loss: 1.0313 - val_accuracy: 0.8372
Epoch 92/110
 - 1s - loss: 0.1639 - accuracy: 0.9838 - val_loss: 1.0066 - val_accuracy: 0.8522
Epoch 93/110
 - 1s - loss: 0.1550 - accuracy: 0.9859 - val_loss: 1.0856 - val_accuracy: 0.8439
Epoch 94/110
 - 1s - loss: 0.1715 - accuracy: 0.9813 - val_loss: 1.1221 - val_accuracy: 0.8372
Epoch 95/110
 - 1s - loss: 0.1768 - accuracy: 0.9776 - val_loss: 1.2463 - val_accuracy: 0.8040
Epoch 96/110
 - 1s - loss: 0.2128 - accuracy: 0.9692 - val_loss: 1.0602 - val_accuracy: 0.8306
Epoch 97/110
 - 1s - loss: 0.1857 - accuracy: 0.9796 - val_loss: 1.1231 - val_accuracy: 0.7874
Epoch 98/110
 - 1s - loss: 0.1798 - accuracy: 0.9784 - val_loss: 1.0648 - val_accuracy: 0.8272
Epoch 99/110
 - 1s - loss: 0.1888 - accuracy: 0.9759 - val_loss: 1.1439 - val_accuracy: 0.8322
Epoch 100/110
 - 1s - loss: 0.2021 - accuracy: 0.9680 - val_loss: 1.2814 - val_accuracy: 0.8239
Epoch 101/110
 - 1s - loss: 0.1922 - accuracy: 0.9771 - val_loss: 1.0676 - val_accuracy: 0.8372
Epoch 102/110
 - 1s - loss: 0.1903 - accuracy: 0.9771 - val_loss: 1.1544 - val_accuracy: 0.8156
Epoch 103/110
 - 1s - loss: 0.1739 - accuracy: 0.9792 - val_loss: 1.1149 - val_accuracy: 0.8372
Epoch 104/110
 - 1s - loss: 0.1583 - accuracy: 0.9867 - val_loss: 1.1248 - val_accuracy: 0.8372
Epoch 105/110
 - 1s - loss: 0.1488 - accuracy: 0.9879 - val_loss: 1.1417 - val_accuracy: 0.8522
Epoch 106/110
 - 1s - loss: 0.1514 - accuracy: 0.9879 - val_loss: 1.1249 - val_accuracy: 0.8538
Epoch 107/110
 - 1s - loss: 0.1736 - accuracy: 0.9813 - val_loss: 1.1846 - val_accuracy: 0.8156
Epoch 108/110
 - 1s - loss: 0.2001 - accuracy: 0.9701 - val_loss: 1.3360 - val_accuracy: 0.7957
Epoch 109/110
 - 1s - loss: 0.2124 - accuracy: 0.9680 - val_loss: 1.2385 - val_accuracy: 0.8140
Epoch 110/110
 - 1s - loss: 0.2343 - accuracy: 0.9630 - val_loss: 1.1564 - val_accuracy: 0.8073
------------------------------------------------------------------------
Training for fold 3 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 1s - loss: 0.2252 - accuracy: 0.9672 - val_loss: 1.0157 - val_accuracy: 0.8123
Epoch 2/110
 - 1s - loss: 0.2079 - accuracy: 0.9701 - val_loss: 1.0604 - val_accuracy: 0.8106
Epoch 3/110
 - 1s - loss: 0.2077 - accuracy: 0.9638 - val_loss: 1.0562 - val_accuracy: 0.8272
Epoch 4/110
 - 1s - loss: 0.2143 - accuracy: 0.9659 - val_loss: 1.1272 - val_accuracy: 0.8239
Epoch 5/110
 - 1s - loss: 0.2007 - accuracy: 0.9697 - val_loss: 1.0228 - val_accuracy: 0.8289
Epoch 6/110
 - 1s - loss: 0.2003 - accuracy: 0.9738 - val_loss: 1.0560 - val_accuracy: 0.8239
Epoch 7/110
 - 1s - loss: 0.1878 - accuracy: 0.9755 - val_loss: 1.0228 - val_accuracy: 0.8140
Epoch 8/110
 - 1s - loss: 0.1764 - accuracy: 0.9796 - val_loss: 1.0718 - val_accuracy: 0.8289
Epoch 9/110
 - 1s - loss: 0.1794 - accuracy: 0.9788 - val_loss: 1.2674 - val_accuracy: 0.8256
Epoch 10/110
 - 1s - loss: 0.2181 - accuracy: 0.9643 - val_loss: 1.1322 - val_accuracy: 0.8256
Epoch 11/110
 - 1s - loss: 0.2155 - accuracy: 0.9692 - val_loss: 1.2150 - val_accuracy: 0.8073
Epoch 12/110
 - 1s - loss: 0.2012 - accuracy: 0.9738 - val_loss: 1.1229 - val_accuracy: 0.8339
Epoch 13/110
 - 1s - loss: 0.1688 - accuracy: 0.9809 - val_loss: 1.1114 - val_accuracy: 0.8372
Epoch 14/110
 - 1s - loss: 0.1832 - accuracy: 0.9788 - val_loss: 1.2383 - val_accuracy: 0.8322
Epoch 15/110
 - 1s - loss: 0.1776 - accuracy: 0.9809 - val_loss: 1.1535 - val_accuracy: 0.8322
Epoch 16/110
 - 1s - loss: 0.1612 - accuracy: 0.9855 - val_loss: 1.1635 - val_accuracy: 0.8439
Epoch 17/110
 - 1s - loss: 0.1549 - accuracy: 0.9863 - val_loss: 1.1242 - val_accuracy: 0.8389
Epoch 18/110
 - 1s - loss: 0.1502 - accuracy: 0.9875 - val_loss: 1.1024 - val_accuracy: 0.8355
Epoch 19/110
 - 1s - loss: 0.1502 - accuracy: 0.9879 - val_loss: 1.1261 - val_accuracy: 0.8538
Epoch 20/110
 - 1s - loss: 0.1648 - accuracy: 0.9821 - val_loss: 1.2613 - val_accuracy: 0.8272
Epoch 21/110
 - 1s - loss: 0.1788 - accuracy: 0.9771 - val_loss: 1.2034 - val_accuracy: 0.8256
Epoch 22/110
 - 1s - loss: 0.1801 - accuracy: 0.9759 - val_loss: 1.0856 - val_accuracy: 0.8272
Epoch 23/110
 - 1s - loss: 0.1768 - accuracy: 0.9788 - val_loss: 1.1321 - val_accuracy: 0.8156
Epoch 24/110
 - 1s - loss: 0.1693 - accuracy: 0.9800 - val_loss: 1.1181 - val_accuracy: 0.8322
Epoch 25/110
 - 1s - loss: 0.1691 - accuracy: 0.9805 - val_loss: 1.1548 - val_accuracy: 0.8189
Epoch 26/110
 - 1s - loss: 0.1798 - accuracy: 0.9767 - val_loss: 1.2513 - val_accuracy: 0.8156
Epoch 27/110
 - 1s - loss: 0.1714 - accuracy: 0.9846 - val_loss: 1.1689 - val_accuracy: 0.8289
Epoch 28/110
 - 1s - loss: 0.1725 - accuracy: 0.9800 - val_loss: 1.1687 - val_accuracy: 0.8156
Epoch 29/110
 - 1s - loss: 0.1904 - accuracy: 0.9751 - val_loss: 1.3020 - val_accuracy: 0.8023
Epoch 30/110
 - 1s - loss: 0.2219 - accuracy: 0.9676 - val_loss: 1.2671 - val_accuracy: 0.8239
Epoch 31/110
 - 1s - loss: 0.2049 - accuracy: 0.9697 - val_loss: 1.2202 - val_accuracy: 0.8156
Epoch 32/110
 - 1s - loss: 0.1729 - accuracy: 0.9788 - val_loss: 1.0103 - val_accuracy: 0.8339
Epoch 33/110
 - 1s - loss: 0.1742 - accuracy: 0.9809 - val_loss: 1.0894 - val_accuracy: 0.8173
Epoch 34/110
 - 1s - loss: 0.2036 - accuracy: 0.9734 - val_loss: 1.2029 - val_accuracy: 0.8173
Epoch 35/110
 - 1s - loss: 0.1950 - accuracy: 0.9709 - val_loss: 1.1199 - val_accuracy: 0.8272
Epoch 36/110
 - 1s - loss: 0.1894 - accuracy: 0.9763 - val_loss: 1.1097 - val_accuracy: 0.8355
Epoch 37/110
 - 1s - loss: 0.1610 - accuracy: 0.9842 - val_loss: 1.1417 - val_accuracy: 0.8522
Epoch 38/110
 - 1s - loss: 0.1702 - accuracy: 0.9809 - val_loss: 1.0516 - val_accuracy: 0.8488
Epoch 39/110
 - 1s - loss: 0.1531 - accuracy: 0.9855 - val_loss: 1.0885 - val_accuracy: 0.8538
Epoch 40/110
 - 1s - loss: 0.1658 - accuracy: 0.9817 - val_loss: 1.0984 - val_accuracy: 0.8306
Epoch 41/110
 - 1s - loss: 0.1833 - accuracy: 0.9784 - val_loss: 1.1392 - val_accuracy: 0.8289
Epoch 42/110
 - 1s - loss: 0.1991 - accuracy: 0.9722 - val_loss: 1.0988 - val_accuracy: 0.8389
Epoch 43/110
 - 1s - loss: 0.1816 - accuracy: 0.9767 - val_loss: 1.1759 - val_accuracy: 0.8090
Epoch 44/110
 - 1s - loss: 0.2040 - accuracy: 0.9734 - val_loss: 1.1192 - val_accuracy: 0.8322
Epoch 45/110
 - 1s - loss: 0.1849 - accuracy: 0.9751 - val_loss: 1.0959 - val_accuracy: 0.8322
Epoch 46/110
 - 1s - loss: 0.1912 - accuracy: 0.9755 - val_loss: 1.0992 - val_accuracy: 0.8223
Epoch 47/110
 - 1s - loss: 0.1830 - accuracy: 0.9763 - val_loss: 1.1105 - val_accuracy: 0.8405
Epoch 48/110
 - 1s - loss: 0.2012 - accuracy: 0.9722 - val_loss: 1.0129 - val_accuracy: 0.8289
Epoch 49/110
 - 1s - loss: 0.1710 - accuracy: 0.9792 - val_loss: 0.9697 - val_accuracy: 0.8339
Epoch 50/110
 - 1s - loss: 0.1713 - accuracy: 0.9842 - val_loss: 1.0359 - val_accuracy: 0.8156
Epoch 51/110
 - 1s - loss: 0.1826 - accuracy: 0.9788 - val_loss: 1.0435 - val_accuracy: 0.8056
Epoch 52/110
 - 1s - loss: 0.1584 - accuracy: 0.9821 - val_loss: 1.0564 - val_accuracy: 0.8156
Epoch 53/110
 - 1s - loss: 0.1685 - accuracy: 0.9813 - val_loss: 1.0895 - val_accuracy: 0.8422
Epoch 54/110
 - 1s - loss: 0.1615 - accuracy: 0.9846 - val_loss: 1.1174 - val_accuracy: 0.8256
Epoch 55/110
 - 1s - loss: 0.1499 - accuracy: 0.9859 - val_loss: 1.0771 - val_accuracy: 0.8522
Epoch 56/110
 - 1s - loss: 0.1494 - accuracy: 0.9884 - val_loss: 1.0808 - val_accuracy: 0.8372
Epoch 57/110
 - 1s - loss: 0.1566 - accuracy: 0.9850 - val_loss: 1.1111 - val_accuracy: 0.8472
Epoch 58/110
 - 1s - loss: 0.1456 - accuracy: 0.9884 - val_loss: 1.1122 - val_accuracy: 0.8538
Epoch 59/110
 - 1s - loss: 0.1454 - accuracy: 0.9863 - val_loss: 1.1652 - val_accuracy: 0.8289
Epoch 60/110
 - 1s - loss: 0.1678 - accuracy: 0.9805 - val_loss: 1.1495 - val_accuracy: 0.8339
Epoch 61/110
 - 1s - loss: 0.1779 - accuracy: 0.9763 - val_loss: 1.0907 - val_accuracy: 0.8389
Epoch 62/110
 - 1s - loss: 0.1904 - accuracy: 0.9763 - val_loss: 1.2815 - val_accuracy: 0.8156
Epoch 63/110
 - 1s - loss: 0.1767 - accuracy: 0.9767 - val_loss: 1.1398 - val_accuracy: 0.8272
Epoch 64/110
 - 1s - loss: 0.2249 - accuracy: 0.9609 - val_loss: 1.0660 - val_accuracy: 0.8090
Epoch 65/110
 - 1s - loss: 0.1883 - accuracy: 0.9717 - val_loss: 1.1650 - val_accuracy: 0.8306
Epoch 66/110
 - 1s - loss: 0.1938 - accuracy: 0.9771 - val_loss: 1.1319 - val_accuracy: 0.8206
Epoch 67/110
 - 1s - loss: 0.1845 - accuracy: 0.9751 - val_loss: 1.0634 - val_accuracy: 0.8322
Epoch 68/110
 - 1s - loss: 0.1644 - accuracy: 0.9813 - val_loss: 1.0218 - val_accuracy: 0.8571
Epoch 69/110
 - 1s - loss: 0.1490 - accuracy: 0.9879 - val_loss: 1.0567 - val_accuracy: 0.8488
Epoch 70/110
 - 1s - loss: 0.1411 - accuracy: 0.9879 - val_loss: 1.0788 - val_accuracy: 0.8422
Epoch 71/110
 - 1s - loss: 0.1518 - accuracy: 0.9850 - val_loss: 1.1672 - val_accuracy: 0.8372
Epoch 72/110
 - 1s - loss: 0.1546 - accuracy: 0.9834 - val_loss: 1.1122 - val_accuracy: 0.8488
Epoch 73/110
 - 1s - loss: 0.1505 - accuracy: 0.9842 - val_loss: 1.1493 - val_accuracy: 0.8306
Epoch 74/110
 - 1s - loss: 0.1727 - accuracy: 0.9821 - val_loss: 1.1250 - val_accuracy: 0.8422
Epoch 75/110
 - 1s - loss: 0.1726 - accuracy: 0.9751 - val_loss: 1.0824 - val_accuracy: 0.8355
Epoch 76/110
 - 1s - loss: 0.1657 - accuracy: 0.9788 - val_loss: 1.1035 - val_accuracy: 0.8422
Epoch 77/110
 - 1s - loss: 0.1612 - accuracy: 0.9792 - val_loss: 1.1079 - val_accuracy: 0.8389
Epoch 78/110
 - 1s - loss: 0.1630 - accuracy: 0.9792 - val_loss: 1.0931 - val_accuracy: 0.8156
Epoch 79/110
 - 1s - loss: 0.1580 - accuracy: 0.9821 - val_loss: 1.1335 - val_accuracy: 0.8339
Epoch 80/110
 - 1s - loss: 0.1678 - accuracy: 0.9784 - val_loss: 1.1950 - val_accuracy: 0.8455
Epoch 81/110
 - 1s - loss: 0.1816 - accuracy: 0.9738 - val_loss: 1.1282 - val_accuracy: 0.8173
Epoch 82/110
 - 1s - loss: 0.2071 - accuracy: 0.9672 - val_loss: 1.1313 - val_accuracy: 0.8256
Epoch 83/110
 - 1s - loss: 0.1840 - accuracy: 0.9746 - val_loss: 0.9977 - val_accuracy: 0.8422
Epoch 84/110
 - 1s - loss: 0.1742 - accuracy: 0.9780 - val_loss: 1.3964 - val_accuracy: 0.8173
Epoch 85/110
 - 1s - loss: 0.2285 - accuracy: 0.9643 - val_loss: 1.2162 - val_accuracy: 0.8023
Epoch 86/110
 - 1s - loss: 0.2307 - accuracy: 0.9655 - val_loss: 0.9990 - val_accuracy: 0.8156
Epoch 87/110
 - 1s - loss: 0.1977 - accuracy: 0.9726 - val_loss: 1.0250 - val_accuracy: 0.8306
Epoch 88/110
 - 1s - loss: 0.1911 - accuracy: 0.9726 - val_loss: 1.1119 - val_accuracy: 0.8206
Epoch 89/110
 - 1s - loss: 0.1851 - accuracy: 0.9767 - val_loss: 1.1255 - val_accuracy: 0.8223
Epoch 90/110
 - 1s - loss: 0.1561 - accuracy: 0.9846 - val_loss: 1.0769 - val_accuracy: 0.8339
Epoch 91/110
 - 1s - loss: 0.1555 - accuracy: 0.9838 - val_loss: 1.2080 - val_accuracy: 0.8322
Epoch 92/110
 - 1s - loss: 0.1556 - accuracy: 0.9830 - val_loss: 1.2076 - val_accuracy: 0.8239
Epoch 93/110
 - 1s - loss: 0.1624 - accuracy: 0.9805 - val_loss: 1.0841 - val_accuracy: 0.8455
Epoch 94/110
 - 1s - loss: 0.1623 - accuracy: 0.9800 - val_loss: 1.2420 - val_accuracy: 0.8206
Epoch 95/110
 - 1s - loss: 0.1803 - accuracy: 0.9780 - val_loss: 1.2376 - val_accuracy: 0.8339
Epoch 96/110
 - 1s - loss: 0.1722 - accuracy: 0.9784 - val_loss: 1.1642 - val_accuracy: 0.8306
Epoch 97/110
 - 1s - loss: 0.1771 - accuracy: 0.9809 - val_loss: 1.1114 - val_accuracy: 0.8355
Epoch 98/110
 - 1s - loss: 0.1686 - accuracy: 0.9792 - val_loss: 1.2172 - val_accuracy: 0.8339
Epoch 99/110
 - 1s - loss: 0.1534 - accuracy: 0.9834 - val_loss: 1.3398 - val_accuracy: 0.8239
Epoch 100/110
 - 1s - loss: 0.1510 - accuracy: 0.9825 - val_loss: 1.3054 - val_accuracy: 0.8140
Epoch 101/110
 - 1s - loss: 0.1595 - accuracy: 0.9813 - val_loss: 1.2091 - val_accuracy: 0.8339
Epoch 102/110
 - 1s - loss: 0.1561 - accuracy: 0.9817 - val_loss: 1.1120 - val_accuracy: 0.8472
Epoch 103/110
 - 1s - loss: 0.1489 - accuracy: 0.9825 - val_loss: 1.1535 - val_accuracy: 0.8422
Epoch 104/110
 - 1s - loss: 0.1564 - accuracy: 0.9821 - val_loss: 1.3239 - val_accuracy: 0.8206
Epoch 105/110
 - 1s - loss: 0.1567 - accuracy: 0.9850 - val_loss: 1.2099 - val_accuracy: 0.8555
Epoch 106/110
 - 1s - loss: 0.1531 - accuracy: 0.9850 - val_loss: 1.2708 - val_accuracy: 0.8372
Epoch 107/110
 - 1s - loss: 0.1584 - accuracy: 0.9809 - val_loss: 1.2094 - val_accuracy: 0.8239
Epoch 108/110
 - 1s - loss: 0.1575 - accuracy: 0.9809 - val_loss: 1.2747 - val_accuracy: 0.8372
Epoch 109/110
 - 1s - loss: 0.1597 - accuracy: 0.9805 - val_loss: 1.3224 - val_accuracy: 0.8372
Epoch 110/110
 - 1s - loss: 0.1452 - accuracy: 0.9859 - val_loss: 1.2270 - val_accuracy: 0.8272
------------------------------------------------------------------------
Training for fold 4 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 1s - loss: 0.1532 - accuracy: 0.9817 - val_loss: 1.3991 - val_accuracy: 0.8123
Epoch 2/110
 - 1s - loss: 0.2049 - accuracy: 0.9692 - val_loss: 1.3002 - val_accuracy: 0.8372
Epoch 3/110
 - 1s - loss: 0.1987 - accuracy: 0.9726 - val_loss: 1.2459 - val_accuracy: 0.8173
Epoch 4/110
 - 1s - loss: 0.1813 - accuracy: 0.9755 - val_loss: 1.0974 - val_accuracy: 0.8488
Epoch 5/110
 - 1s - loss: 0.1520 - accuracy: 0.9855 - val_loss: 1.0796 - val_accuracy: 0.8455
Epoch 6/110
 - 1s - loss: 0.1520 - accuracy: 0.9846 - val_loss: 1.1171 - val_accuracy: 0.8339
Epoch 7/110
 - 1s - loss: 0.1501 - accuracy: 0.9830 - val_loss: 1.1700 - val_accuracy: 0.8239
Epoch 8/110
 - 1s - loss: 0.1530 - accuracy: 0.9813 - val_loss: 1.0927 - val_accuracy: 0.8405
Epoch 9/110
 - 1s - loss: 0.1492 - accuracy: 0.9846 - val_loss: 1.1349 - val_accuracy: 0.8389
Epoch 10/110
 - 1s - loss: 0.1631 - accuracy: 0.9805 - val_loss: 1.2400 - val_accuracy: 0.8289
Epoch 11/110
 - 1s - loss: 0.2083 - accuracy: 0.9680 - val_loss: 1.2070 - val_accuracy: 0.8156
Epoch 12/110
 - 1s - loss: 0.1977 - accuracy: 0.9672 - val_loss: 1.0328 - val_accuracy: 0.8389
Epoch 13/110
 - 1s - loss: 0.1908 - accuracy: 0.9701 - val_loss: 1.1177 - val_accuracy: 0.8322
Epoch 14/110
 - 1s - loss: 0.2059 - accuracy: 0.9730 - val_loss: 1.0039 - val_accuracy: 0.8472
Epoch 15/110
 - 1s - loss: 0.1894 - accuracy: 0.9751 - val_loss: 1.1310 - val_accuracy: 0.8256
Epoch 16/110
 - 1s - loss: 0.1715 - accuracy: 0.9784 - val_loss: 1.1048 - val_accuracy: 0.8422
Epoch 17/110
 - 1s - loss: 0.1960 - accuracy: 0.9709 - val_loss: 1.1993 - val_accuracy: 0.8189
Epoch 18/110
 - 1s - loss: 0.2004 - accuracy: 0.9713 - val_loss: 1.0537 - val_accuracy: 0.8339
Epoch 19/110
 - 1s - loss: 0.2555 - accuracy: 0.9589 - val_loss: 1.0303 - val_accuracy: 0.7774
Epoch 20/110
 - 1s - loss: 0.1874 - accuracy: 0.9688 - val_loss: 0.9074 - val_accuracy: 0.8372
Epoch 21/110
 - 1s - loss: 0.1756 - accuracy: 0.9776 - val_loss: 1.0184 - val_accuracy: 0.8322
Epoch 22/110
 - 1s - loss: 0.1597 - accuracy: 0.9821 - val_loss: 1.0583 - val_accuracy: 0.8422
Epoch 23/110
 - 1s - loss: 0.1461 - accuracy: 0.9855 - val_loss: 1.0354 - val_accuracy: 0.8389
Epoch 24/110
 - 1s - loss: 0.1436 - accuracy: 0.9867 - val_loss: 0.9894 - val_accuracy: 0.8439
Epoch 25/110
 - 1s - loss: 0.1387 - accuracy: 0.9888 - val_loss: 0.9987 - val_accuracy: 0.8522
Epoch 26/110
 - 1s - loss: 0.1448 - accuracy: 0.9863 - val_loss: 1.0414 - val_accuracy: 0.8439
Epoch 27/110
 - 1s - loss: 0.1428 - accuracy: 0.9879 - val_loss: 0.9935 - val_accuracy: 0.8455
Epoch 28/110
 - 1s - loss: 0.1360 - accuracy: 0.9875 - val_loss: 1.1070 - val_accuracy: 0.8322
Epoch 29/110
 - 1s - loss: 0.1366 - accuracy: 0.9892 - val_loss: 1.0681 - val_accuracy: 0.8439
Epoch 30/110
 - 1s - loss: 0.1378 - accuracy: 0.9888 - val_loss: 1.0743 - val_accuracy: 0.8372
Epoch 31/110
 - 1s - loss: 0.1420 - accuracy: 0.9859 - val_loss: 1.1002 - val_accuracy: 0.8322
Epoch 32/110
 - 1s - loss: 0.1656 - accuracy: 0.9780 - val_loss: 1.1323 - val_accuracy: 0.8272
Epoch 33/110
 - 1s - loss: 0.1663 - accuracy: 0.9780 - val_loss: 1.1058 - val_accuracy: 0.8289
Epoch 34/110
 - 1s - loss: 0.1584 - accuracy: 0.9809 - val_loss: 1.1315 - val_accuracy: 0.8223
Epoch 35/110
 - 1s - loss: 0.1507 - accuracy: 0.9830 - val_loss: 1.0796 - val_accuracy: 0.8522
Epoch 36/110
 - 1s - loss: 0.1481 - accuracy: 0.9834 - val_loss: 1.1407 - val_accuracy: 0.8339
Epoch 37/110
 - 1s - loss: 0.1472 - accuracy: 0.9859 - val_loss: 1.1297 - val_accuracy: 0.8405
Epoch 38/110
 - 1s - loss: 0.1495 - accuracy: 0.9859 - val_loss: 1.0711 - val_accuracy: 0.8422
Epoch 39/110
 - 1s - loss: 0.1421 - accuracy: 0.9863 - val_loss: 1.0645 - val_accuracy: 0.8355
Epoch 40/110
 - 1s - loss: 0.1352 - accuracy: 0.9879 - val_loss: 1.0885 - val_accuracy: 0.8389
Epoch 41/110
 - 1s - loss: 0.1359 - accuracy: 0.9879 - val_loss: 1.1272 - val_accuracy: 0.8223
Epoch 42/110
 - 1s - loss: 0.1491 - accuracy: 0.9825 - val_loss: 1.2035 - val_accuracy: 0.8272
Epoch 43/110
 - 1s - loss: 0.1584 - accuracy: 0.9821 - val_loss: 1.0949 - val_accuracy: 0.8289
Epoch 44/110
 - 1s - loss: 0.1631 - accuracy: 0.9817 - val_loss: 1.0782 - val_accuracy: 0.8306
Epoch 45/110
 - 1s - loss: 0.1960 - accuracy: 0.9684 - val_loss: 1.1344 - val_accuracy: 0.8206
Epoch 46/110
 - 1s - loss: 0.2139 - accuracy: 0.9622 - val_loss: 0.9975 - val_accuracy: 0.8223
Epoch 47/110
 - 1s - loss: 0.2027 - accuracy: 0.9684 - val_loss: 1.0583 - val_accuracy: 0.8140
Epoch 48/110
 - 1s - loss: 0.2072 - accuracy: 0.9672 - val_loss: 0.9635 - val_accuracy: 0.8223
Epoch 49/110
 - 1s - loss: 0.2014 - accuracy: 0.9667 - val_loss: 1.0996 - val_accuracy: 0.8405
Epoch 50/110
 - 1s - loss: 0.2196 - accuracy: 0.9643 - val_loss: 1.0910 - val_accuracy: 0.7874
Epoch 51/110
 - 1s - loss: 0.2086 - accuracy: 0.9647 - val_loss: 1.0031 - val_accuracy: 0.8306
Epoch 52/110
 - 1s - loss: 0.1703 - accuracy: 0.9776 - val_loss: 1.0763 - val_accuracy: 0.8322
Epoch 53/110
 - 1s - loss: 0.1597 - accuracy: 0.9805 - val_loss: 1.0035 - val_accuracy: 0.8306
Epoch 54/110
 - 1s - loss: 0.1558 - accuracy: 0.9830 - val_loss: 1.1442 - val_accuracy: 0.8488
Epoch 55/110
 - 1s - loss: 0.1823 - accuracy: 0.9759 - val_loss: 1.1930 - val_accuracy: 0.8256
Epoch 56/110
 - 1s - loss: 0.1558 - accuracy: 0.9821 - val_loss: 1.2538 - val_accuracy: 0.7990
Epoch 57/110
 - 1s - loss: 0.1775 - accuracy: 0.9717 - val_loss: 1.3149 - val_accuracy: 0.8239
Epoch 58/110
 - 1s - loss: 0.2206 - accuracy: 0.9601 - val_loss: 1.3700 - val_accuracy: 0.8173
Epoch 59/110
 - 1s - loss: 0.1811 - accuracy: 0.9709 - val_loss: 1.2980 - val_accuracy: 0.8206
Epoch 60/110
 - 1s - loss: 0.1566 - accuracy: 0.9817 - val_loss: 1.1529 - val_accuracy: 0.8272
Epoch 61/110
 - 1s - loss: 0.1475 - accuracy: 0.9838 - val_loss: 1.1066 - val_accuracy: 0.8455
Epoch 62/110
 - 1s - loss: 0.1385 - accuracy: 0.9871 - val_loss: 1.1381 - val_accuracy: 0.8422
Epoch 63/110
 - 1s - loss: 0.1332 - accuracy: 0.9888 - val_loss: 1.1815 - val_accuracy: 0.8372
Epoch 64/110
 - 1s - loss: 0.1366 - accuracy: 0.9892 - val_loss: 1.1647 - val_accuracy: 0.8389
Epoch 65/110
 - 1s - loss: 0.1372 - accuracy: 0.9871 - val_loss: 1.2349 - val_accuracy: 0.8156
Epoch 66/110
 - 1s - loss: 0.1332 - accuracy: 0.9888 - val_loss: 1.2423 - val_accuracy: 0.8472
Epoch 67/110
 - 1s - loss: 0.1432 - accuracy: 0.9850 - val_loss: 1.1660 - val_accuracy: 0.8422
Epoch 68/110
 - 1s - loss: 0.1420 - accuracy: 0.9879 - val_loss: 1.1614 - val_accuracy: 0.8339
Epoch 69/110
 - 1s - loss: 0.1413 - accuracy: 0.9863 - val_loss: 1.2553 - val_accuracy: 0.8272
Epoch 70/110
 - 1s - loss: 0.1338 - accuracy: 0.9871 - val_loss: 1.1737 - val_accuracy: 0.8455
Epoch 71/110
 - 1s - loss: 0.1382 - accuracy: 0.9871 - val_loss: 1.1747 - val_accuracy: 0.8405
Epoch 72/110
 - 1s - loss: 0.1689 - accuracy: 0.9767 - val_loss: 1.4837 - val_accuracy: 0.7940
Epoch 73/110
 - 1s - loss: 0.2089 - accuracy: 0.9626 - val_loss: 1.2511 - val_accuracy: 0.8339
Epoch 74/110
 - 1s - loss: 0.1690 - accuracy: 0.9780 - val_loss: 1.1459 - val_accuracy: 0.8389
Epoch 75/110
 - 1s - loss: 0.1615 - accuracy: 0.9792 - val_loss: 1.1696 - val_accuracy: 0.8422
Epoch 76/110
 - 1s - loss: 0.1626 - accuracy: 0.9817 - val_loss: 1.1881 - val_accuracy: 0.8272
Epoch 77/110
 - 1s - loss: 0.1627 - accuracy: 0.9825 - val_loss: 1.0682 - val_accuracy: 0.8372
Epoch 78/110
 - 1s - loss: 0.1394 - accuracy: 0.9888 - val_loss: 0.9914 - val_accuracy: 0.8372
Epoch 79/110
 - 1s - loss: 0.1471 - accuracy: 0.9846 - val_loss: 1.0999 - val_accuracy: 0.8239
Epoch 80/110
 - 1s - loss: 0.1494 - accuracy: 0.9850 - val_loss: 1.0078 - val_accuracy: 0.8422
Epoch 81/110
 - 1s - loss: 0.1620 - accuracy: 0.9813 - val_loss: 0.9825 - val_accuracy: 0.8339
Epoch 82/110
 - 1s - loss: 0.1571 - accuracy: 0.9800 - val_loss: 0.9661 - val_accuracy: 0.8372
Epoch 83/110
 - 1s - loss: 0.1556 - accuracy: 0.9825 - val_loss: 1.1346 - val_accuracy: 0.8405
Epoch 84/110
 - 1s - loss: 0.1401 - accuracy: 0.9859 - val_loss: 1.0697 - val_accuracy: 0.8588
Epoch 85/110
 - 1s - loss: 0.1389 - accuracy: 0.9867 - val_loss: 1.1527 - val_accuracy: 0.8389
Epoch 86/110
 - 1s - loss: 0.1488 - accuracy: 0.9830 - val_loss: 1.1012 - val_accuracy: 0.8522
Epoch 87/110
 - 1s - loss: 0.1511 - accuracy: 0.9817 - val_loss: 1.1159 - val_accuracy: 0.8256
Epoch 88/110
 - 1s - loss: 0.1748 - accuracy: 0.9742 - val_loss: 1.1663 - val_accuracy: 0.8140
Epoch 89/110
 - 1s - loss: 0.1772 - accuracy: 0.9726 - val_loss: 1.0314 - val_accuracy: 0.8322
Epoch 90/110
 - 1s - loss: 0.1633 - accuracy: 0.9800 - val_loss: 1.0493 - val_accuracy: 0.8123
Epoch 91/110
 - 1s - loss: 0.1590 - accuracy: 0.9825 - val_loss: 1.0729 - val_accuracy: 0.8405
Epoch 92/110
 - 1s - loss: 0.1420 - accuracy: 0.9850 - val_loss: 1.1426 - val_accuracy: 0.8306
Epoch 93/110
 - 1s - loss: 0.1404 - accuracy: 0.9842 - val_loss: 1.1779 - val_accuracy: 0.8389
Epoch 94/110
 - 1s - loss: 0.1389 - accuracy: 0.9855 - val_loss: 1.2294 - val_accuracy: 0.8140
Epoch 95/110
 - 1s - loss: 0.1450 - accuracy: 0.9821 - val_loss: 1.1952 - val_accuracy: 0.8256
Epoch 96/110
 - 1s - loss: 0.1521 - accuracy: 0.9796 - val_loss: 1.0882 - val_accuracy: 0.8439
Epoch 97/110
 - 1s - loss: 0.1559 - accuracy: 0.9776 - val_loss: 1.0174 - val_accuracy: 0.8306
Epoch 98/110
 - 1s - loss: 0.1583 - accuracy: 0.9809 - val_loss: 0.9907 - val_accuracy: 0.8555
Epoch 99/110
 - 1s - loss: 0.1697 - accuracy: 0.9817 - val_loss: 1.0384 - val_accuracy: 0.8472
Epoch 100/110
 - 1s - loss: 0.1458 - accuracy: 0.9834 - val_loss: 1.1158 - val_accuracy: 0.8189
Epoch 101/110
 - 1s - loss: 0.1490 - accuracy: 0.9825 - val_loss: 1.0669 - val_accuracy: 0.8372
Epoch 102/110
 - 1s - loss: 0.1780 - accuracy: 0.9734 - val_loss: 1.2253 - val_accuracy: 0.8206
Epoch 103/110
 - 1s - loss: 0.2061 - accuracy: 0.9713 - val_loss: 1.1180 - val_accuracy: 0.8306
Epoch 104/110
 - 1s - loss: 0.2082 - accuracy: 0.9742 - val_loss: 1.1408 - val_accuracy: 0.7940
Epoch 105/110
 - 1s - loss: 0.1903 - accuracy: 0.9755 - val_loss: 1.0538 - val_accuracy: 0.8239
Epoch 106/110
 - 1s - loss: 0.1759 - accuracy: 0.9734 - val_loss: 1.0035 - val_accuracy: 0.8422
Epoch 107/110
 - 1s - loss: 0.1705 - accuracy: 0.9742 - val_loss: 0.9937 - val_accuracy: 0.8289
Epoch 108/110
 - 1s - loss: 0.1494 - accuracy: 0.9830 - val_loss: 1.0448 - val_accuracy: 0.8372
Epoch 109/110
 - 1s - loss: 0.1468 - accuracy: 0.9830 - val_loss: 1.0317 - val_accuracy: 0.8339
Epoch 110/110
 - 1s - loss: 0.1495 - accuracy: 0.9842 - val_loss: 1.1249 - val_accuracy: 0.8106
------------------------------------------------------------------------
Training for fold 5 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 1s - loss: 0.1544 - accuracy: 0.9788 - val_loss: 1.1280 - val_accuracy: 0.8206
Epoch 2/110
 - 1s - loss: 0.1441 - accuracy: 0.9846 - val_loss: 1.1906 - val_accuracy: 0.8439
Epoch 3/110
 - 1s - loss: 0.1428 - accuracy: 0.9846 - val_loss: 1.1755 - val_accuracy: 0.8455
Epoch 4/110
 - 1s - loss: 0.1381 - accuracy: 0.9850 - val_loss: 1.2154 - val_accuracy: 0.8306
Epoch 5/110
 - 1s - loss: 0.1386 - accuracy: 0.9871 - val_loss: 1.1265 - val_accuracy: 0.8372
Epoch 6/110
 - 1s - loss: 0.1339 - accuracy: 0.9863 - val_loss: 1.1291 - val_accuracy: 0.8322
Epoch 7/110
 - 1s - loss: 0.1661 - accuracy: 0.9809 - val_loss: 1.2431 - val_accuracy: 0.8206
Epoch 8/110
 - 1s - loss: 0.1905 - accuracy: 0.9626 - val_loss: 1.1009 - val_accuracy: 0.8289
Epoch 9/110
 - 1s - loss: 0.2042 - accuracy: 0.9651 - val_loss: 1.3553 - val_accuracy: 0.8339
Epoch 10/110
 - 1s - loss: 0.1592 - accuracy: 0.9771 - val_loss: 1.2203 - val_accuracy: 0.8389
Epoch 11/110
 - 1s - loss: 0.1543 - accuracy: 0.9796 - val_loss: 1.4669 - val_accuracy: 0.8189
Epoch 12/110
 - 1s - loss: 0.1637 - accuracy: 0.9805 - val_loss: 1.0623 - val_accuracy: 0.8372
Epoch 13/110
 - 1s - loss: 0.1550 - accuracy: 0.9821 - val_loss: 1.1141 - val_accuracy: 0.8455
Epoch 14/110
 - 1s - loss: 0.1679 - accuracy: 0.9771 - val_loss: 1.3139 - val_accuracy: 0.8123
Epoch 15/110
 - 1s - loss: 0.1838 - accuracy: 0.9796 - val_loss: 1.2082 - val_accuracy: 0.7990
Epoch 16/110
 - 1s - loss: 0.1470 - accuracy: 0.9830 - val_loss: 1.0271 - val_accuracy: 0.8455
Epoch 17/110
 - 1s - loss: 0.1312 - accuracy: 0.9884 - val_loss: 1.1200 - val_accuracy: 0.8239
Epoch 18/110
 - 1s - loss: 0.1358 - accuracy: 0.9871 - val_loss: 1.0509 - val_accuracy: 0.8355
Epoch 19/110
 - 1s - loss: 0.1344 - accuracy: 0.9871 - val_loss: 1.1589 - val_accuracy: 0.8272
Epoch 20/110
 - 1s - loss: 0.1394 - accuracy: 0.9846 - val_loss: 1.1070 - val_accuracy: 0.8372
Epoch 21/110
 - 1s - loss: 0.1447 - accuracy: 0.9800 - val_loss: 1.1296 - val_accuracy: 0.8322
Epoch 22/110
 - 1s - loss: 0.1530 - accuracy: 0.9809 - val_loss: 1.1379 - val_accuracy: 0.8339
Epoch 23/110
 - 1s - loss: 0.1496 - accuracy: 0.9834 - val_loss: 1.0628 - val_accuracy: 0.8455
Epoch 24/110
 - 1s - loss: 0.1296 - accuracy: 0.9879 - val_loss: 1.1218 - val_accuracy: 0.8439
Epoch 25/110
 - 1s - loss: 0.1356 - accuracy: 0.9846 - val_loss: 1.0950 - val_accuracy: 0.8355
Epoch 26/110
 - 1s - loss: 0.1322 - accuracy: 0.9863 - val_loss: 1.1087 - val_accuracy: 0.8389
Epoch 27/110
 - 1s - loss: 0.1343 - accuracy: 0.9867 - val_loss: 1.0784 - val_accuracy: 0.8389
Epoch 28/110
 - 1s - loss: 0.1268 - accuracy: 0.9888 - val_loss: 1.1023 - val_accuracy: 0.8306
Epoch 29/110
 - 1s - loss: 0.1264 - accuracy: 0.9892 - val_loss: 1.0436 - val_accuracy: 0.8472
Epoch 30/110
 - 1s - loss: 0.1299 - accuracy: 0.9896 - val_loss: 1.0530 - val_accuracy: 0.8605
Epoch 31/110
 - 1s - loss: 0.1290 - accuracy: 0.9871 - val_loss: 1.0919 - val_accuracy: 0.8223
Epoch 32/110
 - 1s - loss: 0.1991 - accuracy: 0.9684 - val_loss: 1.3360 - val_accuracy: 0.7874
Epoch 33/110
 - 1s - loss: 0.2317 - accuracy: 0.9514 - val_loss: 1.1651 - val_accuracy: 0.8123
Epoch 34/110
 - 1s - loss: 0.2074 - accuracy: 0.9589 - val_loss: 0.9873 - val_accuracy: 0.8272
Epoch 35/110
 - 1s - loss: 0.1948 - accuracy: 0.9717 - val_loss: 1.1175 - val_accuracy: 0.8173
Epoch 36/110
 - 1s - loss: 0.1929 - accuracy: 0.9722 - val_loss: 1.0122 - val_accuracy: 0.8439
Epoch 37/110
 - 1s - loss: 0.1746 - accuracy: 0.9771 - val_loss: 1.0871 - val_accuracy: 0.8272
Epoch 38/110
 - 1s - loss: 0.1478 - accuracy: 0.9830 - val_loss: 1.0528 - val_accuracy: 0.8223
Epoch 39/110
 - 1s - loss: 0.1334 - accuracy: 0.9871 - val_loss: 0.9917 - val_accuracy: 0.8372
Epoch 40/110
 - 1s - loss: 0.1332 - accuracy: 0.9875 - val_loss: 1.0857 - val_accuracy: 0.8372
Epoch 41/110
 - 1s - loss: 0.1318 - accuracy: 0.9871 - val_loss: 1.0316 - val_accuracy: 0.8389
Epoch 42/110
 - 1s - loss: 0.1314 - accuracy: 0.9871 - val_loss: 1.1426 - val_accuracy: 0.8389
Epoch 43/110
 - 1s - loss: 0.1286 - accuracy: 0.9879 - val_loss: 1.0301 - val_accuracy: 0.8488
Epoch 44/110
 - 1s - loss: 0.1261 - accuracy: 0.9892 - val_loss: 1.1929 - val_accuracy: 0.8389
Epoch 45/110
 - 1s - loss: 0.1252 - accuracy: 0.9892 - val_loss: 1.1613 - val_accuracy: 0.8455
Epoch 46/110
 - 1s - loss: 0.1443 - accuracy: 0.9850 - val_loss: 1.1891 - val_accuracy: 0.8289
Epoch 47/110
 - 1s - loss: 0.1494 - accuracy: 0.9817 - val_loss: 1.2434 - val_accuracy: 0.8239
Epoch 48/110
 - 1s - loss: 0.1443 - accuracy: 0.9809 - val_loss: 1.1397 - val_accuracy: 0.8306
Epoch 49/110
 - 1s - loss: 0.1737 - accuracy: 0.9713 - val_loss: 1.2261 - val_accuracy: 0.8056
Epoch 50/110
 - 1s - loss: 0.2251 - accuracy: 0.9597 - val_loss: 1.1824 - val_accuracy: 0.8223
Epoch 51/110
 - 1s - loss: 0.2117 - accuracy: 0.9651 - val_loss: 1.1798 - val_accuracy: 0.8239
Epoch 52/110
 - 1s - loss: 0.1804 - accuracy: 0.9701 - val_loss: 1.0745 - val_accuracy: 0.8422
Epoch 53/110
 - 1s - loss: 0.1625 - accuracy: 0.9788 - val_loss: 1.1635 - val_accuracy: 0.8455
Epoch 54/110
 - 1s - loss: 0.1437 - accuracy: 0.9859 - val_loss: 1.1164 - val_accuracy: 0.8272
Epoch 55/110
 - 1s - loss: 0.1337 - accuracy: 0.9879 - val_loss: 1.0832 - val_accuracy: 0.8239
Epoch 56/110
 - 1s - loss: 0.1263 - accuracy: 0.9884 - val_loss: 1.0737 - val_accuracy: 0.8505
Epoch 57/110
 - 1s - loss: 0.1272 - accuracy: 0.9884 - val_loss: 1.0976 - val_accuracy: 0.8422
Epoch 58/110
 - 1s - loss: 0.1269 - accuracy: 0.9879 - val_loss: 1.1454 - val_accuracy: 0.8306
Epoch 59/110
 - 1s - loss: 0.1330 - accuracy: 0.9875 - val_loss: 1.0864 - val_accuracy: 0.8488
Epoch 60/110
 - 1s - loss: 0.1277 - accuracy: 0.9875 - val_loss: 1.1268 - val_accuracy: 0.8439
Epoch 61/110
 - 1s - loss: 0.1229 - accuracy: 0.9888 - val_loss: 1.1449 - val_accuracy: 0.8389
Epoch 62/110
 - 1s - loss: 0.1211 - accuracy: 0.9909 - val_loss: 1.1699 - val_accuracy: 0.8505
Epoch 63/110
 - 1s - loss: 0.1256 - accuracy: 0.9892 - val_loss: 1.1811 - val_accuracy: 0.8372
Epoch 64/110
 - 1s - loss: 0.1414 - accuracy: 0.9846 - val_loss: 1.2967 - val_accuracy: 0.8272
Epoch 65/110
 - 1s - loss: 0.1644 - accuracy: 0.9755 - val_loss: 1.1993 - val_accuracy: 0.8140
Epoch 66/110
 - 1s - loss: 0.1606 - accuracy: 0.9788 - val_loss: 1.1324 - val_accuracy: 0.8339
Epoch 67/110
 - 1s - loss: 0.1669 - accuracy: 0.9780 - val_loss: 1.1613 - val_accuracy: 0.8339
Epoch 68/110
 - 1s - loss: 0.1579 - accuracy: 0.9784 - val_loss: 1.1384 - val_accuracy: 0.8488
Epoch 69/110
 - 1s - loss: 0.1564 - accuracy: 0.9788 - val_loss: 1.2193 - val_accuracy: 0.8289
Epoch 70/110
 - 1s - loss: 0.1477 - accuracy: 0.9830 - val_loss: 1.2362 - val_accuracy: 0.8306
Epoch 71/110
 - 1s - loss: 0.1447 - accuracy: 0.9838 - val_loss: 1.1133 - val_accuracy: 0.8339
Epoch 72/110
 - 1s - loss: 0.1355 - accuracy: 0.9855 - val_loss: 1.1248 - val_accuracy: 0.8555
Epoch 73/110
 - 1s - loss: 0.1302 - accuracy: 0.9867 - val_loss: 1.0616 - val_accuracy: 0.8339
Epoch 74/110
 - 1s - loss: 0.1252 - accuracy: 0.9859 - val_loss: 1.1199 - val_accuracy: 0.8306
Epoch 75/110
 - 1s - loss: 0.1276 - accuracy: 0.9892 - val_loss: 1.0704 - val_accuracy: 0.8605
Epoch 76/110
 - 1s - loss: 0.1361 - accuracy: 0.9842 - val_loss: 1.2653 - val_accuracy: 0.8189
Epoch 77/110
 - 1s - loss: 0.1492 - accuracy: 0.9830 - val_loss: 1.2196 - val_accuracy: 0.8322
Epoch 78/110
 - 1s - loss: 0.1782 - accuracy: 0.9705 - val_loss: 1.2673 - val_accuracy: 0.8272
Epoch 79/110
 - 1s - loss: 0.1560 - accuracy: 0.9800 - val_loss: 1.1262 - val_accuracy: 0.8405
Epoch 80/110
 - 1s - loss: 0.1546 - accuracy: 0.9784 - val_loss: 1.2270 - val_accuracy: 0.8239
Epoch 81/110
 - 1s - loss: 0.1748 - accuracy: 0.9709 - val_loss: 1.1579 - val_accuracy: 0.8239
Epoch 82/110
 - 1s - loss: 0.1593 - accuracy: 0.9751 - val_loss: 1.0780 - val_accuracy: 0.8322
Epoch 83/110
 - 1s - loss: 0.1538 - accuracy: 0.9784 - val_loss: 1.2284 - val_accuracy: 0.8339
Epoch 84/110
 - 1s - loss: 0.1335 - accuracy: 0.9838 - val_loss: 1.0774 - val_accuracy: 0.8472
Epoch 85/110
 - 1s - loss: 0.1379 - accuracy: 0.9834 - val_loss: 1.2103 - val_accuracy: 0.8455
Epoch 86/110
 - 1s - loss: 0.1279 - accuracy: 0.9888 - val_loss: 1.1469 - val_accuracy: 0.8339
Epoch 87/110
 - 1s - loss: 0.1346 - accuracy: 0.9863 - val_loss: 1.1455 - val_accuracy: 0.8339
Epoch 88/110
 - 1s - loss: 0.1363 - accuracy: 0.9850 - val_loss: 1.0893 - val_accuracy: 0.8339
Epoch 89/110
 - 1s - loss: 0.1228 - accuracy: 0.9888 - val_loss: 1.1258 - val_accuracy: 0.8422
Epoch 90/110
 - 1s - loss: 0.1217 - accuracy: 0.9884 - val_loss: 1.1623 - val_accuracy: 0.8239
Epoch 91/110
 - 1s - loss: 0.1270 - accuracy: 0.9896 - val_loss: 1.1611 - val_accuracy: 0.8173
Epoch 92/110
 - 1s - loss: 0.1287 - accuracy: 0.9855 - val_loss: 1.2027 - val_accuracy: 0.8289
Epoch 93/110
 - 1s - loss: 0.1370 - accuracy: 0.9825 - val_loss: 1.1456 - val_accuracy: 0.8571
Epoch 94/110
 - 1s - loss: 0.1443 - accuracy: 0.9813 - val_loss: 1.2249 - val_accuracy: 0.8405
Epoch 95/110
 - 1s - loss: 0.1744 - accuracy: 0.9759 - val_loss: 1.1155 - val_accuracy: 0.8140
Epoch 96/110
 - 1s - loss: 0.2434 - accuracy: 0.9518 - val_loss: 1.0264 - val_accuracy: 0.8189
Epoch 97/110
 - 1s - loss: 0.2133 - accuracy: 0.9584 - val_loss: 1.1179 - val_accuracy: 0.8223
Epoch 98/110
 - 1s - loss: 0.1856 - accuracy: 0.9771 - val_loss: 1.0639 - val_accuracy: 0.8289
Epoch 99/110
 - 1s - loss: 0.1662 - accuracy: 0.9746 - val_loss: 1.0954 - val_accuracy: 0.8505
Epoch 100/110
 - 1s - loss: 0.1515 - accuracy: 0.9834 - val_loss: 1.0596 - val_accuracy: 0.8355
Epoch 101/110
 - 1s - loss: 0.1522 - accuracy: 0.9805 - val_loss: 1.0652 - val_accuracy: 0.8405
Epoch 102/110
 - 1s - loss: 0.1376 - accuracy: 0.9850 - val_loss: 1.0922 - val_accuracy: 0.8422
Epoch 103/110
 - 1s - loss: 0.1677 - accuracy: 0.9776 - val_loss: 1.1639 - val_accuracy: 0.8239
Epoch 104/110
 - 1s - loss: 0.1480 - accuracy: 0.9805 - val_loss: 1.1868 - val_accuracy: 0.8272
Epoch 105/110
 - 1s - loss: 0.1395 - accuracy: 0.9830 - val_loss: 1.1122 - val_accuracy: 0.8339
Epoch 106/110
 - 1s - loss: 0.1293 - accuracy: 0.9859 - val_loss: 1.0630 - val_accuracy: 0.8638
Epoch 107/110
 - 1s - loss: 0.1401 - accuracy: 0.9825 - val_loss: 1.2831 - val_accuracy: 0.8256
Epoch 108/110
 - 1s - loss: 0.1529 - accuracy: 0.9809 - val_loss: 1.1310 - val_accuracy: 0.8306
Epoch 109/110
 - 1s - loss: 0.1573 - accuracy: 0.9771 - val_loss: 1.1839 - val_accuracy: 0.8372
Epoch 110/110
 - 1s - loss: 0.1596 - accuracy: 0.9788 - val_loss: 1.1185 - val_accuracy: 0.8339
------------------------------------------------------------------------
Training for fold 6 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 1s - loss: 0.1495 - accuracy: 0.9784 - val_loss: 1.1313 - val_accuracy: 0.8389
Epoch 2/110
 - 1s - loss: 0.1590 - accuracy: 0.9759 - val_loss: 1.2155 - val_accuracy: 0.8239
Epoch 3/110
 - 1s - loss: 0.1467 - accuracy: 0.9842 - val_loss: 1.0731 - val_accuracy: 0.8571
Epoch 4/110
 - 1s - loss: 0.1388 - accuracy: 0.9867 - val_loss: 1.0220 - val_accuracy: 0.8422
Epoch 5/110
 - 1s - loss: 0.1338 - accuracy: 0.9879 - val_loss: 1.0757 - val_accuracy: 0.8488
Epoch 6/110
 - 1s - loss: 0.1269 - accuracy: 0.9892 - val_loss: 1.0427 - val_accuracy: 0.8439
Epoch 7/110
 - 1s - loss: 0.1241 - accuracy: 0.9892 - val_loss: 1.1137 - val_accuracy: 0.8455
Epoch 8/110
 - 1s - loss: 0.1322 - accuracy: 0.9871 - val_loss: 1.0822 - val_accuracy: 0.8439
Epoch 9/110
 - 1s - loss: 0.1215 - accuracy: 0.9900 - val_loss: 1.1453 - val_accuracy: 0.8505
Epoch 10/110
 - 1s - loss: 0.1262 - accuracy: 0.9888 - val_loss: 1.1809 - val_accuracy: 0.8405
Epoch 11/110
 - 1s - loss: 0.1262 - accuracy: 0.9863 - val_loss: 1.1522 - val_accuracy: 0.8505
Epoch 12/110
 - 1s - loss: 0.1320 - accuracy: 0.9863 - val_loss: 1.2398 - val_accuracy: 0.8289
Epoch 13/110
 - 1s - loss: 0.1327 - accuracy: 0.9838 - val_loss: 1.1461 - val_accuracy: 0.8588
Epoch 14/110
 - 1s - loss: 0.1325 - accuracy: 0.9838 - val_loss: 1.2395 - val_accuracy: 0.8156
Epoch 15/110
 - 1s - loss: 0.1390 - accuracy: 0.9830 - val_loss: 1.1248 - val_accuracy: 0.8472
Epoch 16/110
 - 1s - loss: 0.1293 - accuracy: 0.9871 - val_loss: 1.1581 - val_accuracy: 0.8372
Epoch 17/110
 - 1s - loss: 0.1270 - accuracy: 0.9863 - val_loss: 1.0978 - val_accuracy: 0.8422
Epoch 18/110
 - 1s - loss: 0.1318 - accuracy: 0.9838 - val_loss: 1.1612 - val_accuracy: 0.8422
Epoch 19/110
 - 1s - loss: 0.1395 - accuracy: 0.9838 - val_loss: 1.2744 - val_accuracy: 0.8189
Epoch 20/110
 - 1s - loss: 0.2172 - accuracy: 0.9626 - val_loss: 1.2120 - val_accuracy: 0.8189
Epoch 21/110
 - 1s - loss: 0.2240 - accuracy: 0.9518 - val_loss: 1.0686 - val_accuracy: 0.8156
Epoch 22/110
 - 1s - loss: 0.1969 - accuracy: 0.9634 - val_loss: 1.1351 - val_accuracy: 0.8272
Epoch 23/110
 - 1s - loss: 0.1994 - accuracy: 0.9651 - val_loss: 1.2454 - val_accuracy: 0.8206
Epoch 24/110
 - 1s - loss: 0.2482 - accuracy: 0.9547 - val_loss: 1.2163 - val_accuracy: 0.8206
Epoch 25/110
 - 1s - loss: 0.2305 - accuracy: 0.9580 - val_loss: 0.8789 - val_accuracy: 0.8322
Epoch 26/110
 - 1s - loss: 0.1643 - accuracy: 0.9755 - val_loss: 1.1848 - val_accuracy: 0.8389
Epoch 27/110
 - 1s - loss: 0.1401 - accuracy: 0.9838 - val_loss: 1.2784 - val_accuracy: 0.8339
Epoch 28/110
 - 1s - loss: 0.1280 - accuracy: 0.9871 - val_loss: 1.2433 - val_accuracy: 0.8422
Epoch 29/110
 - 1s - loss: 0.1242 - accuracy: 0.9879 - val_loss: 1.1989 - val_accuracy: 0.8355
Epoch 30/110
 - 1s - loss: 0.1251 - accuracy: 0.9884 - val_loss: 1.2833 - val_accuracy: 0.8472
Epoch 31/110
 - 1s - loss: 0.1331 - accuracy: 0.9859 - val_loss: 1.2492 - val_accuracy: 0.8405
Epoch 32/110
 - 1s - loss: 0.1272 - accuracy: 0.9879 - val_loss: 1.2225 - val_accuracy: 0.8488
Epoch 33/110
 - 1s - loss: 0.1276 - accuracy: 0.9863 - val_loss: 1.2157 - val_accuracy: 0.8422
Epoch 34/110
 - 1s - loss: 0.1195 - accuracy: 0.9900 - val_loss: 1.2519 - val_accuracy: 0.8322
Epoch 35/110
 - 1s - loss: 0.1182 - accuracy: 0.9900 - val_loss: 1.2269 - val_accuracy: 0.8472
Epoch 36/110
 - 1s - loss: 0.1170 - accuracy: 0.9892 - val_loss: 1.2809 - val_accuracy: 0.8389
Epoch 37/110
 - 1s - loss: 0.1252 - accuracy: 0.9875 - val_loss: 1.2669 - val_accuracy: 0.8422
Epoch 38/110
 - 1s - loss: 0.1228 - accuracy: 0.9871 - val_loss: 1.3405 - val_accuracy: 0.8272
Epoch 39/110
 - 1s - loss: 0.1206 - accuracy: 0.9888 - val_loss: 1.3134 - val_accuracy: 0.8355
Epoch 40/110
 - 1s - loss: 0.1201 - accuracy: 0.9884 - val_loss: 1.3450 - val_accuracy: 0.8372
Epoch 41/110
 - 1s - loss: 0.1221 - accuracy: 0.9879 - val_loss: 1.3644 - val_accuracy: 0.8439
Epoch 42/110
 - 1s - loss: 0.1172 - accuracy: 0.9904 - val_loss: 1.2765 - val_accuracy: 0.8472
Epoch 43/110
 - 1s - loss: 0.1140 - accuracy: 0.9900 - val_loss: 1.2695 - val_accuracy: 0.8472
Epoch 44/110
 - 1s - loss: 0.1166 - accuracy: 0.9888 - val_loss: 1.3541 - val_accuracy: 0.8405
Epoch 45/110
 - 1s - loss: 0.1336 - accuracy: 0.9817 - val_loss: 1.3079 - val_accuracy: 0.8405
Epoch 46/110
 - 1s - loss: 0.1467 - accuracy: 0.9813 - val_loss: 1.3448 - val_accuracy: 0.8256
Epoch 47/110
 - 1s - loss: 0.1547 - accuracy: 0.9784 - val_loss: 1.3440 - val_accuracy: 0.8272
Epoch 48/110
 - 1s - loss: 0.1527 - accuracy: 0.9800 - val_loss: 1.4365 - val_accuracy: 0.8206
Epoch 49/110
 - 1s - loss: 0.1261 - accuracy: 0.9867 - val_loss: 1.3464 - val_accuracy: 0.8422
Epoch 50/110
 - 1s - loss: 0.1537 - accuracy: 0.9817 - val_loss: 1.4474 - val_accuracy: 0.8189
Epoch 51/110
 - 1s - loss: 0.1326 - accuracy: 0.9830 - val_loss: 1.2420 - val_accuracy: 0.8422
Epoch 52/110
 - 1s - loss: 0.1354 - accuracy: 0.9842 - val_loss: 1.2737 - val_accuracy: 0.8339
Epoch 53/110
 - 1s - loss: 0.1438 - accuracy: 0.9796 - val_loss: 1.2642 - val_accuracy: 0.8272
Epoch 54/110
 - 1s - loss: 0.1548 - accuracy: 0.9792 - val_loss: 1.1714 - val_accuracy: 0.8040
Epoch 55/110
 - 1s - loss: 0.1849 - accuracy: 0.9684 - val_loss: 1.2275 - val_accuracy: 0.8206
Epoch 56/110
 - 1s - loss: 0.1749 - accuracy: 0.9713 - val_loss: 1.1133 - val_accuracy: 0.8389
Epoch 57/110
 - 1s - loss: 0.1700 - accuracy: 0.9738 - val_loss: 1.2326 - val_accuracy: 0.8422
Epoch 58/110
 - 1s - loss: 0.1617 - accuracy: 0.9776 - val_loss: 1.3065 - val_accuracy: 0.8189
Epoch 59/110
 - 1s - loss: 0.1635 - accuracy: 0.9713 - val_loss: 1.2194 - val_accuracy: 0.8256
Epoch 60/110
 - 1s - loss: 0.1525 - accuracy: 0.9800 - val_loss: 1.2457 - val_accuracy: 0.8422
Epoch 61/110
 - 1s - loss: 0.1322 - accuracy: 0.9871 - val_loss: 1.2092 - val_accuracy: 0.8439
Epoch 62/110
 - 1s - loss: 0.1188 - accuracy: 0.9913 - val_loss: 1.2435 - val_accuracy: 0.8472
Epoch 63/110
 - 1s - loss: 0.1170 - accuracy: 0.9896 - val_loss: 1.3270 - val_accuracy: 0.8322
Epoch 64/110
 - 1s - loss: 0.1186 - accuracy: 0.9900 - val_loss: 1.3110 - val_accuracy: 0.8322
Epoch 65/110
 - 1s - loss: 0.1212 - accuracy: 0.9871 - val_loss: 1.3261 - val_accuracy: 0.8389
Epoch 66/110
 - 1s - loss: 0.1269 - accuracy: 0.9871 - val_loss: 1.2983 - val_accuracy: 0.8223
Epoch 67/110
 - 1s - loss: 0.1203 - accuracy: 0.9875 - val_loss: 1.2879 - val_accuracy: 0.8422
Epoch 68/110
 - 1s - loss: 0.1288 - accuracy: 0.9838 - val_loss: 1.3175 - val_accuracy: 0.8322
Epoch 69/110
 - 1s - loss: 0.1371 - accuracy: 0.9834 - val_loss: 1.2715 - val_accuracy: 0.8189
Epoch 70/110
 - 1s - loss: 0.1324 - accuracy: 0.9834 - val_loss: 1.2372 - val_accuracy: 0.8372
Epoch 71/110
 - 1s - loss: 0.1337 - accuracy: 0.9842 - val_loss: 1.2856 - val_accuracy: 0.8322
Epoch 72/110
 - 1s - loss: 0.1285 - accuracy: 0.9846 - val_loss: 1.3033 - val_accuracy: 0.8389
Epoch 73/110
 - 1s - loss: 0.1263 - accuracy: 0.9879 - val_loss: 1.2514 - val_accuracy: 0.8289
Epoch 74/110
 - 1s - loss: 0.1333 - accuracy: 0.9838 - val_loss: 1.2114 - val_accuracy: 0.8339
Epoch 75/110
 - 1s - loss: 0.1430 - accuracy: 0.9821 - val_loss: 1.3289 - val_accuracy: 0.8306
Epoch 76/110
 - 1s - loss: 0.1393 - accuracy: 0.9813 - val_loss: 1.4612 - val_accuracy: 0.8223
Epoch 77/110
 - 1s - loss: 0.1417 - accuracy: 0.9805 - val_loss: 1.3367 - val_accuracy: 0.8289
Epoch 78/110
 - 1s - loss: 0.1536 - accuracy: 0.9784 - val_loss: 1.3421 - val_accuracy: 0.8389
Epoch 79/110
 - 1s - loss: 0.1983 - accuracy: 0.9705 - val_loss: 1.2019 - val_accuracy: 0.8140
Epoch 80/110
 - 1s - loss: 0.1758 - accuracy: 0.9726 - val_loss: 1.2817 - val_accuracy: 0.8040
Epoch 81/110
 - 1s - loss: 0.1580 - accuracy: 0.9771 - val_loss: 1.3570 - val_accuracy: 0.8140
Epoch 82/110
 - 1s - loss: 0.1548 - accuracy: 0.9809 - val_loss: 1.1947 - val_accuracy: 0.8239
Epoch 83/110
 - 1s - loss: 0.1416 - accuracy: 0.9825 - val_loss: 1.1237 - val_accuracy: 0.8422
Epoch 84/110
 - 1s - loss: 0.1315 - accuracy: 0.9846 - val_loss: 1.1281 - val_accuracy: 0.8272
Epoch 85/110
 - 1s - loss: 0.1229 - accuracy: 0.9875 - val_loss: 1.0754 - val_accuracy: 0.8472
Epoch 86/110
 - 1s - loss: 0.1275 - accuracy: 0.9871 - val_loss: 1.0829 - val_accuracy: 0.8422
Epoch 87/110
 - 1s - loss: 0.1218 - accuracy: 0.9888 - val_loss: 1.0669 - val_accuracy: 0.8571
Epoch 88/110
 - 1s - loss: 0.1141 - accuracy: 0.9900 - val_loss: 1.1282 - val_accuracy: 0.8372
Epoch 89/110
 - 1s - loss: 0.1159 - accuracy: 0.9900 - val_loss: 1.1342 - val_accuracy: 0.8372
Epoch 90/110
 - 1s - loss: 0.1201 - accuracy: 0.9896 - val_loss: 1.0920 - val_accuracy: 0.8339
Epoch 91/110
 - 1s - loss: 0.1204 - accuracy: 0.9888 - val_loss: 1.2629 - val_accuracy: 0.8372
Epoch 92/110
 - 1s - loss: 0.1227 - accuracy: 0.9871 - val_loss: 1.1706 - val_accuracy: 0.8488
Epoch 93/110
 - 1s - loss: 0.1386 - accuracy: 0.9842 - val_loss: 1.2431 - val_accuracy: 0.8322
Epoch 94/110
 - 1s - loss: 0.1334 - accuracy: 0.9830 - val_loss: 1.0767 - val_accuracy: 0.8538
Epoch 95/110
 - 1s - loss: 0.1333 - accuracy: 0.9825 - val_loss: 1.0517 - val_accuracy: 0.8389
Epoch 96/110
 - 1s - loss: 0.1422 - accuracy: 0.9830 - val_loss: 1.1135 - val_accuracy: 0.8306
Epoch 97/110
 - 1s - loss: 0.1389 - accuracy: 0.9825 - val_loss: 1.1758 - val_accuracy: 0.8339
Epoch 98/110
 - 1s - loss: 0.1212 - accuracy: 0.9875 - val_loss: 1.1596 - val_accuracy: 0.8306
Epoch 99/110
 - 1s - loss: 0.1365 - accuracy: 0.9825 - val_loss: 1.1409 - val_accuracy: 0.8439
Epoch 100/110
 - 1s - loss: 0.1413 - accuracy: 0.9825 - val_loss: 1.0622 - val_accuracy: 0.8306
Epoch 101/110
 - 1s - loss: 0.1289 - accuracy: 0.9838 - val_loss: 1.2450 - val_accuracy: 0.8339
Epoch 102/110
 - 1s - loss: 0.1393 - accuracy: 0.9834 - val_loss: 1.2836 - val_accuracy: 0.8140
Epoch 103/110
 - 1s - loss: 0.1943 - accuracy: 0.9647 - val_loss: 1.1765 - val_accuracy: 0.8173
Epoch 104/110
 - 1s - loss: 0.1967 - accuracy: 0.9688 - val_loss: 1.1655 - val_accuracy: 0.8056
Epoch 105/110
 - 1s - loss: 0.1812 - accuracy: 0.9684 - val_loss: 1.0354 - val_accuracy: 0.8372
Epoch 106/110
 - 1s - loss: 0.1681 - accuracy: 0.9751 - val_loss: 1.1809 - val_accuracy: 0.8322
Epoch 107/110
 - 1s - loss: 0.1488 - accuracy: 0.9838 - val_loss: 1.1749 - val_accuracy: 0.8372
Epoch 108/110
 - 1s - loss: 0.1299 - accuracy: 0.9859 - val_loss: 1.2233 - val_accuracy: 0.8439
Epoch 109/110
 - 1s - loss: 0.1256 - accuracy: 0.9875 - val_loss: 1.1296 - val_accuracy: 0.8355
Epoch 110/110
 - 1s - loss: 0.1260 - accuracy: 0.9867 - val_loss: 1.2459 - val_accuracy: 0.8272
------------------------------------------------------------------------
Training for fold 7 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 1s - loss: 0.1442 - accuracy: 0.9859 - val_loss: 1.2270 - val_accuracy: 0.8289
Epoch 2/110
 - 1s - loss: 0.1536 - accuracy: 0.9767 - val_loss: 1.2155 - val_accuracy: 0.8472
Epoch 3/110
 - 1s - loss: 0.1482 - accuracy: 0.9813 - val_loss: 1.2343 - val_accuracy: 0.8189
Epoch 4/110
 - 1s - loss: 0.1460 - accuracy: 0.9796 - val_loss: 1.1309 - val_accuracy: 0.8156
Epoch 5/110
 - 1s - loss: 0.1341 - accuracy: 0.9850 - val_loss: 1.2095 - val_accuracy: 0.8239
Epoch 6/110
 - 1s - loss: 0.1236 - accuracy: 0.9879 - val_loss: 1.1152 - val_accuracy: 0.8439
Epoch 7/110
 - 1s - loss: 0.1166 - accuracy: 0.9888 - val_loss: 1.1470 - val_accuracy: 0.8355
Epoch 8/110
 - 1s - loss: 0.1174 - accuracy: 0.9892 - val_loss: 1.1529 - val_accuracy: 0.8372
Epoch 9/110
 - 1s - loss: 0.1225 - accuracy: 0.9896 - val_loss: 1.2646 - val_accuracy: 0.8405
Epoch 10/110
 - 1s - loss: 0.1167 - accuracy: 0.9888 - val_loss: 1.2211 - val_accuracy: 0.8439
Epoch 11/110
 - 1s - loss: 0.1186 - accuracy: 0.9900 - val_loss: 1.2292 - val_accuracy: 0.8389
Epoch 12/110
 - 1s - loss: 0.1137 - accuracy: 0.9900 - val_loss: 1.1912 - val_accuracy: 0.8405
Epoch 13/110
 - 1s - loss: 0.1152 - accuracy: 0.9896 - val_loss: 1.2531 - val_accuracy: 0.8339
Epoch 14/110
 - 1s - loss: 0.1240 - accuracy: 0.9842 - val_loss: 1.2323 - val_accuracy: 0.8306
Epoch 15/110
 - 1s - loss: 0.1461 - accuracy: 0.9813 - val_loss: 1.1405 - val_accuracy: 0.8389
Epoch 16/110
 - 1s - loss: 0.1270 - accuracy: 0.9859 - val_loss: 1.1760 - val_accuracy: 0.8389
Epoch 17/110
 - 1s - loss: 0.1316 - accuracy: 0.9850 - val_loss: 1.3105 - val_accuracy: 0.8322
Epoch 18/110
 - 1s - loss: 0.1308 - accuracy: 0.9850 - val_loss: 1.1614 - val_accuracy: 0.8422
Epoch 19/110
 - 1s - loss: 0.1277 - accuracy: 0.9838 - val_loss: 1.1167 - val_accuracy: 0.8472
Epoch 20/110
 - 1s - loss: 0.1276 - accuracy: 0.9850 - val_loss: 1.1550 - val_accuracy: 0.8322
Epoch 21/110
 - 1s - loss: 0.1378 - accuracy: 0.9796 - val_loss: 1.1634 - val_accuracy: 0.8140
Epoch 22/110
 - 1s - loss: 0.1625 - accuracy: 0.9825 - val_loss: 1.0985 - val_accuracy: 0.8223
Epoch 23/110
 - 1s - loss: 0.1342 - accuracy: 0.9846 - val_loss: 1.1419 - val_accuracy: 0.8289
Epoch 24/110
 - 1s - loss: 0.1432 - accuracy: 0.9821 - val_loss: 1.1162 - val_accuracy: 0.8355
Epoch 25/110
 - 1s - loss: 0.1237 - accuracy: 0.9863 - val_loss: 1.1746 - val_accuracy: 0.8389
Epoch 26/110
 - 1s - loss: 0.1298 - accuracy: 0.9867 - val_loss: 1.2994 - val_accuracy: 0.8206
Epoch 27/110
 - 1s - loss: 0.1454 - accuracy: 0.9796 - val_loss: 1.2356 - val_accuracy: 0.8306
Epoch 28/110
 - 1s - loss: 0.1303 - accuracy: 0.9855 - val_loss: 1.2446 - val_accuracy: 0.8289
Epoch 29/110
 - 1s - loss: 0.1321 - accuracy: 0.9842 - val_loss: 1.2145 - val_accuracy: 0.8355
Epoch 30/110
 - 1s - loss: 0.1211 - accuracy: 0.9871 - val_loss: 1.2109 - val_accuracy: 0.8405
Epoch 31/110
 - 1s - loss: 0.1188 - accuracy: 0.9863 - val_loss: 1.2543 - val_accuracy: 0.8372
Epoch 32/110
 - 1s - loss: 0.1162 - accuracy: 0.9875 - val_loss: 1.1453 - val_accuracy: 0.8472
Epoch 33/110
 - 1s - loss: 0.1204 - accuracy: 0.9879 - val_loss: 1.2924 - val_accuracy: 0.8372
Epoch 34/110
 - 1s - loss: 0.1149 - accuracy: 0.9884 - val_loss: 1.1791 - val_accuracy: 0.8339
Epoch 35/110
 - 1s - loss: 0.1246 - accuracy: 0.9838 - val_loss: 1.3946 - val_accuracy: 0.8256
Epoch 36/110
 - 1s - loss: 0.1586 - accuracy: 0.9742 - val_loss: 1.2690 - val_accuracy: 0.8173
Epoch 37/110
 - 1s - loss: 0.1550 - accuracy: 0.9755 - val_loss: 1.1311 - val_accuracy: 0.8223
Epoch 38/110
 - 1s - loss: 0.1526 - accuracy: 0.9763 - val_loss: 1.1408 - val_accuracy: 0.8405
Epoch 39/110
 - 1s - loss: 0.1545 - accuracy: 0.9746 - val_loss: 1.2913 - val_accuracy: 0.8023
Epoch 40/110
 - 1s - loss: 0.1780 - accuracy: 0.9663 - val_loss: 1.2052 - val_accuracy: 0.8322
Epoch 41/110
 - 1s - loss: 0.1889 - accuracy: 0.9651 - val_loss: 1.2110 - val_accuracy: 0.8140
Epoch 42/110
 - 1s - loss: 0.1443 - accuracy: 0.9796 - val_loss: 1.1965 - val_accuracy: 0.8156
Epoch 43/110
 - 1s - loss: 0.1264 - accuracy: 0.9846 - val_loss: 1.1436 - val_accuracy: 0.8289
Epoch 44/110
 - 1s - loss: 0.1230 - accuracy: 0.9879 - val_loss: 1.1784 - val_accuracy: 0.8239
Epoch 45/110
 - 1s - loss: 0.1176 - accuracy: 0.9892 - val_loss: 1.1721 - val_accuracy: 0.8372
Epoch 46/110
 - 1s - loss: 0.1239 - accuracy: 0.9867 - val_loss: 1.1107 - val_accuracy: 0.8256
Epoch 47/110
 - 1s - loss: 0.1455 - accuracy: 0.9834 - val_loss: 1.1031 - val_accuracy: 0.8123
Epoch 48/110
 - 1s - loss: 0.1729 - accuracy: 0.9713 - val_loss: 1.4200 - val_accuracy: 0.8355
Epoch 49/110
 - 1s - loss: 0.1801 - accuracy: 0.9705 - val_loss: 1.3241 - val_accuracy: 0.8123
Epoch 50/110
 - 1s - loss: 0.2077 - accuracy: 0.9613 - val_loss: 1.0644 - val_accuracy: 0.8223
Epoch 51/110
 - 1s - loss: 0.1674 - accuracy: 0.9738 - val_loss: 1.1215 - val_accuracy: 0.8439
Epoch 52/110
 - 1s - loss: 0.1464 - accuracy: 0.9788 - val_loss: 1.1710 - val_accuracy: 0.8455
Epoch 53/110
 - 1s - loss: 0.1231 - accuracy: 0.9867 - val_loss: 1.2293 - val_accuracy: 0.8488
Epoch 54/110
 - 1s - loss: 0.1124 - accuracy: 0.9913 - val_loss: 1.1803 - val_accuracy: 0.8472
Epoch 55/110
 - 1s - loss: 0.1125 - accuracy: 0.9900 - val_loss: 1.2380 - val_accuracy: 0.8488
Epoch 56/110
 - 1s - loss: 0.1134 - accuracy: 0.9896 - val_loss: 1.2379 - val_accuracy: 0.8439
Epoch 57/110
 - 1s - loss: 0.1122 - accuracy: 0.9892 - val_loss: 1.2815 - val_accuracy: 0.8372
Epoch 58/110
 - 1s - loss: 0.1146 - accuracy: 0.9900 - val_loss: 1.2545 - val_accuracy: 0.8488
Epoch 59/110
 - 1s - loss: 0.1130 - accuracy: 0.9896 - val_loss: 1.2153 - val_accuracy: 0.8571
Epoch 60/110
 - 1s - loss: 0.1111 - accuracy: 0.9892 - val_loss: 1.2419 - val_accuracy: 0.8439
Epoch 61/110
 - 1s - loss: 0.1162 - accuracy: 0.9888 - val_loss: 1.2589 - val_accuracy: 0.8472
Epoch 62/110
 - 1s - loss: 0.1116 - accuracy: 0.9909 - val_loss: 1.2900 - val_accuracy: 0.8389
Epoch 63/110
 - 1s - loss: 0.1126 - accuracy: 0.9896 - val_loss: 1.2499 - val_accuracy: 0.8488
Epoch 64/110
 - 1s - loss: 0.1093 - accuracy: 0.9900 - val_loss: 1.2698 - val_accuracy: 0.8389
Epoch 65/110
 - 1s - loss: 0.1170 - accuracy: 0.9871 - val_loss: 1.3396 - val_accuracy: 0.8322
Epoch 66/110
 - 1s - loss: 0.1348 - accuracy: 0.9825 - val_loss: 1.3386 - val_accuracy: 0.8239
Epoch 67/110
 - 1s - loss: 0.1353 - accuracy: 0.9805 - val_loss: 1.3831 - val_accuracy: 0.8522
Epoch 68/110
 - 1s - loss: 0.1407 - accuracy: 0.9813 - val_loss: 1.3856 - val_accuracy: 0.8289
Epoch 69/110
 - 1s - loss: 0.1336 - accuracy: 0.9834 - val_loss: 1.3982 - val_accuracy: 0.8106
Epoch 70/110
 - 1s - loss: 0.1447 - accuracy: 0.9809 - val_loss: 1.3017 - val_accuracy: 0.8173
Epoch 71/110
 - 1s - loss: 0.1618 - accuracy: 0.9738 - val_loss: 1.2167 - val_accuracy: 0.8272
Epoch 72/110
 - 1s - loss: 0.1737 - accuracy: 0.9709 - val_loss: 1.3183 - val_accuracy: 0.8007
Epoch 73/110
 - 1s - loss: 0.1489 - accuracy: 0.9776 - val_loss: 1.1956 - val_accuracy: 0.8289
Epoch 74/110
 - 1s - loss: 0.1225 - accuracy: 0.9863 - val_loss: 1.2404 - val_accuracy: 0.8206
Epoch 75/110
 - 1s - loss: 0.1356 - accuracy: 0.9834 - val_loss: 1.2501 - val_accuracy: 0.8472
Epoch 76/110
 - 1s - loss: 0.1309 - accuracy: 0.9838 - val_loss: 1.2714 - val_accuracy: 0.8289
Epoch 77/110
 - 1s - loss: 0.1371 - accuracy: 0.9834 - val_loss: 1.1742 - val_accuracy: 0.8306
Epoch 78/110
 - 1s - loss: 0.1232 - accuracy: 0.9867 - val_loss: 1.3199 - val_accuracy: 0.8306
Epoch 79/110
 - 1s - loss: 0.1213 - accuracy: 0.9867 - val_loss: 1.2541 - val_accuracy: 0.8505
Epoch 80/110
 - 1s - loss: 0.1118 - accuracy: 0.9904 - val_loss: 1.2355 - val_accuracy: 0.8389
Epoch 81/110
 - 1s - loss: 0.1060 - accuracy: 0.9925 - val_loss: 1.2077 - val_accuracy: 0.8505
Epoch 82/110
 - 1s - loss: 0.1033 - accuracy: 0.9913 - val_loss: 1.2332 - val_accuracy: 0.8405
Epoch 83/110
 - 1s - loss: 0.1036 - accuracy: 0.9913 - val_loss: 1.2734 - val_accuracy: 0.8389
Epoch 84/110
 - 1s - loss: 0.1062 - accuracy: 0.9909 - val_loss: 1.2419 - val_accuracy: 0.8339
Epoch 85/110
 - 1s - loss: 0.1119 - accuracy: 0.9879 - val_loss: 1.1931 - val_accuracy: 0.8405
Epoch 86/110
 - 1s - loss: 0.1156 - accuracy: 0.9884 - val_loss: 1.2809 - val_accuracy: 0.8339
Epoch 87/110
 - 1s - loss: 0.1108 - accuracy: 0.9896 - val_loss: 1.2709 - val_accuracy: 0.8339
Epoch 88/110
 - 1s - loss: 0.1100 - accuracy: 0.9892 - val_loss: 1.3255 - val_accuracy: 0.8472
Epoch 89/110
 - 1s - loss: 0.1249 - accuracy: 0.9842 - val_loss: 1.3458 - val_accuracy: 0.8322
Epoch 90/110
 - 1s - loss: 0.1276 - accuracy: 0.9834 - val_loss: 1.3376 - val_accuracy: 0.8472
Epoch 91/110
 - 1s - loss: 0.1266 - accuracy: 0.9825 - val_loss: 1.3327 - val_accuracy: 0.8522
Epoch 92/110
 - 1s - loss: 0.1365 - accuracy: 0.9792 - val_loss: 1.2161 - val_accuracy: 0.8289
Epoch 93/110
 - 1s - loss: 0.1540 - accuracy: 0.9751 - val_loss: 1.3781 - val_accuracy: 0.8206
Epoch 94/110
 - 1s - loss: 0.2173 - accuracy: 0.9622 - val_loss: 1.3887 - val_accuracy: 0.8272
Epoch 95/110
 - 1s - loss: 0.1704 - accuracy: 0.9705 - val_loss: 1.2697 - val_accuracy: 0.8189
Epoch 96/110
 - 1s - loss: 0.1329 - accuracy: 0.9821 - val_loss: 1.2275 - val_accuracy: 0.8405
Epoch 97/110
 - 1s - loss: 0.1321 - accuracy: 0.9842 - val_loss: 1.1517 - val_accuracy: 0.8272
Epoch 98/110
 - 1s - loss: 0.1202 - accuracy: 0.9871 - val_loss: 1.1849 - val_accuracy: 0.8389
Epoch 99/110
 - 1s - loss: 0.1229 - accuracy: 0.9859 - val_loss: 1.1526 - val_accuracy: 0.8322
Epoch 100/110
 - 1s - loss: 0.1217 - accuracy: 0.9846 - val_loss: 1.2283 - val_accuracy: 0.8239
Epoch 101/110
 - 1s - loss: 0.1240 - accuracy: 0.9875 - val_loss: 1.2716 - val_accuracy: 0.8272
Epoch 102/110
 - 1s - loss: 0.1267 - accuracy: 0.9813 - val_loss: 1.1831 - val_accuracy: 0.8588
Epoch 103/110
 - 1s - loss: 0.1287 - accuracy: 0.9871 - val_loss: 1.1524 - val_accuracy: 0.8439
Epoch 104/110
 - 1s - loss: 0.1242 - accuracy: 0.9846 - val_loss: 1.2500 - val_accuracy: 0.8389
Epoch 105/110
 - 1s - loss: 0.1149 - accuracy: 0.9867 - val_loss: 1.2025 - val_accuracy: 0.8355
Epoch 106/110
 - 1s - loss: 0.1103 - accuracy: 0.9884 - val_loss: 1.0731 - val_accuracy: 0.8389
Epoch 107/110
 - 1s - loss: 0.1034 - accuracy: 0.9909 - val_loss: 1.0888 - val_accuracy: 0.8355
Epoch 108/110
 - 1s - loss: 0.1057 - accuracy: 0.9909 - val_loss: 1.0781 - val_accuracy: 0.8538
Epoch 109/110
 - 1s - loss: 0.1074 - accuracy: 0.9888 - val_loss: 1.1495 - val_accuracy: 0.8389
Epoch 110/110
 - 1s - loss: 0.1085 - accuracy: 0.9896 - val_loss: 1.1781 - val_accuracy: 0.8405
------------------------------------------------------------------------
Training for fold 8 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 1s - loss: 0.1234 - accuracy: 0.9855 - val_loss: 1.1893 - val_accuracy: 0.8289
Epoch 2/110
 - 1s - loss: 0.1159 - accuracy: 0.9859 - val_loss: 1.0962 - val_accuracy: 0.8322
Epoch 3/110
 - 1s - loss: 0.1179 - accuracy: 0.9867 - val_loss: 1.2082 - val_accuracy: 0.8306
Epoch 4/110
 - 1s - loss: 0.1313 - accuracy: 0.9821 - val_loss: 1.1399 - val_accuracy: 0.8223
Epoch 5/110
 - 1s - loss: 0.1576 - accuracy: 0.9713 - val_loss: 1.1935 - val_accuracy: 0.7990
Epoch 6/110
 - 1s - loss: 0.1906 - accuracy: 0.9618 - val_loss: 1.5109 - val_accuracy: 0.7990
Epoch 7/110
 - 1s - loss: 0.1993 - accuracy: 0.9609 - val_loss: 1.2132 - val_accuracy: 0.8455
Epoch 8/110
 - 1s - loss: 0.1885 - accuracy: 0.9647 - val_loss: 1.3678 - val_accuracy: 0.8206
Epoch 9/110
 - 1s - loss: 0.1505 - accuracy: 0.9771 - val_loss: 1.3543 - val_accuracy: 0.8472
Epoch 10/110
 - 1s - loss: 0.1240 - accuracy: 0.9846 - val_loss: 1.2522 - val_accuracy: 0.8322
Epoch 11/110
 - 1s - loss: 0.1277 - accuracy: 0.9863 - val_loss: 1.2940 - val_accuracy: 0.8156
Epoch 12/110
 - 1s - loss: 0.1238 - accuracy: 0.9867 - val_loss: 1.3060 - val_accuracy: 0.8422
Epoch 13/110
 - 1s - loss: 0.1160 - accuracy: 0.9892 - val_loss: 1.2498 - val_accuracy: 0.8322
Epoch 14/110
 - 1s - loss: 0.1125 - accuracy: 0.9892 - val_loss: 1.2981 - val_accuracy: 0.8439
Epoch 15/110
 - 1s - loss: 0.1088 - accuracy: 0.9900 - val_loss: 1.3035 - val_accuracy: 0.8289
Epoch 16/110
 - 1s - loss: 0.1055 - accuracy: 0.9917 - val_loss: 1.3040 - val_accuracy: 0.8488
Epoch 17/110
 - 1s - loss: 0.1046 - accuracy: 0.9917 - val_loss: 1.2700 - val_accuracy: 0.8522
Epoch 18/110
 - 1s - loss: 0.1133 - accuracy: 0.9884 - val_loss: 1.2623 - val_accuracy: 0.8505
Epoch 19/110
 - 1s - loss: 0.1140 - accuracy: 0.9879 - val_loss: 1.3078 - val_accuracy: 0.8538
Epoch 20/110
 - 1s - loss: 0.1155 - accuracy: 0.9850 - val_loss: 1.3837 - val_accuracy: 0.8389
Epoch 21/110
 - 1s - loss: 0.1415 - accuracy: 0.9788 - val_loss: 1.3053 - val_accuracy: 0.8339
Epoch 22/110
 - 1s - loss: 0.1179 - accuracy: 0.9879 - val_loss: 1.3089 - val_accuracy: 0.8322
Epoch 23/110
 - 1s - loss: 0.1197 - accuracy: 0.9867 - val_loss: 1.3138 - val_accuracy: 0.8439
Epoch 24/110
 - 1s - loss: 0.1309 - accuracy: 0.9834 - val_loss: 1.4121 - val_accuracy: 0.8389
Epoch 25/110
 - 1s - loss: 0.1228 - accuracy: 0.9842 - val_loss: 1.3794 - val_accuracy: 0.8488
Epoch 26/110
 - 1s - loss: 0.1195 - accuracy: 0.9867 - val_loss: 1.3624 - val_accuracy: 0.8488
Epoch 27/110
 - 1s - loss: 0.1170 - accuracy: 0.9892 - val_loss: 1.3729 - val_accuracy: 0.8306
Epoch 28/110
 - 1s - loss: 0.1134 - accuracy: 0.9871 - val_loss: 1.4342 - val_accuracy: 0.8306
Epoch 29/110
 - 1s - loss: 0.1173 - accuracy: 0.9863 - val_loss: 1.3816 - val_accuracy: 0.8355
Epoch 30/110
 - 1s - loss: 0.1708 - accuracy: 0.9759 - val_loss: 1.5928 - val_accuracy: 0.8239
Epoch 31/110
 - 1s - loss: 0.1551 - accuracy: 0.9746 - val_loss: 1.3565 - val_accuracy: 0.8455
Epoch 32/110
 - 1s - loss: 0.1559 - accuracy: 0.9771 - val_loss: 1.3202 - val_accuracy: 0.8040
Epoch 33/110
 - 1s - loss: 0.1495 - accuracy: 0.9763 - val_loss: 1.2516 - val_accuracy: 0.8206
Epoch 34/110
 - 1s - loss: 0.1265 - accuracy: 0.9863 - val_loss: 1.1487 - val_accuracy: 0.8256
Epoch 35/110
 - 1s - loss: 0.1200 - accuracy: 0.9884 - val_loss: 1.2870 - val_accuracy: 0.8522
Epoch 36/110
 - 1s - loss: 0.1075 - accuracy: 0.9917 - val_loss: 1.2494 - val_accuracy: 0.8355
Epoch 37/110
 - 1s - loss: 0.1072 - accuracy: 0.9900 - val_loss: 1.3591 - val_accuracy: 0.8439
Epoch 38/110
 - 1s - loss: 0.1282 - accuracy: 0.9834 - val_loss: 1.2575 - val_accuracy: 0.8156
Epoch 39/110
 - 1s - loss: 0.1476 - accuracy: 0.9776 - val_loss: 1.3755 - val_accuracy: 0.8173
Epoch 40/110
 - 1s - loss: 0.1705 - accuracy: 0.9705 - val_loss: 1.2904 - val_accuracy: 0.8223
Epoch 41/110
 - 1s - loss: 0.1446 - accuracy: 0.9771 - val_loss: 1.3015 - val_accuracy: 0.8289
Epoch 42/110
 - 1s - loss: 0.1724 - accuracy: 0.9730 - val_loss: 1.1731 - val_accuracy: 0.8322
Epoch 43/110
 - 1s - loss: 0.1562 - accuracy: 0.9746 - val_loss: 1.1677 - val_accuracy: 0.8189
Epoch 44/110
 - 1s - loss: 0.1290 - accuracy: 0.9825 - val_loss: 1.2513 - val_accuracy: 0.8306
Epoch 45/110
 - 1s - loss: 0.1176 - accuracy: 0.9871 - val_loss: 1.2260 - val_accuracy: 0.8272
Epoch 46/110
 - 1s - loss: 0.1266 - accuracy: 0.9871 - val_loss: 1.2142 - val_accuracy: 0.8355
Epoch 47/110
 - 1s - loss: 0.1169 - accuracy: 0.9888 - val_loss: 1.1537 - val_accuracy: 0.8472
Epoch 48/110
 - 1s - loss: 0.1136 - accuracy: 0.9871 - val_loss: 1.2197 - val_accuracy: 0.8156
Epoch 49/110
 - 1s - loss: 0.1108 - accuracy: 0.9884 - val_loss: 1.2088 - val_accuracy: 0.8488
Epoch 50/110
 - 1s - loss: 0.1269 - accuracy: 0.9842 - val_loss: 1.3405 - val_accuracy: 0.8189
Epoch 51/110
 - 1s - loss: 0.1616 - accuracy: 0.9780 - val_loss: 1.2457 - val_accuracy: 0.8405
Epoch 52/110
 - 1s - loss: 0.1246 - accuracy: 0.9842 - val_loss: 1.2770 - val_accuracy: 0.8389
Epoch 53/110
 - 1s - loss: 0.1172 - accuracy: 0.9875 - val_loss: 1.3897 - val_accuracy: 0.8306
Epoch 54/110
 - 1s - loss: 0.1111 - accuracy: 0.9900 - val_loss: 1.2158 - val_accuracy: 0.8505
Epoch 55/110
 - 1s - loss: 0.1054 - accuracy: 0.9913 - val_loss: 1.1987 - val_accuracy: 0.8605
Epoch 56/110
 - 1s - loss: 0.1043 - accuracy: 0.9909 - val_loss: 1.2283 - val_accuracy: 0.8522
Epoch 57/110
 - 1s - loss: 0.1039 - accuracy: 0.9904 - val_loss: 1.3193 - val_accuracy: 0.8472
Epoch 58/110
 - 1s - loss: 0.1048 - accuracy: 0.9913 - val_loss: 1.3225 - val_accuracy: 0.8505
Epoch 59/110
 - 1s - loss: 0.1021 - accuracy: 0.9909 - val_loss: 1.3057 - val_accuracy: 0.8472
Epoch 60/110
 - 1s - loss: 0.1043 - accuracy: 0.9900 - val_loss: 1.3450 - val_accuracy: 0.8505
Epoch 61/110
 - 1s - loss: 0.1079 - accuracy: 0.9884 - val_loss: 1.2522 - val_accuracy: 0.8522
Epoch 62/110
 - 1s - loss: 0.1049 - accuracy: 0.9896 - val_loss: 1.2858 - val_accuracy: 0.8322
Epoch 63/110
 - 1s - loss: 0.1050 - accuracy: 0.9896 - val_loss: 1.2049 - val_accuracy: 0.8422
Epoch 64/110
 - 1s - loss: 0.1046 - accuracy: 0.9909 - val_loss: 1.2204 - val_accuracy: 0.8439
Epoch 65/110
 - 1s - loss: 0.0985 - accuracy: 0.9921 - val_loss: 1.3041 - val_accuracy: 0.8538
Epoch 66/110
 - 1s - loss: 0.1074 - accuracy: 0.9888 - val_loss: 1.1906 - val_accuracy: 0.8455
Epoch 67/110
 - 1s - loss: 0.1193 - accuracy: 0.9855 - val_loss: 1.1890 - val_accuracy: 0.8322
Epoch 68/110
 - 1s - loss: 0.1136 - accuracy: 0.9867 - val_loss: 1.1663 - val_accuracy: 0.8289
Epoch 69/110
 - 1s - loss: 0.1070 - accuracy: 0.9892 - val_loss: 1.2257 - val_accuracy: 0.8372
Epoch 70/110
 - 1s - loss: 0.1286 - accuracy: 0.9800 - val_loss: 1.3631 - val_accuracy: 0.8306
Epoch 71/110
 - 1s - loss: 0.2226 - accuracy: 0.9551 - val_loss: 1.0825 - val_accuracy: 0.8156
Epoch 72/110
 - 1s - loss: 0.3113 - accuracy: 0.9227 - val_loss: 1.0250 - val_accuracy: 0.7973
Epoch 73/110
 - 1s - loss: 0.1982 - accuracy: 0.9564 - val_loss: 0.9177 - val_accuracy: 0.8223
Epoch 74/110
 - 1s - loss: 0.1825 - accuracy: 0.9634 - val_loss: 0.9711 - val_accuracy: 0.8272
Epoch 75/110
 - 1s - loss: 0.1454 - accuracy: 0.9771 - val_loss: 1.0016 - val_accuracy: 0.8488
Epoch 76/110
 - 1s - loss: 0.1199 - accuracy: 0.9859 - val_loss: 0.9865 - val_accuracy: 0.8505
Epoch 77/110
 - 1s - loss: 0.1125 - accuracy: 0.9904 - val_loss: 1.0027 - val_accuracy: 0.8488
Epoch 78/110
 - 1s - loss: 0.1095 - accuracy: 0.9888 - val_loss: 1.0106 - val_accuracy: 0.8355
Epoch 79/110
 - 1s - loss: 0.1044 - accuracy: 0.9909 - val_loss: 1.0418 - val_accuracy: 0.8339
Epoch 80/110
 - 1s - loss: 0.1021 - accuracy: 0.9921 - val_loss: 1.0123 - val_accuracy: 0.8555
Epoch 81/110
 - 1s - loss: 0.1030 - accuracy: 0.9913 - val_loss: 1.0980 - val_accuracy: 0.8389
Epoch 82/110
 - 1s - loss: 0.1014 - accuracy: 0.9921 - val_loss: 1.0263 - val_accuracy: 0.8522
Epoch 83/110
 - 1s - loss: 0.1001 - accuracy: 0.9929 - val_loss: 1.1139 - val_accuracy: 0.8405
Epoch 84/110
 - 1s - loss: 0.1024 - accuracy: 0.9921 - val_loss: 1.0495 - val_accuracy: 0.8538
Epoch 85/110
 - 1s - loss: 0.1002 - accuracy: 0.9917 - val_loss: 1.0970 - val_accuracy: 0.8355
Epoch 86/110
 - 1s - loss: 0.1029 - accuracy: 0.9913 - val_loss: 1.0487 - val_accuracy: 0.8439
Epoch 87/110
 - 1s - loss: 0.1051 - accuracy: 0.9875 - val_loss: 1.0949 - val_accuracy: 0.8322
Epoch 88/110
 - 1s - loss: 0.1319 - accuracy: 0.9805 - val_loss: 1.1283 - val_accuracy: 0.8372
Epoch 89/110
 - 1s - loss: 0.1343 - accuracy: 0.9821 - val_loss: 1.0981 - val_accuracy: 0.8106
Epoch 90/110
 - 1s - loss: 0.1279 - accuracy: 0.9809 - val_loss: 1.0641 - val_accuracy: 0.8389
Epoch 91/110
 - 1s - loss: 0.1373 - accuracy: 0.9825 - val_loss: 0.9999 - val_accuracy: 0.8422
Epoch 92/110
 - 1s - loss: 0.1501 - accuracy: 0.9784 - val_loss: 1.1150 - val_accuracy: 0.8272
Epoch 93/110
 - 1s - loss: 0.1399 - accuracy: 0.9796 - val_loss: 1.4228 - val_accuracy: 0.8189
Epoch 94/110
 - 1s - loss: 0.1337 - accuracy: 0.9817 - val_loss: 1.4584 - val_accuracy: 0.8206
Epoch 95/110
 - 1s - loss: 0.1161 - accuracy: 0.9871 - val_loss: 1.3205 - val_accuracy: 0.8372
Epoch 96/110
 - 1s - loss: 0.1164 - accuracy: 0.9859 - val_loss: 1.4643 - val_accuracy: 0.8355
Epoch 97/110
 - 1s - loss: 0.1116 - accuracy: 0.9896 - val_loss: 1.3310 - val_accuracy: 0.8306
Epoch 98/110
 - 1s - loss: 0.1066 - accuracy: 0.9909 - val_loss: 1.2935 - val_accuracy: 0.8455
Epoch 99/110
 - 1s - loss: 0.1033 - accuracy: 0.9904 - val_loss: 1.3009 - val_accuracy: 0.8455
Epoch 100/110
 - 1s - loss: 0.1156 - accuracy: 0.9863 - val_loss: 1.2581 - val_accuracy: 0.8488
Epoch 101/110
 - 1s - loss: 0.1104 - accuracy: 0.9850 - val_loss: 1.3156 - val_accuracy: 0.8256
Epoch 102/110
 - 1s - loss: 0.1238 - accuracy: 0.9855 - val_loss: 1.1545 - val_accuracy: 0.8306
Epoch 103/110
 - 1s - loss: 0.1239 - accuracy: 0.9825 - val_loss: 1.4223 - val_accuracy: 0.8206
Epoch 104/110
 - 1s - loss: 0.1139 - accuracy: 0.9863 - val_loss: 1.1930 - val_accuracy: 0.8455
Epoch 105/110
 - 1s - loss: 0.1082 - accuracy: 0.9871 - val_loss: 1.2072 - val_accuracy: 0.8472
Epoch 106/110
 - 1s - loss: 0.1550 - accuracy: 0.9784 - val_loss: 1.3331 - val_accuracy: 0.8355
Epoch 107/110
 - 1s - loss: 0.1600 - accuracy: 0.9726 - val_loss: 1.4964 - val_accuracy: 0.8372
Epoch 108/110
 - 1s - loss: 0.1514 - accuracy: 0.9776 - val_loss: 1.3807 - val_accuracy: 0.8405
Epoch 109/110
 - 1s - loss: 0.1302 - accuracy: 0.9838 - val_loss: 1.1430 - val_accuracy: 0.8339
Epoch 110/110
 - 1s - loss: 0.1246 - accuracy: 0.9846 - val_loss: 1.2109 - val_accuracy: 0.8422
------------------------------------------------------------------------
Training for fold 9 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 1s - loss: 0.1193 - accuracy: 0.9875 - val_loss: 1.3186 - val_accuracy: 0.8289
Epoch 2/110
 - 1s - loss: 0.1246 - accuracy: 0.9850 - val_loss: 1.3507 - val_accuracy: 0.8372
Epoch 3/110
 - 1s - loss: 0.1199 - accuracy: 0.9850 - val_loss: 1.4801 - val_accuracy: 0.8206
Epoch 4/110
 - 1s - loss: 0.1347 - accuracy: 0.9863 - val_loss: 1.3886 - val_accuracy: 0.8306
Epoch 5/110
 - 1s - loss: 0.1307 - accuracy: 0.9821 - val_loss: 1.4153 - val_accuracy: 0.8355
Epoch 6/110
 - 1s - loss: 0.1144 - accuracy: 0.9863 - val_loss: 1.2712 - val_accuracy: 0.8339
Epoch 7/110
 - 1s - loss: 0.1128 - accuracy: 0.9879 - val_loss: 1.2798 - val_accuracy: 0.8389
Epoch 8/110
 - 1s - loss: 0.1199 - accuracy: 0.9846 - val_loss: 1.2286 - val_accuracy: 0.8439
Epoch 9/110
 - 1s - loss: 0.1301 - accuracy: 0.9830 - val_loss: 1.3628 - val_accuracy: 0.8389
Epoch 10/110
 - 1s - loss: 0.1396 - accuracy: 0.9792 - val_loss: 1.2580 - val_accuracy: 0.8272
Epoch 11/110
 - 1s - loss: 0.1467 - accuracy: 0.9805 - val_loss: 1.3362 - val_accuracy: 0.8306
Epoch 12/110
 - 1s - loss: 0.1276 - accuracy: 0.9830 - val_loss: 1.1784 - val_accuracy: 0.8355
Epoch 13/110
 - 1s - loss: 0.1422 - accuracy: 0.9813 - val_loss: 1.2370 - val_accuracy: 0.8272
Epoch 14/110
 - 1s - loss: 0.1444 - accuracy: 0.9796 - val_loss: 1.2901 - val_accuracy: 0.8272
Epoch 15/110
 - 1s - loss: 0.1295 - accuracy: 0.9825 - val_loss: 1.3449 - val_accuracy: 0.8455
Epoch 16/110
 - 1s - loss: 0.1293 - accuracy: 0.9813 - val_loss: 1.1817 - val_accuracy: 0.8322
Epoch 17/110
 - 1s - loss: 0.1337 - accuracy: 0.9817 - val_loss: 1.2613 - val_accuracy: 0.8339
Epoch 18/110
 - 1s - loss: 0.1494 - accuracy: 0.9759 - val_loss: 1.1428 - val_accuracy: 0.8306
Epoch 19/110
 - 1s - loss: 0.1209 - accuracy: 0.9846 - val_loss: 1.0731 - val_accuracy: 0.8223
Epoch 20/110
 - 1s - loss: 0.1077 - accuracy: 0.9888 - val_loss: 1.0399 - val_accuracy: 0.8223
Epoch 21/110
 - 1s - loss: 0.1064 - accuracy: 0.9888 - val_loss: 1.2107 - val_accuracy: 0.8389
Epoch 22/110
 - 1s - loss: 0.1057 - accuracy: 0.9884 - val_loss: 1.1957 - val_accuracy: 0.8289
Epoch 23/110
 - 1s - loss: 0.1101 - accuracy: 0.9900 - val_loss: 1.1074 - val_accuracy: 0.8289
Epoch 24/110
 - 1s - loss: 0.1121 - accuracy: 0.9855 - val_loss: 1.2122 - val_accuracy: 0.8239
Epoch 25/110
 - 1s - loss: 0.1376 - accuracy: 0.9800 - val_loss: 1.3201 - val_accuracy: 0.8272
Epoch 26/110
 - 1s - loss: 0.1274 - accuracy: 0.9821 - val_loss: 1.1902 - val_accuracy: 0.8189
Epoch 27/110
 - 1s - loss: 0.1137 - accuracy: 0.9879 - val_loss: 1.1364 - val_accuracy: 0.8289
Epoch 28/110
 - 1s - loss: 0.1153 - accuracy: 0.9871 - val_loss: 1.2482 - val_accuracy: 0.8272
Epoch 29/110
 - 1s - loss: 0.1193 - accuracy: 0.9846 - val_loss: 1.2573 - val_accuracy: 0.8322
Epoch 30/110
 - 1s - loss: 0.1439 - accuracy: 0.9796 - val_loss: 1.1746 - val_accuracy: 0.8256
Epoch 31/110
 - 1s - loss: 0.1286 - accuracy: 0.9825 - val_loss: 1.1996 - val_accuracy: 0.8189
Epoch 32/110
 - 1s - loss: 0.1311 - accuracy: 0.9817 - val_loss: 1.0844 - val_accuracy: 0.8405
Epoch 33/110
 - 1s - loss: 0.1352 - accuracy: 0.9784 - val_loss: 1.1102 - val_accuracy: 0.8339
Epoch 34/110
 - 1s - loss: 0.1400 - accuracy: 0.9788 - val_loss: 1.1025 - val_accuracy: 0.8455
Epoch 35/110
 - 1s - loss: 0.1240 - accuracy: 0.9855 - val_loss: 1.1544 - val_accuracy: 0.8239
Epoch 36/110
 - 1s - loss: 0.1139 - accuracy: 0.9879 - val_loss: 1.0983 - val_accuracy: 0.8355
Epoch 37/110
 - 1s - loss: 0.1047 - accuracy: 0.9909 - val_loss: 1.1105 - val_accuracy: 0.8355
Epoch 38/110
 - 1s - loss: 0.1009 - accuracy: 0.9904 - val_loss: 1.1529 - val_accuracy: 0.8339
Epoch 39/110
 - 1s - loss: 0.1072 - accuracy: 0.9892 - val_loss: 1.1472 - val_accuracy: 0.8272
Epoch 40/110
 - 1s - loss: 0.1042 - accuracy: 0.9904 - val_loss: 1.1420 - val_accuracy: 0.8306
Epoch 41/110
 - 1s - loss: 0.1084 - accuracy: 0.9909 - val_loss: 1.0798 - val_accuracy: 0.8289
Epoch 42/110
 - 1s - loss: 0.1158 - accuracy: 0.9863 - val_loss: 1.0431 - val_accuracy: 0.8322
Epoch 43/110
 - 1s - loss: 0.1248 - accuracy: 0.9859 - val_loss: 1.1566 - val_accuracy: 0.8339
Epoch 44/110
 - 1s - loss: 0.1241 - accuracy: 0.9813 - val_loss: 1.0964 - val_accuracy: 0.8206
Epoch 45/110
 - 1s - loss: 0.1629 - accuracy: 0.9738 - val_loss: 1.2451 - val_accuracy: 0.8173
Epoch 46/110
 - 1s - loss: 0.1280 - accuracy: 0.9838 - val_loss: 1.1848 - val_accuracy: 0.8173
Epoch 47/110
 - 1s - loss: 0.1149 - accuracy: 0.9842 - val_loss: 1.1293 - val_accuracy: 0.8422
Epoch 48/110
 - 1s - loss: 0.1146 - accuracy: 0.9888 - val_loss: 1.2405 - val_accuracy: 0.8272
Epoch 49/110
 - 1s - loss: 0.1062 - accuracy: 0.9892 - val_loss: 1.2662 - val_accuracy: 0.8439
Epoch 50/110
 - 1s - loss: 0.1059 - accuracy: 0.9900 - val_loss: 1.2066 - val_accuracy: 0.8389
Epoch 51/110
 - 1s - loss: 0.1064 - accuracy: 0.9884 - val_loss: 1.3037 - val_accuracy: 0.8339
Epoch 52/110
 - 1s - loss: 0.1300 - accuracy: 0.9830 - val_loss: 1.3240 - val_accuracy: 0.8355
Epoch 53/110
 - 1s - loss: 0.1371 - accuracy: 0.9817 - val_loss: 1.3028 - val_accuracy: 0.8405
Epoch 54/110
 - 1s - loss: 0.1186 - accuracy: 0.9838 - val_loss: 1.2550 - val_accuracy: 0.8239
Epoch 55/110
 - 1s - loss: 0.1194 - accuracy: 0.9867 - val_loss: 1.1850 - val_accuracy: 0.8488
Epoch 56/110
 - 1s - loss: 0.1087 - accuracy: 0.9888 - val_loss: 1.1777 - val_accuracy: 0.8638
Epoch 57/110
 - 1s - loss: 0.1007 - accuracy: 0.9904 - val_loss: 1.1936 - val_accuracy: 0.8355
Epoch 58/110
 - 1s - loss: 0.0991 - accuracy: 0.9913 - val_loss: 1.0896 - val_accuracy: 0.8472
Epoch 59/110
 - 1s - loss: 0.1068 - accuracy: 0.9896 - val_loss: 1.1523 - val_accuracy: 0.8339
Epoch 60/110
 - 1s - loss: 0.0977 - accuracy: 0.9921 - val_loss: 1.1057 - val_accuracy: 0.8422
Epoch 61/110
 - 1s - loss: 0.0949 - accuracy: 0.9917 - val_loss: 1.1974 - val_accuracy: 0.8339
Epoch 62/110
 - 1s - loss: 0.1004 - accuracy: 0.9904 - val_loss: 1.1503 - val_accuracy: 0.8422
Epoch 63/110
 - 1s - loss: 0.1019 - accuracy: 0.9896 - val_loss: 1.1978 - val_accuracy: 0.8455
Epoch 64/110
 - 1s - loss: 0.1055 - accuracy: 0.9888 - val_loss: 1.1961 - val_accuracy: 0.8372
Epoch 65/110
 - 1s - loss: 0.0963 - accuracy: 0.9909 - val_loss: 1.1837 - val_accuracy: 0.8405
Epoch 66/110
 - 1s - loss: 0.0994 - accuracy: 0.9900 - val_loss: 1.2395 - val_accuracy: 0.8389
Epoch 67/110
 - 1s - loss: 0.0992 - accuracy: 0.9904 - val_loss: 1.2724 - val_accuracy: 0.8405
Epoch 68/110
 - 1s - loss: 0.1136 - accuracy: 0.9855 - val_loss: 1.2227 - val_accuracy: 0.8488
Epoch 69/110
 - 1s - loss: 0.1040 - accuracy: 0.9871 - val_loss: 1.2116 - val_accuracy: 0.8405
Epoch 70/110
 - 1s - loss: 0.1101 - accuracy: 0.9846 - val_loss: 1.3112 - val_accuracy: 0.8322
Epoch 71/110
 - 1s - loss: 0.1273 - accuracy: 0.9800 - val_loss: 1.4399 - val_accuracy: 0.8239
Epoch 72/110
 - 1s - loss: 0.2771 - accuracy: 0.9443 - val_loss: 1.3742 - val_accuracy: 0.7957
Epoch 73/110
 - 1s - loss: 0.2815 - accuracy: 0.9289 - val_loss: 1.3151 - val_accuracy: 0.8056
Epoch 74/110
 - 1s - loss: 0.2609 - accuracy: 0.9422 - val_loss: 0.9893 - val_accuracy: 0.8223
Epoch 75/110
 - 1s - loss: 0.2239 - accuracy: 0.9576 - val_loss: 0.9653 - val_accuracy: 0.8372
Epoch 76/110
 - 1s - loss: 0.1461 - accuracy: 0.9771 - val_loss: 1.0247 - val_accuracy: 0.8372
Epoch 77/110
 - 1s - loss: 0.1176 - accuracy: 0.9875 - val_loss: 1.0216 - val_accuracy: 0.8555
Epoch 78/110
 - 1s - loss: 0.1085 - accuracy: 0.9900 - val_loss: 1.0128 - val_accuracy: 0.8439
Epoch 79/110
 - 1s - loss: 0.1013 - accuracy: 0.9913 - val_loss: 1.0520 - val_accuracy: 0.8355
Epoch 80/110
 - 1s - loss: 0.1023 - accuracy: 0.9917 - val_loss: 1.0301 - val_accuracy: 0.8422
Epoch 81/110
 - 1s - loss: 0.1006 - accuracy: 0.9909 - val_loss: 1.0737 - val_accuracy: 0.8272
Epoch 82/110
 - 1s - loss: 0.1001 - accuracy: 0.9913 - val_loss: 1.0782 - val_accuracy: 0.8472
Epoch 83/110
 - 1s - loss: 0.1038 - accuracy: 0.9904 - val_loss: 1.1371 - val_accuracy: 0.8289
Epoch 84/110
 - 1s - loss: 0.0995 - accuracy: 0.9913 - val_loss: 1.0846 - val_accuracy: 0.8522
Epoch 85/110
 - 1s - loss: 0.0992 - accuracy: 0.9913 - val_loss: 1.0794 - val_accuracy: 0.8389
Epoch 86/110
 - 1s - loss: 0.0986 - accuracy: 0.9917 - val_loss: 1.0951 - val_accuracy: 0.8455
Epoch 87/110
 - 1s - loss: 0.0990 - accuracy: 0.9921 - val_loss: 1.1224 - val_accuracy: 0.8472
Epoch 88/110
 - 1s - loss: 0.0958 - accuracy: 0.9929 - val_loss: 1.1329 - val_accuracy: 0.8505
Epoch 89/110
 - 1s - loss: 0.0976 - accuracy: 0.9933 - val_loss: 1.1341 - val_accuracy: 0.8472
Epoch 90/110
 - 1s - loss: 0.0978 - accuracy: 0.9909 - val_loss: 1.2062 - val_accuracy: 0.8372
Epoch 91/110
 - 1s - loss: 0.1004 - accuracy: 0.9896 - val_loss: 1.1927 - val_accuracy: 0.8372
Epoch 92/110
 - 1s - loss: 0.1083 - accuracy: 0.9875 - val_loss: 1.2926 - val_accuracy: 0.8322
Epoch 93/110
 - 1s - loss: 0.1073 - accuracy: 0.9875 - val_loss: 1.3513 - val_accuracy: 0.8272
Epoch 94/110
 - 1s - loss: 0.1030 - accuracy: 0.9896 - val_loss: 1.2508 - val_accuracy: 0.8272
Epoch 95/110
 - 1s - loss: 0.1078 - accuracy: 0.9900 - val_loss: 1.2659 - val_accuracy: 0.8339
Epoch 96/110
 - 1s - loss: 0.1153 - accuracy: 0.9859 - val_loss: 1.3348 - val_accuracy: 0.8239
Epoch 97/110
 - 1s - loss: 0.1041 - accuracy: 0.9892 - val_loss: 1.2442 - val_accuracy: 0.8389
Epoch 98/110
 - 1s - loss: 0.0956 - accuracy: 0.9909 - val_loss: 1.1890 - val_accuracy: 0.8355
Epoch 99/110
 - 1s - loss: 0.1005 - accuracy: 0.9900 - val_loss: 1.2216 - val_accuracy: 0.8322
Epoch 100/110
 - 1s - loss: 0.1016 - accuracy: 0.9900 - val_loss: 1.1646 - val_accuracy: 0.8289
Epoch 101/110
 - 1s - loss: 0.1070 - accuracy: 0.9863 - val_loss: 1.1003 - val_accuracy: 0.8505
Epoch 102/110
 - 1s - loss: 0.1112 - accuracy: 0.9879 - val_loss: 1.1434 - val_accuracy: 0.8372
Epoch 103/110
 - 1s - loss: 0.1498 - accuracy: 0.9796 - val_loss: 1.2587 - val_accuracy: 0.8355
Epoch 104/110
 - 1s - loss: 0.1847 - accuracy: 0.9622 - val_loss: 1.5060 - val_accuracy: 0.8289
Epoch 105/110
 - 1s - loss: 0.1970 - accuracy: 0.9580 - val_loss: 1.3272 - val_accuracy: 0.8023
Epoch 106/110
 - 1s - loss: 0.1646 - accuracy: 0.9726 - val_loss: 1.4942 - val_accuracy: 0.8173
Epoch 107/110
 - 1s - loss: 0.1393 - accuracy: 0.9805 - val_loss: 1.1834 - val_accuracy: 0.8206
Epoch 108/110
 - 1s - loss: 0.1312 - accuracy: 0.9813 - val_loss: 1.2961 - val_accuracy: 0.8289
Epoch 109/110
 - 1s - loss: 0.1396 - accuracy: 0.9788 - val_loss: 1.3295 - val_accuracy: 0.8140
Epoch 110/110
 - 1s - loss: 0.1459 - accuracy: 0.9776 - val_loss: 1.1448 - val_accuracy: 0.8322
------------------------------------------------------------------------
Training for fold 10 ...
Train on 2406 samples, validate on 602 samples
Epoch 1/110
 - 1s - loss: 0.1098 - accuracy: 0.9896 - val_loss: 1.1370 - val_accuracy: 0.8472
Epoch 2/110
 - 1s - loss: 0.1064 - accuracy: 0.9888 - val_loss: 1.0824 - val_accuracy: 0.8355
Epoch 3/110
 - 1s - loss: 0.1041 - accuracy: 0.9892 - val_loss: 1.2762 - val_accuracy: 0.8571
Epoch 4/110
 - 1s - loss: 0.1175 - accuracy: 0.9871 - val_loss: 1.1303 - val_accuracy: 0.8322
Epoch 5/110
 - 1s - loss: 0.1250 - accuracy: 0.9850 - val_loss: 1.1062 - val_accuracy: 0.8389
Epoch 6/110
 - 1s - loss: 0.1091 - accuracy: 0.9884 - val_loss: 1.2451 - val_accuracy: 0.8322
Epoch 7/110
 - 1s - loss: 0.1145 - accuracy: 0.9850 - val_loss: 1.3033 - val_accuracy: 0.8173
Epoch 8/110
 - 1s - loss: 0.1312 - accuracy: 0.9834 - val_loss: 1.3211 - val_accuracy: 0.8355
Epoch 9/110
 - 1s - loss: 0.1251 - accuracy: 0.9825 - val_loss: 1.2656 - val_accuracy: 0.8140
Epoch 10/110
 - 1s - loss: 0.1301 - accuracy: 0.9817 - val_loss: 1.2425 - val_accuracy: 0.8339
Epoch 11/110
 - 1s - loss: 0.1223 - accuracy: 0.9813 - val_loss: 1.1420 - val_accuracy: 0.8339
Epoch 12/110
 - 1s - loss: 0.1132 - accuracy: 0.9855 - val_loss: 1.3358 - val_accuracy: 0.8090
Epoch 13/110
 - 1s - loss: 0.1277 - accuracy: 0.9821 - val_loss: 1.2312 - val_accuracy: 0.8306
Epoch 14/110
 - 1s - loss: 0.1213 - accuracy: 0.9817 - val_loss: 1.3087 - val_accuracy: 0.8289
Epoch 15/110
 - 1s - loss: 0.1066 - accuracy: 0.9879 - val_loss: 1.2005 - val_accuracy: 0.8405
Epoch 16/110
 - 1s - loss: 0.1007 - accuracy: 0.9900 - val_loss: 1.2317 - val_accuracy: 0.8488
Epoch 17/110
 - 1s - loss: 0.0989 - accuracy: 0.9904 - val_loss: 1.2395 - val_accuracy: 0.8472
Epoch 18/110
 - 1s - loss: 0.0988 - accuracy: 0.9909 - val_loss: 1.2355 - val_accuracy: 0.8505
Epoch 19/110
 - 1s - loss: 0.0964 - accuracy: 0.9917 - val_loss: 1.2428 - val_accuracy: 0.8505
Epoch 20/110
 - 1s - loss: 0.0952 - accuracy: 0.9917 - val_loss: 1.3043 - val_accuracy: 0.8422
Epoch 21/110
 - 1s - loss: 0.0962 - accuracy: 0.9913 - val_loss: 1.2683 - val_accuracy: 0.8339
Epoch 22/110
 - 1s - loss: 0.0952 - accuracy: 0.9917 - val_loss: 1.2783 - val_accuracy: 0.8306
Epoch 23/110
 - 1s - loss: 0.0973 - accuracy: 0.9896 - val_loss: 1.2040 - val_accuracy: 0.8372
Epoch 24/110
 - 1s - loss: 0.0989 - accuracy: 0.9888 - val_loss: 1.2811 - val_accuracy: 0.8355
Epoch 25/110
 - 1s - loss: 0.1047 - accuracy: 0.9859 - val_loss: 1.2796 - val_accuracy: 0.8339
Epoch 26/110
 - 1s - loss: 0.1116 - accuracy: 0.9855 - val_loss: 1.2346 - val_accuracy: 0.8322
Epoch 27/110
 - 1s - loss: 0.1152 - accuracy: 0.9846 - val_loss: 1.3257 - val_accuracy: 0.8306
Epoch 28/110
 - 1s - loss: 0.1146 - accuracy: 0.9846 - val_loss: 1.4825 - val_accuracy: 0.8156
Epoch 29/110
 - 1s - loss: 0.1150 - accuracy: 0.9838 - val_loss: 1.4642 - val_accuracy: 0.8223
Epoch 30/110
 - 1s - loss: 0.1191 - accuracy: 0.9859 - val_loss: 1.3649 - val_accuracy: 0.8306
Epoch 31/110
 - 1s - loss: 0.1074 - accuracy: 0.9871 - val_loss: 1.3217 - val_accuracy: 0.8306
Epoch 32/110
 - 1s - loss: 0.0963 - accuracy: 0.9913 - val_loss: 1.3592 - val_accuracy: 0.8355
Epoch 33/110
 - 1s - loss: 0.0953 - accuracy: 0.9913 - val_loss: 1.3223 - val_accuracy: 0.8472
Epoch 34/110
 - 1s - loss: 0.0987 - accuracy: 0.9896 - val_loss: 1.4120 - val_accuracy: 0.8156
Epoch 35/110
 - 1s - loss: 0.0993 - accuracy: 0.9884 - val_loss: 1.3659 - val_accuracy: 0.8306
Epoch 36/110
 - 1s - loss: 0.1133 - accuracy: 0.9867 - val_loss: 1.3858 - val_accuracy: 0.8389
Epoch 37/110
 - 1s - loss: 0.1363 - accuracy: 0.9805 - val_loss: 1.4363 - val_accuracy: 0.8223
Epoch 38/110
 - 1s - loss: 0.1402 - accuracy: 0.9763 - val_loss: 1.5440 - val_accuracy: 0.8173
Epoch 39/110
 - 1s - loss: 0.1462 - accuracy: 0.9788 - val_loss: 1.3799 - val_accuracy: 0.8488
Epoch 40/110
 - 1s - loss: 0.1237 - accuracy: 0.9813 - val_loss: 1.3026 - val_accuracy: 0.8289
Epoch 41/110
 - 1s - loss: 0.1244 - accuracy: 0.9842 - val_loss: 1.2826 - val_accuracy: 0.8106
Epoch 42/110
 - 1s - loss: 0.1147 - accuracy: 0.9855 - val_loss: 1.3497 - val_accuracy: 0.8272
Epoch 43/110
 - 1s - loss: 0.1084 - accuracy: 0.9871 - val_loss: 1.2941 - val_accuracy: 0.8272
Epoch 44/110
 - 1s - loss: 0.1431 - accuracy: 0.9817 - val_loss: 1.4586 - val_accuracy: 0.8173
Epoch 45/110
 - 1s - loss: 0.1409 - accuracy: 0.9780 - val_loss: 1.3798 - val_accuracy: 0.8289
Epoch 46/110
 - 1s - loss: 0.1524 - accuracy: 0.9692 - val_loss: 1.4586 - val_accuracy: 0.7990
Epoch 47/110
 - 1s - loss: 0.1339 - accuracy: 0.9805 - val_loss: 1.2912 - val_accuracy: 0.8140
Epoch 48/110
 - 1s - loss: 0.1371 - accuracy: 0.9796 - val_loss: 1.2904 - val_accuracy: 0.8355
Epoch 49/110
 - 1s - loss: 0.1110 - accuracy: 0.9859 - val_loss: 1.4182 - val_accuracy: 0.8156
Epoch 50/110
 - 1s - loss: 0.1137 - accuracy: 0.9859 - val_loss: 1.3312 - val_accuracy: 0.8405
Epoch 51/110
 - 1s - loss: 0.1048 - accuracy: 0.9884 - val_loss: 1.3846 - val_accuracy: 0.8389
Epoch 52/110
 - 1s - loss: 0.1146 - accuracy: 0.9859 - val_loss: 1.4031 - val_accuracy: 0.8306
Epoch 53/110
 - 1s - loss: 0.1054 - accuracy: 0.9875 - val_loss: 1.4341 - val_accuracy: 0.8206
Epoch 54/110
 - 1s - loss: 0.1074 - accuracy: 0.9875 - val_loss: 1.4508 - val_accuracy: 0.8372
Epoch 55/110
 - 1s - loss: 0.0984 - accuracy: 0.9896 - val_loss: 1.3649 - val_accuracy: 0.8339
Epoch 56/110
 - 1s - loss: 0.1056 - accuracy: 0.9867 - val_loss: 1.4278 - val_accuracy: 0.8372
Epoch 57/110
 - 1s - loss: 0.1110 - accuracy: 0.9875 - val_loss: 1.5258 - val_accuracy: 0.8173
Epoch 58/110
 - 1s - loss: 0.1023 - accuracy: 0.9896 - val_loss: 1.3765 - val_accuracy: 0.8389
Epoch 59/110
 - 1s - loss: 0.0991 - accuracy: 0.9896 - val_loss: 1.3237 - val_accuracy: 0.8306
Epoch 60/110
 - 1s - loss: 0.1144 - accuracy: 0.9846 - val_loss: 1.3721 - val_accuracy: 0.8256
Epoch 61/110
 - 1s - loss: 0.1592 - accuracy: 0.9722 - val_loss: 1.3065 - val_accuracy: 0.8206
Epoch 62/110
 - 1s - loss: 0.1374 - accuracy: 0.9809 - val_loss: 1.4418 - val_accuracy: 0.8339
Epoch 63/110
 - 1s - loss: 0.1167 - accuracy: 0.9850 - val_loss: 1.3476 - val_accuracy: 0.8306
Epoch 64/110
 - 1s - loss: 0.1128 - accuracy: 0.9859 - val_loss: 1.2535 - val_accuracy: 0.8289
Epoch 65/110
 - 1s - loss: 0.1186 - accuracy: 0.9855 - val_loss: 1.3715 - val_accuracy: 0.8389
Epoch 66/110
 - 1s - loss: 0.1081 - accuracy: 0.9867 - val_loss: 1.2429 - val_accuracy: 0.8405
Epoch 67/110
 - 1s - loss: 0.1231 - accuracy: 0.9825 - val_loss: 1.2755 - val_accuracy: 0.8272
Epoch 68/110
 - 1s - loss: 0.1194 - accuracy: 0.9855 - val_loss: 1.3474 - val_accuracy: 0.8272
Epoch 69/110
 - 1s - loss: 0.1061 - accuracy: 0.9888 - val_loss: 1.2259 - val_accuracy: 0.8488
Epoch 70/110
 - 1s - loss: 0.0991 - accuracy: 0.9900 - val_loss: 1.2965 - val_accuracy: 0.8322
Epoch 71/110
 - 1s - loss: 0.0943 - accuracy: 0.9921 - val_loss: 1.2309 - val_accuracy: 0.8389
Epoch 72/110
 - 1s - loss: 0.0960 - accuracy: 0.9917 - val_loss: 1.2752 - val_accuracy: 0.8289
Epoch 73/110
 - 1s - loss: 0.0973 - accuracy: 0.9900 - val_loss: 1.2169 - val_accuracy: 0.8405
Epoch 74/110
 - 1s - loss: 0.0955 - accuracy: 0.9913 - val_loss: 1.2369 - val_accuracy: 0.8140
Epoch 75/110
 - 1s - loss: 0.0952 - accuracy: 0.9917 - val_loss: 1.1310 - val_accuracy: 0.8439
Epoch 76/110
 - 1s - loss: 0.0919 - accuracy: 0.9917 - val_loss: 1.1966 - val_accuracy: 0.8355
Epoch 77/110
 - 1s - loss: 0.1107 - accuracy: 0.9875 - val_loss: 1.3504 - val_accuracy: 0.8189
Epoch 78/110
 - 1s - loss: 0.1054 - accuracy: 0.9846 - val_loss: 1.3070 - val_accuracy: 0.8206
Epoch 79/110
 - 1s - loss: 0.1112 - accuracy: 0.9842 - val_loss: 1.1236 - val_accuracy: 0.8289
Epoch 80/110
 - 1s - loss: 0.1218 - accuracy: 0.9813 - val_loss: 1.2462 - val_accuracy: 0.8156
Epoch 81/110
 - 1s - loss: 0.1530 - accuracy: 0.9751 - val_loss: 1.4122 - val_accuracy: 0.7874
Epoch 82/110
 - 1s - loss: 0.1959 - accuracy: 0.9655 - val_loss: 1.4139 - val_accuracy: 0.8372
Epoch 83/110
 - 1s - loss: 0.1615 - accuracy: 0.9717 - val_loss: 1.3257 - val_accuracy: 0.7973
Epoch 84/110
 - 1s - loss: 0.1427 - accuracy: 0.9759 - val_loss: 0.9972 - val_accuracy: 0.8505
Epoch 85/110
 - 1s - loss: 0.1227 - accuracy: 0.9817 - val_loss: 1.1952 - val_accuracy: 0.8339
Epoch 86/110
 - 1s - loss: 0.1060 - accuracy: 0.9875 - val_loss: 1.2375 - val_accuracy: 0.8389
Epoch 87/110
 - 1s - loss: 0.0971 - accuracy: 0.9904 - val_loss: 1.2148 - val_accuracy: 0.8472
Epoch 88/110
 - 1s - loss: 0.1050 - accuracy: 0.9884 - val_loss: 1.1877 - val_accuracy: 0.8422
Epoch 89/110
 - 1s - loss: 0.1111 - accuracy: 0.9867 - val_loss: 1.2199 - val_accuracy: 0.8405
Epoch 90/110
 - 1s - loss: 0.1010 - accuracy: 0.9900 - val_loss: 1.2315 - val_accuracy: 0.8372
Epoch 91/110
 - 1s - loss: 0.1080 - accuracy: 0.9888 - val_loss: 1.2682 - val_accuracy: 0.8422
Epoch 92/110
 - 1s - loss: 0.1195 - accuracy: 0.9842 - val_loss: 1.1962 - val_accuracy: 0.8322
Epoch 93/110
 - 1s - loss: 0.1009 - accuracy: 0.9896 - val_loss: 1.1690 - val_accuracy: 0.8372
Epoch 94/110
 - 1s - loss: 0.0977 - accuracy: 0.9909 - val_loss: 1.1011 - val_accuracy: 0.8422
Epoch 95/110
 - 1s - loss: 0.0929 - accuracy: 0.9913 - val_loss: 1.1867 - val_accuracy: 0.8422
Epoch 96/110
 - 1s - loss: 0.0912 - accuracy: 0.9913 - val_loss: 1.1695 - val_accuracy: 0.8538
Epoch 97/110
 - 1s - loss: 0.0922 - accuracy: 0.9917 - val_loss: 1.2092 - val_accuracy: 0.8472
Epoch 98/110
 - 1s - loss: 0.0938 - accuracy: 0.9904 - val_loss: 1.2803 - val_accuracy: 0.8422
Epoch 99/110
 - 1s - loss: 0.0979 - accuracy: 0.9884 - val_loss: 1.2677 - val_accuracy: 0.8289
Epoch 100/110
 - 1s - loss: 0.1060 - accuracy: 0.9867 - val_loss: 1.1536 - val_accuracy: 0.8505
Epoch 101/110
 - 1s - loss: 0.1104 - accuracy: 0.9871 - val_loss: 1.3630 - val_accuracy: 0.8455
Epoch 102/110
 - 1s - loss: 0.1118 - accuracy: 0.9859 - val_loss: 1.3322 - val_accuracy: 0.8339
Epoch 103/110
 - 1s - loss: 0.0977 - accuracy: 0.9896 - val_loss: 1.2761 - val_accuracy: 0.8389
Epoch 104/110
 - 1s - loss: 0.1158 - accuracy: 0.9859 - val_loss: 1.4217 - val_accuracy: 0.8372
Epoch 105/110
 - 1s - loss: 0.1811 - accuracy: 0.9692 - val_loss: 1.0868 - val_accuracy: 0.8256
Epoch 106/110
 - 1s - loss: 0.2008 - accuracy: 0.9589 - val_loss: 0.9725 - val_accuracy: 0.8339
Epoch 107/110
 - 1s - loss: 0.1468 - accuracy: 0.9751 - val_loss: 1.1702 - val_accuracy: 0.8272
Epoch 108/110
 - 1s - loss: 0.1692 - accuracy: 0.9709 - val_loss: 1.0600 - val_accuracy: 0.8306
Epoch 109/110
 - 1s - loss: 0.1463 - accuracy: 0.9759 - val_loss: 1.0165 - val_accuracy: 0.8123
Epoch 110/110
 - 1s - loss: 0.1341 - accuracy: 0.9805 - val_loss: 1.2303 - val_accuracy: 0.8422
------------------------------------------------------------------------
Score per fold
------------------------------------------------------------------------
Score for fold 1
Accuracy_Train: 26.15%
Accuracy_Test: 27.93%
Loss_Train: 34.25
Loss_Test: 34.97
------------------------------------------------------------------------
Score for fold 2
Accuracy_Train: 23.85%
Accuracy_Test: 23.40%
Loss_Train: 55.99
Loss_Test: 57.60
------------------------------------------------------------------------
Score for fold 3
Accuracy_Train: 23.70%
Accuracy_Test: 21.28%
Loss_Train: 17.23
Loss_Test: 16.95
------------------------------------------------------------------------
Score for fold 4
Accuracy_Train: 29.88%
Accuracy_Test: 28.72%
Loss_Train: 18.66
Loss_Test: 19.74
------------------------------------------------------------------------
Score for fold 5
Accuracy_Train: 25.33%
Accuracy_Test: 28.72%
Loss_Train: 48.55
Loss_Test: 45.75
------------------------------------------------------------------------
Score for fold 6
Accuracy_Train: 26.36%
Accuracy_Test: 26.33%
Loss_Train: 40.83
Loss_Test: 43.02
------------------------------------------------------------------------
Score for fold 7
Accuracy_Train: 22.28%
Accuracy_Test: 20.48%
Loss_Train: 17.90
Loss_Test: 18.33
------------------------------------------------------------------------
Score for fold 8
Accuracy_Train: 19.86%
Accuracy_Test: 20.74%
Loss_Train: 16.31
Loss_Test: 16.59
------------------------------------------------------------------------
Score for fold 9
Accuracy_Train: 27.60%
Accuracy_Test: 26.86%
Loss_Train: 8.05
Loss_Test: 8.03
------------------------------------------------------------------------
Score for fold 10
Accuracy_Train: 20.66%
Accuracy_Test: 22.87%
Loss_Train: 31.86
Loss_Test: 31.50
------------------------------------------------------------------------
Average scores for all folds:
Average_Accuracy_Train: 24.57%
	-> (+- 2.9605756308279547 )
Average_Accuracy_Test: 24.73%
	-> (+- 3.1670160428378846 )
Average_Loss_Train: 28.96
	-> (+- 15.018304096105009 )
Average_Loss_Test: 29.25
	-> (+- 15.082472893619329 )
------------------------------------------------------------------------
