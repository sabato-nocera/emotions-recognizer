Dataset used: ../../datasets/full_dataset_without_humidity_augmented.csv 

   Temperature  Sound  Heartbeat   X1  ...    Y2     Z2  Classification  Feedback
0           32      1         60 -680  ... -7424 -15596             100     Happy
1           32      1         60 -780  ... -7408 -15628             100     Happy
2           -1      1         60   -1  ... -7276 -15612             100     Happy
3           -1     -1         60   -1  ...    -1     -1             100     Happy
4           32      1         60 -860  ... -7340 -15720             100     Happy

[5 rows x 11 columns]

Objservations: 24744
Reshaping:  ((19795, 10), (19795, 4), (4949, 10), (4949, 4))  -> ((19795, 1, 10), (19795, 4), (4949, 1, 10), (4949, 4))

Layers:

{'name': 'lstm_1', 'trainable': True, 'batch_input_shape': (None, 1, 10), 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 500, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 2} 

{'name': 'lstm_2', 'trainable': True, 'batch_input_shape': (None, 1, 10), 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 500, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 2} 

{'name': 'lstm_3', 'trainable': True, 'batch_input_shape': (None, 1, 10), 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 500, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 2} 

{'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None} 

{'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 300, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 50, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 15836 samples, validate on 3959 samples
Epoch 1/128
 - 51s - loss: 0.9021 - accuracy: 0.6450 - val_loss: 0.7912 - val_accuracy: 0.6898
Epoch 2/128
 - 49s - loss: 0.7734 - accuracy: 0.7078 - val_loss: 0.7651 - val_accuracy: 0.6934
Epoch 3/128
 - 50s - loss: 0.7298 - accuracy: 0.7231 - val_loss: 0.6925 - val_accuracy: 0.7482
Epoch 4/128
 - 49s - loss: 0.7022 - accuracy: 0.7298 - val_loss: 0.7010 - val_accuracy: 0.7406
Epoch 5/128
 - 48s - loss: 0.6756 - accuracy: 0.7405 - val_loss: 0.6528 - val_accuracy: 0.7590
Epoch 6/128
 - 48s - loss: 0.6551 - accuracy: 0.7520 - val_loss: 0.6246 - val_accuracy: 0.7633
Epoch 7/128
 - 48s - loss: 0.6306 - accuracy: 0.7603 - val_loss: 0.5948 - val_accuracy: 0.7699
Epoch 8/128
 - 51s - loss: 0.6116 - accuracy: 0.7671 - val_loss: 0.5729 - val_accuracy: 0.7823
Epoch 9/128
 - 48s - loss: 0.5971 - accuracy: 0.7711 - val_loss: 0.5602 - val_accuracy: 0.7881
Epoch 10/128
 - 48s - loss: 0.5808 - accuracy: 0.7748 - val_loss: 0.5540 - val_accuracy: 0.7939
Epoch 11/128
 - 48s - loss: 0.5527 - accuracy: 0.7859 - val_loss: 0.5202 - val_accuracy: 0.8065
Epoch 12/128
 - 48s - loss: 0.5387 - accuracy: 0.7926 - val_loss: 0.4971 - val_accuracy: 0.8080
Epoch 13/128
 - 48s - loss: 0.5170 - accuracy: 0.8006 - val_loss: 0.4985 - val_accuracy: 0.8161
Epoch 14/128
 - 48s - loss: 0.5047 - accuracy: 0.8080 - val_loss: 0.4759 - val_accuracy: 0.8267
Epoch 15/128
 - 48s - loss: 0.4824 - accuracy: 0.8135 - val_loss: 0.4763 - val_accuracy: 0.8171
Epoch 16/128
 - 49s - loss: 0.4822 - accuracy: 0.8146 - val_loss: 0.4529 - val_accuracy: 0.8280
Epoch 17/128
 - 48s - loss: 0.4585 - accuracy: 0.8231 - val_loss: 0.4568 - val_accuracy: 0.8323
Epoch 18/128
 - 48s - loss: 0.4453 - accuracy: 0.8282 - val_loss: 0.4529 - val_accuracy: 0.8320
Epoch 19/128
 - 48s - loss: 0.4380 - accuracy: 0.8286 - val_loss: 0.4320 - val_accuracy: 0.8343
Epoch 20/128
 - 48s - loss: 0.4283 - accuracy: 0.8315 - val_loss: 0.4304 - val_accuracy: 0.8356
Epoch 21/128
 - 47s - loss: 0.4327 - accuracy: 0.8294 - val_loss: 0.4506 - val_accuracy: 0.8346
Epoch 22/128
 - 47s - loss: 0.4266 - accuracy: 0.8306 - val_loss: 0.4097 - val_accuracy: 0.8492
Epoch 23/128
 - 47s - loss: 0.4133 - accuracy: 0.8344 - val_loss: 0.4067 - val_accuracy: 0.8479
Epoch 24/128
 - 48s - loss: 0.4029 - accuracy: 0.8388 - val_loss: 0.4202 - val_accuracy: 0.8394
Epoch 25/128
 - 49s - loss: 0.4035 - accuracy: 0.8380 - val_loss: 0.3908 - val_accuracy: 0.8596
Epoch 26/128
 - 48s - loss: 0.4024 - accuracy: 0.8373 - val_loss: 0.4044 - val_accuracy: 0.8469
Epoch 27/128
 - 48s - loss: 0.3899 - accuracy: 0.8429 - val_loss: 0.4211 - val_accuracy: 0.8404
Epoch 28/128
 - 47s - loss: 0.3906 - accuracy: 0.8423 - val_loss: 0.4023 - val_accuracy: 0.8515
Epoch 29/128
 - 48s - loss: 0.3802 - accuracy: 0.8459 - val_loss: 0.3850 - val_accuracy: 0.8500
Epoch 30/128
 - 47s - loss: 0.3777 - accuracy: 0.8488 - val_loss: 0.3987 - val_accuracy: 0.8459
Epoch 31/128
 - 47s - loss: 0.3756 - accuracy: 0.8481 - val_loss: 0.4116 - val_accuracy: 0.8381
Epoch 32/128
 - 48s - loss: 0.3676 - accuracy: 0.8491 - val_loss: 0.3840 - val_accuracy: 0.8520
Epoch 33/128
 - 47s - loss: 0.3690 - accuracy: 0.8512 - val_loss: 0.3659 - val_accuracy: 0.8598
Epoch 34/128
 - 48s - loss: 0.3652 - accuracy: 0.8536 - val_loss: 0.4157 - val_accuracy: 0.8277
Epoch 35/128
 - 49s - loss: 0.3582 - accuracy: 0.8554 - val_loss: 0.3534 - val_accuracy: 0.8646
Epoch 36/128
 - 51s - loss: 0.3551 - accuracy: 0.8549 - val_loss: 0.3615 - val_accuracy: 0.8651
Epoch 37/128
 - 48s - loss: 0.3517 - accuracy: 0.8567 - val_loss: 0.3572 - val_accuracy: 0.8578
Epoch 38/128
 - 48s - loss: 0.3476 - accuracy: 0.8575 - val_loss: 0.3854 - val_accuracy: 0.8474
Epoch 39/128
 - 48s - loss: 0.3481 - accuracy: 0.8581 - val_loss: 0.3662 - val_accuracy: 0.8583
Epoch 40/128
 - 48s - loss: 0.3438 - accuracy: 0.8594 - val_loss: 0.3573 - val_accuracy: 0.8613
Epoch 41/128
 - 48s - loss: 0.3503 - accuracy: 0.8569 - val_loss: 0.4017 - val_accuracy: 0.8512
Epoch 42/128
 - 48s - loss: 0.3444 - accuracy: 0.8587 - val_loss: 0.3431 - val_accuracy: 0.8737
Epoch 43/128
 - 49s - loss: 0.3332 - accuracy: 0.8643 - val_loss: 0.3622 - val_accuracy: 0.8656
Epoch 44/128
 - 49s - loss: 0.3407 - accuracy: 0.8612 - val_loss: 0.3671 - val_accuracy: 0.8611
Epoch 45/128
 - 48s - loss: 0.3325 - accuracy: 0.8622 - val_loss: 0.3561 - val_accuracy: 0.8588
Epoch 46/128
 - 48s - loss: 0.3398 - accuracy: 0.8599 - val_loss: 0.3512 - val_accuracy: 0.8692
Epoch 47/128
 - 48s - loss: 0.3385 - accuracy: 0.8616 - val_loss: 0.3394 - val_accuracy: 0.8699
Epoch 48/128
 - 48s - loss: 0.3318 - accuracy: 0.8630 - val_loss: 0.3502 - val_accuracy: 0.8702
Epoch 49/128
 - 48s - loss: 0.3285 - accuracy: 0.8639 - val_loss: 0.3838 - val_accuracy: 0.8452
Epoch 50/128
 - 48s - loss: 0.3317 - accuracy: 0.8616 - val_loss: 0.3455 - val_accuracy: 0.8692
Epoch 51/128
 - 48s - loss: 0.3318 - accuracy: 0.8618 - val_loss: 0.3534 - val_accuracy: 0.8649
Epoch 52/128
 - 48s - loss: 0.3354 - accuracy: 0.8624 - val_loss: 0.3478 - val_accuracy: 0.8659
Epoch 53/128
 - 47s - loss: 0.3231 - accuracy: 0.8656 - val_loss: 0.3473 - val_accuracy: 0.8606
Epoch 54/128
 - 48s - loss: 0.3256 - accuracy: 0.8624 - val_loss: 0.3410 - val_accuracy: 0.8722
Epoch 55/128
 - 48s - loss: 0.3203 - accuracy: 0.8661 - val_loss: 0.3758 - val_accuracy: 0.8694
Epoch 56/128
 - 48s - loss: 0.3168 - accuracy: 0.8686 - val_loss: 0.3418 - val_accuracy: 0.8704
Epoch 57/128
 - 48s - loss: 0.3219 - accuracy: 0.8664 - val_loss: 0.3525 - val_accuracy: 0.8639
Epoch 58/128
 - 48s - loss: 0.3174 - accuracy: 0.8687 - val_loss: 0.3371 - val_accuracy: 0.8697
Epoch 59/128
 - 48s - loss: 0.3182 - accuracy: 0.8666 - val_loss: 0.3521 - val_accuracy: 0.8679
Epoch 60/128
 - 47s - loss: 0.3213 - accuracy: 0.8664 - val_loss: 0.3323 - val_accuracy: 0.8765
Epoch 61/128
 - 48s - loss: 0.3124 - accuracy: 0.8692 - val_loss: 0.3271 - val_accuracy: 0.8805
Epoch 62/128
 - 48s - loss: 0.3082 - accuracy: 0.8711 - val_loss: 0.3660 - val_accuracy: 0.8740
Epoch 63/128
 - 48s - loss: 0.3227 - accuracy: 0.8649 - val_loss: 0.3373 - val_accuracy: 0.8795
Epoch 64/128
 - 48s - loss: 0.3122 - accuracy: 0.8679 - val_loss: 0.3326 - val_accuracy: 0.8745
Epoch 65/128
 - 47s - loss: 0.3154 - accuracy: 0.8692 - val_loss: 0.3232 - val_accuracy: 0.8750
Epoch 66/128
 - 50s - loss: 0.3139 - accuracy: 0.8682 - val_loss: 0.3469 - val_accuracy: 0.8732
Epoch 67/128
 - 52s - loss: 0.3101 - accuracy: 0.8707 - val_loss: 0.3274 - val_accuracy: 0.8825
Epoch 68/128
 - 53s - loss: 0.3092 - accuracy: 0.8705 - val_loss: 0.3342 - val_accuracy: 0.8767
Epoch 69/128
 - 52s - loss: 0.3082 - accuracy: 0.8695 - val_loss: 0.3249 - val_accuracy: 0.8777
Epoch 70/128
 - 54s - loss: 0.3037 - accuracy: 0.8735 - val_loss: 0.3448 - val_accuracy: 0.8783
Epoch 71/128
 - 54s - loss: 0.3032 - accuracy: 0.8724 - val_loss: 0.3309 - val_accuracy: 0.8798
Epoch 72/128
 - 50s - loss: 0.3143 - accuracy: 0.8687 - val_loss: 0.3372 - val_accuracy: 0.8772
Epoch 73/128
 - 52s - loss: 0.3041 - accuracy: 0.8692 - val_loss: 0.3306 - val_accuracy: 0.8762
Epoch 74/128
 - 51s - loss: 0.2991 - accuracy: 0.8721 - val_loss: 0.3204 - val_accuracy: 0.8790
Epoch 75/128
 - 50s - loss: 0.3075 - accuracy: 0.8701 - val_loss: 0.3122 - val_accuracy: 0.8815
Epoch 76/128
 - 51s - loss: 0.2959 - accuracy: 0.8747 - val_loss: 0.3233 - val_accuracy: 0.8765
Epoch 77/128
 - 57s - loss: 0.2992 - accuracy: 0.8741 - val_loss: 0.3302 - val_accuracy: 0.8745
Epoch 78/128
 - 55s - loss: 0.3039 - accuracy: 0.8705 - val_loss: 0.3293 - val_accuracy: 0.8790
Epoch 79/128
 - 58s - loss: 0.2959 - accuracy: 0.8742 - val_loss: 0.3403 - val_accuracy: 0.8694
Epoch 80/128
 - 55s - loss: 0.3000 - accuracy: 0.8748 - val_loss: 0.3125 - val_accuracy: 0.8810
Epoch 81/128
 - 53s - loss: 0.3003 - accuracy: 0.8736 - val_loss: 0.3351 - val_accuracy: 0.8848
Epoch 82/128
 - 58s - loss: 0.2961 - accuracy: 0.8746 - val_loss: 0.4229 - val_accuracy: 0.8457
Epoch 83/128
 - 52s - loss: 0.2963 - accuracy: 0.8747 - val_loss: 0.3222 - val_accuracy: 0.8818
Epoch 84/128
 - 51s - loss: 0.3007 - accuracy: 0.8723 - val_loss: 0.3102 - val_accuracy: 0.8879
Epoch 85/128
 - 50s - loss: 0.2940 - accuracy: 0.8760 - val_loss: 0.3238 - val_accuracy: 0.8843
Epoch 86/128
 - 51s - loss: 0.2883 - accuracy: 0.8770 - val_loss: 0.3157 - val_accuracy: 0.8856
Epoch 87/128
 - 51s - loss: 0.2888 - accuracy: 0.8769 - val_loss: 0.3161 - val_accuracy: 0.8856
Epoch 88/128
 - 51s - loss: 0.2890 - accuracy: 0.8784 - val_loss: 0.3259 - val_accuracy: 0.8770
Epoch 89/128
 - 54s - loss: 0.2945 - accuracy: 0.8772 - val_loss: 0.3185 - val_accuracy: 0.8906
Epoch 90/128
 - 53s - loss: 0.2866 - accuracy: 0.8800 - val_loss: 0.3252 - val_accuracy: 0.8851
Epoch 91/128
 - 51s - loss: 0.3005 - accuracy: 0.8735 - val_loss: 0.3090 - val_accuracy: 0.8823
Epoch 92/128
 - 49s - loss: 0.2985 - accuracy: 0.8728 - val_loss: 0.3054 - val_accuracy: 0.8861
Epoch 93/128
 - 48s - loss: 0.2793 - accuracy: 0.8796 - val_loss: 0.3122 - val_accuracy: 0.8886
Epoch 94/128
 - 49s - loss: 0.2875 - accuracy: 0.8802 - val_loss: 0.3146 - val_accuracy: 0.8879
Epoch 95/128
 - 48s - loss: 0.2904 - accuracy: 0.8791 - val_loss: 0.2975 - val_accuracy: 0.8914
Epoch 96/128
 - 49s - loss: 0.2773 - accuracy: 0.8820 - val_loss: 0.3157 - val_accuracy: 0.8889
Epoch 97/128
 - 49s - loss: 0.2779 - accuracy: 0.8818 - val_loss: 0.3273 - val_accuracy: 0.8831
Epoch 98/128
 - 48s - loss: 0.2909 - accuracy: 0.8764 - val_loss: 0.3106 - val_accuracy: 0.8909
Epoch 99/128
 - 49s - loss: 0.2824 - accuracy: 0.8803 - val_loss: 0.3013 - val_accuracy: 0.8967
Epoch 100/128
 - 49s - loss: 0.2796 - accuracy: 0.8804 - val_loss: 0.3078 - val_accuracy: 0.8868
Epoch 101/128
 - 49s - loss: 0.2868 - accuracy: 0.8812 - val_loss: 0.3125 - val_accuracy: 0.8914
Epoch 102/128
 - 49s - loss: 0.2828 - accuracy: 0.8808 - val_loss: 0.3134 - val_accuracy: 0.8879
Epoch 103/128
 - 48s - loss: 0.2694 - accuracy: 0.8840 - val_loss: 0.3215 - val_accuracy: 0.8889
Epoch 104/128
 - 49s - loss: 0.2839 - accuracy: 0.8801 - val_loss: 0.3242 - val_accuracy: 0.8861
Epoch 105/128
 - 49s - loss: 0.2743 - accuracy: 0.8807 - val_loss: 0.3097 - val_accuracy: 0.8896
Epoch 106/128
 - 48s - loss: 0.2787 - accuracy: 0.8812 - val_loss: 0.3135 - val_accuracy: 0.8911
Epoch 107/128
 - 49s - loss: 0.2817 - accuracy: 0.8836 - val_loss: 0.3141 - val_accuracy: 0.8846
Epoch 108/128
 - 49s - loss: 0.2938 - accuracy: 0.8810 - val_loss: 0.2924 - val_accuracy: 0.8934
Epoch 109/128
 - 48s - loss: 0.2753 - accuracy: 0.8842 - val_loss: 0.3029 - val_accuracy: 0.8967
Epoch 110/128
 - 49s - loss: 0.2764 - accuracy: 0.8810 - val_loss: 0.3553 - val_accuracy: 0.8813
Epoch 111/128
 - 49s - loss: 0.2893 - accuracy: 0.8801 - val_loss: 0.3168 - val_accuracy: 0.8851
Epoch 112/128
 - 49s - loss: 0.2740 - accuracy: 0.8820 - val_loss: 0.3106 - val_accuracy: 0.8924
Epoch 113/128
 - 49s - loss: 0.2701 - accuracy: 0.8852 - val_loss: 0.3347 - val_accuracy: 0.8863
Epoch 114/128
 - 48s - loss: 0.2724 - accuracy: 0.8840 - val_loss: 0.3166 - val_accuracy: 0.8876
Epoch 115/128
 - 49s - loss: 0.2739 - accuracy: 0.8847 - val_loss: 0.3331 - val_accuracy: 0.8866
Epoch 116/128
 - 48s - loss: 0.2613 - accuracy: 0.8891 - val_loss: 0.3236 - val_accuracy: 0.8924
Epoch 117/128
 - 48s - loss: 0.2847 - accuracy: 0.8800 - val_loss: 0.3219 - val_accuracy: 0.8876
Epoch 118/128
 - 49s - loss: 0.2630 - accuracy: 0.8855 - val_loss: 0.3469 - val_accuracy: 0.8884
Epoch 119/128
 - 49s - loss: 0.2789 - accuracy: 0.8827 - val_loss: 0.3029 - val_accuracy: 0.8924
Epoch 120/128
 - 49s - loss: 0.2858 - accuracy: 0.8778 - val_loss: 0.3370 - val_accuracy: 0.8800
Epoch 121/128
 - 49s - loss: 0.2725 - accuracy: 0.8846 - val_loss: 0.2777 - val_accuracy: 0.8944
Epoch 122/128
 - 48s - loss: 0.2683 - accuracy: 0.8858 - val_loss: 0.2873 - val_accuracy: 0.8896
Epoch 123/128
 - 49s - loss: 0.2651 - accuracy: 0.8865 - val_loss: 0.2985 - val_accuracy: 0.8884
Epoch 124/128
 - 49s - loss: 0.2694 - accuracy: 0.8841 - val_loss: 0.3023 - val_accuracy: 0.8848
Epoch 125/128
 - 49s - loss: 0.2677 - accuracy: 0.8863 - val_loss: 0.3185 - val_accuracy: 0.8861
Epoch 126/128
 - 49s - loss: 0.2605 - accuracy: 0.8894 - val_loss: 0.3183 - val_accuracy: 0.8929
Epoch 127/128
 - 49s - loss: 0.2612 - accuracy: 0.8892 - val_loss: 0.3010 - val_accuracy: 0.8906
Epoch 128/128
 - 48s - loss: 0.2646 - accuracy: 0.8885 - val_loss: 0.3060 - val_accuracy: 0.8894

Fit: epochs= 128 , batch_size= 32 , verbose= 2 , shuffle= False , validation_split= 0.2 

Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 1, 500)            1022000   
_________________________________________________________________
lstm_2 (LSTM)                (None, 1, 500)            2002000   
_________________________________________________________________
lstm_3 (LSTM)                (None, 500)               2002000   
_________________________________________________________________
dropout_1 (Dropout)          (None, 500)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 300)               150300    
_________________________________________________________________
dense_2 (Dense)              (None, 200)               60200     
_________________________________________________________________
dense_3 (Dense)              (None, 100)               20100     
_________________________________________________________________
dense_4 (Dense)              (None, 50)                5050      
_________________________________________________________________
dense_5 (Dense)              (None, 20)                1020      
_________________________________________________________________
dense_6 (Dense)              (None, 4)                 84        
=================================================================
Total params: 5,262,754
Trainable params: 5,262,754
Non-trainable params: 0
_________________________________________________________________
None

Accuracy Train: 88.89%
Accuracy Test: 88.34%
Loss Train: 0.26
Loss Test: 0.30
Numero dati esaminati: 4949
True Positive 4372
False Positive 577
