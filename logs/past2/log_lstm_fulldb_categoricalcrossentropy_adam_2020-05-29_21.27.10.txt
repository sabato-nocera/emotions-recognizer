Dataset used: ../../datasets/full_dataset.csv 

   Temperature  Humidity  Sound  ...     Z2  Classification  Feedback
0           32        95      1  ... -15596             100     Happy
1           32        86      1  ... -15628             100     Happy
2           -1        -1      1  ... -15612             100     Happy
3           -1        -1     -1  ...     -1             100     Happy
4           32        75      1  ... -15720             100     Happy

[5 rows x 12 columns]

Objservations: 8560
Reshaping:  ((6848, 11), (6848, 4), (1712, 11), (1712, 4))  -> ((6848, 1, 11), (6848, 4), (1712, 1, 11), (1712, 4))

Layers:

{'name': 'lstm_1', 'trainable': True, 'batch_input_shape': (None, 1, 11), 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 256, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 2} 

{'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 5478 samples, validate on 1370 samples
Epoch 1/500
 - 2s - loss: 1.0866 - accuracy: 0.5581 - val_loss: 0.8826 - val_accuracy: 0.6635
Epoch 2/500
 - 1s - loss: 0.8442 - accuracy: 0.6857 - val_loss: 0.8085 - val_accuracy: 0.6927
Epoch 3/500
 - 1s - loss: 0.7973 - accuracy: 0.7024 - val_loss: 0.7810 - val_accuracy: 0.7044
Epoch 4/500
 - 1s - loss: 0.7730 - accuracy: 0.7083 - val_loss: 0.7612 - val_accuracy: 0.7197
Epoch 5/500
 - 1s - loss: 0.7534 - accuracy: 0.7112 - val_loss: 0.7461 - val_accuracy: 0.7234
Epoch 6/500
 - 1s - loss: 0.7351 - accuracy: 0.7156 - val_loss: 0.7305 - val_accuracy: 0.7248
Epoch 7/500
 - 1s - loss: 0.7189 - accuracy: 0.7227 - val_loss: 0.7171 - val_accuracy: 0.7270
Epoch 8/500
 - 1s - loss: 0.7047 - accuracy: 0.7338 - val_loss: 0.7053 - val_accuracy: 0.7299
Epoch 9/500
 - 1s - loss: 0.6918 - accuracy: 0.7399 - val_loss: 0.6945 - val_accuracy: 0.7307
Epoch 10/500
 - 1s - loss: 0.6802 - accuracy: 0.7448 - val_loss: 0.6846 - val_accuracy: 0.7358
Epoch 11/500
 - 1s - loss: 0.6689 - accuracy: 0.7508 - val_loss: 0.6755 - val_accuracy: 0.7445
Epoch 12/500
 - 1s - loss: 0.6585 - accuracy: 0.7554 - val_loss: 0.6653 - val_accuracy: 0.7504
Epoch 13/500
 - 1s - loss: 0.6483 - accuracy: 0.7601 - val_loss: 0.6567 - val_accuracy: 0.7526
Epoch 14/500
 - 1s - loss: 0.6385 - accuracy: 0.7629 - val_loss: 0.6488 - val_accuracy: 0.7562
Epoch 15/500
 - 1s - loss: 0.6291 - accuracy: 0.7643 - val_loss: 0.6388 - val_accuracy: 0.7569
Epoch 16/500
 - 1s - loss: 0.6196 - accuracy: 0.7674 - val_loss: 0.6316 - val_accuracy: 0.7606
Epoch 17/500
 - 1s - loss: 0.6118 - accuracy: 0.7714 - val_loss: 0.6247 - val_accuracy: 0.7635
Epoch 18/500
 - 1s - loss: 0.6033 - accuracy: 0.7740 - val_loss: 0.6175 - val_accuracy: 0.7672
Epoch 19/500
 - 1s - loss: 0.5961 - accuracy: 0.7764 - val_loss: 0.6121 - val_accuracy: 0.7679
Epoch 20/500
 - 1s - loss: 0.5882 - accuracy: 0.7784 - val_loss: 0.6066 - val_accuracy: 0.7723
Epoch 21/500
 - 1s - loss: 0.5817 - accuracy: 0.7817 - val_loss: 0.6004 - val_accuracy: 0.7737
Epoch 22/500
 - 1s - loss: 0.5748 - accuracy: 0.7837 - val_loss: 0.5961 - val_accuracy: 0.7810
Epoch 23/500
 - 1s - loss: 0.5686 - accuracy: 0.7861 - val_loss: 0.5916 - val_accuracy: 0.7839
Epoch 24/500
 - 1s - loss: 0.5623 - accuracy: 0.7890 - val_loss: 0.5866 - val_accuracy: 0.7832
Epoch 25/500
 - 1s - loss: 0.5564 - accuracy: 0.7912 - val_loss: 0.5820 - val_accuracy: 0.7883
Epoch 26/500
 - 1s - loss: 0.5504 - accuracy: 0.7928 - val_loss: 0.5773 - val_accuracy: 0.7861
Epoch 27/500
 - 1s - loss: 0.5451 - accuracy: 0.7928 - val_loss: 0.5737 - val_accuracy: 0.7847
Epoch 28/500
 - 1s - loss: 0.5407 - accuracy: 0.7943 - val_loss: 0.5695 - val_accuracy: 0.7883
Epoch 29/500
 - 1s - loss: 0.5345 - accuracy: 0.7961 - val_loss: 0.5643 - val_accuracy: 0.7927
Epoch 30/500
 - 1s - loss: 0.5302 - accuracy: 0.7955 - val_loss: 0.5610 - val_accuracy: 0.7927
Epoch 31/500
 - 1s - loss: 0.5250 - accuracy: 0.7979 - val_loss: 0.5564 - val_accuracy: 0.7927
Epoch 32/500
 - 1s - loss: 0.5206 - accuracy: 0.7983 - val_loss: 0.5536 - val_accuracy: 0.7949
Epoch 33/500
 - 1s - loss: 0.5171 - accuracy: 0.7992 - val_loss: 0.5508 - val_accuracy: 0.7927
Epoch 34/500
 - 1s - loss: 0.5126 - accuracy: 0.8016 - val_loss: 0.5473 - val_accuracy: 0.7949
Epoch 35/500
 - 1s - loss: 0.5084 - accuracy: 0.8021 - val_loss: 0.5450 - val_accuracy: 0.7985
Epoch 36/500
 - 1s - loss: 0.5048 - accuracy: 0.8047 - val_loss: 0.5436 - val_accuracy: 0.7949
Epoch 37/500
 - 1s - loss: 0.5013 - accuracy: 0.8065 - val_loss: 0.5390 - val_accuracy: 0.7978
Epoch 38/500
 - 1s - loss: 0.4975 - accuracy: 0.8072 - val_loss: 0.5390 - val_accuracy: 0.7993
Epoch 39/500
 - 1s - loss: 0.4940 - accuracy: 0.8089 - val_loss: 0.5362 - val_accuracy: 0.7985
Epoch 40/500
 - 1s - loss: 0.4909 - accuracy: 0.8103 - val_loss: 0.5358 - val_accuracy: 0.7964
Epoch 41/500
 - 1s - loss: 0.4876 - accuracy: 0.8112 - val_loss: 0.5342 - val_accuracy: 0.8000
Epoch 42/500
 - 1s - loss: 0.4850 - accuracy: 0.8127 - val_loss: 0.5306 - val_accuracy: 0.8000
Epoch 43/500
 - 1s - loss: 0.4814 - accuracy: 0.8134 - val_loss: 0.5289 - val_accuracy: 0.8007
Epoch 44/500
 - 1s - loss: 0.4783 - accuracy: 0.8138 - val_loss: 0.5260 - val_accuracy: 0.8029
Epoch 45/500
 - 1s - loss: 0.4760 - accuracy: 0.8136 - val_loss: 0.5251 - val_accuracy: 0.7993
Epoch 46/500
 - 1s - loss: 0.4731 - accuracy: 0.8167 - val_loss: 0.5241 - val_accuracy: 0.8015
Epoch 47/500
 - 1s - loss: 0.4707 - accuracy: 0.8167 - val_loss: 0.5232 - val_accuracy: 0.8015
Epoch 48/500
 - 1s - loss: 0.4688 - accuracy: 0.8173 - val_loss: 0.5201 - val_accuracy: 0.8029
Epoch 49/500
 - 1s - loss: 0.4656 - accuracy: 0.8187 - val_loss: 0.5187 - val_accuracy: 0.8044
Epoch 50/500
 - 1s - loss: 0.4627 - accuracy: 0.8204 - val_loss: 0.5182 - val_accuracy: 0.8015
Epoch 51/500
 - 1s - loss: 0.4608 - accuracy: 0.8206 - val_loss: 0.5169 - val_accuracy: 0.8051
Epoch 52/500
 - 1s - loss: 0.4591 - accuracy: 0.8217 - val_loss: 0.5173 - val_accuracy: 0.8036
Epoch 53/500
 - 1s - loss: 0.4564 - accuracy: 0.8233 - val_loss: 0.5157 - val_accuracy: 0.8044
Epoch 54/500
 - 1s - loss: 0.4545 - accuracy: 0.8237 - val_loss: 0.5153 - val_accuracy: 0.8058
Epoch 55/500
 - 1s - loss: 0.4520 - accuracy: 0.8222 - val_loss: 0.5133 - val_accuracy: 0.8051
Epoch 56/500
 - 1s - loss: 0.4503 - accuracy: 0.8246 - val_loss: 0.5122 - val_accuracy: 0.8058
Epoch 57/500
 - 1s - loss: 0.4480 - accuracy: 0.8255 - val_loss: 0.5138 - val_accuracy: 0.8044
Epoch 58/500
 - 1s - loss: 0.4465 - accuracy: 0.8264 - val_loss: 0.5116 - val_accuracy: 0.8036
Epoch 59/500
 - 1s - loss: 0.4446 - accuracy: 0.8244 - val_loss: 0.5117 - val_accuracy: 0.8044
Epoch 60/500
 - 1s - loss: 0.4424 - accuracy: 0.8268 - val_loss: 0.5095 - val_accuracy: 0.8058
Epoch 61/500
 - 1s - loss: 0.4411 - accuracy: 0.8268 - val_loss: 0.5083 - val_accuracy: 0.8066
Epoch 62/500
 - 1s - loss: 0.4393 - accuracy: 0.8268 - val_loss: 0.5085 - val_accuracy: 0.8095
Epoch 63/500
 - 1s - loss: 0.4375 - accuracy: 0.8280 - val_loss: 0.5087 - val_accuracy: 0.8088
Epoch 64/500
 - 1s - loss: 0.4358 - accuracy: 0.8297 - val_loss: 0.5061 - val_accuracy: 0.8022
Epoch 65/500
 - 1s - loss: 0.4344 - accuracy: 0.8299 - val_loss: 0.5081 - val_accuracy: 0.8095
Epoch 66/500
 - 1s - loss: 0.4322 - accuracy: 0.8313 - val_loss: 0.5038 - val_accuracy: 0.8066
Epoch 67/500
 - 1s - loss: 0.4307 - accuracy: 0.8315 - val_loss: 0.5043 - val_accuracy: 0.8102
Epoch 68/500
 - 1s - loss: 0.4297 - accuracy: 0.8311 - val_loss: 0.5039 - val_accuracy: 0.8095
Epoch 69/500
 - 1s - loss: 0.4282 - accuracy: 0.8324 - val_loss: 0.5026 - val_accuracy: 0.8095
Epoch 70/500
 - 1s - loss: 0.4263 - accuracy: 0.8319 - val_loss: 0.5025 - val_accuracy: 0.8088
Epoch 71/500
 - 1s - loss: 0.4245 - accuracy: 0.8332 - val_loss: 0.5002 - val_accuracy: 0.8117
Epoch 72/500
 - 1s - loss: 0.4240 - accuracy: 0.8332 - val_loss: 0.5006 - val_accuracy: 0.8109
Epoch 73/500
 - 1s - loss: 0.4227 - accuracy: 0.8328 - val_loss: 0.5018 - val_accuracy: 0.8153
Epoch 74/500
 - 1s - loss: 0.4204 - accuracy: 0.8342 - val_loss: 0.4977 - val_accuracy: 0.8182
Epoch 75/500
 - 1s - loss: 0.4194 - accuracy: 0.8359 - val_loss: 0.4990 - val_accuracy: 0.8182
Epoch 76/500
 - 1s - loss: 0.4176 - accuracy: 0.8357 - val_loss: 0.4987 - val_accuracy: 0.8197
Epoch 77/500
 - 1s - loss: 0.4163 - accuracy: 0.8363 - val_loss: 0.4996 - val_accuracy: 0.8168
Epoch 78/500
 - 1s - loss: 0.4150 - accuracy: 0.8364 - val_loss: 0.4972 - val_accuracy: 0.8182
Epoch 79/500
 - 1s - loss: 0.4138 - accuracy: 0.8379 - val_loss: 0.4979 - val_accuracy: 0.8204
Epoch 80/500
 - 1s - loss: 0.4122 - accuracy: 0.8375 - val_loss: 0.4963 - val_accuracy: 0.8204
Epoch 81/500
 - 1s - loss: 0.4114 - accuracy: 0.8368 - val_loss: 0.4963 - val_accuracy: 0.8197
Epoch 82/500
 - 1s - loss: 0.4103 - accuracy: 0.8377 - val_loss: 0.4958 - val_accuracy: 0.8204
Epoch 83/500
 - 1s - loss: 0.4094 - accuracy: 0.8384 - val_loss: 0.4968 - val_accuracy: 0.8197
Epoch 84/500
 - 1s - loss: 0.4078 - accuracy: 0.8379 - val_loss: 0.4947 - val_accuracy: 0.8204
Epoch 85/500
 - 1s - loss: 0.4074 - accuracy: 0.8383 - val_loss: 0.4958 - val_accuracy: 0.8226
Epoch 86/500
 - 1s - loss: 0.4049 - accuracy: 0.8375 - val_loss: 0.4933 - val_accuracy: 0.8226
Epoch 87/500
 - 1s - loss: 0.4036 - accuracy: 0.8386 - val_loss: 0.4951 - val_accuracy: 0.8219
Epoch 88/500
 - 1s - loss: 0.4031 - accuracy: 0.8394 - val_loss: 0.4966 - val_accuracy: 0.8219
Epoch 89/500
 - 1s - loss: 0.4023 - accuracy: 0.8395 - val_loss: 0.4954 - val_accuracy: 0.8241
Epoch 90/500
 - 1s - loss: 0.4008 - accuracy: 0.8414 - val_loss: 0.4964 - val_accuracy: 0.8241
Epoch 91/500
 - 1s - loss: 0.3999 - accuracy: 0.8399 - val_loss: 0.4903 - val_accuracy: 0.8241
Epoch 92/500
 - 1s - loss: 0.3988 - accuracy: 0.8412 - val_loss: 0.4911 - val_accuracy: 0.8241
Epoch 93/500
 - 1s - loss: 0.3972 - accuracy: 0.8415 - val_loss: 0.4904 - val_accuracy: 0.8270
Epoch 94/500
 - 1s - loss: 0.3962 - accuracy: 0.8417 - val_loss: 0.4914 - val_accuracy: 0.8263
Epoch 95/500
 - 1s - loss: 0.3954 - accuracy: 0.8432 - val_loss: 0.4898 - val_accuracy: 0.8292
Epoch 96/500
 - 1s - loss: 0.3948 - accuracy: 0.8432 - val_loss: 0.4910 - val_accuracy: 0.8234
Epoch 97/500
 - 1s - loss: 0.3935 - accuracy: 0.8430 - val_loss: 0.4874 - val_accuracy: 0.8299
Epoch 98/500
 - 1s - loss: 0.3925 - accuracy: 0.8448 - val_loss: 0.4877 - val_accuracy: 0.8321
Epoch 99/500
 - 1s - loss: 0.3915 - accuracy: 0.8445 - val_loss: 0.4885 - val_accuracy: 0.8292
Epoch 100/500
 - 1s - loss: 0.3904 - accuracy: 0.8457 - val_loss: 0.4873 - val_accuracy: 0.8314
Epoch 101/500
 - 1s - loss: 0.3894 - accuracy: 0.8443 - val_loss: 0.4875 - val_accuracy: 0.8336
Epoch 102/500
 - 1s - loss: 0.3879 - accuracy: 0.8465 - val_loss: 0.4878 - val_accuracy: 0.8343
Epoch 103/500
 - 1s - loss: 0.3878 - accuracy: 0.8467 - val_loss: 0.4889 - val_accuracy: 0.8270
Epoch 104/500
 - 1s - loss: 0.3870 - accuracy: 0.8459 - val_loss: 0.4853 - val_accuracy: 0.8336
Epoch 105/500
 - 1s - loss: 0.3850 - accuracy: 0.8459 - val_loss: 0.4894 - val_accuracy: 0.8336
Epoch 106/500
 - 1s - loss: 0.3852 - accuracy: 0.8478 - val_loss: 0.4895 - val_accuracy: 0.8358
Epoch 107/500
 - 1s - loss: 0.3837 - accuracy: 0.8467 - val_loss: 0.4862 - val_accuracy: 0.8365
Epoch 108/500
 - 1s - loss: 0.3839 - accuracy: 0.8470 - val_loss: 0.4855 - val_accuracy: 0.8328
Epoch 109/500
 - 1s - loss: 0.3821 - accuracy: 0.8465 - val_loss: 0.4860 - val_accuracy: 0.8336
Epoch 110/500
 - 1s - loss: 0.3815 - accuracy: 0.8472 - val_loss: 0.4839 - val_accuracy: 0.8343
Epoch 111/500
 - 1s - loss: 0.3808 - accuracy: 0.8470 - val_loss: 0.4859 - val_accuracy: 0.8358
Epoch 112/500
 - 1s - loss: 0.3796 - accuracy: 0.8463 - val_loss: 0.4855 - val_accuracy: 0.8328
Epoch 113/500
 - 1s - loss: 0.3793 - accuracy: 0.8476 - val_loss: 0.4823 - val_accuracy: 0.8350
Epoch 114/500
 - 1s - loss: 0.3786 - accuracy: 0.8485 - val_loss: 0.4832 - val_accuracy: 0.8365
Epoch 115/500
 - 1s - loss: 0.3777 - accuracy: 0.8488 - val_loss: 0.4844 - val_accuracy: 0.8365
Epoch 116/500
 - 1s - loss: 0.3770 - accuracy: 0.8494 - val_loss: 0.4815 - val_accuracy: 0.8394
Epoch 117/500
 - 1s - loss: 0.3758 - accuracy: 0.8492 - val_loss: 0.4815 - val_accuracy: 0.8409
Epoch 118/500
 - 1s - loss: 0.3754 - accuracy: 0.8487 - val_loss: 0.4827 - val_accuracy: 0.8431
Epoch 119/500
 - 1s - loss: 0.3739 - accuracy: 0.8498 - val_loss: 0.4814 - val_accuracy: 0.8387
Epoch 120/500
 - 1s - loss: 0.3727 - accuracy: 0.8507 - val_loss: 0.4816 - val_accuracy: 0.8409
Epoch 121/500
 - 1s - loss: 0.3724 - accuracy: 0.8521 - val_loss: 0.4796 - val_accuracy: 0.8380
Epoch 122/500
 - 1s - loss: 0.3719 - accuracy: 0.8501 - val_loss: 0.4792 - val_accuracy: 0.8409
Epoch 123/500
 - 1s - loss: 0.3708 - accuracy: 0.8503 - val_loss: 0.4832 - val_accuracy: 0.8365
Epoch 124/500
 - 1s - loss: 0.3712 - accuracy: 0.8494 - val_loss: 0.4820 - val_accuracy: 0.8387
Epoch 125/500
 - 1s - loss: 0.3698 - accuracy: 0.8518 - val_loss: 0.4778 - val_accuracy: 0.8394
Epoch 126/500
 - 1s - loss: 0.3695 - accuracy: 0.8501 - val_loss: 0.4812 - val_accuracy: 0.8394
Epoch 127/500
 - 1s - loss: 0.3691 - accuracy: 0.8525 - val_loss: 0.4802 - val_accuracy: 0.8394
Epoch 128/500
 - 1s - loss: 0.3679 - accuracy: 0.8507 - val_loss: 0.4765 - val_accuracy: 0.8401
Epoch 129/500
 - 1s - loss: 0.3675 - accuracy: 0.8520 - val_loss: 0.4809 - val_accuracy: 0.8387
Epoch 130/500
 - 1s - loss: 0.3672 - accuracy: 0.8516 - val_loss: 0.4808 - val_accuracy: 0.8394
Epoch 131/500
 - 1s - loss: 0.3664 - accuracy: 0.8530 - val_loss: 0.4744 - val_accuracy: 0.8438
Epoch 132/500
 - 1s - loss: 0.3658 - accuracy: 0.8541 - val_loss: 0.4794 - val_accuracy: 0.8394
Epoch 133/500
 - 1s - loss: 0.3660 - accuracy: 0.8525 - val_loss: 0.4760 - val_accuracy: 0.8431
Epoch 134/500
 - 1s - loss: 0.3655 - accuracy: 0.8534 - val_loss: 0.4764 - val_accuracy: 0.8423
Epoch 135/500
 - 1s - loss: 0.3650 - accuracy: 0.8532 - val_loss: 0.4794 - val_accuracy: 0.8394
Epoch 136/500
 - 1s - loss: 0.3642 - accuracy: 0.8532 - val_loss: 0.4755 - val_accuracy: 0.8409
Epoch 137/500
 - 1s - loss: 0.3640 - accuracy: 0.8543 - val_loss: 0.4776 - val_accuracy: 0.8431
Epoch 138/500
 - 1s - loss: 0.3641 - accuracy: 0.8532 - val_loss: 0.4765 - val_accuracy: 0.8474

Fit: epochs = 500, batch_size = 80, verbose = 2, shuffle=False, validation_split = 0.20, callbacks=[EarlyStopping(monitor='val_loss',patience=7, min_delta=0.0001)]

Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 256)               274432    
_________________________________________________________________
dense_1 (Dense)              (None, 200)               51400     
_________________________________________________________________
dense_2 (Dense)              (None, 100)               20100     
_________________________________________________________________
dense_3 (Dense)              (None, 4)                 404       
=================================================================
Total params: 346,336
Trainable params: 346,336
Non-trainable params: 0
_________________________________________________________________
None

Accuracy Train: 85.75%
Accuracy Test: 84.23%
Numero dati esaminati: 1712
True Positive 1442
False Positive 270
