Dataset used: ../../datasets/sorted_dataset.csv 

   Temperature  Humidity  Sound  Heartbeat  ...  Y2  Z2  Classification  Feedback
0           33        95     -1         52  ...  -1  -1             100     Angry
1           -1        -1     -1         52  ...  -1  -1             100     Angry
2           33        95     -1         52  ...  -1  -1             100     Angry
3           33        95     -1         56  ...  -1  -1             150     Angry
4           33        95     -1         56  ...  -1  -1             150     Angry

[5 rows x 12 columns]

Objservations: 8560
Other x for train: 4279
Other y for train: 4279
Number of train examples: 11127
Reshaping:  ((11127, 11), (11127, 4), (1712, 11), (1712, 4))  -> ((11127, 11, 1), (11127, 4), (1712, 11, 1), (1712, 4))

Layers:

{'name': 'conv1d_1', 'trainable': True, 'batch_input_shape': (None, 11, 1), 'dtype': 'float32', 'filters': 500, 'kernel_size': (1,), 'strides': (1,), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'activation_1', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'} 

{'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.4, 'noise_shape': None, 'seed': None} 

{'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 400, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 300, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'activation_2', 'trainable': True, 'dtype': 'float32', 'activation': 'softmax'} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 8901 samples, validate on 2226 samples
Epoch 1/192
 - 12s - loss: 2.4415 - accuracy: 0.5935 - val_loss: 0.9016 - val_accuracy: 0.7053
Epoch 2/192
 - 12s - loss: 0.6864 - accuracy: 0.7535 - val_loss: 0.5929 - val_accuracy: 0.7799
Epoch 3/192
 - 12s - loss: 0.5862 - accuracy: 0.7844 - val_loss: 0.6798 - val_accuracy: 0.7547
Epoch 4/192
 - 11s - loss: 0.6666 - accuracy: 0.7760 - val_loss: 0.5625 - val_accuracy: 0.7978
Epoch 5/192
 - 11s - loss: 0.5211 - accuracy: 0.8047 - val_loss: 0.5133 - val_accuracy: 0.8059
Epoch 6/192
 - 11s - loss: 0.5117 - accuracy: 0.8083 - val_loss: 0.6144 - val_accuracy: 0.7857
Epoch 7/192
 - 11s - loss: 0.5247 - accuracy: 0.8108 - val_loss: 0.5169 - val_accuracy: 0.8127
Epoch 8/192
 - 11s - loss: 0.4828 - accuracy: 0.8241 - val_loss: 0.5182 - val_accuracy: 0.8100
Epoch 9/192
 - 11s - loss: 0.4776 - accuracy: 0.8253 - val_loss: 0.5250 - val_accuracy: 0.8001
Epoch 10/192
 - 11s - loss: 0.4728 - accuracy: 0.8279 - val_loss: 0.4754 - val_accuracy: 0.8257
Epoch 11/192
 - 11s - loss: 0.4512 - accuracy: 0.8364 - val_loss: 0.5285 - val_accuracy: 0.7951
Epoch 12/192
 - 11s - loss: 0.4716 - accuracy: 0.8281 - val_loss: 1.0159 - val_accuracy: 0.7817
Epoch 13/192
 - 12s - loss: 0.4966 - accuracy: 0.8269 - val_loss: 0.4249 - val_accuracy: 0.8419
Epoch 14/192
 - 12s - loss: 0.4245 - accuracy: 0.8441 - val_loss: 0.4183 - val_accuracy: 0.8437
Epoch 15/192
 - 11s - loss: 0.4047 - accuracy: 0.8482 - val_loss: 0.3974 - val_accuracy: 0.8513
Epoch 16/192
 - 11s - loss: 0.4129 - accuracy: 0.8435 - val_loss: 0.5087 - val_accuracy: 0.8387
Epoch 17/192
 - 12s - loss: 0.4426 - accuracy: 0.8381 - val_loss: 0.3909 - val_accuracy: 0.8522
Epoch 18/192
 - 12s - loss: 0.3979 - accuracy: 0.8505 - val_loss: 0.3953 - val_accuracy: 0.8544
Epoch 19/192
 - 12s - loss: 0.3879 - accuracy: 0.8525 - val_loss: 0.3859 - val_accuracy: 0.8535
Epoch 20/192
 - 12s - loss: 0.3828 - accuracy: 0.8524 - val_loss: 0.4422 - val_accuracy: 0.8329
Epoch 21/192
 - 13s - loss: 0.4126 - accuracy: 0.8484 - val_loss: 0.4272 - val_accuracy: 0.8464
Epoch 22/192
 - 13s - loss: 0.3863 - accuracy: 0.8545 - val_loss: 0.4573 - val_accuracy: 0.8315
Epoch 23/192
 - 12s - loss: 0.3879 - accuracy: 0.8542 - val_loss: 0.4170 - val_accuracy: 0.8419
Epoch 24/192
 - 12s - loss: 0.3743 - accuracy: 0.8566 - val_loss: 0.4099 - val_accuracy: 0.8302
Epoch 25/192
 - 12s - loss: 0.3694 - accuracy: 0.8574 - val_loss: 0.4768 - val_accuracy: 0.8441
Epoch 26/192
 - 13s - loss: 0.3614 - accuracy: 0.8593 - val_loss: 0.3753 - val_accuracy: 0.8576
Epoch 27/192
 - 13s - loss: 0.3717 - accuracy: 0.8574 - val_loss: 0.3951 - val_accuracy: 0.8473
Epoch 28/192
 - 12s - loss: 0.5273 - accuracy: 0.8365 - val_loss: 0.3778 - val_accuracy: 0.8531
Epoch 29/192
 - 13s - loss: 0.3612 - accuracy: 0.8610 - val_loss: 0.3772 - val_accuracy: 0.8522
Epoch 30/192
 - 13s - loss: 0.3420 - accuracy: 0.8655 - val_loss: 0.3590 - val_accuracy: 0.8643
Epoch 31/192
 - 13s - loss: 0.3370 - accuracy: 0.8664 - val_loss: 0.3597 - val_accuracy: 0.8639
Epoch 32/192
 - 13s - loss: 0.3383 - accuracy: 0.8683 - val_loss: 0.3861 - val_accuracy: 0.8441
Epoch 33/192
 - 13s - loss: 0.3324 - accuracy: 0.8692 - val_loss: 0.3765 - val_accuracy: 0.8576
Epoch 34/192
 - 13s - loss: 0.3279 - accuracy: 0.8736 - val_loss: 0.3736 - val_accuracy: 0.8585
Epoch 35/192
 - 13s - loss: 0.3319 - accuracy: 0.8705 - val_loss: 0.3592 - val_accuracy: 0.8697
Epoch 36/192
 - 13s - loss: 0.3272 - accuracy: 0.8739 - val_loss: 0.3662 - val_accuracy: 0.8652
Epoch 37/192
 - 13s - loss: 0.3255 - accuracy: 0.8709 - val_loss: 0.3450 - val_accuracy: 0.8706
Epoch 38/192
 - 13s - loss: 0.3186 - accuracy: 0.8751 - val_loss: 0.3458 - val_accuracy: 0.8706
Epoch 39/192
 - 13s - loss: 0.3229 - accuracy: 0.8747 - val_loss: 0.3417 - val_accuracy: 0.8697
Epoch 40/192
 - 13s - loss: 0.3103 - accuracy: 0.8807 - val_loss: 0.3766 - val_accuracy: 0.8603
Epoch 41/192
 - 14s - loss: 0.4012 - accuracy: 0.8626 - val_loss: 0.3540 - val_accuracy: 0.8652
Epoch 42/192
 - 13s - loss: 0.3205 - accuracy: 0.8754 - val_loss: 0.3591 - val_accuracy: 0.8693
Epoch 43/192
 - 14s - loss: 0.3086 - accuracy: 0.8787 - val_loss: 0.3468 - val_accuracy: 0.8675
Epoch 44/192
 - 13s - loss: 0.3115 - accuracy: 0.8763 - val_loss: 0.3422 - val_accuracy: 0.8742
Epoch 45/192
 - 14s - loss: 0.3009 - accuracy: 0.8810 - val_loss: 0.3393 - val_accuracy: 0.8787
Epoch 46/192
 - 13s - loss: 0.3198 - accuracy: 0.8773 - val_loss: 0.3392 - val_accuracy: 0.8769
Epoch 47/192
 - 13s - loss: 0.3028 - accuracy: 0.8807 - val_loss: 0.3318 - val_accuracy: 0.8760
Epoch 48/192
 - 13s - loss: 0.3025 - accuracy: 0.8815 - val_loss: 0.3214 - val_accuracy: 0.8832
Epoch 49/192
 - 13s - loss: 0.2958 - accuracy: 0.8843 - val_loss: 0.3263 - val_accuracy: 0.8778
Epoch 50/192
 - 13s - loss: 0.3014 - accuracy: 0.8805 - val_loss: 0.3609 - val_accuracy: 0.8715
Epoch 51/192
 - 13s - loss: 0.2931 - accuracy: 0.8834 - val_loss: 0.3225 - val_accuracy: 0.8823
Epoch 52/192
 - 13s - loss: 0.3282 - accuracy: 0.8739 - val_loss: 0.3517 - val_accuracy: 0.8684
Epoch 53/192
 - 12s - loss: 0.3139 - accuracy: 0.8791 - val_loss: 0.3253 - val_accuracy: 0.8751
Epoch 54/192
 - 12s - loss: 0.2925 - accuracy: 0.8841 - val_loss: 0.3293 - val_accuracy: 0.8742
Epoch 55/192
 - 12s - loss: 0.2866 - accuracy: 0.8850 - val_loss: 0.3384 - val_accuracy: 0.8742
Epoch 56/192
 - 12s - loss: 0.2838 - accuracy: 0.8878 - val_loss: 0.3191 - val_accuracy: 0.8783
Epoch 57/192
 - 12s - loss: 0.2836 - accuracy: 0.8869 - val_loss: 0.3338 - val_accuracy: 0.8805
Epoch 58/192
 - 12s - loss: 0.3323 - accuracy: 0.8727 - val_loss: 0.3846 - val_accuracy: 0.8679
Epoch 59/192
 - 12s - loss: 0.2881 - accuracy: 0.8865 - val_loss: 0.3236 - val_accuracy: 0.8760
Epoch 60/192
 - 12s - loss: 0.2783 - accuracy: 0.8909 - val_loss: 0.3426 - val_accuracy: 0.8639
Epoch 61/192
 - 12s - loss: 0.2831 - accuracy: 0.8883 - val_loss: 0.3235 - val_accuracy: 0.8792
Epoch 62/192
 - 12s - loss: 0.2783 - accuracy: 0.8875 - val_loss: 0.3263 - val_accuracy: 0.8774
Epoch 63/192
 - 12s - loss: 0.2909 - accuracy: 0.8830 - val_loss: 0.3729 - val_accuracy: 0.8612
Epoch 64/192
 - 12s - loss: 0.2885 - accuracy: 0.8870 - val_loss: 0.3219 - val_accuracy: 0.8796
Epoch 65/192
 - 12s - loss: 0.2762 - accuracy: 0.8897 - val_loss: 0.3458 - val_accuracy: 0.8760
Epoch 66/192
 - 12s - loss: 0.2976 - accuracy: 0.8848 - val_loss: 0.3297 - val_accuracy: 0.8747
Epoch 67/192
 - 12s - loss: 0.3016 - accuracy: 0.8869 - val_loss: 0.3226 - val_accuracy: 0.8792
Epoch 68/192
 - 12s - loss: 0.2694 - accuracy: 0.8933 - val_loss: 0.3649 - val_accuracy: 0.8558
Epoch 69/192
 - 12s - loss: 0.2723 - accuracy: 0.8914 - val_loss: 0.3221 - val_accuracy: 0.8827
Epoch 70/192
 - 12s - loss: 0.2775 - accuracy: 0.8908 - val_loss: 0.3217 - val_accuracy: 0.8805
Epoch 71/192
 - 12s - loss: 0.2639 - accuracy: 0.8938 - val_loss: 0.3274 - val_accuracy: 0.8854
Epoch 72/192
 - 12s - loss: 0.2780 - accuracy: 0.8905 - val_loss: 0.3281 - val_accuracy: 0.8733
Epoch 73/192
 - 12s - loss: 0.2698 - accuracy: 0.8930 - val_loss: 0.3084 - val_accuracy: 0.8859
Epoch 74/192
 - 12s - loss: 0.2656 - accuracy: 0.8953 - val_loss: 0.3027 - val_accuracy: 0.8913
Epoch 75/192
 - 12s - loss: 0.2753 - accuracy: 0.8890 - val_loss: 0.3088 - val_accuracy: 0.8859
Epoch 76/192
 - 12s - loss: 0.2734 - accuracy: 0.8901 - val_loss: 0.3006 - val_accuracy: 0.8895
Epoch 77/192
 - 12s - loss: 0.2695 - accuracy: 0.8944 - val_loss: 0.3253 - val_accuracy: 0.8827
Epoch 78/192
 - 12s - loss: 0.2632 - accuracy: 0.8939 - val_loss: 0.3238 - val_accuracy: 0.8814
Epoch 79/192
 - 12s - loss: 0.2633 - accuracy: 0.8945 - val_loss: 0.3211 - val_accuracy: 0.8801
Epoch 80/192
 - 12s - loss: 0.2653 - accuracy: 0.8953 - val_loss: 0.3162 - val_accuracy: 0.8850
Epoch 81/192
 - 12s - loss: 0.2663 - accuracy: 0.8925 - val_loss: 0.3086 - val_accuracy: 0.8881
Epoch 82/192
 - 12s - loss: 0.2537 - accuracy: 0.8968 - val_loss: 0.3200 - val_accuracy: 0.8886
Epoch 83/192
 - 12s - loss: 0.2612 - accuracy: 0.8946 - val_loss: 0.3211 - val_accuracy: 0.8845
Epoch 84/192
 - 12s - loss: 0.3270 - accuracy: 0.8816 - val_loss: 0.3301 - val_accuracy: 0.8810
Epoch 85/192
 - 12s - loss: 0.2570 - accuracy: 0.8930 - val_loss: 0.3199 - val_accuracy: 0.8823
Epoch 86/192
 - 12s - loss: 0.2720 - accuracy: 0.8937 - val_loss: 0.3134 - val_accuracy: 0.8850
Epoch 87/192
 - 12s - loss: 0.2523 - accuracy: 0.8993 - val_loss: 0.3125 - val_accuracy: 0.8863
Epoch 88/192
 - 12s - loss: 0.2561 - accuracy: 0.8971 - val_loss: 0.3068 - val_accuracy: 0.8922
Epoch 89/192
 - 12s - loss: 0.2520 - accuracy: 0.9001 - val_loss: 0.3021 - val_accuracy: 0.8922
Epoch 90/192
 - 12s - loss: 0.2511 - accuracy: 0.8980 - val_loss: 0.3142 - val_accuracy: 0.8935
Epoch 91/192
 - 12s - loss: 0.2497 - accuracy: 0.8998 - val_loss: 0.3076 - val_accuracy: 0.8899
Epoch 92/192
 - 12s - loss: 0.2485 - accuracy: 0.8989 - val_loss: 0.3129 - val_accuracy: 0.8908
Epoch 93/192
 - 12s - loss: 0.2648 - accuracy: 0.8928 - val_loss: 0.2925 - val_accuracy: 0.8958
Epoch 94/192
 - 12s - loss: 0.2870 - accuracy: 0.8935 - val_loss: 0.3756 - val_accuracy: 0.8693
Epoch 95/192
 - 12s - loss: 0.3126 - accuracy: 0.8865 - val_loss: 0.3253 - val_accuracy: 0.8922
Epoch 96/192
 - 12s - loss: 0.2483 - accuracy: 0.9000 - val_loss: 0.3514 - val_accuracy: 0.8931
Epoch 97/192
 - 12s - loss: 0.2532 - accuracy: 0.8981 - val_loss: 0.3095 - val_accuracy: 0.8962
Epoch 98/192
 - 12s - loss: 0.2587 - accuracy: 0.8959 - val_loss: 0.3167 - val_accuracy: 0.8908
Epoch 99/192
 - 12s - loss: 0.2472 - accuracy: 0.9016 - val_loss: 0.3142 - val_accuracy: 0.8958
Epoch 100/192
 - 12s - loss: 0.2569 - accuracy: 0.8960 - val_loss: 0.3183 - val_accuracy: 0.8935
Epoch 101/192
 - 12s - loss: 0.2459 - accuracy: 0.9005 - val_loss: 0.3107 - val_accuracy: 0.8917
Epoch 102/192
 - 12s - loss: 0.2456 - accuracy: 0.9012 - val_loss: 0.3317 - val_accuracy: 0.8940
Epoch 103/192
 - 12s - loss: 0.2438 - accuracy: 0.9006 - val_loss: 0.3435 - val_accuracy: 0.8859
Epoch 104/192
 - 12s - loss: 0.2418 - accuracy: 0.9010 - val_loss: 0.3270 - val_accuracy: 0.8926
Epoch 105/192
 - 12s - loss: 0.2427 - accuracy: 0.9020 - val_loss: 0.3222 - val_accuracy: 0.8953
Epoch 106/192
 - 12s - loss: 0.2424 - accuracy: 0.9001 - val_loss: 0.3077 - val_accuracy: 0.8917
Epoch 107/192
 - 12s - loss: 0.2473 - accuracy: 0.9011 - val_loss: 0.3061 - val_accuracy: 0.8962
Epoch 108/192
 - 12s - loss: 0.2507 - accuracy: 0.8983 - val_loss: 0.3338 - val_accuracy: 0.8859
Epoch 109/192
 - 12s - loss: 0.2568 - accuracy: 0.8961 - val_loss: 0.3111 - val_accuracy: 0.8953
Epoch 110/192
 - 12s - loss: 0.2519 - accuracy: 0.8988 - val_loss: 0.3183 - val_accuracy: 0.8949
Epoch 111/192
 - 12s - loss: 0.2392 - accuracy: 0.9011 - val_loss: 0.3132 - val_accuracy: 0.8944
Epoch 112/192
 - 12s - loss: 0.2396 - accuracy: 0.9038 - val_loss: 0.3256 - val_accuracy: 0.8962
Epoch 113/192
 - 12s - loss: 0.2501 - accuracy: 0.8992 - val_loss: 0.2993 - val_accuracy: 0.8940
Epoch 114/192
 - 12s - loss: 0.2460 - accuracy: 0.9003 - val_loss: 0.3169 - val_accuracy: 0.8899
Epoch 115/192
 - 12s - loss: 0.2618 - accuracy: 0.8974 - val_loss: 0.3323 - val_accuracy: 0.8940
Epoch 116/192
 - 12s - loss: 0.2878 - accuracy: 0.8927 - val_loss: 0.3618 - val_accuracy: 0.8634
Epoch 117/192
 - 12s - loss: 0.2774 - accuracy: 0.8928 - val_loss: 0.3216 - val_accuracy: 0.8926
Epoch 118/192
 - 12s - loss: 0.2419 - accuracy: 0.9021 - val_loss: 0.3257 - val_accuracy: 0.8895
Epoch 119/192
 - 12s - loss: 0.2383 - accuracy: 0.9029 - val_loss: 0.3221 - val_accuracy: 0.8940
Epoch 120/192
 - 12s - loss: 0.2396 - accuracy: 0.9037 - val_loss: 0.3172 - val_accuracy: 0.8985
Epoch 121/192
 - 12s - loss: 0.2369 - accuracy: 0.9033 - val_loss: 0.3090 - val_accuracy: 0.8949
Epoch 122/192
 - 12s - loss: 0.2375 - accuracy: 0.9048 - val_loss: 0.3120 - val_accuracy: 0.8940
Epoch 123/192
 - 12s - loss: 0.2451 - accuracy: 0.8977 - val_loss: 0.3055 - val_accuracy: 0.9039
Epoch 124/192
 - 12s - loss: 0.2280 - accuracy: 0.9035 - val_loss: 0.3081 - val_accuracy: 0.9007
Epoch 125/192
 - 12s - loss: 0.2439 - accuracy: 0.9030 - val_loss: 0.3121 - val_accuracy: 0.8940
Epoch 126/192
 - 12s - loss: 0.2361 - accuracy: 0.9032 - val_loss: 0.2984 - val_accuracy: 0.8962
Epoch 127/192
 - 12s - loss: 0.2404 - accuracy: 0.9037 - val_loss: 0.3035 - val_accuracy: 0.9016
Epoch 128/192
 - 12s - loss: 0.2360 - accuracy: 0.9016 - val_loss: 0.3099 - val_accuracy: 0.8967
Epoch 129/192
 - 12s - loss: 0.2342 - accuracy: 0.9034 - val_loss: 0.3135 - val_accuracy: 0.8886
Epoch 130/192
 - 12s - loss: 0.2342 - accuracy: 0.9039 - val_loss: 0.3054 - val_accuracy: 0.8971
Epoch 131/192
 - 12s - loss: 0.2423 - accuracy: 0.9025 - val_loss: 0.3129 - val_accuracy: 0.8998
Epoch 132/192
 - 12s - loss: 0.2375 - accuracy: 0.9033 - val_loss: 0.3145 - val_accuracy: 0.8949
Epoch 133/192
 - 12s - loss: 0.2387 - accuracy: 0.9027 - val_loss: 0.3188 - val_accuracy: 0.8953
Epoch 134/192
 - 12s - loss: 0.2364 - accuracy: 0.9029 - val_loss: 0.3269 - val_accuracy: 0.8917
Epoch 135/192
 - 12s - loss: 0.2339 - accuracy: 0.9033 - val_loss: 0.3166 - val_accuracy: 0.8962
Epoch 136/192
 - 16s - loss: 0.2552 - accuracy: 0.9019 - val_loss: 0.2962 - val_accuracy: 0.9021
Epoch 137/192
 - 19s - loss: 0.2504 - accuracy: 0.8981 - val_loss: 0.3411 - val_accuracy: 0.8895
Epoch 138/192
 - 15s - loss: 0.2358 - accuracy: 0.9028 - val_loss: 0.3038 - val_accuracy: 0.8971
Epoch 139/192
 - 16s - loss: 0.2323 - accuracy: 0.9029 - val_loss: 0.3026 - val_accuracy: 0.8976
Epoch 140/192
 - 16s - loss: 0.2297 - accuracy: 0.9052 - val_loss: 0.3159 - val_accuracy: 0.8899
Epoch 141/192
 - 15s - loss: 0.2248 - accuracy: 0.9075 - val_loss: 0.3118 - val_accuracy: 0.8976
Epoch 142/192
 - 17s - loss: 0.2292 - accuracy: 0.9041 - val_loss: 0.3329 - val_accuracy: 0.8944
Epoch 143/192
 - 17s - loss: 0.2345 - accuracy: 0.9028 - val_loss: 0.3230 - val_accuracy: 0.8967
Epoch 144/192
 - 16s - loss: 0.2411 - accuracy: 0.9025 - val_loss: 0.3497 - val_accuracy: 0.8917
Epoch 145/192
 - 16s - loss: 0.2386 - accuracy: 0.9029 - val_loss: 0.3195 - val_accuracy: 0.8953
Epoch 146/192
 - 16s - loss: 0.2280 - accuracy: 0.9017 - val_loss: 0.3142 - val_accuracy: 0.8989
Epoch 147/192
 - 16s - loss: 0.2375 - accuracy: 0.9018 - val_loss: 0.3396 - val_accuracy: 0.8792
Epoch 148/192
 - 17s - loss: 0.2338 - accuracy: 0.9023 - val_loss: 0.3233 - val_accuracy: 0.8953
Epoch 149/192
 - 19s - loss: 0.2633 - accuracy: 0.8996 - val_loss: 0.3147 - val_accuracy: 0.8913
Epoch 150/192
 - 18s - loss: 0.2552 - accuracy: 0.8990 - val_loss: 0.3161 - val_accuracy: 0.8976
Epoch 151/192
 - 17s - loss: 0.2390 - accuracy: 0.9019 - val_loss: 0.3112 - val_accuracy: 0.8958
Epoch 152/192
 - 17s - loss: 0.2208 - accuracy: 0.9073 - val_loss: 0.3210 - val_accuracy: 0.8985
Epoch 153/192
 - 17s - loss: 0.2230 - accuracy: 0.9087 - val_loss: 0.3212 - val_accuracy: 0.8953
Epoch 154/192
 - 17s - loss: 0.2521 - accuracy: 0.8992 - val_loss: 0.3181 - val_accuracy: 0.8985
Epoch 155/192
 - 16s - loss: 0.2314 - accuracy: 0.9055 - val_loss: 0.3423 - val_accuracy: 0.9034
Epoch 156/192
 - 17s - loss: 0.2264 - accuracy: 0.9080 - val_loss: 0.3226 - val_accuracy: 0.9007
Epoch 157/192
 - 17s - loss: 0.2309 - accuracy: 0.9047 - val_loss: 0.3106 - val_accuracy: 0.8994
Epoch 158/192
 - 16s - loss: 0.2323 - accuracy: 0.9033 - val_loss: 0.3280 - val_accuracy: 0.9003
Epoch 159/192
 - 16s - loss: 0.2251 - accuracy: 0.9048 - val_loss: 0.3308 - val_accuracy: 0.8926
Epoch 160/192
 - 17s - loss: 0.2348 - accuracy: 0.9041 - val_loss: 0.3262 - val_accuracy: 0.8922
Epoch 161/192
 - 16s - loss: 0.2226 - accuracy: 0.9061 - val_loss: 0.3176 - val_accuracy: 0.8976
Epoch 162/192
 - 16s - loss: 0.2477 - accuracy: 0.9017 - val_loss: 0.3353 - val_accuracy: 0.8989
Epoch 163/192
 - 17s - loss: 0.2340 - accuracy: 0.9033 - val_loss: 0.3097 - val_accuracy: 0.9003
Epoch 164/192
 - 13s - loss: 0.2277 - accuracy: 0.9061 - val_loss: 0.3224 - val_accuracy: 0.9007
Epoch 165/192
 - 13s - loss: 0.2220 - accuracy: 0.9075 - val_loss: 0.3374 - val_accuracy: 0.9034
Epoch 166/192
 - 13s - loss: 0.2237 - accuracy: 0.9071 - val_loss: 0.3496 - val_accuracy: 0.8985
Epoch 167/192
 - 12s - loss: 0.3304 - accuracy: 0.8743 - val_loss: 0.3835 - val_accuracy: 0.8832
Epoch 168/192
 - 13s - loss: 0.2415 - accuracy: 0.9032 - val_loss: 0.3230 - val_accuracy: 0.8967
Epoch 169/192
 - 13s - loss: 0.2480 - accuracy: 0.9023 - val_loss: 0.4160 - val_accuracy: 0.8688
Epoch 170/192
 - 15s - loss: 0.2478 - accuracy: 0.9008 - val_loss: 0.3211 - val_accuracy: 0.8953
Epoch 171/192
 - 12s - loss: 0.2357 - accuracy: 0.9050 - val_loss: 0.3233 - val_accuracy: 0.8971
Epoch 172/192
 - 12s - loss: 0.2297 - accuracy: 0.9065 - val_loss: 0.3151 - val_accuracy: 0.8976
Epoch 173/192
 - 12s - loss: 0.2337 - accuracy: 0.9075 - val_loss: 0.3397 - val_accuracy: 0.8890
Epoch 174/192
 - 12s - loss: 0.2251 - accuracy: 0.9092 - val_loss: 0.3194 - val_accuracy: 0.9030
Epoch 175/192
 - 12s - loss: 0.2231 - accuracy: 0.9072 - val_loss: 0.3265 - val_accuracy: 0.8944
Epoch 176/192
 - 12s - loss: 0.2275 - accuracy: 0.9073 - val_loss: 0.3365 - val_accuracy: 0.8994
Epoch 177/192
 - 12s - loss: 0.2294 - accuracy: 0.9069 - val_loss: 0.3072 - val_accuracy: 0.8976
Epoch 178/192
 - 12s - loss: 0.2226 - accuracy: 0.9090 - val_loss: 0.3238 - val_accuracy: 0.8971
Epoch 179/192
 - 12s - loss: 0.2204 - accuracy: 0.9088 - val_loss: 0.3332 - val_accuracy: 0.9003
Epoch 180/192
 - 12s - loss: 0.2296 - accuracy: 0.9057 - val_loss: 0.3091 - val_accuracy: 0.9016
Epoch 181/192
 - 12s - loss: 0.2233 - accuracy: 0.9060 - val_loss: 0.3149 - val_accuracy: 0.9025
Epoch 182/192
 - 12s - loss: 0.2301 - accuracy: 0.9055 - val_loss: 0.3237 - val_accuracy: 0.9012
Epoch 183/192
 - 12s - loss: 0.2192 - accuracy: 0.9100 - val_loss: 0.3252 - val_accuracy: 0.8953
Epoch 184/192
 - 12s - loss: 0.3397 - accuracy: 0.9014 - val_loss: 0.3244 - val_accuracy: 0.8940
Epoch 185/192
 - 12s - loss: 0.2265 - accuracy: 0.9064 - val_loss: 0.3347 - val_accuracy: 0.9039
Epoch 186/192
 - 12s - loss: 0.2212 - accuracy: 0.9077 - val_loss: 0.3426 - val_accuracy: 0.8989
Epoch 187/192
 - 12s - loss: 0.2315 - accuracy: 0.9073 - val_loss: 0.3207 - val_accuracy: 0.9043
Epoch 188/192
 - 12s - loss: 0.2208 - accuracy: 0.9089 - val_loss: 0.3219 - val_accuracy: 0.9048
Epoch 189/192
 - 14s - loss: 0.2150 - accuracy: 0.9103 - val_loss: 0.3304 - val_accuracy: 0.8998
Epoch 190/192
 - 12s - loss: 0.2183 - accuracy: 0.9091 - val_loss: 0.3238 - val_accuracy: 0.9025
Epoch 191/192
 - 12s - loss: 0.2659 - accuracy: 0.8999 - val_loss: 0.3617 - val_accuracy: 0.8895
Epoch 192/192
 - 12s - loss: 0.2320 - accuracy: 0.9051 - val_loss: 0.3405 - val_accuracy: 0.9066

Fit: epochs = 192, batch_size = 32, verbose = 2, shuffle=False, validation_split = 0.20

Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 11, 500)           1000      
_________________________________________________________________
activation_1 (Activation)    (None, 11, 500)           0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 5500)              0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 5500)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 400)               2200400   
_________________________________________________________________
dense_2 (Dense)              (None, 300)               120300    
_________________________________________________________________
dense_3 (Dense)              (None, 200)               60200     
_________________________________________________________________
dense_4 (Dense)              (None, 100)               20100     
_________________________________________________________________
dense_5 (Dense)              (None, 4)                 404       
_________________________________________________________________
activation_2 (Activation)    (None, 4)                 0         
=================================================================
Total params: 2,402,404
Trainable params: 2,402,404
Non-trainable params: 0
_________________________________________________________________
None

Accuracy Train: 92.01%
Accuracy Test: 85.05%
Loss Train: 0.22
Loss Test: 2.65
Numero dati esaminati: 1712
True Positive 1456
False Positive 256
