Dataset used: ../../datasets/full_dataset.csv 

   Temperature  Humidity  Sound  ...     Z2  Classification  Feedback
0           32        95      1  ... -15596             100     Happy
1           32        86      1  ... -15628             100     Happy
2           -1        -1      1  ... -15612             100     Happy
3           -1        -1     -1  ...     -1             100     Happy
4           32        75      1  ... -15720             100     Happy

[5 rows x 12 columns]

Objservations: 8560
Reshaping:  ((6848, 11), (6848, 4), (1712, 11), (1712, 4))  -> ((6848, 11, 1), (6848, 4), (1712, 11, 1), (1712, 4))

Layers:

{'name': 'conv1d_1', 'trainable': True, 'batch_input_shape': (None, 11, 1), 'dtype': 'float32', 'filters': 512, 'kernel_size': (1,), 'strides': (1,), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1,), 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'activation_1', 'trainable': True, 'dtype': 'float32', 'activation': 'relu'} 

{'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'} 

{'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.4, 'noise_shape': None, 'seed': None} 

{'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} 

{'name': 'activation_2', 'trainable': True, 'dtype': 'float32', 'activation': 'softmax'} 

Compile: loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

Start computation...

Train on 5478 samples, validate on 1370 samples
Epoch 1/192
 - 5s - loss: 0.9715 - accuracy: 0.6165 - val_loss: 0.8459 - val_accuracy: 0.6715
Epoch 2/192
 - 5s - loss: 0.8022 - accuracy: 0.6762 - val_loss: 0.7632 - val_accuracy: 0.6985
Epoch 3/192
 - 4s - loss: 0.7435 - accuracy: 0.6997 - val_loss: 0.7189 - val_accuracy: 0.7212
Epoch 4/192
 - 4s - loss: 0.7026 - accuracy: 0.7203 - val_loss: 0.6902 - val_accuracy: 0.7263
Epoch 5/192
 - 4s - loss: 0.6707 - accuracy: 0.7342 - val_loss: 0.6685 - val_accuracy: 0.7358
Epoch 6/192
 - 4s - loss: 0.6365 - accuracy: 0.7488 - val_loss: 0.6422 - val_accuracy: 0.7416
Epoch 7/192
 - 4s - loss: 0.6142 - accuracy: 0.7585 - val_loss: 0.6178 - val_accuracy: 0.7526
Epoch 8/192
 - 4s - loss: 0.5953 - accuracy: 0.7649 - val_loss: 0.6051 - val_accuracy: 0.7591
Epoch 9/192
 - 4s - loss: 0.5743 - accuracy: 0.7711 - val_loss: 0.5929 - val_accuracy: 0.7555
Epoch 10/192
 - 4s - loss: 0.5583 - accuracy: 0.7758 - val_loss: 0.5841 - val_accuracy: 0.7613
Epoch 11/192
 - 4s - loss: 0.5482 - accuracy: 0.7795 - val_loss: 0.5673 - val_accuracy: 0.7591
Epoch 12/192
 - 4s - loss: 0.5266 - accuracy: 0.7879 - val_loss: 0.5732 - val_accuracy: 0.7591
Epoch 13/192
 - 4s - loss: 0.5200 - accuracy: 0.7906 - val_loss: 0.5556 - val_accuracy: 0.7766
Epoch 14/192
 - 4s - loss: 0.5024 - accuracy: 0.7937 - val_loss: 0.5536 - val_accuracy: 0.7723
Epoch 15/192
 - 4s - loss: 0.4920 - accuracy: 0.8032 - val_loss: 0.5510 - val_accuracy: 0.7810
Epoch 16/192
 - 4s - loss: 0.4786 - accuracy: 0.8050 - val_loss: 0.5507 - val_accuracy: 0.7818
Epoch 17/192
 - 4s - loss: 0.4739 - accuracy: 0.8052 - val_loss: 0.5422 - val_accuracy: 0.7869
Epoch 18/192
 - 4s - loss: 0.4660 - accuracy: 0.8087 - val_loss: 0.5349 - val_accuracy: 0.7993
Epoch 19/192
 - 4s - loss: 0.4589 - accuracy: 0.8127 - val_loss: 0.5258 - val_accuracy: 0.8015
Epoch 20/192
 - 4s - loss: 0.4507 - accuracy: 0.8151 - val_loss: 0.5240 - val_accuracy: 0.8022
Epoch 21/192
 - 4s - loss: 0.4420 - accuracy: 0.8217 - val_loss: 0.5284 - val_accuracy: 0.7978
Epoch 22/192
 - 5s - loss: 0.4413 - accuracy: 0.8193 - val_loss: 0.5242 - val_accuracy: 0.8073
Epoch 23/192
 - 4s - loss: 0.4347 - accuracy: 0.8235 - val_loss: 0.5348 - val_accuracy: 0.7978
Epoch 24/192
 - 4s - loss: 0.4267 - accuracy: 0.8257 - val_loss: 0.5186 - val_accuracy: 0.8131
Epoch 25/192
 - 4s - loss: 0.4136 - accuracy: 0.8271 - val_loss: 0.5265 - val_accuracy: 0.7971
Epoch 26/192
 - 4s - loss: 0.4114 - accuracy: 0.8300 - val_loss: 0.5206 - val_accuracy: 0.8080
Epoch 27/192
 - 5s - loss: 0.4026 - accuracy: 0.8379 - val_loss: 0.5141 - val_accuracy: 0.8036
Epoch 28/192
 - 5s - loss: 0.3999 - accuracy: 0.8372 - val_loss: 0.5231 - val_accuracy: 0.8088
Epoch 29/192
 - 5s - loss: 0.3962 - accuracy: 0.8361 - val_loss: 0.5303 - val_accuracy: 0.7964
Epoch 30/192
 - 5s - loss: 0.3908 - accuracy: 0.8392 - val_loss: 0.5236 - val_accuracy: 0.8044
Epoch 31/192
 - 5s - loss: 0.3775 - accuracy: 0.8425 - val_loss: 0.5376 - val_accuracy: 0.8007
Epoch 32/192
 - 5s - loss: 0.3811 - accuracy: 0.8454 - val_loss: 0.5216 - val_accuracy: 0.8051
Epoch 33/192
 - 5s - loss: 0.3744 - accuracy: 0.8415 - val_loss: 0.5081 - val_accuracy: 0.8139
Epoch 34/192
 - 4s - loss: 0.3726 - accuracy: 0.8456 - val_loss: 0.5118 - val_accuracy: 0.8153
Epoch 35/192
 - 4s - loss: 0.3712 - accuracy: 0.8509 - val_loss: 0.5310 - val_accuracy: 0.7978
Epoch 36/192
 - 4s - loss: 0.3711 - accuracy: 0.8457 - val_loss: 0.5223 - val_accuracy: 0.8102
Epoch 37/192
 - 5s - loss: 0.3587 - accuracy: 0.8530 - val_loss: 0.5052 - val_accuracy: 0.8175
Epoch 38/192
 - 5s - loss: 0.3585 - accuracy: 0.8541 - val_loss: 0.5202 - val_accuracy: 0.8168
Epoch 39/192
 - 4s - loss: 0.3557 - accuracy: 0.8523 - val_loss: 0.5319 - val_accuracy: 0.8168
Epoch 40/192
 - 4s - loss: 0.3501 - accuracy: 0.8562 - val_loss: 0.5062 - val_accuracy: 0.8248
Epoch 41/192
 - 4s - loss: 0.3408 - accuracy: 0.8607 - val_loss: 0.5337 - val_accuracy: 0.8139
Epoch 42/192
 - 4s - loss: 0.3377 - accuracy: 0.8591 - val_loss: 0.5024 - val_accuracy: 0.8387
Epoch 43/192
 - 4s - loss: 0.3415 - accuracy: 0.8591 - val_loss: 0.5150 - val_accuracy: 0.8175
Epoch 44/192
 - 4s - loss: 0.3348 - accuracy: 0.8600 - val_loss: 0.5393 - val_accuracy: 0.8234
Epoch 45/192
 - 4s - loss: 0.3350 - accuracy: 0.8627 - val_loss: 0.5238 - val_accuracy: 0.8321
Epoch 46/192
 - 4s - loss: 0.3254 - accuracy: 0.8675 - val_loss: 0.5215 - val_accuracy: 0.8204
Epoch 47/192
 - 4s - loss: 0.3314 - accuracy: 0.8644 - val_loss: 0.5212 - val_accuracy: 0.8197
Epoch 48/192
 - 5s - loss: 0.3280 - accuracy: 0.8644 - val_loss: 0.5096 - val_accuracy: 0.8197
Epoch 49/192
 - 5s - loss: 0.3214 - accuracy: 0.8687 - val_loss: 0.5095 - val_accuracy: 0.8219
Epoch 50/192
 - 4s - loss: 0.3204 - accuracy: 0.8695 - val_loss: 0.5072 - val_accuracy: 0.8372
Epoch 51/192
 - 5s - loss: 0.3147 - accuracy: 0.8748 - val_loss: 0.5039 - val_accuracy: 0.8226
Epoch 52/192
 - 5s - loss: 0.3109 - accuracy: 0.8735 - val_loss: 0.5159 - val_accuracy: 0.8285
Epoch 53/192
 - 4s - loss: 0.3138 - accuracy: 0.8698 - val_loss: 0.4877 - val_accuracy: 0.8394
Epoch 54/192
 - 4s - loss: 0.3095 - accuracy: 0.8715 - val_loss: 0.5141 - val_accuracy: 0.8219
Epoch 55/192
 - 4s - loss: 0.3101 - accuracy: 0.8748 - val_loss: 0.5239 - val_accuracy: 0.8234
Epoch 56/192
 - 4s - loss: 0.3039 - accuracy: 0.8748 - val_loss: 0.5070 - val_accuracy: 0.8248
Epoch 57/192
 - 4s - loss: 0.3065 - accuracy: 0.8762 - val_loss: 0.5229 - val_accuracy: 0.8277
Epoch 58/192
 - 5s - loss: 0.3003 - accuracy: 0.8792 - val_loss: 0.5097 - val_accuracy: 0.8358
Epoch 59/192
 - 5s - loss: 0.2942 - accuracy: 0.8788 - val_loss: 0.5182 - val_accuracy: 0.8343
Epoch 60/192
 - 5s - loss: 0.2947 - accuracy: 0.8760 - val_loss: 0.4996 - val_accuracy: 0.8431
Epoch 61/192
 - 5s - loss: 0.2883 - accuracy: 0.8813 - val_loss: 0.4863 - val_accuracy: 0.8460
Epoch 62/192
 - 5s - loss: 0.2892 - accuracy: 0.8812 - val_loss: 0.5080 - val_accuracy: 0.8248
Epoch 63/192
 - 5s - loss: 0.2861 - accuracy: 0.8866 - val_loss: 0.5111 - val_accuracy: 0.8314
Epoch 64/192
 - 5s - loss: 0.2797 - accuracy: 0.8883 - val_loss: 0.5199 - val_accuracy: 0.8336
Epoch 65/192
 - 5s - loss: 0.2804 - accuracy: 0.8810 - val_loss: 0.5126 - val_accuracy: 0.8387
Epoch 66/192
 - 6s - loss: 0.2891 - accuracy: 0.8823 - val_loss: 0.4886 - val_accuracy: 0.8496
Epoch 67/192
 - 6s - loss: 0.2807 - accuracy: 0.8828 - val_loss: 0.5094 - val_accuracy: 0.8372
Epoch 68/192
 - 6s - loss: 0.2762 - accuracy: 0.8863 - val_loss: 0.5147 - val_accuracy: 0.8314
Epoch 69/192
 - 5s - loss: 0.2811 - accuracy: 0.8792 - val_loss: 0.5106 - val_accuracy: 0.8438
Epoch 70/192
 - 5s - loss: 0.2705 - accuracy: 0.8910 - val_loss: 0.4907 - val_accuracy: 0.8445
Epoch 71/192
 - 5s - loss: 0.2764 - accuracy: 0.8865 - val_loss: 0.4874 - val_accuracy: 0.8380
Epoch 72/192
 - 5s - loss: 0.2732 - accuracy: 0.8868 - val_loss: 0.4977 - val_accuracy: 0.8365
Epoch 73/192
 - 5s - loss: 0.2683 - accuracy: 0.8897 - val_loss: 0.4942 - val_accuracy: 0.8423
Epoch 74/192
 - 5s - loss: 0.2676 - accuracy: 0.8877 - val_loss: 0.4941 - val_accuracy: 0.8504
Epoch 75/192
 - 5s - loss: 0.2654 - accuracy: 0.8901 - val_loss: 0.4832 - val_accuracy: 0.8445
Epoch 76/192
 - 5s - loss: 0.2656 - accuracy: 0.8897 - val_loss: 0.4829 - val_accuracy: 0.8526
Epoch 77/192
 - 6s - loss: 0.2656 - accuracy: 0.8903 - val_loss: 0.4915 - val_accuracy: 0.8416
Epoch 78/192
 - 5s - loss: 0.2633 - accuracy: 0.8908 - val_loss: 0.4805 - val_accuracy: 0.8445
Epoch 79/192
 - 6s - loss: 0.2581 - accuracy: 0.8936 - val_loss: 0.4810 - val_accuracy: 0.8518
Epoch 80/192
 - 6s - loss: 0.2581 - accuracy: 0.8947 - val_loss: 0.4824 - val_accuracy: 0.8445
Epoch 81/192
 - 6s - loss: 0.2620 - accuracy: 0.8901 - val_loss: 0.4734 - val_accuracy: 0.8453
Epoch 82/192
 - 6s - loss: 0.2493 - accuracy: 0.8970 - val_loss: 0.4908 - val_accuracy: 0.8467
Epoch 83/192
 - 5s - loss: 0.2579 - accuracy: 0.8938 - val_loss: 0.4670 - val_accuracy: 0.8540
Epoch 84/192
 - 4s - loss: 0.2530 - accuracy: 0.8943 - val_loss: 0.4778 - val_accuracy: 0.8460
Epoch 85/192
 - 5s - loss: 0.2536 - accuracy: 0.8941 - val_loss: 0.4828 - val_accuracy: 0.8533
Epoch 86/192
 - 5s - loss: 0.2486 - accuracy: 0.8945 - val_loss: 0.4774 - val_accuracy: 0.8518
Epoch 87/192
 - 5s - loss: 0.2513 - accuracy: 0.9003 - val_loss: 0.4640 - val_accuracy: 0.8577
Epoch 88/192
 - 6s - loss: 0.2494 - accuracy: 0.8978 - val_loss: 0.4814 - val_accuracy: 0.8489
Epoch 89/192
 - 6s - loss: 0.2491 - accuracy: 0.8967 - val_loss: 0.4708 - val_accuracy: 0.8518
Epoch 90/192
 - 5s - loss: 0.2411 - accuracy: 0.9031 - val_loss: 0.4789 - val_accuracy: 0.8489
Epoch 91/192
 - 5s - loss: 0.2367 - accuracy: 0.9000 - val_loss: 0.4715 - val_accuracy: 0.8467
Epoch 92/192
 - 5s - loss: 0.2464 - accuracy: 0.8970 - val_loss: 0.4668 - val_accuracy: 0.8533
Epoch 93/192
 - 5s - loss: 0.2372 - accuracy: 0.9016 - val_loss: 0.4740 - val_accuracy: 0.8606
Epoch 94/192
 - 5s - loss: 0.2367 - accuracy: 0.9043 - val_loss: 0.4668 - val_accuracy: 0.8555
Epoch 95/192
 - 5s - loss: 0.2328 - accuracy: 0.9056 - val_loss: 0.4500 - val_accuracy: 0.8569
Epoch 96/192
 - 5s - loss: 0.2324 - accuracy: 0.9078 - val_loss: 0.4826 - val_accuracy: 0.8533
Epoch 97/192
 - 5s - loss: 0.2360 - accuracy: 0.8996 - val_loss: 0.4676 - val_accuracy: 0.8635
Epoch 98/192
 - 5s - loss: 0.2303 - accuracy: 0.9064 - val_loss: 0.4497 - val_accuracy: 0.8635
Epoch 99/192
 - 5s - loss: 0.2340 - accuracy: 0.9036 - val_loss: 0.4780 - val_accuracy: 0.8569
Epoch 100/192
 - 5s - loss: 0.2325 - accuracy: 0.9016 - val_loss: 0.4890 - val_accuracy: 0.8679
Epoch 101/192
 - 4s - loss: 0.2339 - accuracy: 0.9040 - val_loss: 0.4713 - val_accuracy: 0.8613
Epoch 102/192
 - 4s - loss: 0.2250 - accuracy: 0.9040 - val_loss: 0.4826 - val_accuracy: 0.8584
Epoch 103/192
 - 4s - loss: 0.2258 - accuracy: 0.9089 - val_loss: 0.4934 - val_accuracy: 0.8540
Epoch 104/192
 - 4s - loss: 0.2229 - accuracy: 0.9076 - val_loss: 0.4864 - val_accuracy: 0.8496
Epoch 105/192
 - 5s - loss: 0.2239 - accuracy: 0.9073 - val_loss: 0.4940 - val_accuracy: 0.8504
Epoch 106/192
 - 4s - loss: 0.2281 - accuracy: 0.9060 - val_loss: 0.4665 - val_accuracy: 0.8664
Epoch 107/192
 - 4s - loss: 0.2273 - accuracy: 0.9069 - val_loss: 0.4807 - val_accuracy: 0.8547
Epoch 108/192
 - 4s - loss: 0.2231 - accuracy: 0.9093 - val_loss: 0.4714 - val_accuracy: 0.8599
Epoch 109/192
 - 4s - loss: 0.2169 - accuracy: 0.9085 - val_loss: 0.4662 - val_accuracy: 0.8584
Epoch 110/192
 - 4s - loss: 0.2217 - accuracy: 0.9062 - val_loss: 0.5122 - val_accuracy: 0.8599
Epoch 111/192
 - 4s - loss: 0.2229 - accuracy: 0.9093 - val_loss: 0.4836 - val_accuracy: 0.8518
Epoch 112/192
 - 4s - loss: 0.2251 - accuracy: 0.9053 - val_loss: 0.4805 - val_accuracy: 0.8657
Epoch 113/192
 - 4s - loss: 0.2130 - accuracy: 0.9098 - val_loss: 0.4771 - val_accuracy: 0.8642
Epoch 114/192
 - 5s - loss: 0.2182 - accuracy: 0.9062 - val_loss: 0.5148 - val_accuracy: 0.8540
Epoch 115/192
 - 5s - loss: 0.2198 - accuracy: 0.9111 - val_loss: 0.5253 - val_accuracy: 0.8511
Epoch 116/192
 - 5s - loss: 0.2165 - accuracy: 0.9107 - val_loss: 0.5073 - val_accuracy: 0.8562
Epoch 117/192
 - 5s - loss: 0.2147 - accuracy: 0.9074 - val_loss: 0.5048 - val_accuracy: 0.8569
Epoch 118/192
 - 4s - loss: 0.2081 - accuracy: 0.9093 - val_loss: 0.5070 - val_accuracy: 0.8620
Epoch 119/192
 - 4s - loss: 0.2065 - accuracy: 0.9155 - val_loss: 0.5229 - val_accuracy: 0.8555
Epoch 120/192
 - 4s - loss: 0.2099 - accuracy: 0.9157 - val_loss: 0.4874 - val_accuracy: 0.8613
Epoch 121/192
 - 4s - loss: 0.2170 - accuracy: 0.9096 - val_loss: 0.4930 - val_accuracy: 0.8526
Epoch 122/192
 - 4s - loss: 0.2072 - accuracy: 0.9171 - val_loss: 0.4859 - val_accuracy: 0.8584
Epoch 123/192
 - 4s - loss: 0.2009 - accuracy: 0.9151 - val_loss: 0.5051 - val_accuracy: 0.8577
Epoch 124/192
 - 5s - loss: 0.2024 - accuracy: 0.9188 - val_loss: 0.5087 - val_accuracy: 0.8599
Epoch 125/192
 - 5s - loss: 0.2023 - accuracy: 0.9168 - val_loss: 0.5108 - val_accuracy: 0.8599
Epoch 126/192
 - 5s - loss: 0.2147 - accuracy: 0.9127 - val_loss: 0.5138 - val_accuracy: 0.8628
Epoch 127/192
 - 5s - loss: 0.2039 - accuracy: 0.9168 - val_loss: 0.5097 - val_accuracy: 0.8584
Epoch 128/192
 - 5s - loss: 0.2064 - accuracy: 0.9089 - val_loss: 0.5127 - val_accuracy: 0.8613
Epoch 129/192
 - 5s - loss: 0.2023 - accuracy: 0.9149 - val_loss: 0.5275 - val_accuracy: 0.8562
Epoch 130/192
 - 4s - loss: 0.2045 - accuracy: 0.9160 - val_loss: 0.5090 - val_accuracy: 0.8599
Epoch 131/192
 - 4s - loss: 0.2038 - accuracy: 0.9160 - val_loss: 0.5162 - val_accuracy: 0.8533
Epoch 132/192
 - 5s - loss: 0.2055 - accuracy: 0.9122 - val_loss: 0.5191 - val_accuracy: 0.8606
Epoch 133/192
 - 4s - loss: 0.2104 - accuracy: 0.9135 - val_loss: 0.5044 - val_accuracy: 0.8606
Epoch 134/192
 - 4s - loss: 0.2063 - accuracy: 0.9133 - val_loss: 0.5091 - val_accuracy: 0.8620
Epoch 135/192
 - 4s - loss: 0.1949 - accuracy: 0.9175 - val_loss: 0.5213 - val_accuracy: 0.8496
Epoch 136/192
 - 4s - loss: 0.1969 - accuracy: 0.9166 - val_loss: 0.5308 - val_accuracy: 0.8599
Epoch 137/192
 - 4s - loss: 0.1954 - accuracy: 0.9197 - val_loss: 0.5137 - val_accuracy: 0.8686
Epoch 138/192
 - 4s - loss: 0.1944 - accuracy: 0.9166 - val_loss: 0.5254 - val_accuracy: 0.8569
Epoch 139/192
 - 5s - loss: 0.1920 - accuracy: 0.9182 - val_loss: 0.5446 - val_accuracy: 0.8533
Epoch 140/192
 - 5s - loss: 0.2029 - accuracy: 0.9157 - val_loss: 0.5372 - val_accuracy: 0.8606
Epoch 141/192
 - 4s - loss: 0.1998 - accuracy: 0.9138 - val_loss: 0.5244 - val_accuracy: 0.8599
Epoch 142/192
 - 4s - loss: 0.1951 - accuracy: 0.9199 - val_loss: 0.5406 - val_accuracy: 0.8496
Epoch 143/192
 - 4s - loss: 0.1956 - accuracy: 0.9213 - val_loss: 0.5047 - val_accuracy: 0.8715
Epoch 144/192
 - 4s - loss: 0.1952 - accuracy: 0.9199 - val_loss: 0.5282 - val_accuracy: 0.8679
Epoch 145/192
 - 5s - loss: 0.1950 - accuracy: 0.9179 - val_loss: 0.5220 - val_accuracy: 0.8730
Epoch 146/192
 - 4s - loss: 0.1903 - accuracy: 0.9202 - val_loss: 0.5500 - val_accuracy: 0.8591
Epoch 147/192
 - 4s - loss: 0.1904 - accuracy: 0.9224 - val_loss: 0.5061 - val_accuracy: 0.8759
Epoch 148/192
 - 4s - loss: 0.1974 - accuracy: 0.9177 - val_loss: 0.5295 - val_accuracy: 0.8657
Epoch 149/192
 - 4s - loss: 0.1912 - accuracy: 0.9215 - val_loss: 0.5426 - val_accuracy: 0.8533
Epoch 150/192
 - 4s - loss: 0.1935 - accuracy: 0.9177 - val_loss: 0.5187 - val_accuracy: 0.8715
Epoch 151/192
 - 4s - loss: 0.1876 - accuracy: 0.9213 - val_loss: 0.5192 - val_accuracy: 0.8664
Epoch 152/192
 - 4s - loss: 0.1842 - accuracy: 0.9226 - val_loss: 0.5270 - val_accuracy: 0.8730
Epoch 153/192
 - 4s - loss: 0.1906 - accuracy: 0.9160 - val_loss: 0.5382 - val_accuracy: 0.8591
Epoch 154/192
 - 5s - loss: 0.1919 - accuracy: 0.9182 - val_loss: 0.5221 - val_accuracy: 0.8701
Epoch 155/192
 - 4s - loss: 0.1900 - accuracy: 0.9200 - val_loss: 0.5190 - val_accuracy: 0.8766
Epoch 156/192
 - 4s - loss: 0.1917 - accuracy: 0.9180 - val_loss: 0.5270 - val_accuracy: 0.8642
Epoch 157/192
 - 4s - loss: 0.1818 - accuracy: 0.9248 - val_loss: 0.5306 - val_accuracy: 0.8686
Epoch 158/192
 - 4s - loss: 0.1889 - accuracy: 0.9189 - val_loss: 0.5408 - val_accuracy: 0.8599
Epoch 159/192
 - 5s - loss: 0.1829 - accuracy: 0.9186 - val_loss: 0.5310 - val_accuracy: 0.8635
Epoch 160/192
 - 5s - loss: 0.1842 - accuracy: 0.9211 - val_loss: 0.5188 - val_accuracy: 0.8672
Epoch 161/192
 - 5s - loss: 0.1783 - accuracy: 0.9261 - val_loss: 0.5162 - val_accuracy: 0.8679
Epoch 162/192
 - 4s - loss: 0.1866 - accuracy: 0.9202 - val_loss: 0.5402 - val_accuracy: 0.8708
Epoch 163/192
 - 5s - loss: 0.1887 - accuracy: 0.9241 - val_loss: 0.5327 - val_accuracy: 0.8664
Epoch 164/192
 - 4s - loss: 0.1819 - accuracy: 0.9237 - val_loss: 0.5238 - val_accuracy: 0.8679
Epoch 165/192
 - 5s - loss: 0.1814 - accuracy: 0.9264 - val_loss: 0.5134 - val_accuracy: 0.8781
Epoch 166/192
 - 6s - loss: 0.1837 - accuracy: 0.9235 - val_loss: 0.5309 - val_accuracy: 0.8672
Epoch 167/192
 - 5s - loss: 0.1795 - accuracy: 0.9235 - val_loss: 0.5065 - val_accuracy: 0.8723
Epoch 168/192
 - 4s - loss: 0.1803 - accuracy: 0.9219 - val_loss: 0.5358 - val_accuracy: 0.8737
Epoch 169/192
 - 4s - loss: 0.1830 - accuracy: 0.9246 - val_loss: 0.5141 - val_accuracy: 0.8737
Epoch 170/192
 - 5s - loss: 0.1789 - accuracy: 0.9235 - val_loss: 0.5454 - val_accuracy: 0.8774
Epoch 171/192
 - 5s - loss: 0.1835 - accuracy: 0.9208 - val_loss: 0.5297 - val_accuracy: 0.8774
Epoch 172/192
 - 5s - loss: 0.1788 - accuracy: 0.9261 - val_loss: 0.5346 - val_accuracy: 0.8774
Epoch 173/192
 - 5s - loss: 0.1781 - accuracy: 0.9261 - val_loss: 0.5511 - val_accuracy: 0.8664
Epoch 174/192
 - 5s - loss: 0.1728 - accuracy: 0.9264 - val_loss: 0.5426 - val_accuracy: 0.8679
Epoch 175/192
 - 4s - loss: 0.1781 - accuracy: 0.9272 - val_loss: 0.5672 - val_accuracy: 0.8657
Epoch 176/192
 - 4s - loss: 0.1773 - accuracy: 0.9242 - val_loss: 0.5232 - val_accuracy: 0.8745
Epoch 177/192
 - 4s - loss: 0.1676 - accuracy: 0.9306 - val_loss: 0.5300 - val_accuracy: 0.8730
Epoch 178/192
 - 4s - loss: 0.1739 - accuracy: 0.9290 - val_loss: 0.5273 - val_accuracy: 0.8781
Epoch 179/192
 - 4s - loss: 0.1787 - accuracy: 0.9226 - val_loss: 0.5209 - val_accuracy: 0.8788
Epoch 180/192
 - 4s - loss: 0.1830 - accuracy: 0.9228 - val_loss: 0.5131 - val_accuracy: 0.8723
Epoch 181/192
 - 5s - loss: 0.1758 - accuracy: 0.9279 - val_loss: 0.5034 - val_accuracy: 0.8883
Epoch 182/192
 - 6s - loss: 0.1815 - accuracy: 0.9215 - val_loss: 0.5241 - val_accuracy: 0.8847
Epoch 183/192
 - 5s - loss: 0.1739 - accuracy: 0.9255 - val_loss: 0.5109 - val_accuracy: 0.8803
Epoch 184/192
 - 5s - loss: 0.1721 - accuracy: 0.9275 - val_loss: 0.5218 - val_accuracy: 0.8752
Epoch 185/192
 - 5s - loss: 0.1721 - accuracy: 0.9299 - val_loss: 0.5220 - val_accuracy: 0.8825
Epoch 186/192
 - 5s - loss: 0.1761 - accuracy: 0.9242 - val_loss: 0.5114 - val_accuracy: 0.8818
Epoch 187/192
 - 6s - loss: 0.1711 - accuracy: 0.9253 - val_loss: 0.5358 - val_accuracy: 0.8788
Epoch 188/192
 - 5s - loss: 0.1759 - accuracy: 0.9272 - val_loss: 0.5120 - val_accuracy: 0.8869
Epoch 189/192
 - 4s - loss: 0.1675 - accuracy: 0.9294 - val_loss: 0.5168 - val_accuracy: 0.8832
Epoch 190/192
 - 5s - loss: 0.1693 - accuracy: 0.9303 - val_loss: 0.5302 - val_accuracy: 0.8810
Epoch 191/192
 - 5s - loss: 0.1709 - accuracy: 0.9286 - val_loss: 0.5251 - val_accuracy: 0.8759
Epoch 192/192
 - 4s - loss: 0.1716 - accuracy: 0.9281 - val_loss: 0.5316 - val_accuracy: 0.8715

Fit: epochs = 192, batch_size = 32, verbose = 2, shuffle=False, validation_split = 0.20

Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 11, 512)           1024      
_________________________________________________________________
activation_1 (Activation)    (None, 11, 512)           0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 5632)              0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 5632)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 200)               1126600   
_________________________________________________________________
dense_2 (Dense)              (None, 100)               20100     
_________________________________________________________________
dense_3 (Dense)              (None, 4)                 404       
_________________________________________________________________
activation_2 (Activation)    (None, 4)                 0         
=================================================================
Total params: 1,148,128
Trainable params: 1,148,128
Non-trainable params: 0
_________________________________________________________________
None

Accuracy Train: 92.38%
Accuracy Test: 87.79%
Loss Train: 0.23
Loss Test: 0.46
Numero dati esaminati: 1712
True Positive 1503
False Positive 209
